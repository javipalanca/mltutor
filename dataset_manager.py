"""
Este m√≥dulo contiene funciones para la carga y gesti√≥n de datos en la aplicaci√≥n MLTutor.
Incluye funciones para cargar conjuntos de datos integrados, cargar archivos CSV y procesar datos.
"""

import pandas as pd
import numpy as np
import streamlit as st
import os
from sklearn.datasets import load_iris, load_wine, load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
from additional_datasets import load_additional_dataset


def load_builtin_dataset(dataset_name):
    """
    Carga un conjunto de datos integrado seg√∫n el nombre.

    Parameters:
    -----------
    dataset_name : str
        Nombre del conjunto de datos ('Iris', 'Vino', 'C√°ncer', 'Titanic', 'Propinas', 'Viviendas California', 'Ping√ºinos')

    Returns:
    --------
    X : DataFrame
        Caracter√≠sticas
    y : Series
        Variable objetivo
    feature_names : list
        Nombres de las caracter√≠sticas
    class_names : list
        Nombres de las clases
    dataset_info : str
        Informaci√≥n sobre el conjunto de datos
    """
    if "Iris" in dataset_name:
        data = load_iris()
        X = pd.DataFrame(data.data, columns=data.feature_names)
        y = pd.Series(data.target, name="species")
        feature_names = data.feature_names.tolist() if hasattr(
            data.feature_names, 'tolist') else list(data.feature_names)
        class_names = data.target_names.tolist()
        dataset_info = "Dataset Iris: 150 muestras, 4 caracter√≠sticas, 3 clases de flores"
        task_type = "Clasificaci√≥n"

    elif "Vino" in dataset_name:
        data = load_wine()
        X = pd.DataFrame(data.data, columns=data.feature_names)
        y = pd.Series(data.target, name="wine_type")
        feature_names = data.feature_names.tolist() if hasattr(
            data.feature_names, 'tolist') else list(data.feature_names)
        class_names = data.target_names.tolist()
        dataset_info = "Dataset Vino: 178 muestras, 13 caracter√≠sticas, 3 tipos de vino"
        task_type = "Clasificaci√≥n"

    elif "C√°ncer" in dataset_name:
        data = load_breast_cancer()
        X = pd.DataFrame(data.data, columns=data.feature_names)
        y = pd.Series(data.target, name="malignant")
        feature_names = data.feature_names.tolist() if hasattr(
            data.feature_names, 'tolist') else list(data.feature_names)
        class_names = data.target_names.tolist()
        dataset_info = "Dataset C√°ncer: 569 muestras, 30 caracter√≠sticas, diagn√≥stico binario"
        task_type = "Clasificaci√≥n"

    elif "Titanic" in dataset_name:
        X, y, feature_names, class_names, dataset_info, task_type = load_additional_dataset(
            dataset_name)

    elif "Propinas" in dataset_name:
        X, y, feature_names, class_names, dataset_info, task_type = load_additional_dataset(
            dataset_name)

    elif "Viviendas California" in dataset_name:
        X, y, feature_names, class_names, dataset_info, task_type = load_additional_dataset(
            dataset_name)

    elif "Ping√ºinos" in dataset_name:
        X, y, feature_names, class_names, dataset_info, task_type = load_additional_dataset(
            dataset_name)

    else:
        raise ValueError(f"Conjunto de datos '{dataset_name}' no reconocido")

    return X, y, feature_names, class_names, dataset_info, task_type


def load_dataset_from_file(file_path, target_column=None, task_type="auto"):
    """
    Carga un conjunto de datos desde un archivo CSV.

    Parameters:
    -----------
    file_path : str
        Ruta al archivo CSV
    target_column : str, optional
        Nombre de la columna objetivo. Si es None, se usa la √∫ltima columna.
    task_type : str, default="auto"
        Tipo de tarea ('Clasificaci√≥n', 'Regresi√≥n', 'auto')

    Returns:
    --------
    X : DataFrame
        Caracter√≠sticas
    y : Series
        Variable objetivo
    feature_names : list
        Nombres de las caracter√≠sticas
    class_names : list or None
        Nombres de las clases (solo para clasificaci√≥n)
    dataset_info : str
        Informaci√≥n sobre el conjunto de datos
    task_type : str
        Tipo de tarea ('Clasificaci√≥n' o 'Regresi√≥n')
    """
    # Cargar el dataset
    try:
        df = pd.read_csv(file_path)
    except Exception as e:
        raise ValueError(f"Error al cargar el archivo: {str(e)}")

    # Determinar la columna objetivo
    if target_column is None:
        target_column = df.columns[-1]

    if target_column not in df.columns:
        raise ValueError(
            f"Columna objetivo '{target_column}' no encontrada en el dataset")

    # Separar caracter√≠sticas y objetivo
    X = df.drop(columns=[target_column])
    y = df[target_column]

    # Codificar autom√°ticamente caracter√≠sticas categ√≥ricas (string/object)
    categorical_features = X.select_dtypes(include=['object']).columns
    if len(categorical_features) > 0:
        from sklearn.preprocessing import LabelEncoder
        for col in categorical_features:
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col].astype(str))

    # Codificar variable objetivo si es categ√≥rica
    if y.dtype == 'object':
        from sklearn.preprocessing import LabelEncoder
        le_target = LabelEncoder()
        y = pd.Series(le_target.fit_transform(
            y.astype(str)), name=target_column)

    # Obtener nombres de caracter√≠sticas
    feature_names = X.columns.tolist()

    # Determinar tipo de tarea si es autom√°tico
    if task_type == "auto":
        # Si y tiene pocos valores √∫nicos (menos del 5% del total), asumimos clasificaci√≥n
        if len(y.unique()) < max(5, len(y) * 0.05):
            task_type = "Clasificaci√≥n"
        else:
            task_type = "Regresi√≥n"

    # Para clasificaci√≥n, determinar nombres de clases
    if task_type == "Clasificaci√≥n":
        class_values = sorted(y.unique())
        # Intentar usar etiquetas si est√°n disponibles
        if hasattr(y, 'cat') and hasattr(y.cat, 'categories'):
            class_names = y.cat.categories.tolist()
        else:
            # Si son n√∫meros enteros, usar nombres gen√©ricos
            if all(isinstance(val, (int, np.integer)) for val in class_values):
                class_names = [f"Clase {i}" for i in class_values]
            else:
                class_names = [str(val) for val in class_values]
    else:
        class_names = None

    # Generar informaci√≥n del dataset
    n_samples, n_features = X.shape
    if task_type == "Clasificaci√≥n":
        n_classes = len(class_names)
        dataset_info = f"Dataset personalizado: {n_samples} muestras, {n_features} caracter√≠sticas, {n_classes} clases"
    else:
        dataset_info = f"Dataset personalizado: {n_samples} muestras, {n_features} caracter√≠sticas, regresi√≥n"

    return X, y, feature_names, class_names, dataset_info, task_type


def list_sample_datasets():
    """
    Lista los conjuntos de datos de ejemplo disponibles en el directorio 'data/sample_datasets'.

    Returns:
    --------
    list
        Lista de rutas a los archivos CSV de ejemplo
    """
    sample_dir = os.path.join(os.path.dirname(
        os.path.abspath(__file__)), "data", "sample_datasets")
    if not os.path.exists(sample_dir):
        return []

    return [
        os.path.join(sample_dir, f)
        for f in os.listdir(sample_dir)
        if f.endswith('.csv')
    ]


def preprocess_data(X, y, test_size=0.3, random_state=42):
    """
    Divide los datos en conjuntos de entrenamiento y prueba.

    Parameters:
    -----------
    X : DataFrame o array
        Caracter√≠sticas
    y : Series o array
        Variable objetivo
    test_size : float, default=0.3
        Proporci√≥n de datos para prueba
    random_state : int, default=42
        Semilla para reproducibilidad

    Returns:
    --------
    X_train, X_test, y_train, y_test : arrays
        Conjuntos de entrenamiento y prueba
    """
    return train_test_split(X, y, test_size=test_size, random_state=random_state)


def load_data(dataset_option):
    """
    Carga un conjunto de datos seg√∫n la opci√≥n seleccionada.

    Parameters:
    -----------
    dataset_option : str
        Nombre del conjunto de datos a cargar

    Returns:
    --------
    X : DataFrame
        Caracter√≠sticas
    y : Series
        Variable objetivo
    feature_names : list
        Nombres de las caracter√≠sticas
    class_names : list o None
        Nombres de las clases (para clasificaci√≥n)
    dataset_info : str
        Informaci√≥n sobre el conjunto de datos
    task_type : str
        Tipo de tarea
    """
    # Lista de datasets integrados (tanto formato antiguo como nuevo)
    dataset_mapping = {
        "Iris (clasificaci√≥n de flores)": "üå∏ Iris - Clasificaci√≥n de flores",
        "Vino (clasificaci√≥n de vinos)": "üç∑ Vino - Clasificaci√≥n de vinos",
        "C√°ncer de mama (diagn√≥stico)": "üî¨ C√°ncer - Diagn√≥stico binario",
        "üå∏ Iris - Clasificaci√≥n de flores": "üå∏ Iris - Clasificaci√≥n de flores",
        "üç∑ Vino - Clasificaci√≥n de vinos": "üç∑ Vino - Clasificaci√≥n de vinos",
        "üî¨ C√°ncer - Diagn√≥stico binario": "üî¨ C√°ncer - Diagn√≥stico binario",
        "üö¢ Titanic - Supervivencia": "üö¢ Titanic - Supervivencia",
        "üí∞ Propinas - Predicci√≥n de propinas": "üí∞ Propinas - Predicci√≥n de propinas",
        "üè† Viviendas California - Precios": "üè† Viviendas California - Precios",
        "üêß Ping√ºinos - Clasificaci√≥n de especies": "üêß Ping√ºinos - Clasificaci√≥n de especies"
    }

    # Comprobar si es un dataset CSV personalizado cargado
    import streamlit as st
    if hasattr(st, 'session_state') and 'csv_datasets' in st.session_state and dataset_option in st.session_state.csv_datasets:
        csv_info = st.session_state.csv_datasets[dataset_option]
        return load_dataset_from_file(
            csv_info['file_path'],
            csv_info['target_col'],
            csv_info['task_type']
        )

    # Normalizar el nombre del dataset
    if dataset_option in dataset_mapping:
        normalized_name = dataset_mapping[dataset_option]
        return load_builtin_dataset(normalized_name)

    # Comprobar si es un conjunto de datos personalizado (CSV) - compatibilidad con formato anterior
    if dataset_option.endswith('.csv'):
        file_path = dataset_option
        if not os.path.exists(file_path):
            # Comprobar si est√° en el directorio de muestras
            sample_dir = os.path.join(os.path.dirname(
                os.path.abspath(__file__)), "data", "sample_datasets")
            sample_path = os.path.join(sample_dir, os.path.basename(file_path))
            if os.path.exists(sample_path):
                file_path = sample_path

        return load_dataset_from_file(file_path)

    # Si llegamos aqu√≠, el conjunto de datos no se reconoce
    raise ValueError(f"Conjunto de datos '{dataset_option}' no reconocido")


def create_dataset_selector(show_predefined=True):
    """
    Crea un selector de conjuntos de datos mejorado para la interfaz de usuario.

    Parameters:
    -----------
    show_predefined : bool, default=True
        Si mostrar la opci√≥n de datasets predefinidos

    Returns:
    --------
    str or tuple
        Si se carga un archivo CSV: tuple (ruta_archivo, columna_objetivo, tipo_tarea)
        Si no: nombre del dataset seleccionado
    """
    st.subheader("üìä Selecci√≥n de Dataset")

    # Opciones de datasets expandidas
    builtin_options = [
        "üå∏ Iris - Clasificaci√≥n de flores",
        "üç∑ Vino - Clasificaci√≥n de vinos",
        "üî¨ C√°ncer - Diagn√≥stico binario",
        "üö¢ Titanic - Supervivencia",
        "üí∞ Propinas - Predicci√≥n de propinas",
        "üè† Viviendas California - Precios",
        "üêß Ping√ºinos - Clasificaci√≥n de especies"
    ]

    # M√©todo de carga
    if show_predefined:
        data_source = st.radio(
            "Fuente de datos:",
            ["Datasets predefinidos", "Cargar archivo CSV"],
            help="Selecciona si quieres usar un dataset incluido o cargar tu propio archivo CSV"
        )
    else:
        data_source = "Cargar archivo CSV"
        st.info(
            "üí° En esta secci√≥n puedes cargar tu propio archivo CSV para an√°lisis personalizado")

    if data_source == "Cargar archivo CSV":
        st.markdown("### üìÅ Cargar Archivo CSV")

        uploaded_file = st.file_uploader(
            "Selecciona un archivo CSV:",
            type=['csv'],
            help="El archivo debe estar en formato CSV con encabezados"
        )

        if uploaded_file is not None:
            try:
                # Leer el archivo
                df = pd.read_csv(uploaded_file)

                # Validaciones b√°sicas
                if df.empty:
                    st.error("‚ùå El archivo est√° vac√≠o")
                    return None

                if len(df.columns) < 2:
                    st.error(
                        "‚ùå El archivo debe tener al menos 2 columnas (caracter√≠sticas + objetivo)")
                    return None

                # Mostrar vista previa
                st.success(
                    f"‚úÖ Archivo cargado exitosamente: {df.shape[0]} filas, {df.shape[1]} columnas")

                with st.expander("üëÄ Vista previa del dataset", expanded=True):
                    st.dataframe(df.head(), use_container_width=True)

                    # Informaci√≥n del dataset
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Filas", df.shape[0])
                    with col2:
                        st.metric("Columnas", df.shape[1])
                    with col3:
                        missing_values = df.isnull().sum().sum()
                        st.metric("Valores faltantes", missing_values)

                # Configuraci√≥n
                st.markdown("### ‚öôÔ∏è Configuraci√≥n")

                col1, col2 = st.columns(2)

                with col1:
                    target_col = st.selectbox(
                        "Columna objetivo:",
                        df.columns.tolist(),
                        index=len(df.columns)-1,
                        help="Selecciona la columna que contiene la variable a predecir"
                    )

                with col2:
                    # Detectar tipo de tarea autom√°ticamente
                    if target_col:
                        unique_values = df[target_col].nunique()
                        total_values = len(df[target_col])

                        if unique_values <= 20 and unique_values < total_values * 0.1:
                            suggested_task = "Clasificaci√≥n"
                        else:
                            suggested_task = "Regresi√≥n"
                    else:
                        suggested_task = "Clasificaci√≥n"

                    task_options = ["auto", "Clasificaci√≥n", "Regresi√≥n"]
                    default_idx = task_options.index(
                        suggested_task) if suggested_task in task_options else 0

                    task_type = st.selectbox(
                        "Tipo de tarea:",
                        task_options,
                        index=default_idx,
                        help="'auto' detecta autom√°ticamente, o selecciona manualmente"
                    )

                # Informaci√≥n adicional sobre la columna objetivo
                if target_col:
                    st.markdown("### üéØ Informaci√≥n de la Variable Objetivo")
                    col1, col2 = st.columns(2)

                    with col1:
                        st.write(f"**Columna:** {target_col}")
                        st.write(
                            f"**Valores √∫nicos:** {df[target_col].nunique()}")
                        st.write(f"**Tipo de datos:** {df[target_col].dtype}")

                    with col2:
                        if df[target_col].nunique() <= 10:
                            st.write("**Distribuci√≥n de valores:**")
                            value_counts = df[target_col].value_counts()
                            for val, count in value_counts.items():
                                st.write(
                                    f"‚Ä¢ {val}: {count} ({count/len(df)*100:.1f}%)")

                # Guardar en archivo temporal
                import tempfile
                temp_file = tempfile.NamedTemporaryFile(
                    mode='w+', delete=False, suffix='.csv')
                df.to_csv(temp_file.name, index=False)
                temp_file.close()

                # A√±adir dataset a la lista de datasets disponibles en session_state
                dataset_name = f"üìÑ {uploaded_file.name}"
                if 'csv_datasets' not in st.session_state:
                    st.session_state.csv_datasets = {}

                st.session_state.csv_datasets[dataset_name] = {
                    'file_path': temp_file.name,
                    'target_col': target_col,
                    'task_type': task_type,
                    'original_name': uploaded_file.name
                }

                # Actualizar el dataset seleccionado para usar el nuevo CSV
                st.session_state.selected_dataset = dataset_name

                st.success(
                    f"‚úÖ Dataset '{uploaded_file.name}' a√±adido a la lista de datasets disponibles")

                return temp_file.name, target_col, task_type

            except Exception as e:
                st.error(f"‚ùå Error al procesar el archivo: {str(e)}")
                return None

        else:
            st.info("üëÜ Por favor, carga un archivo CSV para continuar")
            return None

    else:  # Datasets predefinidos
        st.markdown("### üéØ Datasets Disponibles")
        dataset_option = st.selectbox(
            "Selecciona un dataset:",
            builtin_options,
            help="Estos datasets est√°n listos para usar y son perfectos para aprender Machine Learning"
        )

        # Mostrar informaci√≥n del dataset seleccionado
        dataset_info = {
            "üå∏ Iris - Clasificaci√≥n de flores": "150 muestras ‚Ä¢ 4 caracter√≠sticas ‚Ä¢ 3 especies de iris ‚Ä¢ Clasificaci√≥n cl√°sica",
            "üç∑ Vino - Clasificaci√≥n de vinos": "178 muestras ‚Ä¢ 13 caracter√≠sticas qu√≠micas ‚Ä¢ 3 clases de vino ‚Ä¢ Clasificaci√≥n",
            "üî¨ C√°ncer - Diagn√≥stico binario": "569 muestras ‚Ä¢ 30 caracter√≠sticas ‚Ä¢ Benigno/Maligno ‚Ä¢ Clasificaci√≥n m√©dica",
            "üö¢ Titanic - Supervivencia": "891 pasajeros ‚Ä¢ 11 caracter√≠sticas ‚Ä¢ Supervivencia ‚Ä¢ Clasificaci√≥n hist√≥rica",
            "üí∞ Propinas - Predicci√≥n de propinas": "244 cuentas ‚Ä¢ 6 caracter√≠sticas ‚Ä¢ Monto de propina ‚Ä¢ Regresi√≥n",
            "üè† Viviendas California - Precios": "20,640 distritos ‚Ä¢ 8 caracter√≠sticas ‚Ä¢ Precio vivienda ‚Ä¢ Regresi√≥n",
            "üêß Ping√ºinos - Clasificaci√≥n de especies": "333 ping√ºinos ‚Ä¢ 6 caracter√≠sticas ‚Ä¢ 3 especies ‚Ä¢ Clasificaci√≥n biol√≥gica"
        }

        if dataset_option in dataset_info:
            st.info(f"‚ÑπÔ∏è {dataset_info[dataset_option]}")

        return dataset_option
