import streamlit as st
import streamlit.components.v1 as components


def evaluate_nn(model, X_test, y_test, task_type):
    # Mostrar m√©tricas b√°sicas con explicaciones
    st.markdown("#### üìä Resultados del Entrenamiento")

    if task_type == "Clasificaci√≥n":
        test_loss, test_acc = model.evaluate(
            X_test, y_test, verbose=0)
        col_m1, col_m2 = st.columns(2)
        with col_m1:
            st.metric("üéØ Precisi√≥n en Test", f"{test_acc:.3f}",
                      help="Porcentaje de predicciones correctas en datos nunca vistos")
        with col_m2:
            st.metric("üìâ P√©rdida en Test", f"{test_loss:.3f}",
                      help="Qu√© tan 'equivocada' est√° la red en promedio")
    else:
        test_loss = model.evaluate(X_test, y_test, verbose=0)
        test_loss = test_loss[0] if isinstance(test_loss, list) else test_loss
        st.metric("üìâ Error en Test", f"{test_loss:.3f}")

    # Gr√°fico de entrenamiento en tiempo real
    st.markdown("### üìà Progreso del Entrenamiento")
    history = st.session_state.nn_history
    plot_training_history(history, task_type)


def create_neural_network_visualization(architecture, activation, output_activation, task_type):
    """
    Crea una visualizaci√≥n din√°mica de la arquitectura de red neuronal usando HTML5 Canvas.
    """
    try:
        # Colores para diferentes elementos
        colors = {
            'input': '#4ECDC4',
            'hidden': '#45B7D1',
            'output': '#FF6B6B',
            'connection': '#BDC3C7',
            'text': '#2C3E50'
        }

        html_code = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <style>
                .nn-container {{
                    max-width: 100%;
                    margin: 0 auto;
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
                }}
                .canvas-container {{
                    position: relative;
                    border: 2px solid #e0e0e0;
                    border-radius: 8px;
                    margin: 10px 0;
                    background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
                    width: 100%;
                    overflow: hidden;
                }}
                #nnCanvas {{
                    display: block;
                    width: 100%;
                    height: auto;
                    max-width: 100%;
                }}
                .info-box {{
                    background: #e3f2fd;
                    border-left: 4px solid #2196F3;
                    padding: 10px;
                    margin: 10px 0;
                    border-radius: 4px;
                    font-size: 14px;
                }}
                .layer-info {{
                    display: flex;
                    gap: 15px;
                    margin-top: 10px;
                    flex-wrap: wrap;
                    justify-content: center;
                    font-size: 12px;
                }}
                .layer-item {{
                    display: flex;
                    align-items: center;
                    gap: 5px;
                    padding: 5px 10px;
                    background: white;
                    border-radius: 15px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                }}
                .layer-color {{
                    width: 12px;
                    height: 12px;
                    border-radius: 50%;
                }}
            </style>
        </head>
        <body>
            <div class="nn-container">
                <div class="info-box">
                    <strong>üß† Arquitectura de Red Neuronal</strong><br>
                    Visualizaci√≥n din√°mica de la estructura de la red para {task_type.lower()}
                </div>
                
                <div class="canvas-container">
                    <canvas id="nnCanvas"></canvas>
                </div>
                
                <div class="layer-info">
                    <div class="layer-item">
                        <div class="layer-color" style="background-color: {colors['input']}"></div>
                        <span>Capa de Entrada</span>
                    </div>
                    <div class="layer-item">
                        <div class="layer-color" style="background-color: {colors['hidden']}"></div>
                        <span>Capas Ocultas ({activation.upper()})</span>
                    </div>
                    <div class="layer-item">
                        <div class="layer-color" style="background-color: {colors['output']}"></div>
                        <span>Capa de Salida ({output_activation.upper()})</span>
                    </div>
                </div>
            </div>

            <script>
                const canvas = document.getElementById('nnCanvas');
                const ctx = canvas.getContext('2d');
                
                // Arquitectura de la red
                const architecture = {architecture};
                const maxNeurons = Math.max(...architecture);
                
                // Funci√≥n para redimensionar el canvas
                function resizeCanvas() {{
                    const container = document.querySelector('.canvas-container');
                    const containerWidth = container.clientWidth - 4;
                    const aspectRatio = 2/1;
                    const canvasHeight = Math.max(300, containerWidth / aspectRatio);
                    
                    canvas.width = containerWidth;
                    canvas.height = canvasHeight;
                    canvas.style.width = containerWidth + 'px';
                    canvas.style.height = canvasHeight + 'px';
                    
                    drawNetwork();
                }}
                
                // Funci√≥n para dibujar la red neuronal
                function drawNetwork() {{
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    
                    const margin = 40;
                    const layerWidth = (canvas.width - 2 * margin) / (architecture.length - 1);
                    const maxRadius = Math.min(20, canvas.width / (architecture.length * 8));
                    
                    // Dibujar conexiones primero
                    ctx.strokeStyle = '{colors['connection']}';
                    ctx.lineWidth = 1;
                    ctx.globalAlpha = 0.3;
                    
                    for (let i = 0; i < architecture.length - 1; i++) {{
                        const currentLayerSize = architecture[i];
                        const nextLayerSize = architecture[i + 1];
                        
                        const currentX = margin + i * layerWidth;
                        const nextX = margin + (i + 1) * layerWidth;
                        
                        for (let j = 0; j < currentLayerSize; j++) {{
                            const currentY = getNodeY(j, currentLayerSize);
                            
                            for (let k = 0; k < nextLayerSize; k++) {{
                                const nextY = getNodeY(k, nextLayerSize);
                                
                                ctx.beginPath();
                                ctx.moveTo(currentX, currentY);
                                ctx.lineTo(nextX, nextY);
                                ctx.stroke();
                            }}
                        }}
                    }}
                    
                    ctx.globalAlpha = 1.0;
                    
                    // Dibujar nodos
                    architecture.forEach((layerSize, layerIndex) => {{
                        const x = margin + layerIndex * layerWidth;
                        const radius = Math.min(maxRadius, Math.max(8, (canvas.height - 2 * margin) / (maxNeurons * 3)));
                        
                        // Color seg√∫n tipo de capa
                        let color;
                        if (layerIndex === 0) {{
                            color = '{colors['input']}';
                        }} else if (layerIndex === architecture.length - 1) {{
                            color = '{colors['output']}';
                        }} else {{
                            color = '{colors['hidden']}';
                        }}
                        
                        // Dibujar nodos de la capa
                        for (let nodeIndex = 0; nodeIndex < layerSize; nodeIndex++) {{
                            const y = getNodeY(nodeIndex, layerSize);
                            
                            // Nodo
                            ctx.fillStyle = color;
                            ctx.beginPath();
                            ctx.arc(x, y, radius, 0, 2 * Math.PI);
                            ctx.fill();
                            
                            // Borde
                            ctx.strokeStyle = '#2C3E50';
                            ctx.lineWidth = 2;
                            ctx.stroke();
                        }}
                        
                        // Etiqueta de capa
                        ctx.fillStyle = '{colors['text']}';
                        ctx.font = `bold ${{Math.max(10, canvas.width / 50)}}px Arial`;
                        ctx.textAlign = 'center';
                        
                        let layerLabel;
                        if (layerIndex === 0) {{
                            layerLabel = `Entrada\\n(${{layerSize}})`;
                        }} else if (layerIndex === architecture.length - 1) {{
                            layerLabel = `Salida\\n(${{layerSize}})`;
                        }} else {{
                            layerLabel = `Oculta ${{layerIndex}}\\n(${{layerSize}})`;
                        }}
                        
                        // Dibujar texto en m√∫ltiples l√≠neas
                        const lines = layerLabel.split('\\n');
                        lines.forEach((line, lineIndex) => {{
                            ctx.fillText(line, x, canvas.height - 25 + lineIndex * 15);
                        }});
                    }});
                }}
                
                // Funci√≥n auxiliar para calcular posici√≥n Y de un nodo
                function getNodeY(nodeIndex, layerSize) {{
                    const margin = 40;
                    const availableHeight = canvas.height - 2 * margin - 60; // Espacio para etiquetas
                    
                    if (layerSize === 1) {{
                        return margin + availableHeight / 2;
                    }}
                    
                    const spacing = availableHeight / (layerSize + 1);
                    return margin + spacing * (nodeIndex + 1);
                }}
                
                // Inicializaci√≥n
                resizeCanvas();
                
                // Redimensionar cuando cambie el tama√±o de ventana
                window.addEventListener('resize', function() {{
                    setTimeout(resizeCanvas, 100);
                }});
                
                // Observer para detectar cambios en el contenedor
                if (window.ResizeObserver) {{
                    const resizeObserver = new ResizeObserver(entries => {{
                        for (let entry of entries) {{
                            if (entry.target.querySelector('#nnCanvas')) {{
                                resizeCanvas();
                            }}
                        }}
                    }});
                    resizeObserver.observe(document.querySelector('.canvas-container'));
                }}
            </script>
        </body>
        </html>
        """

        components.html(html_code, height=400, scrolling=False)

    except Exception as e:
        st.error(f"Error en la visualizaci√≥n de red neuronal: {str(e)}")


def calculate_network_parameters(architecture):
    """Calcula el n√∫mero total de par√°metros en la red."""
    total_params = 0
    for i in range(len(architecture) - 1):
        # Pesos: current_layer * next_layer + Sesgos: next_layer
        weights = architecture[i] * architecture[i + 1]
        biases = architecture[i + 1]
        total_params += weights + biases
    return total_params


def plot_training_history(history, task_type):
    """Grafica el historial de entrenamiento."""
    try:
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        import streamlit as st

        # Crear subplots
        if task_type == 'Clasificaci√≥n':
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=('P√©rdida durante el Entrenamiento',
                                'Precisi√≥n durante el Entrenamiento')
            )

            # P√©rdida
            fig.add_trace(
                go.Scatter(
                    y=history.history['loss'], name='Entrenamiento', line=dict(color='blue')),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(
                    y=history.history['val_loss'], name='Validaci√≥n', line=dict(color='red')),
                row=1, col=1
            )

            # Precisi√≥n
            fig.add_trace(
                go.Scatter(y=history.history['accuracy'], name='Entrenamiento', line=dict(
                    color='blue'), showlegend=False),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(y=history.history['val_accuracy'], name='Validaci√≥n', line=dict(
                    color='red'), showlegend=False),
                row=1, col=2
            )

            fig.update_yaxes(title_text="P√©rdida", row=1, col=1)
            fig.update_yaxes(title_text="Precisi√≥n", row=1, col=2)

        else:
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=(
                    'P√©rdida (MSE) durante el Entrenamiento', 'Error Absoluto Medio')
            )

            # MSE
            fig.add_trace(
                go.Scatter(
                    y=history.history['loss'], name='Entrenamiento', line=dict(color='blue')),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(
                    y=history.history['val_loss'], name='Validaci√≥n', line=dict(color='red')),
                row=1, col=1
            )

            # MAE
            fig.add_trace(
                go.Scatter(y=history.history['mae'], name='Entrenamiento', line=dict(
                    color='blue'), showlegend=False),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(y=history.history['val_mae'], name='Validaci√≥n', line=dict(
                    color='red'), showlegend=False),
                row=1, col=2
            )

            fig.update_yaxes(title_text="MSE", row=1, col=1)
            fig.update_yaxes(title_text="MAE", row=1, col=2)

        fig.update_xaxes(title_text="√âpoca")
        fig.update_layout(height=400, showlegend=True)

        st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"Error graficando historial: {str(e)}")


def show_neural_network_evaluation():
    """Muestra la evaluaci√≥n detallada del modelo de red neuronal."""

    # Tips educativos sobre evaluaci√≥n
    st.info("""
    üéì **Evaluaci√≥n de Redes Neuronales:**
    - **Accuracy**: Porcentaje de predicciones correctas (para clasificaci√≥n)
    - **Matriz de Confusi√≥n**: Muestra qu√© clases se confunden entre s√≠
    - **MSE/MAE**: Errores promedio para regresi√≥n
    - **Datos de test**: Nunca vistos durante entrenamiento, miden la capacidad real
    """)

    try:
        import tensorflow as tf
        import numpy as np
        import pandas as pd
        from sklearn.metrics import classification_report, confusion_matrix, r2_score, mean_squared_error, mean_absolute_error
        import plotly.graph_objects as go
        import plotly.figure_factory as ff
        from plotly.subplots import make_subplots

        model = st.session_state.nn_model
        X_test, y_test = st.session_state.nn_test_data
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        # Hacer predicciones
        y_pred = model.predict(X_test, verbose=0)

        # M√©tricas seg√∫n el tipo de tarea
        if config['task_type'] == 'Clasificaci√≥n':
            # Obtener el tama√±o de salida de forma segura
            output_size = safe_get_output_size(config)

            # Para clasificaci√≥n - detectar formato de y_test
            # One-hot encoded (multiclase)
            if len(y_test.shape) > 1 and y_test.shape[1] > 1:
                y_pred_classes = np.argmax(y_pred, axis=1)
                y_test_classes = np.argmax(y_test, axis=1)
            else:  # Binaria o multiclase sin one-hot
                if output_size == 1:  # Binaria con 1 neurona
                    y_pred_classes = (y_pred > 0.5).astype(int).flatten()
                    y_test_classes = y_test.flatten()
                else:  # Multiclase sin one-hot (sparse)
                    y_pred_classes = np.argmax(y_pred, axis=1)
                    y_test_classes = y_test.flatten()

            # Accuracy
            accuracy = np.mean(y_pred_classes == y_test_classes)

            # Mostrar m√©tricas principales con explicaciones
            st.markdown("### üéØ M√©tricas Principales")
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("üéØ Accuracy", f"{accuracy:.4f}", f"{accuracy*100:.2f}%",
                          help="Porcentaje de predicciones correctas en datos nunca vistos")

                # Interpretaci√≥n del accuracy
                if accuracy >= 0.9:
                    st.success("üåü **Excelente**: Tu red predice muy bien")
                elif accuracy >= 0.8:
                    st.success("‚úÖ **Muy Bueno**: Predicciones muy confiables")
                elif accuracy >= 0.7:
                    st.warning("‚ö†Ô∏è **Bueno**: Predicciones aceptables")
                elif accuracy >= 0.6:
                    st.warning("üü° **Regular**: Hay margen de mejora")
                else:
                    st.error("üî¥ **Bajo**: Considera ajustar el modelo")

            with col2:
                # Calcular confianza promedio
                # One-hot multiclase
                if len(y_test.shape) > 1 and y_test.shape[1] > 1:
                    confidence = np.mean(np.max(y_pred, axis=1))
                elif output_size == 1:  # Binaria
                    confidence = np.mean(np.maximum(
                        y_pred.flatten(), 1 - y_pred.flatten()))
                else:  # Multiclase sparse
                    confidence = np.mean(np.max(y_pred, axis=1))
                st.metric("üé≤ Confianza Promedio",
                          f"{confidence:.4f}", f"{confidence*100:.2f}%")

            with col3:
                # N√∫mero de predicciones correctas
                correct_preds = np.sum(y_pred_classes == y_test_classes)
                st.metric("‚úÖ Predicciones Correctas",
                          f"{correct_preds}/{len(y_test_classes)}")

            # Matriz de confusi√≥n
            st.subheader("üîç Matriz de Confusi√≥n")

            try:
                cm = confusion_matrix(y_test_classes, y_pred_classes)

                # Obtener nombres de clases
                if label_encoder and hasattr(label_encoder, 'classes_'):
                    class_names = list(label_encoder.classes_)
                else:
                    # Determinar clases basado en los datos √∫nicos
                    all_classes = sorted(
                        set(list(y_test_classes) + list(y_pred_classes)))
                    class_names = [f"Clase {i}" for i in all_classes]

                # Ajustar class_names al tama√±o de la matriz si es necesario
                if len(class_names) != cm.shape[0]:
                    class_names = [f"Clase {i}" for i in range(cm.shape[0])]

                # Crear heatmap de la matriz de confusi√≥n
                fig_cm = ff.create_annotated_heatmap(
                    z=cm,
                    x=class_names,
                    y=class_names,
                    annotation_text=cm,
                    colorscale='Blues',
                    showscale=True
                )

                fig_cm.update_layout(
                    title='Matriz de Confusi√≥n',
                    xaxis_title='Predicciones',
                    yaxis_title='Valores Reales',
                    height=500
                )

                st.plotly_chart(fig_cm, use_container_width=True)

            except Exception as cm_error:
                st.error(
                    f"‚ùå Error creando matriz de confusi√≥n: {str(cm_error)}")
                st.info(
                    "La matriz de confusi√≥n no pudo generarse. El modelo funciona correctamente pero hay un problema con la visualizaci√≥n.")

            # Reporte de clasificaci√≥n detallado
            st.subheader("üìã Reporte de Clasificaci√≥n")

            if label_encoder:
                target_names = label_encoder.classes_
            else:
                target_names = [f"Clase {i}" for i in range(
                    len(np.unique(y_test_classes)))]

            # Generar reporte
            report = classification_report(
                y_test_classes, y_pred_classes,
                target_names=target_names,
                output_dict=True
            )

            # Mostrar m√©tricas por clase
            metrics_data = []
            for class_name in target_names:
                if class_name in report:
                    metrics_data.append({
                        'Clase': class_name,
                        'Precisi√≥n': f"{report[class_name]['precision']:.4f}",
                        'Recall': f"{report[class_name]['recall']:.4f}",
                        'F1-Score': f"{report[class_name]['f1-score']:.4f}",
                        'Soporte': report[class_name]['support']
                    })

            st.dataframe(metrics_data, use_container_width=True)

            # M√©tricas macro y weighted
            st.subheader("üìä M√©tricas Agregadas")
            col1, col2 = st.columns(2)

            with col1:
                st.info(f"""
                **Macro Average:**
                - Precisi√≥n: {report['macro avg']['precision']:.4f}
                - Recall: {report['macro avg']['recall']:.4f}
                - F1-Score: {report['macro avg']['f1-score']:.4f}
                """)

            with col2:
                st.info(f"""
                **Weighted Average:**
                - Precisi√≥n: {report['weighted avg']['precision']:.4f}
                - Recall: {report['weighted avg']['recall']:.4f}
                - F1-Score: {report['weighted avg']['f1-score']:.4f}
                """)

        else:
            # Para regresi√≥n
            y_pred_flat = y_pred.flatten()
            y_test_flat = y_test.flatten()

            # M√©tricas de regresi√≥n
            mse = mean_squared_error(y_test_flat, y_pred_flat)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test_flat, y_pred_flat)
            r2 = r2_score(y_test_flat, y_pred_flat)

            # Mostrar m√©tricas principales
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("üìä R¬≤ Score", f"{r2:.4f}")

            with col2:
                st.metric("üìè MAE", f"{mae:.4f}")

            with col3:
                st.metric("üìê RMSE", f"{rmse:.4f}")

            with col4:
                st.metric("üéØ MSE", f"{mse:.4f}")

            # Gr√°ficos de evaluaci√≥n para regresi√≥n
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=('Predicciones vs Valores Reales',
                                'Distribuci√≥n de Residuos')
            )

            # Scatter plot de predicciones vs reales
            fig.add_trace(
                go.Scatter(
                    x=y_test_flat,
                    y=y_pred_flat,
                    mode='markers',
                    name='Predicciones',
                    marker=dict(size=8, opacity=0.6)
                ),
                row=1, col=1
            )

            # L√≠nea de referencia y = x
            min_val = min(y_test_flat.min(), y_pred_flat.min())
            max_val = max(y_test_flat.max(), y_pred_flat.max())

            fig.add_trace(
                go.Scatter(
                    x=[min_val, max_val],
                    y=[min_val, max_val],
                    mode='lines',
                    name='L√≠nea Ideal',
                    line=dict(color='red', dash='dash')
                ),
                row=1, col=1
            )

            # Histograma de residuos
            residuals = y_test_flat - y_pred_flat
            fig.add_trace(
                go.Histogram(
                    x=residuals,
                    name='Residuos',
                    nbinsx=30,
                    opacity=0.7
                ),
                row=1, col=2
            )

            fig.update_xaxes(title_text="Valores Reales", row=1, col=1)
            fig.update_yaxes(title_text="Predicciones", row=1, col=1)
            fig.update_xaxes(title_text="Residuos", row=1, col=2)
            fig.update_yaxes(title_text="Frecuencia", row=1, col=2)

            fig.update_layout(height=500, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)

        # Informaci√≥n del modelo
        st.subheader("üîß Informaci√≥n del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            st.info(f"""
            **Arquitectura:**
            - Capas: {len(config['architecture'])}
            - Neuronas por capa: {config['architecture']}
            - Funci√≥n de activaci√≥n: {config['activation']}
            - Activaci√≥n de salida: {config['output_activation']}
            """)

        with col2:
            total_params = calculate_network_parameters(config['architecture'])
            st.info(f"""
            **Par√°metros:**
            - Total de par√°metros: {total_params:,}
            - Optimizador: {config['optimizer']}
            - Dropout: {config['dropout_rate']}
            - Batch size: {config['batch_size']}
            """)

        # Bot√≥n para generar c√≥digo Python de evaluaci√≥n
        st.markdown("### üíª C√≥digo Python")
        if st.button("üìù Generar C√≥digo de Evaluaci√≥n", use_container_width=True):
            # Generar c√≥digo Python para evaluaci√≥n
            code = generate_neural_network_evaluation_code(
                config, st.session_state.nn_feature_names, st.session_state.nn_class_names
            )

            st.markdown("#### üêç C√≥digo Python para Evaluaci√≥n")
            st.code(code, language='python')

            # Bot√≥n para descargar el c√≥digo
            st.download_button(
                label="üíæ Descargar C√≥digo de Evaluaci√≥n",
                data=code,
                file_name=f"evaluacion_red_neuronal_{config['task_type'].lower()}.py",
                mime="text/plain"
            )

        # Navegaci√≥n
        st.markdown("---")
        st.markdown("### üß≠ Navegaci√≥n")
        col_nav1, col_nav2 = st.columns(2)
        with col_nav1:
            if st.button("üîô Volver a Entrenamiento", use_container_width=True):
                st.session_state.active_tab_nn = 2
                st.rerun()
        with col_nav2:
            if st.button("üéØ Ver Visualizaciones", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 4
                st.rerun()

    except Exception as e:
        st.error(f"Error en la evaluaci√≥n: {str(e)}")
        st.info(
            "Aseg√∫rate de que TensorFlow est√© instalado y el modelo est√© entrenado correctamente.")


def show_neural_network_visualizations():
    """Muestra visualizaciones avanzadas del modelo."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "‚ö†Ô∏è Primero debes entrenar un modelo en la pesta√±a 'Entrenamiento'")
        return

    # Tips educativos sobre visualizaciones
    st.info("""
    üéì **Visualizaciones de Redes Neuronales:**
    - **Historial de entrenamiento**: Muestra c√≥mo evoluciona el aprendizaje
    - **Pesos y sesgos**: Revelan qu√© ha aprendido cada neurona
    - **Superficie de decisi√≥n**: C√≥mo la red separa las clases (2D)
    - **An√°lisis de capas**: Activaciones y patrones internos
    
    üîß **Reparaci√≥n Autom√°tica**: Esta funci√≥n incluye inicializaci√≥n autom√°tica del modelo para prevenir errores comunes.
    """)

    try:
        import tensorflow as tf
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        import numpy as np
        import matplotlib.pyplot as plt
        from sklearn.preprocessing import StandardScaler

        model = st.session_state.nn_model
        history = st.session_state.nn_history
        config = st.session_state.nn_config

        # SOLUCI√ìN DEFINITIVA PARA EL ERROR DE TENSORFLOW
        st.info("üîÑ Inicializando modelo para visualizaciones...")

        # Obtener datos de test
        X_test, _ = st.session_state.nn_test_data

        # ESTRATEGIA DEFINITIVA: FORZAR CONSTRUCCI√ìN COMPLETA
        try:
            # Preparar datos de muestra
            sample_data = X_test[:1].astype(np.float32)

            # PASO 1: Forzar la construcci√≥n del modelo de forma agresiva
            st.info("üèóÔ∏è Forzando construcci√≥n del modelo...")

            # DIAGN√ìSTICO INICIAL
            st.info(
                f"Estado inicial: built={getattr(model, 'built', False)}, input={'definido' if hasattr(model, 'input') and model.input is not None else 'None'}")

            # ESTRATEGIA ESPEC√çFICA PARA EL PROBLEMA DETECTADO
            # Cuando model.built=True pero model.input=None
            construction_success = False

            for attempt in range(3):
                try:
                    st.info(f"Intento {attempt + 1}/3 de construcci√≥n...")

                    # ESTRATEGIA 1: Forzar predicci√≥n simple
                    _ = model.predict(sample_data, verbose=0)

                    # ESTRATEGIA 2: Si input sigue siendo None, forzar build con input_shape
                    if not hasattr(model, 'input') or model.input is None:
                        st.info("üîß Aplicando fix espec√≠fico para input=None...")
                        # Reconstruir completamente el modelo
                        model.build(input_shape=(None, X_test.shape[1]))

                        # Forzar que el modelo "vea" datos reales
                        _ = model(sample_data)  # Llamada directa

                    # ESTRATEGIA 3: Si a√∫n no funciona, usar _set_inputs (m√©todo interno)
                    if not hasattr(model, 'input') or model.input is None:
                        st.info("üîß Aplicando fix avanzado...")
                        # M√©todo interno de TensorFlow para forzar input
                        try:
                            model._set_inputs(sample_data)
                        except:
                            # Si falla, intentar con fit en modo dummy usando la funci√≥n de p√©rdida CORRECTA
                            try:
                                # Determinar la funci√≥n de p√©rdida correcta seg√∫n la arquitectura
                                output_size = model.layers[-1].units if hasattr(
                                    model.layers[-1], 'units') else 1

                                if output_size == 1:
                                    # Clasificaci√≥n binaria o regresi√≥n
                                    if hasattr(model.layers[-1], 'activation') and 'sigmoid' in str(model.layers[-1].activation):
                                        loss_func = 'binary_crossentropy'
                                    else:
                                        loss_func = 'mse'  # Regresi√≥n
                                else:
                                    # Clasificaci√≥n multiclase
                                    loss_func = 'sparse_categorical_crossentropy'

                                st.info(
                                    f"üîß Usando {loss_func} para reparaci√≥n...")
                                model.compile(optimizer='adam', loss=loss_func)

                                # Crear dummy target con el tama√±o correcto
                                if loss_func == 'sparse_categorical_crossentropy':
                                    dummy_target = np.zeros(
                                        (1,), dtype=np.int32)  # Clase 0
                                elif loss_func == 'binary_crossentropy':
                                    dummy_target = np.zeros(
                                        (1, 1), dtype=np.float32)  # Probabilidad 0
                                else:  # MSE
                                    dummy_target = np.zeros(
                                        (1, output_size), dtype=np.float32)

                                model.fit(sample_data, dummy_target,
                                          epochs=1, verbose=0)
                            except Exception as fit_error:
                                st.warning(
                                    f"Fix avanzado fall√≥: {str(fit_error)}")
                                pass

                    # VERIFICACI√ìN CR√çTICA
                    if hasattr(model, 'input') and model.input is not None:
                        st.success(
                            f"‚úÖ Construcci√≥n exitosa en intento {attempt + 1}")
                        construction_success = True
                        break
                    else:
                        st.warning(
                            f"‚ö†Ô∏è Intento {attempt + 1} fall√≥: input sigue siendo None")

                except Exception as build_error:
                    st.warning(
                        f"‚ö†Ô∏è Intento {attempt + 1} fall√≥: {str(build_error)}")
                    if attempt == 2:  # √öltimo intento
                        # √öltimo recurso: recrear el modelo completamente
                        st.info("üî• √öLTIMO RECURSO: Intentando recrear modelo...")
                        try:
                            # Obtener pesos del modelo actual
                            weights = model.get_weights()

                            # Recrear arquitectura desde config
                            config = st.session_state.nn_config

                            import tensorflow as tf
                            new_model = tf.keras.Sequential()
                            new_model.add(tf.keras.layers.Input(
                                shape=(config['input_size'],)))

                            # Recrear capas densas (excluyendo Input y Dropout)
                            layer_idx = 0
                            for i, layer in enumerate(model.layers):
                                if hasattr(layer, 'units'):  # Es una capa Dense
                                    if layer_idx == 0:  # Primera capa densa
                                        new_model.add(tf.keras.layers.Dense(
                                            layer.units,
                                            activation=layer.activation.__name__
                                        ))
                                    else:  # Capas siguientes
                                        new_model.add(tf.keras.layers.Dense(
                                            layer.units,
                                            activation=layer.activation.__name__
                                        ))
                                    layer_idx += 1
                                elif hasattr(layer, 'rate'):  # Es Dropout
                                    new_model.add(
                                        tf.keras.layers.Dropout(layer.rate))

                            # Compilar nuevo modelo con la configuraci√≥n CORRECTA
                            if config['task_type'] == 'Clasificaci√≥n':
                                if config.get('output_size', 1) == 1:
                                    loss_func = 'binary_crossentropy'
                                else:
                                    loss_func = 'sparse_categorical_crossentropy'
                            else:
                                loss_func = 'mse'

                            new_model.compile(optimizer='adam', loss=loss_func)

                            # Forzar construcci√≥n
                            _ = new_model.predict(sample_data, verbose=0)

                            # Copiar pesos si es posible
                            try:
                                new_model.set_weights(weights)
                                st.info("‚úÖ Pesos copiados exitosamente")
                            except:
                                st.warning(
                                    "‚ö†Ô∏è No se pudieron copiar los pesos")

                            # Reemplazar modelo en session_state
                            st.session_state.nn_model = new_model
                            model = new_model

                            if model.input is not None:
                                st.success("üéâ Modelo recreado exitosamente!")
                                construction_success = True
                                break

                        except Exception as recreate_error:
                            st.error(
                                f"‚ùå Recreaci√≥n fall√≥: {str(recreate_error)}")

                            # √öLTIMO √öLTIMO RECURSO: Modelo completamente nuevo SIN copiar pesos
                            st.info(
                                "üö® √öLTIMO RECURSO EXTREMO: Modelo completamente nuevo...")
                            try:
                                config = st.session_state.nn_config

                                # Crear modelo minimalista garantizado que SIEMPRE funciona
                                minimal_model = tf.keras.Sequential([
                                    tf.keras.layers.Input(
                                        shape=(config['input_size'],)),
                                    tf.keras.layers.Dense(
                                        32, activation='relu'),
                                    tf.keras.layers.Dense(
                                        config['output_size'], activation=config['output_activation'])
                                ])

                                # Compilar con configuraci√≥n correcta
                                if config['task_type'] == 'Clasificaci√≥n':
                                    loss_func = 'sparse_categorical_crossentropy' if config[
                                        'output_size'] > 1 else 'binary_crossentropy'
                                else:
                                    loss_func = 'mse'

                                minimal_model.compile(
                                    optimizer='adam', loss=loss_func, metrics=['accuracy'])

                                # Forzar construcci√≥n INMEDIATA
                                dummy_input = np.zeros(
                                    (1, config['input_size']), dtype=np.float32)
                                _ = minimal_model.predict(
                                    dummy_input, verbose=0)

                                # VERIFICAR que funcione
                                if minimal_model.input is not None:
                                    st.warning(
                                        "‚ö†Ô∏è Modelo minimal creado (PERDISTE los pesos entrenados)")
                                    st.info(
                                        "üí° Este modelo te permitir√° ver las visualizaciones, pero necesitar√°s reentrenar")
                                    st.session_state.nn_model = minimal_model
                                    model = minimal_model
                                    construction_success = True
                                    break
                                else:
                                    st.error(
                                        "üö® IMPOSIBLE: Incluso el modelo minimal fall√≥")

                            except Exception as minimal_error:
                                st.error(
                                    f"‚ùå Modelo minimal fall√≥: {str(minimal_error)}")
                                st.error(
                                    "üö® ERROR CR√çTICO: TensorFlow no funciona correctamente en este entorno")
                                pass

            if not construction_success:
                raise Exception(
                    "Fallo total en construcci√≥n despu√©s de todos los intentos")

            # PASO 2: Verificaci√≥n EXHAUSTIVA que el modelo funcione
            # No solo verificar model.input, sino que REALMENTE funcione
            test_prediction = model.predict(sample_data, verbose=0)

            # Verificar que las capas est√°n construidas
            layers_built = all(getattr(layer, 'built', True)
                               for layer in model.layers)

            if model.input is not None and layers_built and test_prediction is not None:
                st.success("‚úÖ Modelo completamente construido y funcional")

                # PASO 3: Crear modelo de activaciones CON VERIFICACI√ìN ROBUSTA
                if len(model.layers) > 2:  # Al menos Input + Hidden + Output
                    try:
                        # Identificar capas v√°lidas para activaciones (excluir Input y Output)
                        intermediate_layers = []
                        for i, layer in enumerate(model.layers):
                            # Excluir la primera capa (Input) y la √∫ltima (Output)
                            if i > 0 and i < len(model.layers) - 1:
                                if hasattr(layer, 'output') and layer.output is not None:
                                    intermediate_layers.append(layer.output)

                        if intermediate_layers:
                            # Crear modelo de activaciones
                            activation_model = tf.keras.Model(
                                inputs=model.input,
                                outputs=intermediate_layers
                            )

                            # VERIFICAR que el modelo de activaciones funcione
                            test_activations = activation_model.predict(
                                sample_data, verbose=0)

                            # Guardar solo si funciona
                            st.session_state.activation_model = activation_model
                            st.success(
                                f"‚úÖ Modelo de activaciones creado ({len(intermediate_layers)} capas)")
                        else:
                            st.warning(
                                "‚ö†Ô∏è No hay capas intermedias v√°lidas para an√°lisis")
                            st.session_state.activation_model = None
                    except Exception as activation_error:
                        st.warning("‚ö†Ô∏è Error creando modelo de activaciones")
                        st.caption(f"Detalle: {str(activation_error)}")
                        st.session_state.activation_model = None
                else:
                    st.info("‚ÑπÔ∏è Red muy simple, an√°lisis de capas limitado")
                    st.session_state.activation_model = None

            else:
                # Si llegamos aqu√≠, hay un problema fundamental
                error_details = []
                if model.input is None:
                    error_details.append("model.input es None")
                if not layers_built:
                    error_details.append("capas no construidas")
                if test_prediction is None:
                    error_details.append("predicci√≥n fall√≥")

                raise Exception(
                    f"Modelo no funcional: {', '.join(error_details)}")

        except Exception as error:
            st.error("‚ùå FALLO CR√çTICO: El modelo no se puede inicializar")
            st.markdown("### üö® Diagn√≥stico del Error")
            st.code(f"Error: {str(error)}")

            # Diagn√≥stico t√©cnico detallado
            st.markdown("### üî¨ Estado T√©cnico del Modelo")
            try:
                st.write(f"- **Tipo de modelo**: {type(model).__name__}")
                st.write(
                    f"- **Modelo construido**: {getattr(model, 'built', 'Desconocido')}")
                st.write(
                    f"- **Input definido**: {model.input is not None if hasattr(model, 'input') else 'No disponible'}")
                st.write(
                    f"- **N√∫mero de capas**: {len(model.layers) if hasattr(model, 'layers') else 'Desconocido'}")

                if hasattr(model, 'layers'):
                    st.write("- **Estado de capas**:")
                    for i, layer in enumerate(model.layers):
                        built_status = getattr(layer, 'built', 'Desconocido')
                        st.write(
                            f"  - Capa {i+1} ({layer.__class__.__name__}): {built_status}")

            except Exception as diag_error:
                st.write(f"Error en diagn√≥stico: {diag_error}")

            st.markdown("### üí° Soluci√≥n Obligatoria")
            st.error(
                "**El modelo est√° corrupto o mal construido. DEBES reentrenarlo desde cero.**")
            st.markdown("""
            **Pasos para solucionarlo:**
            1. Ve a la pesta√±a **'Entrenamiento'**
            2. Reentrena el modelo completamente
            3. NO uses modelos guardados previamente
            4. Regresa a esta pesta√±a despu√©s del entrenamiento
            """)

            if st.button("üîô Ir a Reentrenar Modelo", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 2
                st.rerun()

            return

        # CREAR PESTA√ëAS DE VISUALIZACI√ìN UNA VEZ QUE EL MODELO EST√Å REPARADO
        viz_tab1, viz_tab2, viz_tab3, viz_tab4 = st.tabs([
            "üìä Historial de Entrenamiento",
            "üß† Pesos y Sesgos",
            "üéØ Superficie de Decisi√≥n",
            "üìâ An√°lisis de Capas"
        ])

        with viz_tab1:
            st.subheader("üìä Historial de Entrenamiento Detallado")
            st.markdown("üìà **¬øC√≥mo aprendi√≥ tu red neuronal?**")

            # Explicaci√≥n sobre el historial
            with st.expander("üí° ¬øC√≥mo interpretar estas gr√°ficas?"):
                st.markdown("""
                **Gr√°fica de P√©rdida (Loss):**
                - **Bajando**: La red est√° aprendiendo ‚úÖ
                - **Estable**: Ha convergido üéØ
                - **Subiendo**: Posible sobreajuste ‚ö†Ô∏è
                - **Gap grande entre train/val**: Sobreajuste üö®
                
                **Gr√°fica de Accuracy (clasificaci√≥n) o MAE (regresi√≥n):**
                - **Subiendo**: Mejorando en las predicciones ‚úÖ
                - **Plateau**: Ha alcanzado su l√≠mite üìä
                - **Train > Val**: Normal, pero gap grande = sobreajuste ‚ö†Ô∏è
                """)

            plot_training_history(history, config['task_type'])

            # Informaci√≥n adicional del entrenamiento
            st.markdown("#### üìä Estad√≠sticas del Entrenamiento")
            col1, col2, col3 = st.columns(3)

            with col1:
                final_loss = history.history['loss'][-1]
                initial_loss = history.history['loss'][0]
                improvement = ((initial_loss - final_loss) /
                               initial_loss) * 100
                st.metric("üî¥ P√©rdida Final (Entrenamiento)", f"{final_loss:.6f}",
                          f"-{improvement:.1f}% desde inicio")

            with col2:
                if 'val_loss' in history.history:
                    final_val_loss = history.history['val_loss'][-1]
                    overfitting_gap = final_val_loss - final_loss
                    st.metric("üü° P√©rdida Final (Validaci√≥n)", f"{final_val_loss:.6f}",
                              f"Gap: {overfitting_gap:.6f}")

                    # Interpretaci√≥n del gap
                    if overfitting_gap < 0.01:
                        st.success("‚úÖ **Sin sobreajuste**: Gap muy peque√±o")
                    elif overfitting_gap < 0.05:
                        st.warning("‚ö†Ô∏è **Sobreajuste leve**: Gap aceptable")
                    else:
                        st.error("üö® **Sobreajuste**: Gap significativo")

            with col3:
                epochs_trained = len(history.history['loss'])
                st.metric("‚è±Ô∏è √âpocas Entrenadas", epochs_trained)

                # ¬øPar√≥ por early stopping?
                if 'nn_config' in st.session_state:
                    max_epochs = st.session_state.get('training_epochs', 100)
                    if epochs_trained < max_epochs:
                        st.caption(
                            "üõë **Early Stopping**: Par√≥ autom√°ticamente")
                    else:
                        st.caption("üîÑ **Complet√≥ todas las √©pocas**")

        with viz_tab2:
            st.subheader("üß† An√°lisis de Pesos y Sesgos")
            st.markdown("üîç **¬øQu√© ha aprendido cada neurona?**")

            # Explicaci√≥n sobre pesos
            with st.expander("üí° ¬øQu√© significan los pesos?"):
                st.markdown("""
                **Pesos (Weights):**
                - **Valores altos**: Conexiones importantes entre neuronas
                - **Valores cercanos a 0**: Conexiones d√©biles o irrelevantes
                - **Valores negativos**: Relaciones inversas
                - **Distribuci√≥n**: Indica si la red est√° bien inicializada
                
                **Sesgos (Biases):**
                - **Valores altos**: Neurona se activa f√°cilmente
                - **Valores bajos**: Neurona es m√°s selectiva
                - **Distribuci√≥n**: Debe ser razonable, no extrema
                """)

            # Obtener pesos de todas las capas
            layer_weights = []
            layer_biases = []

            for i, layer in enumerate(model.layers):
                if hasattr(layer, 'get_weights') and layer.get_weights():
                    weights = layer.get_weights()
                    if len(weights) >= 2:  # Pesos y sesgos
                        layer_weights.append(weights[0])
                        layer_biases.append(weights[1])

            if layer_weights:
                # Crear gr√°ficos para cada capa
                for i, (weights, biases) in enumerate(zip(layer_weights, layer_biases)):
                    st.markdown(f"#### üìä Capa {i+1}")

                    col1, col2 = st.columns(2)

                    with col1:
                        # Histograma de pesos
                        fig_weights = go.Figure()
                        fig_weights.add_trace(go.Histogram(
                            x=weights.flatten(),
                            nbinsx=50,
                            name=f'Pesos Capa {i+1}',
                            opacity=0.7
                        ))
                        fig_weights.update_layout(
                            title=f'Distribuci√≥n de Pesos - Capa {i+1}',
                            xaxis_title='Valor de Peso',
                            yaxis_title='Frecuencia',
                            height=300
                        )
                        st.plotly_chart(fig_weights, use_container_width=True)

                        # Estad√≠sticas de pesos
                        st.caption(f"üìä **Estad√≠sticas**: Media={np.mean(weights):.4f}, "
                                   f"Std={np.std(weights):.4f}, "
                                   f"Min={np.min(weights):.4f}, "
                                   f"Max={np.max(weights):.4f}")

                    with col2:
                        # Histograma de sesgos
                        fig_biases = go.Figure()
                        fig_biases.add_trace(go.Histogram(
                            x=biases.flatten(),
                            nbinsx=20,
                            name=f'Sesgos Capa {i+1}',
                            opacity=0.7,
                            marker_color='orange'
                        ))
                        fig_biases.update_layout(
                            title=f'Distribuci√≥n de Sesgos - Capa {i+1}',
                            xaxis_title='Valor de Sesgo',
                            yaxis_title='Frecuencia',
                            height=300
                        )
                        st.plotly_chart(fig_biases, use_container_width=True)

                        # Estad√≠sticas de sesgos
                        st.caption(f"üìä **Estad√≠sticas**: Media={np.mean(biases):.4f}, "
                                   f"Std={np.std(biases):.4f}, "
                                   f"Min={np.min(biases):.4f}, "
                                   f"Max={np.max(biases):.4f}")

                # An√°lisis general
                st.markdown("#### üîç An√°lisis General de la Red")
                all_weights = np.concatenate(
                    [w.flatten() for w in layer_weights])
                all_biases = np.concatenate(
                    [b.flatten() for b in layer_biases])

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üéØ Pesos Promedio",
                              f"{np.mean(all_weights):.6f}")
                with col2:
                    st.metric("üìä Desv. Std. Pesos",
                              f"{np.std(all_weights):.6f}")
                with col3:
                    dead_neurons = np.sum(np.abs(all_weights) < 1e-6)
                    st.metric("üíÄ Pesos ~0", f"{dead_neurons}")

                # Salud de la red
                if np.std(all_weights) < 0.01:
                    st.error(
                        "üö® **Problema**: Pesos muy peque√±os, la red puede no haber aprendido")
                elif np.std(all_weights) > 2:
                    st.warning(
                        "‚ö†Ô∏è **Atenci√≥n**: Pesos muy grandes, posible inestabilidad")
                else:
                    st.success("‚úÖ **Saludable**: Distribuci√≥n de pesos normal")
            else:
                st.warning("No se pudieron extraer los pesos del modelo")

        with viz_tab3:
            st.subheader("üéØ Superficie de Decisi√≥n")
            st.markdown(
                "üó∫Ô∏è **¬øC√≥mo divide tu red el espacio de caracter√≠sticas?**")

            # Verificar si es clasificaci√≥n para mostrar superficie de decisi√≥n
            if config.get('task_type', 'Clasificaci√≥n') == 'Clasificaci√≥n':
                # Si hay m√°s de 2 caracter√≠sticas, permitir seleccionar 2
                if config['input_size'] > 2:
                    st.info(
                        "üí° Tu dataset tiene m√°s de 2 caracter√≠sticas. Selecciona 2 para visualizar la superficie de decisi√≥n.")

                    # Obtener nombres de caracter√≠sticas
                    if 'nn_feature_names' in st.session_state:
                        feature_names = st.session_state.nn_feature_names
                    else:
                        feature_names = [
                            f'Caracter√≠stica {i+1}' for i in range(config['input_size'])]

                    st.markdown("### Selecci√≥n de Caracter√≠sticas")
                    col1, col2 = st.columns(2)

                    with col1:
                        feature1 = st.selectbox(
                            "Primera caracter√≠stica:",
                            feature_names,
                            index=0,
                            key="viz_feature1_nn"
                        )

                    with col2:
                        feature2 = st.selectbox(
                            "Segunda caracter√≠stica:",
                            feature_names,
                            index=min(1, len(feature_names) - 1),
                            key="viz_feature2_nn"
                        )

                    if feature1 != feature2:
                        # Obtener datos de test para la visualizaci√≥n
                        X_test, y_test = st.session_state.nn_test_data

                        # Obtener √≠ndices de las caracter√≠sticas seleccionadas
                        feature_idx = [feature_names.index(
                            feature1), feature_names.index(feature2)]

                        # Extraer las caracter√≠sticas seleccionadas
                        X_2d = X_test[:, feature_idx]

                        # Generar superficie de decisi√≥n
                        try:
                            st.info("üé® Generando superficie de decisi√≥n...")

                            # Crear malla de puntos para la superficie
                            h = 0.02  # tama√±o del paso en la malla
                            x_min, x_max = X_2d[:, 0].min(
                            ) - 0.5, X_2d[:, 0].max() + 0.5
                            y_min, y_max = X_2d[:, 1].min(
                            ) - 0.5, X_2d[:, 1].max() + 0.5
                            xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                                                 np.arange(y_min, y_max, h))

                            # Para hacer predicciones en la malla, necesitamos crear puntos completos
                            # con valores promedio para las caracter√≠sticas no seleccionadas
                            X_full_test = X_test.copy()
                            mesh_points = []

                            for i in range(xx.ravel().shape[0]):
                                # Usar valores promedio
                                point = np.mean(X_full_test, axis=0)
                                # Primera caracter√≠stica seleccionada
                                point[feature_idx[0]] = xx.ravel()[i]
                                # Segunda caracter√≠stica seleccionada
                                point[feature_idx[1]] = yy.ravel()[i]
                                mesh_points.append(point)

                            mesh_points = np.array(mesh_points)

                            # Hacer predicciones en la malla
                            Z = model.predict(mesh_points, verbose=0)

                            # Si es clasificaci√≥n multiclase, tomar la clase con mayor probabilidad
                            if len(Z.shape) > 1 and Z.shape[1] > 1:
                                Z = np.argmax(Z, axis=1)
                            else:
                                # Para clasificaci√≥n binaria
                                Z = (Z > 0.5).astype(int).ravel()

                            Z = Z.reshape(xx.shape)

                            # Crear la visualizaci√≥n
                            fig, ax = plt.subplots(figsize=(10, 8))

                            # Dibujar la superficie de decisi√≥n
                            contourf = ax.contourf(
                                xx, yy, Z, levels=50, alpha=0.8, cmap='RdYlBu')

                            # A√±adir los puntos de datos reales
                            if 'nn_class_names' in st.session_state and st.session_state.nn_class_names:
                                class_names = st.session_state.nn_class_names
                                # Mapear y_test a √≠ndices de clase si es necesario
                                if hasattr(y_test, 'shape') and len(y_test.shape) > 1:
                                    y_plot = np.argmax(y_test, axis=1)
                                else:
                                    y_plot = y_test

                                # Crear scatter plot por clase
                                unique_classes = np.unique(y_plot)
                                colors = plt.cm.Set1(
                                    np.linspace(0, 1, len(unique_classes)))

                                for i, class_idx in enumerate(unique_classes):
                                    mask = y_plot == class_idx
                                    class_name = class_names[class_idx] if class_idx < len(
                                        class_names) else f'Clase {class_idx}'
                                    ax.scatter(X_2d[mask, 0], X_2d[mask, 1],
                                               c=[colors[i]], label=class_name,
                                               edgecolors='black', s=50, alpha=0.9)
                            else:
                                ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y_test,
                                           cmap='RdYlBu', edgecolors='black', s=50, alpha=0.9)

                            # Configurar etiquetas y t√≠tulo
                            ax.set_xlabel(feature1, fontsize=12)
                            ax.set_ylabel(feature2, fontsize=12)
                            ax.set_title(
                                f'Superficie de Decisi√≥n de Red Neuronal\n{feature1} vs {feature2}', fontsize=14)
                            ax.grid(True, alpha=0.3)

                            # A√±adir leyenda si hay nombres de clase
                            if 'nn_class_names' in st.session_state and st.session_state.nn_class_names:
                                ax.legend(bbox_to_anchor=(
                                    1.05, 1), loc='upper left')

                            # A√±adir colorbar para la superficie
                            plt.colorbar(contourf, ax=ax,
                                         label='Predicci√≥n de Clase')

                            plt.tight_layout()
                            st.pyplot(fig)

                            # Informaci√≥n adicional
                            st.success(
                                "‚úÖ Superficie de decisi√≥n generada exitosamente")
                            st.info(f"""
                            üîç **Informaci√≥n de la visualizaci√≥n:**
                            - **Caracter√≠sticas mostradas:** {feature1} vs {feature2}
                            - **Otras caracter√≠sticas:** Se mantienen en sus valores promedio
                            - **Colores de fondo:** Regiones de decisi√≥n de la red neuronal
                            - **Puntos:** Datos reales de prueba
                            - **Fronteras:** L√≠mites donde la red cambia de decisi√≥n
                            """)

                            # Interpretaci√≥n de la superficie
                            with st.expander("üí° ¬øC√≥mo interpretar la superficie de decisi√≥n?"):
                                st.markdown("""
                                **Colores de fondo:**
                                - Cada color representa una clase diferente que predice la red
                                - Las transiciones suaves indican fronteras de decisi√≥n graduales
                                - Las transiciones bruscas indican fronteras m√°s definidas
                                
                                **Puntos de datos:**
                                - Muestran d√≥nde est√°n ubicados los datos reales en este espacio 2D
                                - Puntos del mismo color deber√≠an estar en regiones del mismo color de fondo
                                - Puntos en la regi√≥n "incorrecta" indican errores de clasificaci√≥n
                                
                                **Complejidad de las fronteras:**
                                - Fronteras muy complejas pueden indicar sobreajuste
                                - Fronteras muy simples pueden indicar subajuste
                                - Lo ideal son fronteras que capturen el patr√≥n sin ser excesivamente complejas
                                """)

                        except Exception as e:
                            st.error(
                                f"‚ùå Error al generar la superficie de decisi√≥n: {str(e)}")
                            st.info(
                                "üí° Intenta con diferentes caracter√≠sticas o verifica que el modelo est√© correctamente entrenado.")

                    else:
                        st.warning(
                            "‚ö†Ô∏è Por favor selecciona dos caracter√≠sticas diferentes.")

                else:
                    # Dataset con 2 o menos caracter√≠sticas - mostrar directamente
                    st.info("üé® Generando superficie de decisi√≥n...")
                    st.markdown("""
                    **Superficie de Decisi√≥n 2D:**
                    - Cada color representa una clase predicha
                    - Los puntos son tus datos de entrenamiento
                    - Las fronteras muestran c√≥mo la red separa las clases
                    - Fronteras suaves = red bien generalizada
                    - Fronteras muy complejas = posible sobreajuste
                    """)

                    # Aqu√≠ se podr√≠a implementar la visualizaci√≥n directa para datasets 2D
                    st.info(
                        "üí° Implementaci√≥n completa para datasets 2D pr√≥ximamente.")

            else:
                # Para tareas de regresi√≥n
                st.info("üèîÔ∏è **Superficie de Predicci√≥n para Regresi√≥n**")
                st.markdown("""
                Para tareas de regresi√≥n, se puede visualizar una superficie de predicci√≥n que muestra 
                c√≥mo var√≠an las predicciones num√©ricas en el espacio de caracter√≠sticas.
                """)

                if config['input_size'] > 2:
                    st.markdown(
                        "üí° Selecciona 2 caracter√≠sticas para visualizar la superficie de predicci√≥n.")
                    # Aqu√≠ se podr√≠a implementar similar l√≥gica para regresi√≥n
                    st.info(
                        "üöß Implementaci√≥n de superficie de predicci√≥n para regresi√≥n pr√≥ximamente.")
                else:
                    st.info(
                        "üöß Implementaci√≥n de superficie de predicci√≥n pr√≥ximamente.")

        with viz_tab4:
            st.subheader("üìâ An√°lisis de Capas")
            st.markdown("üî¨ **Activaciones y patrones internos de la red**")

            # Explicaci√≥n sobre activaciones
            with st.expander("üí° ¬øQu√© son las activaciones?"):
                st.markdown("""
                **Activaciones:**
                - **Valores que producen las neuronas** cuando procesan datos
                - **Primeras capas**: Detectan caracter√≠sticas b√°sicas
                - **Capas intermedias**: Combinan caracter√≠sticas en patrones
                - **√öltima capa**: Decisi√≥n final o predicci√≥n
                
                **Qu√© buscar:**
                - **Muchos ceros**: Neuronas "muertas" (problema)
                - **Valores extremos**: Saturaci√≥n (problema)
                - **Distribuci√≥n balanceada**: Red saludable ‚úÖ
                """)

            # USAR EL MODELO DE ACTIVACIONES PRE-CREADO EN LA INICIALIZACI√ìN
            try:
                # Obtener datos de test
                X_test, y_test = st.session_state.nn_test_data
                sample_size = min(100, len(X_test))
                X_sample = X_test[:sample_size]

                # Verificar que el modelo tiene suficientes capas
                if len(model.layers) <= 1:
                    st.warning(
                        "‚ö†Ô∏è El modelo tiene muy pocas capas para an√°lisis detallado")
                    return

                # VERIFICAR SI HAY MODELO DE ACTIVACIONES PRE-CREADO
                activation_model = None

                # M√©todo 1: Modelo creado durante el entrenamiento
                if hasattr(model, '_activation_model_ready'):
                    activation_model = model._activation_model_ready
                    st.success(
                        "‚úÖ Usando modelo de activaciones preparado durante el entrenamiento")

                # M√©todo 2: Modelo guardado en session_state
                elif 'activation_model' in st.session_state and st.session_state.activation_model is not None:
                    activation_model = st.session_state.activation_model
                    st.success(
                        "‚úÖ Usando modelo de activaciones de session_state")

                # M√©todo 3: Crear on-demand si no existe
                else:
                    st.info("üîß Creando modelo de activaciones...")
                    try:
                        import tensorflow as tf
                        intermediate_layers = []
                        for i, layer in enumerate(model.layers):
                            # Excluir la primera capa (Input) y la √∫ltima (Output)
                            if i > 0 and i < len(model.layers) - 1:
                                if hasattr(layer, 'output') and layer.output is not None:
                                    intermediate_layers.append(layer.output)

                        if intermediate_layers:
                            activation_model = tf.keras.Model(
                                inputs=model.input,
                                outputs=intermediate_layers
                            )
                            # Verificar que funcione
                            _ = activation_model.predict(
                                X_sample[:1], verbose=0)
                            st.session_state.activation_model = activation_model
                            st.success(
                                "‚úÖ Modelo de activaciones creado exitosamente")
                        else:
                            st.warning(
                                "‚ö†Ô∏è No hay capas intermedias v√°lidas para an√°lisis")
                            return
                    except Exception as create_error:
                        st.error(
                            f"‚ùå Error creando modelo de activaciones: {str(create_error)}")
                        st.info(
                            "üí° El modelo necesita ser reentrenado para an√°lisis de capas")
                        return

                # Si llegamos aqu√≠, tenemos un modelo de activaciones v√°lido
                if activation_model is None:
                    st.error("‚ùå No se pudo obtener modelo de activaciones")
                    return

                # Obtener activaciones usando el modelo pre-creado
                activations = activation_model.predict(X_sample, verbose=0)

                if not isinstance(activations, list):
                    activations = [activations]

                st.success(
                    f"‚úÖ An√°lisis de {len(activations)} capas completado exitosamente")

                # Mostrar estad√≠sticas por capa
                for i, activation in enumerate(activations):
                    st.markdown(f"#### üìä Capa {i+1} - Activaciones")

                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("üî• Media", f"{np.mean(activation):.4f}")
                    with col2:
                        st.metric("üìä Desv. Std.", f"{np.std(activation):.4f}")
                    with col3:
                        dead_ratio = np.mean(activation == 0) * 100
                        st.metric("üíÄ % Neuronas Muertas", f"{dead_ratio:.1f}%")
                    with col4:
                        saturated_ratio = np.mean(activation >= 0.99) * 100
                        st.metric("üî¥ % Saturadas", f"{saturated_ratio:.1f}%")

                    # Interpretaci√≥n de la salud
                    if dead_ratio > 50:
                        st.error(
                            f"üö® **Problema en Capa {i+1}**: Muchas neuronas muertas")
                    elif dead_ratio > 20:
                        st.warning(
                            f"‚ö†Ô∏è **Atenci√≥n en Capa {i+1}**: Algunas neuronas muertas")
                    else:
                        st.success(
                            f"‚úÖ **Capa {i+1} Saludable**: Buena activaci√≥n")

            except Exception as e:
                error_msg = str(e)
                if "never been called" in error_msg or "no defined input" in error_msg:
                    st.error(
                        "üö® **Error de Inicializaci√≥n del Modelo Sequential**")
                    st.markdown("""
                    **¬øQu√© significa este error?**
                    - El modelo Sequential de TensorFlow no ha sido completamente inicializado
                    - Las capas no conocen el tama√±o de sus entradas
                    - Se necesita hacer al menos una predicci√≥n para construir el modelo
                    
                    **Soluci√≥n Autom√°tica:**
                    La funci√≥n incluye reparaci√≥n autom√°tica que deber√≠a resolver esto.
                    Si persiste, usa el bot√≥n de 'Reparar Modelo' en la secci√≥n de errores abajo.
                    """)
                    st.info(
                        "üí° **Tip:** Este error es com√∫n con modelos Sequential reci√©n cargados y tiene soluci√≥n autom√°tica.")
                else:
                    st.error(f"‚ùå Error inesperado en el an√°lisis: {str(e)}")
                    st.info(
                        "üîß Esto puede indicar un problema con la arquitectura del modelo.")

                st.markdown(f"**Error t√©cnico:** {error_msg}")

        # Bot√≥n para generar c√≥digo de visualizaci√≥n
        st.markdown("### üíª C√≥digo Python")
        if st.button("üìù Generar C√≥digo de Visualizaci√≥n", use_container_width=True):
            code = generate_neural_network_visualization_code(config)
            st.markdown("#### üêç C√≥digo Python para Visualizaciones")
            st.code(code, language='python')

            st.download_button(
                label="üíæ Descargar C√≥digo de Visualizaci√≥n",
                data=code,
                file_name="visualizaciones_red_neuronal.py",
                mime="text/plain"
            )

        # Navegaci√≥n
        st.markdown("---")
        st.markdown("### üß≠ Navegaci√≥n")
        col_nav1, col_nav2 = st.columns(2)
        with col_nav1:
            if st.button("üîô Volver a Evaluaci√≥n", use_container_width=True):
                st.session_state.active_tab_nn = 3
                st.rerun()
        with col_nav2:
            if st.button("üîÆ Hacer Predicciones", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 5
                st.rerun()

    except Exception as e:
        st.error(f"‚ùå Error en las visualizaciones: {str(e)}")

        # Diagn√≥stico detallado del error
        error_type = type(e).__name__
        error_msg = str(e)

        st.markdown("### üîç Diagn√≥stico del Error")

        if "never been called" in error_msg or "no defined input" in error_msg:
            st.error("üö® **Problema de Inicializaci√≥n del Modelo**")
            st.markdown("""
            **Causa del problema:**
            - El modelo Sequential no ha sido completamente inicializado
            - Las capas no tienen sus formas de entrada definidas
            - Se necesita hacer al menos una predicci√≥n para construir el modelo
            """)

            # Bot√≥n de reparaci√≥n autom√°tica
            col1, col2 = st.columns(2)

            with col1:
                if st.button("üîß Reparar Modelo Autom√°ticamente", type="primary", key="auto_repair"):
                    try:
                        st.info("üîÑ Iniciando reparaci√≥n exhaustiva del modelo...")

                        # Obtener datos de test
                        if 'nn_test_data' in st.session_state:
                            X_test, y_test = st.session_state.nn_test_data

                            # Forzar construcci√≥n del modelo con m√∫ltiples estrategias MEJORADAS
                            with st.spinner("Aplicando estrategias de reparaci√≥n..."):
                                progress_bar = st.progress(0)

                                # Estrategia 1: Predicci√≥n simple
                                progress_bar.progress(20)
                                _ = model.predict(X_test[:1], verbose=0)

                                # Estrategia 2: Llamada directa al modelo
                                progress_bar.progress(40)
                                _ = model(X_test[:1])

                                # Estrategia 3: Predicci√≥n con batch m√°s grande
                                progress_bar.progress(60)
                                batch_size = min(10, len(X_test))
                                _ = model.predict(
                                    X_test[:batch_size], verbose=0)

                                # Estrategia 4: Compilar expl√≠citamente si es necesario
                                progress_bar.progress(80)
                                if not model.built:
                                    model.build(input_shape=(
                                        None, X_test.shape[1]))

                                # Estrategia 5: Verificar input tensor
                                if model.input is None:
                                    model._set_inputs(X_test[:1])

                                # Estrategia 6: Forzar todas las capas
                                for i, layer in enumerate(model.layers):
                                    if hasattr(layer, 'built') and not layer.built:
                                        if i == 0:
                                            layer.build(input_shape=(
                                                None, X_test.shape[1]))
                                        else:
                                            prev_output = model.layers[i -
                                                                       1].output_shape
                                            layer.build(prev_output)

                                progress_bar.progress(100)

                            # Verificaci√≥n EXHAUSTIVA que el modelo est√© funcionando
                            st.info("‚úÖ Verificando reparaci√≥n...")

                            # Test m√∫ltiples operaciones
                            test_pred = model.predict(X_test[:5], verbose=0)
                            _ = model.get_weights()

                            # Test cr√≠tico: modelo de activaciones
                            if len(model.layers) > 1:
                                layer_outputs = [
                                    layer.output for layer in model.layers[:-1]]
                                test_activation_model = tf.keras.Model(
                                    inputs=model.input, outputs=layer_outputs)
                                _ = test_activation_model.predict(
                                    X_test[:1], verbose=0)

                            st.success("üéâ ¬°Modelo reparado exitosamente!")
                            st.info(
                                "‚úÖ El modelo est√° completamente inicializado y listo para todas las visualizaciones.")

                            # Bot√≥n para recargar visualizaciones
                            if st.button("üîÑ Recargar Visualizaciones", type="primary"):
                                st.rerun()

                        else:
                            st.error(
                                "‚ùå No se encontraron datos de test para reparar el modelo")

                    except Exception as repair_error:
                        st.error(
                            f"‚ùå Error durante la reparaci√≥n: {repair_error}")

                        # Diagn√≥stico espec√≠fico del error
                        if "never been called" in str(repair_error):
                            st.warning(
                                "üîß **Error persistente de inicializaci√≥n**")
                            st.markdown("""
                            **Estrategias adicionales:**
                            1. Reinicia la aplicaci√≥n completamente
                            2. Reentrena el modelo desde cero  
                            3. Verifica que TensorFlow est√© actualizado
                            4. Prueba con un dataset m√°s peque√±o
                            """)
                        else:
                            st.info("üí° Intenta reentrenar el modelo desde cero.")

            with col2:
                st.markdown("**üí° Soluci√≥n manual:**")
                st.markdown("""
                1. Ve a la pesta√±a **'Entrenamiento'**
                2. Reentrena el modelo desde cero
                3. Regresa a esta pesta√±a
                4. Las visualizaciones deber√≠an funcionar
                """)

                if st.button("üîô Ir a Entrenamiento", key="go_training"):
                    st.session_state.active_tab_nn = 2
                    st.rerun()

        else:
            # Otros tipos de errores
            st.warning("‚ö†Ô∏è **Error Inesperado**")
            st.code(f"Tipo: {error_type}\nMensaje: {error_msg}")

            st.markdown("""
            **Posibles soluciones:**
            - Verifica que TensorFlow est√© instalado correctamente
            - Aseg√∫rate de que el modelo est√© entrenado
            - Intenta reentrenar el modelo
            - Reinicia la aplicaci√≥n si persiste el problema
            """)

        # Informaci√≥n t√©cnica adicional
        with st.expander("üî¨ Informaci√≥n T√©cnica Detallada"):
            try:
                st.write("**Estado del Modelo:**")
                st.write(f"- Tipo: {type(model).__name__}")
                st.write(
                    f"- Construido: {getattr(model, 'built', 'No disponible')}")
                st.write(
                    f"- N√∫mero de capas: {len(model.layers) if hasattr(model, 'layers') else 'No disponible'}")

                if hasattr(model, 'input'):
                    st.write(
                        f"- Input definido: {'‚úÖ' if model.input is not None else '‚ùå'}")

                if hasattr(model, 'layers'):
                    st.write("**Estado de las Capas:**")
                    for i, layer in enumerate(model.layers):
                        layer_built = getattr(layer, 'built', False)
                        st.write(
                            f"  - Capa {i+1} ({layer.__class__.__name__}): {'‚úÖ' if layer_built else '‚ùå'}")

            except Exception as debug_error:
                st.write(f"Error obteniendo informaci√≥n: {debug_error}")

        st.info("üí° **Tip**: Este error es com√∫n con modelos Sequential. La reparaci√≥n autom√°tica deber√≠a resolverlo.")


def show_neural_network_predictions():
    """Interfaz para hacer predicciones con el modelo entrenado."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "‚ö†Ô∏è Primero debes entrenar un modelo en la pesta√±a 'Entrenamiento'")
        return

    try:
        import numpy as np
        import pandas as pd
        import scipy.stats

        model = st.session_state.nn_model
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        if 'nn_df' not in st.session_state or 'nn_target_col' not in st.session_state:
            st.error("No hay datos disponibles para hacer predicciones.")
            return

        df = st.session_state.nn_df
        target_col = st.session_state.nn_target_col
        feature_cols = [col for col in df.columns if col != target_col]

        st.header("üéØ Hacer Predicciones")

        # Tabs para diferentes tipos de predicci√≥n
        pred_tab1, pred_tab2, pred_tab3 = st.tabs([
            "üîç Predicci√≥n Individual",
            "üìä Predicci√≥n por Lotes",
            "üé≤ Exploraci√≥n Interactiva"
        ])

        with pred_tab1:
            st.subheader("üîç Predicci√≥n Individual")
            st.markdown("Introduce los valores para cada caracter√≠stica:")

            # Crear inputs para cada caracter√≠stica
            input_values = {}

            # Organizar en columnas
            num_cols = min(3, len(feature_cols))
            cols = st.columns(num_cols)

            for i, feature in enumerate(feature_cols):
                col_idx = i % num_cols

                with cols[col_idx]:
                    # Obtener estad√≠sticas de la caracter√≠stica
                    min_val = float(df[feature].min())
                    max_val = float(df[feature].max())
                    mean_val = float(df[feature].mean())

                    input_values[feature] = st.number_input(
                        f"{feature}",
                        min_value=min_val,
                        max_value=max_val,
                        value=mean_val,
                        step=(max_val - min_val) / 100,
                        key=f"nn_pred_{feature}"
                    )

                    st.caption(
                        f"Min: {min_val:.2f}, Max: {max_val:.2f}, Media: {mean_val:.2f}")

            # Bot√≥n para hacer predicci√≥n
            if st.button("üöÄ Hacer Predicci√≥n", type="primary"):
                # Preparar datos para predicci√≥n
                input_array = np.array(
                    [[input_values[feature] for feature in feature_cols]])
                input_scaled = scaler.transform(input_array)

                # Hacer predicci√≥n
                prediction = model.predict(input_scaled, verbose=0)

                # Mostrar resultados
                st.success("‚úÖ Predicci√≥n completada")

                if config['task_type'] == 'Clasificaci√≥n':
                    output_size = safe_get_output_size(config)
                    if output_size > 2:  # Multiclase
                        predicted_class_idx = np.argmax(prediction[0])
                        confidence = prediction[0][predicted_class_idx]

                        if label_encoder:
                            predicted_class = label_encoder.inverse_transform(
                                [predicted_class_idx])[0]
                        else:
                            predicted_class = f"Clase {predicted_class_idx}"

                        # Mostrar resultado principal
                        col1, col2 = st.columns(2)

                        with col1:
                            st.metric("üéØ Clase Predicha", predicted_class)

                        with col2:
                            st.metric(
                                "üé≤ Confianza", f"{confidence:.4f}", f"{confidence*100:.2f}%")

                        # Mostrar probabilidades para todas las clases
                        st.subheader("üìä Probabilidades por Clase")

                        prob_data = []
                        for i, prob in enumerate(prediction[0]):
                            if label_encoder:
                                class_name = label_encoder.inverse_transform([i])[
                                    0]
                            else:
                                class_name = f"Clase {i}"

                            prob_data.append({
                                'Clase': class_name,
                                'Probabilidad': f"{prob:.4f}",
                                'Porcentaje': f"{prob*100:.2f}%"
                            })

                        st.dataframe(prob_data, use_container_width=True)

                        # Gr√°fico de barras de probabilidades
                        import plotly.graph_objects as go

                        class_names = [item['Clase'] for item in prob_data]
                        probabilities = [float(item['Probabilidad'])
                                         for item in prob_data]

                        fig = go.Figure(data=[
                            go.Bar(x=class_names, y=probabilities,
                                   marker_color=['red' if i == predicted_class_idx else 'lightblue'
                                                 for i in range(len(class_names))])
                        ])

                        fig.update_layout(
                            title="Distribuci√≥n de Probabilidades",
                            xaxis_title="Clases",
                            yaxis_title="Probabilidad",
                            height=400
                        )

                        st.plotly_chart(fig, use_container_width=True)

                    else:  # Binaria
                        probability = prediction[0][0]
                        predicted_class_idx = 1 if probability > 0.5 else 0

                        if label_encoder:
                            predicted_class = label_encoder.inverse_transform(
                                [predicted_class_idx])[0]
                        else:
                            predicted_class = f"Clase {predicted_class_idx}"

                        col1, col2, col3 = st.columns(3)

                        with col1:
                            st.metric("üéØ Clase Predicha", predicted_class)

                        with col2:
                            st.metric("üé≤ Probabilidad", f"{probability:.4f}")

                        with col3:
                            confidence = max(probability, 1 - probability)
                            st.metric(
                                "‚ú® Confianza", f"{confidence:.4f}", f"{confidence*100:.2f}%")

                else:  # Regresi√≥n
                    predicted_value = prediction[0][0]

                    st.metric("üéØ Valor Predicho", f"{predicted_value:.6f}")

                    # Informaci√≥n adicional para regresi√≥n
                    target_stats = df[target_col].describe()

                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.info(f"üìä **Estad√≠sticas del Target:**\n"
                                f"- Media: {target_stats['mean']:.4f}\n"
                                f"- Mediana: {target_stats['50%']:.4f}")

                    with col2:
                        st.info(f"üìè **Rango de Datos:**\n"
                                f"- M√≠nimo: {target_stats['min']:.4f}\n"
                                f"- M√°ximo: {target_stats['max']:.4f}")

                    with col3:
                        deviation_from_mean = abs(
                            predicted_value - target_stats['mean'])
                        st.info(f"üéØ **An√°lisis:**\n"
                                f"- Desviaci√≥n de la media: {deviation_from_mean:.4f}\n"
                                f"- Percentil aproximado: {scipy.stats.percentileofscore(df[target_col], predicted_value):.1f}%")

        with pred_tab2:
            st.subheader("üìä Predicci√≥n por Lotes")

            st.markdown(
                "Sube un archivo CSV con nuevos datos para hacer predicciones en lote:")

            uploaded_file = st.file_uploader(
                "Selecciona archivo CSV",
                type=['csv'],
                key="nn_batch_predictions"
            )

            if uploaded_file is not None:
                try:
                    # Cargar datos
                    new_df = pd.read_csv(uploaded_file)

                    st.success(
                        f"‚úÖ Archivo cargado: {new_df.shape[0]} filas, {new_df.shape[1]} columnas")

                    # Verificar que las columnas coincidan
                    missing_features = set(feature_cols) - set(new_df.columns)
                    extra_features = set(new_df.columns) - set(feature_cols)

                    if missing_features:
                        st.error(
                            f"‚ùå Faltan caracter√≠sticas: {', '.join(missing_features)}")
                    elif extra_features:
                        st.warning(
                            f"‚ö†Ô∏è Caracter√≠sticas adicionales (ser√°n ignoradas): {', '.join(extra_features)}")
                        # Seleccionar solo las caracter√≠sticas necesarias
                        new_df = new_df[feature_cols]

                    if not missing_features:
                        # Mostrar vista previa
                        st.dataframe(new_df.head(), use_container_width=True)

                        if st.button("üöÄ Generar Predicciones", type="primary"):
                            # Procesar datos
                            new_data_scaled = scaler.transform(new_df)

                            # Hacer predicciones
                            batch_predictions = model.predict(
                                new_data_scaled, verbose=0)

                            # Procesar resultados seg√∫n el tipo de tarea
                            if config['task_type'] == 'Clasificaci√≥n':
                                output_size = safe_get_output_size(config)
                                if output_size > 2:
                                    predicted_classes_idx = np.argmax(
                                        batch_predictions, axis=1)
                                    confidences = np.max(
                                        batch_predictions, axis=1)

                                    if label_encoder:
                                        predicted_classes = label_encoder.inverse_transform(
                                            predicted_classes_idx)
                                    else:
                                        predicted_classes = [
                                            f"Clase {idx}" for idx in predicted_classes_idx]

                                    results_df = new_df.copy()
                                    results_df['Predicci√≥n'] = predicted_classes
                                    results_df['Confianza'] = confidences

                                else:  # Binaria
                                    probabilities = batch_predictions.flatten()
                                    predicted_classes_idx = (
                                        probabilities > 0.5).astype(int)
                                    confidences = np.maximum(
                                        probabilities, 1 - probabilities)

                                    if label_encoder:
                                        predicted_classes = label_encoder.inverse_transform(
                                            predicted_classes_idx)
                                    else:
                                        predicted_classes = [
                                            f"Clase {idx}" for idx in predicted_classes_idx]

                                    results_df = new_df.copy()
                                    results_df['Predicci√≥n'] = predicted_classes
                                    results_df['Probabilidad'] = probabilities
                                    results_df['Confianza'] = confidences

                            else:  # Regresi√≥n
                                predicted_values = batch_predictions.flatten()

                                results_df = new_df.copy()
                                results_df['Predicci√≥n'] = predicted_values

                            # Mostrar resultados
                            st.success(
                                f"‚úÖ Predicciones generadas para {len(results_df)} muestras")
                            st.dataframe(results_df, use_container_width=True)

                            # Bot√≥n para descargar resultados
                            csv_results = results_df.to_csv(index=False)
                            st.download_button(
                                label="üì• Descargar Resultados",
                                data=csv_results,
                                file_name="predicciones_neural_network.csv",
                                mime="text/csv"
                            )

                except Exception as e:
                    st.error(f"Error procesando archivo: {str(e)}")

            else:
                # Mostrar formato esperado
                st.info("üìã **Formato esperado del archivo CSV:**")

                sample_data = df[feature_cols].head(3)
                st.dataframe(sample_data, use_container_width=True)

                st.markdown(
                    "El archivo debe contener las siguientes columnas:")
                st.code(", ".join(feature_cols))

        with pred_tab3:
            st.subheader("üé≤ Exploraci√≥n Interactiva")

            # Informaci√≥n educativa sobre la exploraci√≥n interactiva
            with st.expander("‚ÑπÔ∏è ¬øQu√© es la Exploraci√≥n Interactiva?", expanded=False):
                st.markdown("""
                **La exploraci√≥n interactiva** te permite entender c√≥mo el modelo neural toma decisiones:
                
                üîç **¬øPara qu√© sirve?**
                - Ver c√≥mo cada caracter√≠stica influye en las predicciones
                - Identificar patrones y comportamientos del modelo
                - Detectar posibles sesgos o comportamientos inesperados
                - Comprender la sensibilidad del modelo a cambios en los datos
                
                üìä **¬øC√≥mo interpretar los resultados?**
                - **L√≠neas ascendentes**: La caracter√≠stica tiene correlaci√≥n positiva
                - **L√≠neas descendentes**: La caracter√≠stica tiene correlaci√≥n negativa  
                - **L√≠neas planas**: La caracter√≠stica tiene poco impacto
                - **Cambios abruptos**: Puntos de decisi√≥n cr√≠ticos del modelo
                
                üí° **Consejos de uso:**
                - Prueba diferentes muestras base para ver patrones generales
                - Observa qu√© caracter√≠sticas causan mayores cambios
                - Busca comportamientos inesperados o poco realistas
                """)

            st.markdown(
                "üéØ **Explora c√≥mo cambian las predicciones al modificar diferentes caracter√≠sticas:**")

            # Seleccionar una muestra base
            st.markdown("**1. üìç Selecciona una muestra base:**")

            st.info("üí° **Tip:** La muestra base es tu punto de referencia. Todas las exploraciones mostrar√°n c√≥mo cambian las predicciones desde este punto inicial.")

            sample_idx = st.selectbox(
                "√çndice de muestra:",
                range(len(df)),
                format_func=lambda x: f"Muestra {x}",
                key="nn_interactive_sample"
            )

            base_sample = df.iloc[sample_idx][feature_cols].to_dict()

            # Mostrar valores base
            st.markdown("**2. üìã Valores base de la muestra:**")
            st.caption(
                "Estos son los valores de todas las caracter√≠sticas para la muestra seleccionada:")
            base_df = pd.DataFrame([base_sample])
            st.dataframe(base_df, use_container_width=True)

            # Hacer predicci√≥n base
            base_array = np.array([[base_sample[feature]
                                  for feature in feature_cols]])
            base_scaled = scaler.transform(base_array)
            base_prediction = model.predict(base_scaled, verbose=0)

            if config['task_type'] == 'Clasificaci√≥n':
                output_size = safe_get_output_size(config)
                if output_size > 2:
                    base_class_idx = np.argmax(base_prediction[0])
                    base_confidence = base_prediction[0][base_class_idx]

                    if label_encoder:
                        base_class = label_encoder.inverse_transform([base_class_idx])[
                            0]
                    else:
                        base_class = f"Clase {base_class_idx}"

                    st.info(
                        f"üéØ **Predicci√≥n Base:** {base_class} (Confianza: {base_confidence:.3f})")
                else:
                    base_prob = base_prediction[0][0]
                    base_class_idx = 1 if base_prob > 0.5 else 0

                    if label_encoder:
                        base_class = label_encoder.inverse_transform([base_class_idx])[
                            0]
                    else:
                        base_class = f"Clase {base_class_idx}"

                    st.info(
                        f"üéØ **Predicci√≥n Base:** {base_class} (Probabilidad: {base_prob:.3f})")
            else:
                base_value = base_prediction[0][0]
                st.info(f"üéØ **Predicci√≥n Base:** {base_value:.6f}")

            # Seleccionar caracter√≠stica para explorar
            st.markdown("**3. üîç Explora el efecto de una caracter√≠stica:**")

            st.info("üéØ **Objetivo:** Ver√°s c√≥mo cambia la predicci√≥n cuando modificas solo UNA caracter√≠stica, manteniendo todas las dem√°s constantes. Esto te ayuda a entender la importancia relativa de cada variable.")

            feature_to_explore = st.selectbox(
                "Caracter√≠stica a explorar:",
                feature_cols,
                key="nn_explore_feature",
                help="Selecciona la caracter√≠stica cuyo efecto quieres analizar en las predicciones"
            )

            # Crear rango de valores para la caracter√≠stica seleccionada
            min_val = float(df[feature_to_explore].min())
            max_val = float(df[feature_to_explore].max())

            # Generar valores para exploraci√≥n
            exploration_values = np.linspace(min_val, max_val, 50)
            exploration_predictions = []

            for val in exploration_values:
                # Crear muestra modificada
                modified_sample = base_sample.copy()
                modified_sample[feature_to_explore] = val

                # Hacer predicci√≥n
                modified_array = np.array(
                    [[modified_sample[feature] for feature in feature_cols]])
                modified_scaled = scaler.transform(modified_array)
                pred = model.predict(modified_scaled, verbose=0)

                if config['task_type'] == 'Clasificaci√≥n':
                    output_size = safe_get_output_size(config)
                    if output_size > 2:
                        pred_class_idx = np.argmax(pred[0])
                        confidence = pred[0][pred_class_idx]
                        exploration_predictions.append(
                            (pred_class_idx, confidence))
                    else:
                        prob = pred[0][0]
                        exploration_predictions.append(prob)
                else:
                    exploration_predictions.append(pred[0][0])

            # Crear visualizaci√≥n
            import plotly.graph_objects as go

            fig = go.Figure()

            if config['task_type'] == 'Clasificaci√≥n':
                output_size = safe_get_output_size(config)
                if output_size > 2:
                    # Multiclase: mostrar clase predicha y confianza
                    classes = [pred[0] for pred in exploration_predictions]
                    confidences = [pred[1] for pred in exploration_predictions]

                    fig.add_trace(go.Scatter(
                        x=exploration_values,
                        y=classes,
                        mode='lines+markers',
                        name='Clase Predicha',
                        yaxis='y1'
                    ))

                    fig.add_trace(go.Scatter(
                        x=exploration_values,
                        y=confidences,
                        mode='lines+markers',
                        name='Confianza',
                        yaxis='y2',
                        line=dict(color='red')
                    ))

                    fig.update_layout(
                        title=f'Efecto de {feature_to_explore} en la Predicci√≥n',
                        xaxis_title=feature_to_explore,
                        yaxis=dict(title='Clase Predicha', side='left'),
                        yaxis2=dict(title='Confianza',
                                    side='right', overlaying='y'),
                        height=500
                    )
                else:
                    # Binaria: mostrar probabilidad
                    fig.add_trace(go.Scatter(
                        x=exploration_values,
                        y=exploration_predictions,
                        mode='lines+markers',
                        name='Probabilidad'
                    ))

                    fig.add_hline(y=0.5, line_dash="dash", line_color="red",
                                  annotation_text="Umbral de decisi√≥n")

                    fig.update_layout(
                        title=f'Efecto de {feature_to_explore} en la Probabilidad',
                        xaxis_title=feature_to_explore,
                        yaxis_title='Probabilidad',
                        height=500
                    )
            else:
                # Regresi√≥n
                fig.add_trace(go.Scatter(
                    x=exploration_values,
                    y=exploration_predictions,
                    mode='lines+markers',
                    name='Predicci√≥n'
                ))

                fig.update_layout(
                    title=f'Efecto de {feature_to_explore} en la Predicci√≥n',
                    xaxis_title=feature_to_explore,
                    yaxis_title='Valor Predicho',
                    height=500
                )

            # Marcar el valor base
            base_val = base_sample[feature_to_explore]
            fig.add_vline(x=base_val, line_dash="dash", line_color="green",
                          annotation_text="Valor Base")

            st.plotly_chart(fig, use_container_width=True)

            # An√°lisis interpretativo
            st.markdown("**üìà An√°lisis de Resultados:**")

            # Calcular estad√≠sticas del efecto
            if config['task_type'] == 'Clasificaci√≥n':
                output_size = safe_get_output_size(config)
                if output_size <= 2:
                    pred_range = max(exploration_predictions) - \
                        min(exploration_predictions)
                    volatility = np.std(exploration_predictions)

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Rango de Probabilidades", f"{pred_range:.3f}",
                                  help="Diferencia entre la probabilidad m√°xima y m√≠nima observada")
                    with col2:
                        st.metric("Volatilidad", f"{volatility:.3f}",
                                  help="Qu√© tan variables son las predicciones (desviaci√≥n est√°ndar)")

                    if pred_range > 0.3:
                        st.success(
                            f"üéØ **Caracter√≠stica muy influyente:** '{feature_to_explore}' tiene un gran impacto en las predicciones")
                    elif pred_range > 0.1:
                        st.warning(
                            f"üìä **Caracter√≠stica moderadamente influyente:** '{feature_to_explore}' tiene un impacto moderado")
                    else:
                        st.info(
                            f"üìâ **Caracter√≠stica poco influyente:** '{feature_to_explore}' tiene poco impacto en las predicciones")
            else:
                pred_range = max(exploration_predictions) - \
                    min(exploration_predictions)
                pred_mean = np.mean(exploration_predictions)
                relative_impact = (pred_range / abs(pred_mean)
                                   ) * 100 if pred_mean != 0 else 0

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Rango de Predicciones", f"{pred_range:.6f}")
                with col2:
                    st.metric("Impacto Relativo", f"{relative_impact:.1f}%")

                if relative_impact > 20:
                    st.success(
                        f"üéØ **Caracter√≠stica muy influyente:** '{feature_to_explore}' causa cambios significativos")
                elif relative_impact > 5:
                    st.warning(
                        f"üìä **Caracter√≠stica moderadamente influyente:** '{feature_to_explore}' tiene impacto moderado")
                else:
                    st.info(
                        f"üìâ **Caracter√≠stica poco influyente:** '{feature_to_explore}' tiene poco impacto")

            # Consejos interpretativos
            with st.expander("üí° Consejos para Interpretar los Resultados", expanded=False):
                st.markdown(f"""
                **üîç Analizando '{feature_to_explore}':**
                
                ‚úÖ **Buenas se√±ales:**
                - Cambios graduales y suaves en las predicciones
                - Comportamiento consistente con el conocimiento del dominio
                - Relaciones monot√≥nicas (siempre creciente o decreciente)
                
                ‚ö†Ô∏è **Se√±ales de alerta:**
                - Cambios muy abruptos sin explicaci√≥n l√≥gica
                - Comportamientos contradictorios al conocimiento experto
                - Excesiva sensibilidad a peque√±os cambios
                
                **üéØ Pr√≥ximos pasos:**
                1. Prueba con diferentes muestras base para confirmar patrones
                2. Explora otras caracter√≠sticas para comparar importancias
                3. Si encuentras comportamientos extra√±os, considera reentrenar el modelo
                4. Documenta los insights para mejorar futuras versiones del modelo
                """)

    except Exception as e:
        st.error(f"Error en las predicciones: {str(e)}")
        st.info("Aseg√∫rate de que el modelo est√© entrenado correctamente.")


def safe_get_output_size(config):
    """
    Extrae el tama√±o de salida de forma segura para evitar errores de comparaci√≥n de arrays.
    """
    try:
        output_size = config['output_size']
        # Si es un array o lista, tomar el primer elemento
        if hasattr(output_size, '__len__') and not isinstance(output_size, (str, bytes)):
            return int(output_size[0]) if len(output_size) > 0 else 1
        # Si es un escalar
        return int(output_size)
    except:
        return 1
