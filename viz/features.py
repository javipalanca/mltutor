import streamlit as st
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from sklearn.inspection import permutation_importance


def display_feature_importance(model, feature_names, X_test=None, y_test=None, task_type="Clasificaci칩n"):
    """
    Muestra la importancia de las caracter칤sticas de forma inteligente seg칰n el modelo.
    Funciona con 치rboles de decisi칩n, KNN, regresi칩n y cualquier modelo de sklearn.
    """
    st.markdown("### Importancia de Caracter칤sticas")

    # Determinar qu칠 m칠todo usar para calcular importancia
    if hasattr(model, 'feature_importances_'):
        # Modelos con importancia nativa (치rboles, random forest, etc.)
        importances = model.feature_importances_
        method = "Importancia Nativa del Modelo"
        method_description = "Basada en la reducci칩n de impureza (Gini/Entropy) o varianza (MSE) durante la construcci칩n del 치rbol."

    elif X_test is not None and y_test is not None:
        # Usar permutation importance para modelos sin importancia nativa (KNN, etc.)
        st.info(
            "游댃 Calculando Permutation Importance... Esto puede tomar unos segundos.")

        try:
            

            # Calcular permutation importance
            with st.spinner("Calculando importancia por permutaci칩n..."):
                perm_imp = permutation_importance(
                    model, X_test, y_test,
                    n_repeats=10,
                    random_state=42,
                    n_jobs=-1  # Usar todos los cores disponibles
                )

            importances = perm_imp.importances_mean
            importances_std = perm_imp.importances_std
            method = "Permutation Importance"
            method_description = "Mide cu치nto disminuye el rendimiento del modelo cuando se permutan aleatoriamente los valores de cada caracter칤stica."

            # Mostrar informaci칩n adicional sobre la desviaci칩n est치ndar
            st.markdown(f"""
            **M칠todo utilizado:** {method}
            
            {method_description}
            
            游늵 **Interpretaci칩n:**
            - Valores m치s altos = mayor importancia
            - Se calcul칩 con 10 repeticiones para mayor robustez
            - Las barras de error muestran la variabilidad entre repeticiones
            """)

        except Exception as e:
            st.error(f"Error al calcular Permutation Importance: {str(e)}")
            st.info(
                "游눠 Aseg칰rate de que el modelo est칠 entrenado y los datos de prueba sean v치lidos.")
            return
    else:
        st.warning("""
        丘멆잺 **No se puede calcular la importancia de caracter칤sticas**
        
        Este modelo no tiene importancia nativa y no se proporcionaron datos de prueba.
        
        **Para ver la importancia de caracter칤sticas necesitas:**
        - Modelos con importancia nativa (츼rboles de Decisi칩n, Random Forest, etc.), O
        - Datos de prueba (X_test, y_test) para calcular Permutation Importance
        """)
        return

    # Crear DataFrame para ordenar
    feature_importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': importances
    }).sort_values('importance', ascending=True)

    # A침adir desviaci칩n est치ndar si est치 disponible
    if 'importances_std' in locals():
        feature_importance_df['std'] = importances_std[feature_importance_df.index]

    # Crear visualizaci칩n
    fig, ax = plt.subplots(figsize=(12, max(8, len(feature_names) * 0.4)))

    # Barplot horizontal con barras de error si est치n disponibles
    if 'importances_std' in locals():
        bars = ax.barh(
            feature_importance_df['feature'],
            feature_importance_df['importance'],
            xerr=feature_importance_df['std'],
            capsize=3,
            alpha=0.8
        )
    else:
        bars = ax.barh(
            feature_importance_df['feature'],
            feature_importance_df['importance'],
            alpha=0.8
        )

    # Colorear barras con gradiente
    colors = plt.cm.viridis(np.linspace(0, 1, len(bars)))
    for bar, color in zip(bars, colors):
        bar.set_color(color)

    # Configuraci칩n del gr치fico
    ax.set_xlabel('Importancia')
    ax.set_title(f'Importancia de Caracter칤sticas\n({method})')
    ax.grid(True, alpha=0.3, axis='x')

    # A침adir valores en las barras
    for i, (feature, importance) in enumerate(zip(feature_importance_df['feature'], feature_importance_df['importance'])):
        # Posicionar el texto ligeramente a la derecha de la barra
        text_x = importance + (ax.get_xlim()[1] * 0.01)
        ax.text(text_x, i, f'{importance:.3f}', va='center', fontsize=9)

    # Ajustar layout
    plt.tight_layout()
    st.pyplot(fig, use_container_width=True)

    # Mostrar tabla con los valores
    st.markdown("### Valores Detallados")
    importance_table = feature_importance_df.sort_values(
        'importance', ascending=False)
    importance_table['importance'] = importance_table['importance'].round(4)

    # A침adir columna de desviaci칩n est치ndar si est치 disponible
    if 'std' in importance_table.columns:
        importance_table['std'] = importance_table['std'].round(4)
        importance_table = importance_table.rename(columns={
            'feature': 'Caracter칤stica',
            'importance': 'Importancia',
            'std': 'Desv. Est치ndar'
        })
    else:
        importance_table = importance_table.rename(columns={
            'feature': 'Caracter칤stica',
            'importance': 'Importancia'
        })

    st.dataframe(importance_table, use_container_width=True)

    # Interpretaci칩n espec칤fica seg칰n el modelo y tarea
    with st.expander("游닀 C칩mo interpretar estos resultados", expanded=False):
        if hasattr(model, 'feature_importances_'):
            if task_type == "Clasificaci칩n":
                st.markdown("""
                **Importancia Nativa - Clasificaci칩n:**
                - Mide cu치nto contribuye cada caracter칤stica a reducir la impureza (Gini o Entropy)
                - Valores m치s altos = m치s 칰tiles para separar las clases
                - La suma de todas las importancias = 1.0
                """)
            else:  # Regresi칩n
                st.markdown("""
                **Importancia Nativa - Regresi칩n:**
                - Mide cu치nto contribuye cada caracter칤stica a reducir la varianza (MSE)
                - Valores m치s altos = m치s 칰tiles para predecir el valor objetivo
                - La suma de todas las importancias = 1.0
                """)
        else:
            st.markdown("""
            **Permutation Importance:**
            - Mide cu치nto empeora el modelo cuando se "rompe" cada caracter칤stica
            - Valores m치s altos = el modelo depende m치s de esa caracter칤stica
            - Valores pueden ser negativos (caracter칤stica confunde al modelo)
            - La desviaci칩n est치ndar indica la estabilidad de la medici칩n
            """)

        st.markdown("""
        **Consejos generales:**
        - Caracter칤sticas con importancia muy baja pueden ser eliminadas
        - Caracter칤sticas con alta importancia son cr칤ticas para el modelo
        - Usar estos resultados para selecci칩n de caracter칤sticas o interpretabilidad
        """)

