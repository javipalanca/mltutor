from utils import (
    get_image_download_link, generate_model_code, export_model_pickle, export_model_onnx,
    create_info_box, format_number, show_code_with_download
)
from tree_visualizer import (
    render_tree_visualization,
    create_tree_visualization, get_tree_text
)
from ui import (
    setup_page, init_session_state, show_welcome_page,
    display_feature_importance, display_model_export_options, create_prediction_interface
)
from sklearn.model_selection import train_test_split
from decision_boundary import plot_decision_boundary
from model_evaluation import evaluate_classification_model, evaluate_regression_model, show_detailed_evaluation
from model_training import train_decision_tree, predict_sample, train_linear_model, train_knn_model
from dataset_manager import load_data, preprocess_data, create_dataset_selector, load_dataset_from_file
import io
import base64
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import streamlit as st


def run_knn_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de K-Nearest Neighbors (KNN) para clasificaci√≥n y regresi√≥n."""
    import streamlit as st
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt

    st.header("üîç K-Nearest Neighbors (KNN)")
    st.markdown("Aprende sobre K-vecinos m√°s cercanos de forma interactiva.")

    # Explicaci√≥n te√≥rica
    with st.expander("‚ÑπÔ∏è ¬øQu√© es K-Nearest Neighbors?", expanded=False):
        st.markdown("""
        K-Nearest Neighbors (KNN) es un algoritmo supervisado que predice la clase o el valor de una muestra bas√°ndose en las muestras m√°s cercanas en el espacio de caracter√≠sticas.

        **Caracter√≠sticas principales:**
        - No requiere entrenamiento expl√≠cito (modelo perezoso)
        - Puede usarse para clasificaci√≥n y regresi√≥n
        - La predicci√≥n depende de la distancia a los vecinos m√°s cercanos
        - Sensible a la escala de los datos y a la elecci√≥n de K
        """)

    # Variables para almacenar datos
    dataset_loaded = False
    X, y, feature_names, class_names, dataset_info, task_type = None, None, None, None, None, None

    # Inicializar el estado de la pesta√±a activa si no existe
    if 'active_tab_knn' not in st.session_state:
        st.session_state.active_tab_knn = 0

    # Crear pesta√±as para organizar la informaci√≥n
    tab_options = [
        "üìä Datos",
        "üèãÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üìâ Visualizaci√≥n",
        "üîÆ Predicciones"
    ]

    tab_cols = st.columns(len(tab_options))

    # Estilo CSS para los botones de pesta√±as (KNN)
    st.markdown("""
    <style>
    div.tab-button-knn > button {
        border-radius: 4px 4px 0 0;
        padding: 10px;
        width: 100%;
        white-space: nowrap;
        background-color: #F0F2F6;
        border-bottom: 2px solid #E0E0E0;
        color: #333333;
    }
    div.tab-button-knn-active > button {
        background-color: #E3F2FD !important;
        border-bottom: 2px solid #1E88E5 !important;
        font-weight: bold !important;
        color: #1E88E5 !important;
    }
    div.tab-button-knn > button:hover {
        background-color: #E8EAF6;
    }
    </style>
    """, unsafe_allow_html=True)

    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_knn_{i}"
        button_style = "tab-button-knn-active" if st.session_state.active_tab_knn == i else "tab-button-knn"
        is_active = st.session_state.active_tab_knn == i
        with col:
            st.markdown(f"<div class='{button_style}'>",
                        unsafe_allow_html=True)
            if st.button(tab_name, key=button_key, use_container_width=True, type="primary" if is_active else "secondary"):
                st.session_state.active_tab_knn = i
                st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    # Separador visual
    st.markdown("---")

    # SELECTOR UNIFICADO DE DATASET (solo mostrar en pesta√±as que lo necesiten)
    # Exploraci√≥n y Entrenamiento
    if st.session_state.active_tab_knn in [0, 1]:
        st.markdown("### üìä Selecci√≥n de Dataset")

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset_knn' not in st.session_state:
            st.session_state.selected_dataset_knn = "üå∏ Iris - Clasificaci√≥n de flores"

        # Lista base de datasets predefinidos
        builtin_datasets = [
            "üå∏ Iris - Clasificaci√≥n de flores",
            "üç∑ Vino - Clasificaci√≥n de vinos",
            "üî¨ C√°ncer - Diagn√≥stico binario",
            "üö¢ Titanic - Supervivencia",
            "üí∞ Propinas - Predicci√≥n de propinas",
            "üè† Viviendas California - Precios",
            "üêß Ping√ºinos - Clasificaci√≥n de especies"
        ]

        # A√±adir datasets CSV cargados si existen
        available_datasets = builtin_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado est√© en la lista disponible
        if st.session_state.selected_dataset_knn not in available_datasets:
            st.session_state.selected_dataset_knn = builtin_datasets[0]

        # Selector unificado
        dataset_option = st.selectbox(
            "Dataset:",
            available_datasets,
            index=available_datasets.index(
                st.session_state.selected_dataset_knn),
            key="unified_dataset_selector_knn",
            help="El dataset seleccionado se mantendr√° entre las pesta√±as de Exploraci√≥n y Entrenamiento"
        )

        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset_knn = dataset_option

        # Separador despu√©s del selector
        st.markdown("---")
    else:
        # Para otras pesta√±as, mostrar qu√© dataset est√° seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset_knn'):
            st.info(
                f"üìä **Dataset actual:** {st.session_state.selected_dataset_knn}")
            st.markdown("---")

    # L√≥gica de cada pesta√±a (similar a los otros algoritmos)
    from dataset_manager import create_dataset_selector, load_data
    from model_training import train_knn_model
    from model_evaluation import evaluate_classification_model, evaluate_regression_model, show_detailed_evaluation
    from ui import create_prediction_interface
    import seaborn as sns

    # Estado de datos y modelo
    if 'knn_dataset' not in st.session_state:
        st.session_state.knn_dataset = None
    if 'knn_X' not in st.session_state:
        st.session_state.knn_X = None
    if 'knn_y' not in st.session_state:
        st.session_state.knn_y = None
    if 'knn_feature_names' not in st.session_state:
        st.session_state.knn_feature_names = None
    if 'knn_class_names' not in st.session_state:
        st.session_state.knn_class_names = None
    if 'knn_task_type' not in st.session_state:
        st.session_state.knn_task_type = 'Clasificaci√≥n'
    if 'knn_model' not in st.session_state:
        st.session_state.knn_model = None
    if 'knn_metrics' not in st.session_state:
        st.session_state.knn_metrics = None
    if 'knn_trained' not in st.session_state:
        st.session_state.knn_trained = False

    tab = st.session_state.active_tab_knn

    # Pesta√±a 0: Datos
    if tab == 0:
        st.header("Exploraci√≥n de Datos")

        try:
            # Cargar datos para exploraci√≥n usando el dataset seleccionado
            X, y, feature_names, class_names, info, task_type = load_data(
                st.session_state.selected_dataset_knn)

            # Crear DataFrame para mostrar los datos
            import pandas as pd
            if isinstance(X, pd.DataFrame):
                data = X.copy()
            else:
                data = pd.DataFrame(X, columns=feature_names)

            # A√±adir la variable objetivo
            target_name = 'target'
            if isinstance(info, dict):
                target_name = info.get('target', 'target')
            data[target_name] = y

            # Actualizar el estado de la sesi√≥n
            st.session_state.knn_dataset = st.session_state.selected_dataset_knn
            st.session_state.knn_X = X
            st.session_state.knn_y = y
            st.session_state.knn_feature_names = feature_names
            st.session_state.knn_class_names = class_names
            st.session_state.knn_task_type = task_type

            # Mostrar informaci√≥n del dataset
            st.markdown("### Informaci√≥n del Dataset")
            from utils import create_info_box
            st.markdown(create_info_box(info), unsafe_allow_html=True)

            # Mostrar las primeras filas de los datos
            st.markdown("### Vista previa de datos")
            st.dataframe(data.head(20), use_container_width=True)
            st.markdown(f"**Caracter√≠sticas:** {', '.join(feature_names)}")

            # Determinar el nombre de la variable objetivo
            if isinstance(info, dict):
                target_display = info.get('target', 'target')
            else:
                target_display = 'target'
            st.markdown(f"**Variable objetivo:** {target_display}")

            st.markdown(f"**Tipo de tarea:** {task_type}")

            # Mostrar clases correctamente
            if class_names is not None:
                if isinstance(class_names, list):
                    st.markdown(
                        f"**Clases:** {', '.join(map(str, class_names))}")
                else:
                    st.markdown(f"**Clases:** {class_names}")
            else:
                st.markdown("**Clases:** N/A (regresi√≥n)")

            if X is not None and hasattr(X, 'shape') and len(X.shape) >= 2:
                st.markdown(
                    f"**Tama√±o del dataset:** {X.shape[0]} muestras, {X.shape[1]} caracter√≠sticas")
            elif X is not None and hasattr(X, 'shape') and len(X.shape) == 1:
                st.markdown(
                    f"**Tama√±o del dataset:** {X.shape[0]} muestras, 1 caracter√≠stica")
            else:
                st.markdown("**Tama√±o del dataset:** No disponible")
            st.session_state.knn_trained = False

        except Exception as e:
            st.error(f"Error al cargar el dataset: {str(e)}")
            st.info(
                "Por favor, selecciona un dataset v√°lido para continuar con la exploraci√≥n.")

    # Pesta√±a 1: Entrenamiento
    elif tab == 1:
        st.header("Configuraci√≥n del Modelo KNN")

        # Inicializar variables de sesi√≥n necesarias
        if 'dataset_option_knn' not in st.session_state:
            st.session_state.dataset_option_knn = st.session_state.selected_dataset_knn

        # Cargar datos para la vista previa si cambia el dataset o si no se ha cargado
        if st.session_state.selected_dataset_knn != st.session_state.dataset_option_knn or st.session_state.knn_X is None:
            try:
                X, y, feature_names, class_names, info, task_type = load_data(
                    st.session_state.selected_dataset_knn)

                st.session_state.dataset_option_knn = st.session_state.selected_dataset_knn

                # Actualizar informaci√≥n del dataset
                st.session_state.knn_dataset = st.session_state.selected_dataset_knn
                st.session_state.knn_X = X
                st.session_state.knn_y = y
                st.session_state.knn_feature_names = feature_names
                st.session_state.knn_class_names = class_names
                st.session_state.knn_task_type = task_type

                # Mostrar informaci√≥n del dataset
                st.markdown("### Informaci√≥n del Dataset")
                from utils import create_info_box
                st.markdown(create_info_box(info), unsafe_allow_html=True)

            except Exception as e:
                st.error(f"Error al cargar el dataset: {str(e)}")

        # Verificar que los datos est√©n disponibles
        if st.session_state.knn_X is not None and st.session_state.knn_y is not None:
            st.markdown("### Par√°metros del Modelo")
            st.markdown("Configura los hiperpar√°metros del modelo KNN:")

            col1, col2, col3 = st.columns(3)
            with col1:
                n_neighbors = st.number_input(
                    "Vecinos (K)", min_value=1, max_value=20, value=5, step=1, key="knn_n_neighbors")
            with col2:
                weights = st.selectbox(
                    "Pesos", options=["uniform", "distance"], key="knn_weights")
            with col3:
                metric = st.selectbox("M√©trica", options=[
                                      "minkowski", "euclidean", "manhattan"], key="knn_metric")

            if st.button("üöÄ Entrenar Modelo KNN", key="train_knn_button", type="primary"):
                with st.spinner("Entrenando modelo..."):
                    try:
                        result = train_knn_model(
                            st.session_state.knn_X,
                            st.session_state.knn_y,
                            task_type=st.session_state.knn_task_type,
                            n_neighbors=n_neighbors,
                            weights=weights,
                            metric=metric
                        )
                        st.session_state.knn_model = result["model"]
                        st.session_state.knn_metrics = result["evaluation"]
                        st.session_state.knn_trained = True
                        st.success("¬°Modelo KNN entrenado correctamente!")

                        # Sugerir ir a la pesta√±a de evaluaci√≥n
                        st.info(
                            "üëâ Ve a la pesta√±a 'üìà Evaluaci√≥n' para ver los resultados del modelo.")

                    except Exception as e:
                        st.error(f"Error al entrenar el modelo: {str(e)}")
        else:
            st.info("Primero selecciona y carga un dataset en la pesta√±a de Datos.")

    # Pesta√±a 2: Evaluaci√≥n
    elif tab == 2:
        st.header("üìà Evaluaci√≥n del Modelo KNN")
        if st.session_state.knn_trained and st.session_state.knn_metrics is not None:
            # Obtener las predicciones del modelo
            if hasattr(st.session_state, 'knn_X') and hasattr(st.session_state, 'knn_y'):
                from sklearn.model_selection import train_test_split

                # Recrear el split de entrenamiento/prueba con los mismos par√°metros
                X_train, X_test, y_train, y_test = train_test_split(
                    st.session_state.knn_X,
                    st.session_state.knn_y,
                    test_size=0.3,
                    random_state=42
                )

                # Obtener las predicciones
                y_pred = st.session_state.knn_model.predict(X_test)

                # Mostrar evaluaci√≥n detallada del modelo usando la misma funci√≥n que otros algoritmos
                show_detailed_evaluation(
                    y_test,
                    y_pred,
                    st.session_state.knn_class_names if st.session_state.knn_task_type == "Clasificaci√≥n" else None,
                    st.session_state.knn_task_type
                )
            else:
                st.error(
                    "No se encontraron los datos necesarios para la evaluaci√≥n.")
        else:
            st.info("Primero entrena un modelo KNN.")

    # Pesta√±a 3: Visualizaci√≥n
    elif tab == 3:
        st.header("üìâ Visualizaci√≥n de KNN")
        if st.session_state.knn_trained and st.session_state.knn_model is not None:
            X = st.session_state.knn_X
            y = st.session_state.knn_y
            model = st.session_state.knn_model
            feature_names = st.session_state.knn_feature_names
            task_type = st.session_state.knn_task_type

            st.markdown("### Opciones de Visualizaci√≥n")

            # Selector de tipo de visualizaci√≥n
            viz_options = []

            # Siempre disponible: Distribuci√≥n de predicciones
            viz_options.append("üìä Distribuci√≥n de Predicciones")

            # Si hay al menos 2 caracter√≠sticas: Frontera de decisi√≥n/superficie
            if X.shape[1] >= 2:
                if task_type == "Clasificaci√≥n":
                    viz_options.append("üéØ Frontera de Decisi√≥n")
                else:
                    viz_options.append("üèîÔ∏è Superficie de Predicci√≥n")

            # Si es clasificaci√≥n: Matriz de distancias
            if task_type == "Clasificaci√≥n":
                viz_options.append("üìè An√°lisis de Distancias")

            viz_type = st.selectbox("Tipo de visualizaci√≥n:", viz_options)

            if viz_type == "üìä Distribuci√≥n de Predicciones":
                # Recrear el split para obtener predicciones
                from sklearn.model_selection import train_test_split
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.3, random_state=42
                )
                y_pred = model.predict(X_test)

                if task_type == "Clasificaci√≥n":
                    # Mostrar distribuci√≥n de clases predichas vs reales
                    import pandas as pd

                    col1, col2 = st.columns(2)

                    with col1:
                        st.markdown("#### Distribuci√≥n Real")
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        real_counts = pd.Series(
                            y_test).value_counts().sort_index()
                        ax1.bar(range(len(real_counts)),
                                real_counts.values, alpha=0.7, color='skyblue')
                        ax1.set_xlabel('Clase')
                        ax1.set_ylabel('Frecuencia')
                        ax1.set_title('Distribuci√≥n Real')
                        if st.session_state.knn_class_names:
                            ax1.set_xticks(range(len(real_counts)))
                            ax1.set_xticklabels(
                                [st.session_state.knn_class_names[i] for i in real_counts.index], rotation=45)
                        st.pyplot(fig1)

                    with col2:
                        st.markdown("#### Distribuci√≥n Predicha")
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        pred_counts = pd.Series(
                            y_pred).value_counts().sort_index()
                        ax2.bar(range(len(pred_counts)), pred_counts.values,
                                alpha=0.7, color='lightcoral')
                        ax2.set_xlabel('Clase')
                        ax2.set_ylabel('Frecuencia')
                        ax2.set_title('Distribuci√≥n Predicha')
                        if st.session_state.knn_class_names:
                            ax2.set_xticks(range(len(pred_counts)))
                            ax2.set_xticklabels(
                                [st.session_state.knn_class_names[i] for i in pred_counts.index], rotation=45)
                        st.pyplot(fig2)

                else:  # Regresi√≥n
                    col1, col2 = st.columns(2)

                    with col1:
                        st.markdown("#### Valores Reales vs Predichos")
                        fig1, ax1 = plt.subplots(figsize=(6, 5))
                        ax1.scatter(y_test, y_pred, alpha=0.6)
                        ax1.plot([y_test.min(), y_test.max()], [
                                 y_test.min(), y_test.max()], 'r--', lw=2)
                        ax1.set_xlabel('Valores Reales')
                        ax1.set_ylabel('Valores Predichos')
                        ax1.set_title('Predicciones vs Realidad')
                        st.pyplot(fig1)

                    with col2:
                        st.markdown("#### Distribuci√≥n de Errores")
                        fig2, ax2 = plt.subplots(figsize=(6, 5))
                        errors = y_test - y_pred
                        ax2.hist(errors, bins=20, alpha=0.7,
                                 color='lightgreen', edgecolor='black')
                        ax2.axvline(x=0, color='red',
                                    linestyle='--', linewidth=2)
                        ax2.set_xlabel('Error (Real - Predicho)')
                        ax2.set_ylabel('Frecuencia')
                        ax2.set_title('Distribuci√≥n de Errores')
                        st.pyplot(fig2)

            elif viz_type in ["üéØ Frontera de Decisi√≥n", "üèîÔ∏è Superficie de Predicci√≥n"]:
                st.markdown("### Selecci√≥n de Caracter√≠sticas")
                st.markdown("Selecciona 2 caracter√≠sticas para visualizar:")

                col1, col2 = st.columns(2)

                with col1:
                    feature1 = st.selectbox(
                        "Primera caracter√≠stica:",
                        feature_names,
                        index=0,
                        key="viz_feature1"
                    )

                with col2:
                    feature2 = st.selectbox(
                        "Segunda caracter√≠stica:",
                        feature_names,
                        index=min(1, len(feature_names) - 1),
                        key="viz_feature2"
                    )

                if feature1 != feature2:
                    # Obtener √≠ndices de las caracter√≠sticas seleccionadas
                    feature_idx = [feature_names.index(
                        feature1), feature_names.index(feature2)]

                    # Extraer las caracter√≠sticas seleccionadas
                    if hasattr(X, 'iloc'):  # DataFrame
                        X_2d = X.iloc[:, feature_idx].values
                    else:  # numpy array
                        X_2d = X[:, feature_idx]

                    # Entrenar un modelo KNN con solo estas 2 caracter√≠sticas
                    from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor

                    if task_type == "Clasificaci√≥n":
                        model_2d = KNeighborsClassifier(
                            n_neighbors=model.n_neighbors,
                            weights=model.weights,
                            metric=model.metric
                        )
                    else:
                        model_2d = KNeighborsRegressor(
                            n_neighbors=model.n_neighbors,
                            weights=model.weights,
                            metric=model.metric
                        )

                    model_2d.fit(X_2d, y)

                    # Crear la visualizaci√≥n
                    fig, ax = plt.subplots(figsize=(10, 8))

                    # Crear malla de puntos
                    h = 0.02
                    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1
                    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1
                    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                                         np.arange(y_min, y_max, h))

                    # Predecir en la malla
                    Z = model_2d.predict(np.c_[xx.ravel(), yy.ravel()])
                    Z = Z.reshape(xx.shape)

                    if task_type == "Clasificaci√≥n":
                        # Frontera de decisi√≥n para clasificaci√≥n
                        n_classes = len(np.unique(y))

                        # Usar diferentes mapas de colores seg√∫n el n√∫mero de clases
                        if n_classes == 2:
                            contour = ax.contourf(
                                xx, yy, Z, alpha=0.3, cmap='RdBu', levels=50)
                            scatter_cmap = 'RdBu'
                        else:
                            contour = ax.contourf(
                                xx, yy, Z, alpha=0.3, cmap='Set3', levels=n_classes)
                            scatter_cmap = 'Set3'

                        # Scatter plot de los datos
                        scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y,
                                             cmap=scatter_cmap, edgecolor='black', s=50, alpha=0.8)

                        # Leyenda para clasificaci√≥n
                        if st.session_state.knn_class_names and n_classes <= 10:
                            import matplotlib.patches as mpatches
                            if n_classes == 2:
                                colors = ['#d7191c', '#2c7bb6']  # RdBu colors
                            else:
                                colors = plt.cm.Set3(
                                    np.linspace(0, 1, n_classes))

                            patches = [mpatches.Patch(color=colors[i],
                                                      label=st.session_state.knn_class_names[i])
                                       for i in range(min(len(st.session_state.knn_class_names), n_classes))]
                            ax.legend(handles=patches,
                                      loc='best', title='Clases')

                        ax.set_title(
                            f'Frontera de Decisi√≥n KNN (K={model.n_neighbors})')

                    else:
                        # Superficie de predicci√≥n para regresi√≥n
                        contour = ax.contourf(
                            xx, yy, Z, alpha=0.6, cmap='viridis', levels=20)
                        scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y,
                                             cmap='viridis', edgecolor='black', s=50, alpha=0.8)

                        # Barra de colores
                        cbar = plt.colorbar(scatter, ax=ax, shrink=0.8)
                        cbar.set_label('Valor Objetivo')

                        ax.set_title(
                            f'Superficie de Predicci√≥n KNN (K={model.n_neighbors})')

                    ax.set_xlabel(feature1)
                    ax.set_ylabel(feature2)
                    ax.grid(True, alpha=0.3)

                    st.pyplot(fig)

                    # Informaci√≥n adicional
                    st.info(f"""
                    üîç **Informaci√≥n de la visualizaci√≥n:**
                    - **Caracter√≠sticas:** {feature1} vs {feature2}
                    - **N√∫mero de vecinos (K):** {model.n_neighbors}
                    - **Tipo de peso:** {model.weights}
                    - **M√©trica de distancia:** {model.metric}
                    - **Tipo de tarea:** {task_type}
                    """)

                else:
                    st.warning(
                        "Por favor selecciona dos caracter√≠sticas diferentes.")

            elif viz_type == "üìè An√°lisis de Distancias":
                st.markdown("### An√°lisis de Distancias entre Clases")

                # Calcular distancias promedio entre clases
                from sklearn.metrics.pairwise import pairwise_distances

                # Recrear el split para an√°lisis
                from sklearn.model_selection import train_test_split
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.3, random_state=42
                )

                classes = np.unique(y_train)
                n_classes = len(classes)

                if n_classes > 1:
                    # Matriz de distancias promedio entre clases
                    dist_matrix = np.zeros((n_classes, n_classes))

                    for i, class1 in enumerate(classes):
                        for j, class2 in enumerate(classes):
                            if i != j:
                                X_class1 = X_train[y_train == class1]
                                X_class2 = X_train[y_train == class2]

                                # Calcular distancia promedio entre las dos clases
                                distances = pairwise_distances(
                                    X_class1, X_class2, metric=model.metric)
                                dist_matrix[i, j] = np.mean(distances)

                    # Visualizar matriz de distancias
                    fig, ax = plt.subplots(figsize=(8, 6))
                    im = ax.imshow(dist_matrix, cmap='viridis', aspect='auto')

                    # A√±adir valores a las celdas
                    for i in range(n_classes):
                        for j in range(n_classes):
                            if i != j:
                                text = ax.text(j, i, f'{dist_matrix[i, j]:.2f}',
                                               ha="center", va="center", color="white")

                    # Configurar etiquetas
                    if st.session_state.knn_class_names:
                        class_labels = [
                            st.session_state.knn_class_names[int(c)] for c in classes]
                    else:
                        class_labels = [f'Clase {int(c)}' for c in classes]

                    ax.set_xticks(range(n_classes))
                    ax.set_yticks(range(n_classes))
                    ax.set_xticklabels(class_labels, rotation=45)
                    ax.set_yticklabels(class_labels)
                    ax.set_title(
                        f'Distancias Promedio entre Clases\n(M√©trica: {model.metric})')

                    plt.colorbar(im, ax=ax, label='Distancia Promedio')
                    plt.tight_layout()
                    st.pyplot(fig)

                    # An√°lisis de separabilidad
                    min_dist = np.min(dist_matrix[dist_matrix > 0])
                    max_dist = np.max(dist_matrix)

                    st.markdown("### An√°lisis de Separabilidad")
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("Distancia M√≠nima", f"{min_dist:.3f}")
                    with col2:
                        st.metric("Distancia M√°xima", f"{max_dist:.3f}")
                    with col3:
                        ratio = max_dist / min_dist if min_dist > 0 else 0
                        st.metric("Ratio Max/Min", f"{ratio:.2f}")

                    if ratio > 5:
                        st.success(
                            "üü¢ Las clases est√°n bien separadas (ratio > 5)")
                    elif ratio > 2:
                        st.warning(
                            "üü° Separaci√≥n moderada entre clases (2 < ratio ‚â§ 5)")
                    else:
                        st.error("üî¥ Las clases est√°n muy pr√≥ximas (ratio ‚â§ 2)")
                else:
                    st.info(
                        "Se necesitan al menos 2 clases para el an√°lisis de distancias.")

        else:
            st.info("Primero entrena un modelo KNN.")

    # Pesta√±a 4: Predicciones
    elif tab == 4:
        st.header("üîÆ Predicciones con KNN")
        if st.session_state.knn_trained and st.session_state.knn_model is not None:
            create_prediction_interface(
                st.session_state.knn_model,
                st.session_state.knn_feature_names,
                st.session_state.knn_class_names,
                st.session_state.knn_task_type,
                st.session_state.knn_X,
                st.session_state.knn_dataset
            )
        else:
            st.info("Primero entrena un modelo KNN.")


#!/usr/bin/env python3
"""
MLTutor: Plataforma educativa para el aprendizaje de Machine Learning.
"""


# Importar m√≥dulos refactorizados


def main():
    """Funci√≥n principal que ejecuta la aplicaci√≥n MLTutor."""
    # Configuraci√≥n de la p√°gina
    setup_page()

    # Inicializar estado de la sesi√≥n
    init_session_state()

    # Configurar navegaci√≥n principal con botones en lugar de radio
    st.sidebar.markdown("### Navegaci√≥n:")

    # Estilo para los botones de navegaci√≥n
    button_style = """
    <style>
    div.stButton > button {
        width: 100%;
        text-align: left;
        padding: 10px;
        margin-bottom: 5px;
        border-radius: 5px;
        font-weight: normal;
    }
    div.stButton > button:hover {
        background-color: #E3F2FD;
        border-color: #90CAF9;
    }
    </style>
    """
    st.sidebar.markdown(button_style, unsafe_allow_html=True)

    # Crear los botones de navegaci√≥n
    if st.sidebar.button("üè† Inicio",
                         key="nav_home",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üè† Inicio" else "primary"):
        st.session_state.navigation = "üè† Inicio"
        st.rerun()

    if st.sidebar.button("üå≤ √Årboles de Decisi√≥n",
                         key="nav_trees",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üå≤ √Årboles de Decisi√≥n" else "primary"):
        st.session_state.navigation = "üå≤ √Årboles de Decisi√≥n"
        st.rerun()

    if st.sidebar.button("üìä Regresi√≥n",
                         key="nav_linear",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üìä Regresi√≥n" else "primary"):
        st.session_state.navigation = "üìä Regresi√≥n"
        st.rerun()

    if st.sidebar.button("üîç K-Nearest Neighbors",
                         key="nav_knn",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üîç K-Nearest Neighbors" else "primary"):
        st.session_state.navigation = "üîç K-Nearest Neighbors"
        st.rerun()

    if st.sidebar.button("üß† Redes Neuronales (pr√≥ximamente)",
                         key="nav_nn",
                         use_container_width=True,
                         disabled=True):
        st.session_state.navigation = "üß† Redes Neuronales (pr√≥ximamente)"
        st.rerun()

    # Separador
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üîß Herramientas:")

    if st.sidebar.button("üìÅ Cargar CSV Personalizado",
                         key="nav_csv",
                         use_container_width=True):
        st.session_state.navigation = "üìÅ Cargar CSV Personalizado"
        st.rerun()

    # P√°gina de inicio
    if st.session_state.navigation == "üè† Inicio":
        show_welcome_page()
        return

    # P√°ginas de algoritmos
    if st.session_state.navigation == "üå≤ √Årboles de Decisi√≥n":
        run_decision_trees_app()
    elif st.session_state.navigation == "üìä Regresi√≥n":
        run_linear_regression_app()
    elif st.session_state.navigation == "üîç K-Nearest Neighbors":
        run_knn_app()
    elif st.session_state.navigation == "üìÅ Cargar CSV Personalizado":
        run_csv_loader_app()
    elif st.session_state.navigation in ["üß† Redes Neuronales (pr√≥ximamente)"]:
        algorithm_name = st.session_state.navigation.split(" ")[1]
        st.header(f"{algorithm_name} (pr√≥ximamente)")
        st.info(
            f"La funcionalidad de {algorithm_name} estar√° disponible pr√≥ximamente. Por ahora, puedes explorar los √Årboles de Decisi√≥n.")

        # Mostrar una imagen ilustrativa seg√∫n el algoritmo
        if "Regresi√≥n Log√≠stica" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_logistic_001.png",
                     caption="Ilustraci√≥n de Regresi√≥n Log√≠stica")
        elif "K-Nearest Neighbors" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_classification_001.png",
                     caption="Ilustraci√≥n de K-Nearest Neighbors")
        elif "Redes Neuronales" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_mlp_001.png",
                     caption="Ilustraci√≥n de Redes Neuronales")


def run_decision_trees_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de √°rboles de decisi√≥n."""
    st.header("üå≤ √Årboles de Decisi√≥n")
    st.markdown("Aprende sobre los √°rboles de decisi√≥n de forma interactiva")

    # Informaci√≥n sobre √°rboles de decisi√≥n
    with st.expander("‚ÑπÔ∏è ¬øQu√© son los √Årboles de Decisi√≥n?", expanded=False):
        st.markdown("""
        Los √°rboles de decisi√≥n son algoritmos de aprendizaje supervisado que se pueden usar tanto para tareas de clasificaci√≥n como de regresi√≥n.

        **Caracter√≠sticas principales:**
        - Funcionan dividiendo el conjunto de datos en subconjuntos m√°s peque√±os bas√°ndose en condiciones sobre las caracter√≠sticas
        - Son f√°ciles de interpretar y visualizar
        - Pueden manejar tanto datos num√©ricos como categ√≥ricos
        - No requieren escalado de datos

        **Limitaciones:**
        - Pueden sobreajustarse f√°cilmente (esto se puede controlar con par√°metros como max_depth)
        - Pueden ser inestables (peque√±os cambios en los datos pueden generar √°rboles muy diferentes)
        - No son tan precisos como algoritmos m√°s complejos para algunas tareas

        Experimenta con diferentes configuraciones para ver c√≥mo afectan al rendimiento del modelo.
        """)

    # Variables para almacenar datos
    dataset_loaded = False
    X, y, feature_names, class_names, dataset_info, task_type = None, None, None, None, None, None

    # Inicializar el estado de la pesta√±a activa si no existe
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = 0

    # Crear pesta√±as para organizar la informaci√≥n
    tab_options = [
        "üìä Datos",
        "üèãÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üå≤ Visualizaci√≥n",
        "üîç Caracter√≠sticas",
        "üîÆ Predicciones",
        "üíæ Exportar Modelo"
    ]

    # Crear contenedor para los botones de las pesta√±as
    tab_cols = st.columns(len(tab_options))

    # Estilo CSS para los botones de pesta√±as (Decision Trees)
    st.markdown("""
    <style>
    div.tab-button-dt > button {
        border-radius: 4px 4px 0 0;
        padding: 10px;
        width: 100%;
        white-space: nowrap;
        background-color: #F0F2F6;
        border-bottom: 2px solid #E0E0E0;
        color: #333333;
    }
    div.tab-button-dt-active > button {
        background-color: #E3F2FD !important;
        border-bottom: 2px solid #1E88E5 !important;
        font-weight: bold !important;
        color: #1E88E5 !important;
    }
    div.tab-button-dt > button:hover {
        background-color: #E8EAF6;
    }
    </style>
    """, unsafe_allow_html=True)

    # Crear botones para las pesta√±as
    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_{i}"
        button_style = "tab-button-dt-active" if st.session_state.active_tab == i else "tab-button-dt"

    # Crear botones para las pesta√±as
    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_{i}"
        button_style = "tab-button-dt-active" if st.session_state.active_tab == i else "tab-button-dt"
        is_active = st.session_state.active_tab == i

        with col:
            st.markdown(f"<div class='{button_style}'>",
                        unsafe_allow_html=True)
            # Usar type="primary" para el bot√≥n activo
            if st.button(tab_name, key=button_key, use_container_width=True,
                         type="primary" if is_active else "secondary"):
                st.session_state.active_tab = i
                st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    # Separador visual
    st.markdown("---")

    # SELECTOR UNIFICADO DE DATASET (solo mostrar en pesta√±as que lo necesiten)
    if st.session_state.active_tab in [0, 1]:  # Exploraci√≥n y Entrenamiento
        st.markdown("### üìä Selecci√≥n de Dataset")

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset' not in st.session_state:
            st.session_state.selected_dataset = "üå∏ Iris - Clasificaci√≥n de flores"

        # Lista base de datasets predefinidos
        builtin_datasets = [
            "üå∏ Iris - Clasificaci√≥n de flores",
            "üç∑ Vino - Clasificaci√≥n de vinos",
            "üî¨ C√°ncer - Diagn√≥stico binario",
            "üö¢ Titanic - Supervivencia",
            "üí∞ Propinas - Predicci√≥n de propinas",
            "üè† Viviendas California - Precios",
            "üêß Ping√ºinos - Clasificaci√≥n de especies"
        ]

        # A√±adir datasets CSV cargados si existen
        available_datasets = builtin_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado est√© en la lista disponible
        if st.session_state.selected_dataset not in available_datasets:
            st.session_state.selected_dataset = builtin_datasets[0]

        # Selector unificado
        dataset_option = st.selectbox(
            "Dataset:",
            available_datasets,
            index=available_datasets.index(st.session_state.selected_dataset),
            key="unified_dataset_selector",
            help="El dataset seleccionado se mantendr√° entre las pesta√±as de Exploraci√≥n y Entrenamiento"
        )

        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset = dataset_option

        # Separador despu√©s del selector
        st.markdown("---")
    else:
        # Para otras pesta√±as, mostrar qu√© dataset est√° seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset'):
            st.info(
                f"üìä **Dataset actual:** {st.session_state.selected_dataset}")
            st.markdown("---")

    # Pesta√±a de Datos
    if st.session_state.active_tab == 0:
        st.header("Exploraci√≥n de Datos")

        try:
            # Cargar datos para exploraci√≥n
            X, y, feature_names, class_names, dataset_info, task_type = load_data(
                st.session_state.selected_dataset)

            # Convertir a DataFrames para facilitar el manejo
            # FIXED: No sobrescribir las columnas si X ya es DataFrame para evitar NaN
            if isinstance(X, pd.DataFrame):
                X_df = X.copy()  # Usar las columnas originales
                # Crear mapeo de nombres para mostrar
                column_mapping = {}
                if len(feature_names) == len(X_df.columns):
                    column_mapping = dict(zip(X_df.columns, feature_names))
            else:
                X_df = pd.DataFrame(X, columns=feature_names)
                column_mapping = {}

            y_df = pd.Series(y, name="target")

            # Mapear nombres de clases si est√°n disponibles
            if task_type == "Clasificaci√≥n" and class_names is not None:
                y_df = y_df.map(
                    {i: name for i, name in enumerate(class_names)})

            df = pd.concat([X_df, y_df], axis=1)

            # Renombrar columnas para mostrar nombres amigables si existe el mapeo
            if column_mapping:
                df_display = df.rename(columns=column_mapping)
            else:
                df_display = df

            # Mostrar informaci√≥n del dataset
            st.markdown("### Informaci√≥n del Dataset")
            st.markdown(create_info_box(dataset_info), unsafe_allow_html=True)

            # Mostrar las primeras filas de los datos
            st.markdown("### Vista previa de datos")
            st.dataframe(df_display.head(10))

            # Estad√≠sticas descriptivas
            st.markdown("### Estad√≠sticas Descriptivas")
            st.dataframe(df_display.describe())

            # Distribuci√≥n de clases o valores objetivo
            st.markdown("### Distribuci√≥n del Objetivo")

            fig, ax = plt.subplots(figsize=(10, 6))

            if task_type == "Clasificaci√≥n":
                # Gr√°fico de barras para clasificaci√≥n
                value_counts = y_df.value_counts().sort_index()
                sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
                ax.set_title("Distribuci√≥n de Clases")
                ax.set_xlabel("Clase")
                ax.set_ylabel("Cantidad")

                # Rotar etiquetas si son muchas
                if len(value_counts) > 3:
                    plt.xticks(rotation=45, ha='right')
            else:
                # Histograma para regresi√≥n
                # Convertir a num√©rico en caso de que sean strings
                y_numeric = pd.to_numeric(y_df, errors='coerce')
                # Usar matplotlib directamente para evitar problemas de tipo
                ax.hist(y_numeric.dropna(), bins=30,
                        alpha=0.7, edgecolor='black')
                ax.set_title("Distribuci√≥n de Valores Objetivo")
                ax.set_xlabel("Valor")
                ax.set_ylabel("Frecuencia")

            # Mostrar la figura con tama√±o reducido pero expandible
            col1, col2, col3 = st.columns([1, 3, 1])
            with col2:
                st.pyplot(fig, use_container_width=True)

            # An√°lisis de correlaci√≥n
            st.markdown("### Matriz de Correlaci√≥n")

            # Matriz de correlaci√≥n
            corr = X_df.corr()

            # Generar m√°scara para el tri√°ngulo superior
            mask = np.triu(np.ones_like(corr, dtype=bool))

            # Generar mapa de calor
            fig_corr, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
                        square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
            ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

            # Mostrar la figura con tama√±o reducido pero expandible
            col1, col2, col3 = st.columns([1, 3, 1])
            with col2:
                st.pyplot(fig_corr, use_container_width=True)

            # Matriz de dispersi√≥n (Scatterplot Matrix)
            st.markdown("### Matriz de Dispersi√≥n (Pairplot)")

            # Opciones de visualizaci√≥n
            st.markdown("#### Opciones de visualizaci√≥n")
            col1, col2 = st.columns(2)

            with col1:
                # Seleccionar tipo de gr√°fico para la diagonal
                diag_kind = st.radio(
                    "Tipo de gr√°fico en la diagonal:",
                    ["Histograma", "KDE (Estimaci√≥n de Densidad)"],
                    index=1,
                    horizontal=True
                )
                diag_kind = "hist" if diag_kind == "Histograma" else "kde"

            with col2:
                # Seleccionar n√∫mero m√°ximo de caracter√≠sticas
                max_features_selected = st.slider(
                    "N√∫mero m√°ximo de caracter√≠sticas:",
                    min_value=2,
                    max_value=min(6, len(X_df.columns)),
                    value=min(4, len(X_df.columns)),
                    help="Un n√∫mero mayor de caracter√≠sticas puede hacer que el gr√°fico sea m√°s dif√≠cil de interpretar."
                )

            # Permitir al usuario seleccionar las caracter√≠sticas espec√≠ficas
            st.markdown("#### Selecciona las caracter√≠sticas para visualizar")

            # Limitar a max_features_selected
            # Usar nombres amigables si est√°n disponibles, sino usar originales
            if column_mapping:
                available_features = list(
                    column_mapping.values())  # Nombres amigables
                display_to_original = {
                    v: k for k, v in column_mapping.items()}  # Mapeo inverso
            else:
                available_features = X_df.columns.tolist()
                display_to_original = {}

            # Usar multiselect para seleccionar caracter√≠sticas
            selected_features = st.multiselect(
                "Caracter√≠sticas a incluir en la matriz de dispersi√≥n:",
                available_features,
                default=available_features[:max_features_selected],
                max_selections=max_features_selected,
                help=f"Selecciona hasta {max_features_selected} caracter√≠sticas para incluir en la visualizaci√≥n."
            )

            # Si no se seleccion√≥ ninguna caracter√≠stica, usar las primeras por defecto
            if not selected_features:
                selected_features = available_features[:max_features_selected]
                st.info(
                    f"No se seleccionaron caracter√≠sticas. Usando las primeras {max_features_selected} por defecto.")

            # Convertir nombres amigables a nombres originales si es necesario
            if column_mapping:
                original_features = [display_to_original[feat]
                                     for feat in selected_features]
            else:
                original_features = selected_features

            # Crear el dataframe para la visualizaci√≥n
            plot_df = X_df[original_features].copy()
            # Renombrar a nombres amigables para visualizaci√≥n
            if column_mapping:
                plot_df = plot_df.rename(columns=column_mapping)
            # A√±adir la variable objetivo para colorear
            plot_df['target'] = y_df

            # Generar el pairplot
            with st.spinner("Generando matriz de dispersi√≥n..."):
                pair_plot = sns.pairplot(
                    plot_df,
                    hue='target',
                    diag_kind=diag_kind,
                    plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
                    diag_kws={'alpha': 0.5},
                    height=2.0  # Reducir altura para que sea m√°s compacto
                )
                pair_plot.fig.suptitle(
                    "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=14)

                # Mostrar la figura con tama√±o reducido pero expandible
                col1, col2, col3 = st.columns([1, 3, 1])
                with col2:
                    st.pyplot(pair_plot.fig, use_container_width=True)

                # Enlace para descargar
                st.markdown(
                    get_image_download_link(
                        pair_plot.fig, "matriz_dispersion", "üì• Descargar matriz de dispersi√≥n"),
                    unsafe_allow_html=True
                )

            # Generar c√≥digo para este an√°lisis
            code = """
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar tus datos (reemplaza esto con tu m√©todo de carga)
# df = pd.read_csv('tu_archivo.csv')

# Separar caracter√≠sticas y objetivo
X = df.iloc[:, :-1]  # Todas las columnas excepto la √∫ltima
y = df.iloc[:, -1]   # √öltima columna como objetivo

# Estad√≠sticas descriptivas
print(df.describe())

# Distribuci√≥n del objetivo
fig, ax = plt.subplots(figsize=(10, 6))

# Para clasificaci√≥n:
if len(np.unique(y)) <= 10:  # Si hay pocas clases √∫nicas
    value_counts = y.value_counts().sort_index()
    sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
    ax.set_title("Distribuci√≥n de Clases")
    ax.set_xlabel("Clase")
    ax.set_ylabel("Cantidad")
else:  # Para regresi√≥n
    sns.histplot(y, kde=True, ax=ax)
    ax.set_title("Distribuci√≥n de Valores Objetivo")
    ax.set_xlabel("Valor")
    ax.set_ylabel("Frecuencia")

plt.tight_layout()
plt.show()

# Matriz de correlaci√≥n
corr = X.corr()
# M√°scara para tri√°ngulo superior
mask = np.triu(np.ones_like(corr, dtype=bool))

fig, ax = plt.subplots(figsize=(12, 10))
sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
           square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

plt.tight_layout()
plt.show()

# Matriz de dispersi√≥n (Scatterplot Matrix)
# Seleccionar caracter√≠sticas espec√≠ficas para visualizar
# Reemplaza con tus caracter√≠sticas de inter√©s
selected_features = ['feature1', 'feature2', 'feature3']
max_features = min(6, len(selected_features))

# Crear el dataframe para la visualizaci√≥n
plot_df = X[selected_features].copy()
plot_df['target'] = y  # A√±adir la variable objetivo para colorear

# Generar el pairplot
pair_plot = sns.pairplot(
    plot_df,
    hue='target',
    diag_kind='kde',  # Opciones: 'hist' para histograma o 'kde' para densidad
    plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
    diag_kws={'alpha': 0.5},
    height=2.5
)
pair_plot.fig.suptitle(
    "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=16)
plt.tight_layout()
plt.show()
"""

            show_code_with_download(
                code, "C√≥digo para an√°lisis exploratorio", "analisis_exploratorio.py")

        except Exception as e:
            st.error(f"Error al cargar el dataset: {str(e)}")
            st.info(
                "Por favor, selecciona un dataset v√°lido para continuar con la exploraci√≥n.")

    # Pesta√±a de Entrenamiento
    elif st.session_state.active_tab == 1:
        st.header("Configuraci√≥n del Modelo")

        # Inicializar session state variables
        if 'dataset_option' not in st.session_state:
            st.session_state.dataset_option = st.session_state.selected_dataset
        if 'tree_type' not in st.session_state:
            st.session_state.tree_type = "Clasificaci√≥n"
        if 'is_trained' not in st.session_state:
            st.session_state.is_trained = False

        # Cargar datos para la vista previa si cambia el dataset o si no se ha cargado
        if st.session_state.selected_dataset != st.session_state.dataset_option or not dataset_loaded:
            try:
                X, y, feature_names, class_names, dataset_info, task_type = load_data(
                    st.session_state.selected_dataset)

                st.session_state.dataset_option = st.session_state.selected_dataset
                dataset_loaded = True

                # Mostrar informaci√≥n del dataset
                st.markdown("### Informaci√≥n del Dataset")
                st.markdown(create_info_box(dataset_info),
                            unsafe_allow_html=True)

                # Usar el tipo de tarea detectado por la funci√≥n load_data
                st.markdown("### Tipo de √Årbol de Decisi√≥n")

                # Usar botones en lugar de radio para seleccionar el tipo de √°rbol
                tipo_col1, tipo_col2 = st.columns(2)

                with tipo_col1:
                    is_classification = True
                    if "tree_type" in st.session_state:
                        is_classification = st.session_state.tree_type == "Clasificaci√≥n"

                    if st.button("üè∑Ô∏è Clasificaci√≥n",
                                 key="btn_classification",
                                 type="primary" if is_classification else "secondary",
                                 use_container_width=True,
                                 help="Para predecir categor√≠as o clases"):
                        tree_type = "Clasificaci√≥n"
                        st.session_state.tree_type = tree_type
                        st.rerun()

                with tipo_col2:
                    is_regression = False
                    if "tree_type" in st.session_state:
                        is_regression = st.session_state.tree_type == "Regresi√≥n"

                    if st.button("üìà Regresi√≥n",
                                 key="btn_regression",
                                 type="primary" if is_regression else "secondary",
                                 use_container_width=True,
                                 help="Para predecir valores num√©ricos continuos"):
                        tree_type = "Regresi√≥n"
                        st.session_state.tree_type = tree_type
                        st.rerun()

                # Obtener el valor actual del tipo de √°rbol
                tree_type = st.session_state.get('tree_type', task_type)

                # Si no hay tree_type definido, usar el detectado
                if 'tree_type' not in st.session_state:
                    st.session_state.tree_type = task_type

                # Mostrar advertencia si la selecci√≥n no coincide con el tipo de tarea detectado
                if tree_type != task_type:
                    st.warning(
                        f"Este dataset parece ser m√°s adecuado para {task_type}. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")

            except Exception as e:
                st.error(f"Error al cargar el dataset: {str(e)}")
                dataset_loaded = False

        # Par√°metros del modelo
        st.markdown("### Par√°metros del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            criterion = st.selectbox(
                "Criterio de Divisi√≥n:",
                ["gini", "entropy"] if st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" else [
                    "squared_error", "friedman_mse", "absolute_error"],
                index=0,
                help="Medida de la calidad de una divisi√≥n. Gini o Entropy para clasificaci√≥n, MSE para regresi√≥n."
            )

            max_depth = st.slider(
                "Profundidad M√°xima:",
                min_value=1,
                max_value=10,
                value=3,
                help="La profundidad m√°xima del √°rbol. A mayor profundidad, m√°s complejo el modelo."
            )

        with col2:
            min_samples_split = st.slider(
                "Muestras M√≠nimas para Divisi√≥n:",
                min_value=2,
                max_value=10,
                value=2,
                help="N√∫mero m√≠nimo de muestras para dividir un nodo."
            )

            test_size = st.slider(
                "Tama√±o del Conjunto de Prueba:",
                min_value=0.1,
                max_value=0.5,
                value=0.3,
                step=0.05,
                help="Proporci√≥n de datos que se usar√° para evaluar el modelo."
            )

        # Guardar par√°metros en el estado de la sesi√≥n
        st.session_state.criterion = criterion
        st.session_state.max_depth = max_depth
        st.session_state.min_samples_split = min_samples_split
        st.session_state.test_size = test_size

        # Bot√≥n para entrenar el modelo
        train_button = st.button("Entrenar Modelo", type="primary")

        if train_button:
            with st.spinner("Entrenando modelo..."):
                try:
                    # Cargar y preprocesar datos
                    X, y, feature_names, class_names, dataset_info, task_type = load_data(
                        st.session_state.selected_dataset)
                    X_train, X_test, y_train, y_test = preprocess_data(
                        X, y, test_size=test_size)

                    # Entrenar el modelo
                    model_results = train_decision_tree(
                        X_train, y_train,
                        criterion=criterion,
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        tree_type=tree_type
                    )

                    # Extraer el modelo del diccionario de resultados
                    tree_model = model_results["model"]

                    # Guardar en el estado de la sesi√≥n
                    st.session_state.tree_model = tree_model
                    st.session_state.X_train = X_train
                    st.session_state.X_test = X_test
                    st.session_state.y_train = y_train
                    st.session_state.y_test = y_test
                    st.session_state.feature_names = feature_names
                    st.session_state.class_names = class_names
                    st.session_state.dataset_info = dataset_info
                    st.session_state.is_trained = True

                    # Evaluar el modelo
                    if tree_type == "Clasificaci√≥n":
                        # Obtener predicciones del modelo
                        y_pred = tree_model.predict(X_test)
                        st.session_state.test_results = evaluate_classification_model(
                            y_test, y_pred, class_names
                        )
                    else:
                        # Obtener predicciones del modelo
                        y_pred = tree_model.predict(X_test)
                        st.session_state.test_results = evaluate_regression_model(
                            y_test, y_pred
                        )

                    st.success(
                        "¬°Modelo entrenado con √©xito! Ahora puedes explorar las otras pesta√±as.")

                    # Sugerir ir a la pesta√±a de visualizaci√≥n
                    st.info(
                        "üëâ Ve a la pesta√±a 'üå≤ Visualizaci√≥n' para ver el √°rbol generado.")

                except Exception as e:
                    st.error(f"Error al entrenar el modelo: {str(e)}")

    # Pesta√±a de Evaluaci√≥n
    elif st.session_state.active_tab == 2:
        st.header("Evaluaci√≥n del Modelo")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Obtener predicciones del modelo
            y_pred = st.session_state.tree_model.predict(
                st.session_state.X_test)

            # Mostrar evaluaci√≥n detallada del modelo
            show_detailed_evaluation(
                st.session_state.y_test,
                y_pred,
                st.session_state.class_names if st.session_state.get(
                    'tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" else None,
                st.session_state.get('tree_type', 'Clasificaci√≥n')
            )

            # Decisi√≥n boundary si es clasificaci√≥n y tiene 2 caracter√≠sticas
            if st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" and st.session_state.X_train.shape[1] <= 2:
                st.markdown("### Frontera de Decisi√≥n")

                if st.session_state.X_train.shape[1] == 1:
                    # Caso especial: solo una caracter√≠stica - agregar una segunda artificial
                    if hasattr(st.session_state.X_train, 'values'):
                        # DataFrame
                        X_values = st.session_state.X_train.values
                    else:
                        # numpy array
                        X_values = st.session_state.X_train
                    X_plot = np.column_stack(
                        [X_values, np.zeros_like(X_values)])
                    feature_idx = [0]
                    feature_names_plot = [
                        st.session_state.feature_names[0], "Caracter√≠stica artificial"]
                else:
                    # Dos caracter√≠sticas - dejar seleccionar cu√°les usar
                    st.markdown(
                        "Selecciona las caracter√≠sticas para visualizar la frontera de decisi√≥n:")
                    col1, col2 = st.columns(2)

                    with col1:
                        feature1 = st.selectbox(
                            "Primera caracter√≠stica:",
                            st.session_state.feature_names,
                            index=0
                        )

                    with col2:
                        feature2 = st.selectbox(
                            "Segunda caracter√≠stica:",
                            st.session_state.feature_names,
                            index=min(
                                1, len(st.session_state.feature_names) - 1)
                        )

                    feature_idx = [st.session_state.feature_names.index(feature1),
                                   st.session_state.feature_names.index(feature2)]

                    # Manejar DataFrame vs numpy array
                    if hasattr(st.session_state.X_train, 'iloc'):
                        # DataFrame
                        X_plot = st.session_state.X_train.iloc[:,
                                                               feature_idx].values
                    else:
                        # numpy array
                        X_plot = st.session_state.X_train[:, feature_idx]
                    feature_names_plot = [feature1, feature2]

                # Generar y mostrar el plot en tama√±o reducido
                try:
                    fig, ax = plot_decision_boundary(
                        st.session_state.tree_model,
                        X_plot,
                        st.session_state.y_train,
                        feature_names=feature_names_plot,
                        class_names=st.session_state.class_names
                    )

                    # Mostrar en columnas para reducir el tama√±o al 75%
                    col1, col2, col3 = st.columns([1, 3, 1])
                    with col2:
                        # Mostrar la figura directamente
                        plt.tight_layout()
                        st.pyplot(fig, clear_figure=True,
                                  use_container_width=True)

                    # Enlace para descargar
                    st.markdown(
                        get_image_download_link(
                            fig, "frontera_decision", "üì• Descargar visualizaci√≥n de la frontera"),
                        unsafe_allow_html=True
                    )
                except Exception as e:
                    st.error(
                        f"Error al mostrar la visualizaci√≥n de frontera de decisi√≥n: {str(e)}")
                    st.info(
                        "La frontera de decisi√≥n requiere exactamente 2 caracter√≠sticas para visualizarse.")

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_boundary = """
import numpy as np
import matplotlib.pyplot as plt
from sklearn.inspection import DecisionBoundaryDisplay

def plot_decision_boundary(model, X, y, feature_names=None, class_names=None):
    \"\"\"
    Visualiza la frontera de decisi√≥n para un modelo con 2 caracter√≠sticas.

    Parameters:
    -----------
    model : Modelo de scikit-learn
        Modelo entrenado con m√©todo predict
    X : array-like
        Datos de caracter√≠sticas (solo se usan las primeras 2 columnas)
    y : array-like
        Etiquetas de clase
    feature_names : list, opcional
        Nombres de las caracter√≠sticas
    class_names : list, opcional
        Nombres de las clases

    Returns:
    --------
    fig : Figura de matplotlib
    \"\"\"
    # Asegurar que solo usamos 2 caracter√≠sticas
    X_plot = X[:, :2] if X.shape[1] > 2 else X

    # Crear figura
    fig, ax = plt.subplots(figsize=(8, 6))

    # Crear objeto de visualizaci√≥n de frontera
    disp = DecisionBoundaryDisplay.from_estimator(
        model,
        X_plot,
        alpha=0.5,
        ax=ax,
        response_method="predict"
    )

    # Colorear los puntos seg√∫n su clase
    scatter = ax.scatter(
        X_plot[:, 0],
        X_plot[:, 1],
        c=y,
        edgecolor="k",
        s=50
    )

    # Configurar etiquetas
    if feature_names and len(feature_names) >= 2:
        ax.set_xlabel(feature_names[0])
        ax.set_ylabel(feature_names[1])
    else:
        ax.set_xlabel("Caracter√≠stica 1")
        ax.set_ylabel("Caracter√≠stica 2")

    # Configurar leyenda
    if class_names:
        legend_labels = class_names
    else:
        legend_labels = [f"Clase {i}" for i in range(len(np.unique(y)))]

    legend = ax.legend(
        handles=scatter.legend_elements()[0],
        labels=legend_labels,
        title="Clases"
    )

    ax.add_artist(legend)
    ax.set_title("Frontera de Decisi√≥n")

    return fig

# Para usar:
# fig = plot_decision_boundary(model, X, y, feature_names, class_names)
# plt.show()
"""

                show_code_with_download(
                    code_boundary, "C√≥digo para generar la frontera de decisi√≥n",
                    "frontera_decision.py"
                )

    # Pesta√±a de Visualizaci√≥n
    elif st.session_state.active_tab == 3:
        st.header("Visualizaci√≥n del √Årbol")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Configuraci√≥n de la visualizaci√≥n
            st.markdown("### Tipo de visualizaci√≥n")

            # Usar botones para seleccionar el tipo de visualizaci√≥n
            if "viz_type" not in st.session_state:
                st.session_state.viz_type = "Est√°ndar"

            # Determinar si mostrar la opci√≥n de frontera de decisi√≥n
            show_boundary = (st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n"
                             and len(st.session_state.get('feature_names', [])) >= 2)

            if show_boundary:
                viz_col1, viz_col2, viz_col3 = st.columns(3)
            else:
                viz_col1, viz_col2 = st.columns(2)
                viz_col3 = None

            with viz_col1:
                if st.button("üìä Est√°ndar",
                             key="viz_standard",
                             type="primary" if st.session_state.viz_type == "Est√°ndar" else "secondary",
                             use_container_width=True):
                    st.session_state.viz_type = "Est√°ndar"
                    st.rerun()

            with viz_col2:
                if st.button("üìù Texto",
                             key="viz_text",
                             type="primary" if st.session_state.viz_type == "Texto" else "secondary",
                             use_container_width=True):
                    st.session_state.viz_type = "Texto"
                    st.rerun()

            if show_boundary and viz_col3:
                with viz_col3:
                    if st.button("üåà Frontera",
                                 key="viz_boundary",
                                 type="primary" if st.session_state.viz_type == "Frontera" else "secondary",
                                 use_container_width=True):
                        st.session_state.viz_type = "Frontera"
                        st.rerun()

            viz_type = st.session_state.viz_type

            # Opciones de tama√±o para la visualizaci√≥n
            col1, col2 = st.columns(2)

            with col1:
                fig_width = st.slider("Ancho de figura:", 8, 20, 14)

            with col2:
                fig_height = st.slider("Alto de figura:", 6, 15, 10)

            # Mostrar la visualizaci√≥n seg√∫n el tipo seleccionado
            if viz_type == "Est√°ndar":
                # Visualizaci√≥n est√°ndar de scikit-learn
                fig, ax = plt.subplots(figsize=(fig_width, fig_height))
                from sklearn.tree import plot_tree

                plot_tree(
                    st.session_state.tree_model,
                    feature_names=st.session_state.feature_names,
                    class_names=st.session_state.class_names if st.session_state.tree_type == "Clasificaci√≥n" else None,
                    filled=True,
                    rounded=True,
                    ax=ax,
                    proportion=True,
                    impurity=True
                )

                # Mostrar con tama√±o reducido pero expandible
                col1, col2, col3 = st.columns([1, 4, 1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Enlace para descargar
                st.markdown(
                    get_image_download_link(
                        fig, "arbol_decision", "üì• Descargar visualizaci√≥n del √°rbol"),
                    unsafe_allow_html=True
                )

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_tree = """
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# Suponiendo que ya tienes un modelo entrenado (tree_model)
# y los nombres de las caracter√≠sticas (feature_names) y clases (class_names)

fig, ax = plt.subplots(figsize=(14, 10))

plot_tree(
    tree_model,
    feature_names=feature_names,
    class_names=class_names,  # Solo para clasificaci√≥n
    filled=True,
    rounded=True,
    ax=ax,
    proportion=True,
    impurity=True
)

plt.tight_layout()
plt.show()

# Para guardar a un archivo:
# plt.savefig('arbol_decision.png', dpi=300, bbox_inches='tight')
"""

                show_code_with_download(
                    code_tree, "C√≥digo para visualizar el √°rbol", "visualizar_arbol.py")

            elif viz_type == "Texto":
                # Obtener representaci√≥n de texto
                tree_text = get_tree_text(
                    st.session_state.tree_model,
                    st.session_state.feature_names,
                )

                # Mostrar en un √°rea de texto
                st.text(tree_text)

                # Bot√≥n para descargar
                text_bytes = tree_text.encode()
                b64 = base64.b64encode(text_bytes).decode()
                href = f'<a href="data:text/plain;base64,{b64}" download="arbol_texto.txt">üì• Descargar texto del √°rbol</a>'
                st.markdown(href, unsafe_allow_html=True)

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_text = """
from sklearn.tree import export_text

def get_tree_text(model, feature_names, show_class_name=True):
    \"\"\"
    Obtiene una representaci√≥n de texto de un √°rbol de decisi√≥n.

    Parameters:
    -----------
    model : DecisionTreeClassifier o DecisionTreeRegressor
        Modelo de √°rbol entrenado
    feature_names : list
        Nombres de las caracter√≠sticas
    show_class_name : bool
        Si es True, muestra los nombres de las clases (para clasificaci√≥n)

    Returns:
    --------
    str
        Representaci√≥n de texto del √°rbol
    \"\"\"
    return export_text(
        model,
        feature_names=feature_names,
        show_weights=True
    )

# Ejemplo de uso:
tree_text = get_tree_text(tree_model, feature_names)
print(tree_text)

# Para guardar a un archivo:
# with open('arbol_texto.txt', 'w') as f:
#     f.write(tree_text)
"""

                show_code_with_download(
                    code_text, "C√≥digo para obtener el texto del √°rbol", "texto_arbol.py")

            elif viz_type == "Frontera":
                # Visualizaci√≥n de frontera de decisi√≥n
                st.markdown("### Visualizaci√≥n de Frontera de Decisi√≥n")

                st.info("""
                **C√≥mo interpretar esta visualizaci√≥n:**
                - Las √°reas coloreadas muestran las regiones de decisi√≥n para cada clase
                - Los puntos representan las muestras de entrenamiento
                - Las l√≠neas entre colores son las fronteras de decisi√≥n
                - Solo se muestran las primeras dos caracter√≠sticas para crear la visualizaci√≥n 2D
                """)

                # Selecci√≥n de caracter√≠sticas para la visualizaci√≥n
                if len(st.session_state.feature_names) > 2:
                    cols = st.columns(2)
                    with cols[0]:
                        feature1 = st.selectbox(
                            "Primera caracter√≠stica:",
                            st.session_state.feature_names,
                            index=0,
                            key="feature1_boundary_viz"
                        )
                    with cols[1]:
                        feature2 = st.selectbox(
                            "Segunda caracter√≠stica:",
                            st.session_state.feature_names,
                            index=1,
                            key="feature2_boundary_viz"
                        )

                    # Obtener √≠ndices de las caracter√≠sticas seleccionadas
                    feature_names_list = list(st.session_state.feature_names)
                    f1_idx = feature_names_list.index(feature1)
                    f2_idx = feature_names_list.index(feature2)

                    # Crear array con solo las dos caracter√≠sticas seleccionadas
                    # Verificar si X_train es DataFrame o numpy array
                    if hasattr(st.session_state.X_train, 'iloc'):
                        # Es un DataFrame, usar iloc para indexaci√≥n posicional
                        X_boundary = st.session_state.X_train.iloc[:, [
                            f1_idx, f2_idx]].values
                    else:
                        # Es un numpy array, usar indexaci√≥n normal
                        X_boundary = st.session_state.X_train[:, [
                            f1_idx, f2_idx]]
                    feature_names_boundary = [feature1, feature2]
                else:
                    # Si solo hay dos caracter√≠sticas, usarlas directamente
                    if hasattr(st.session_state.X_train, 'values'):
                        # Es un DataFrame, convertir a numpy array
                        X_boundary = st.session_state.X_train.values
                    else:
                        # Es un numpy array
                        X_boundary = st.session_state.X_train
                    feature_names_boundary = st.session_state.feature_names

                # Crear figura y dibujar frontera de decisi√≥n
                try:
                    fig, ax = plt.subplots(figsize=(fig_width, fig_height))
                    plot_decision_boundary(
                        st.session_state.tree_model,
                        X_boundary,
                        st.session_state.y_train,
                        ax=ax,
                        feature_names=feature_names_boundary,
                        class_names=st.session_state.class_names,
                        show_code=False
                    )

                    # Mostrar la figura
                    col1, col2, col3 = st.columns([1, 4, 1])
                    with col2:
                        st.pyplot(fig, use_container_width=True)

                    # Enlace para descargar
                    st.markdown(
                        get_image_download_link(
                            fig, "frontera_decision", "üì• Descargar visualizaci√≥n de frontera"),
                        unsafe_allow_html=True
                    )

                    # Explicaci√≥n adicional
                    st.markdown("""
                    **Nota:** Esta visualizaci√≥n muestra c√≥mo el √°rbol de decisi√≥n divide el espacio de caracter√≠sticas
                    en regiones de decisi√≥n. Cada color representa una clase diferente. 
                    
                    Para crear esta visualizaci√≥n 2D, se entrena un nuevo √°rbol utilizando solo las dos caracter√≠sticas 
                    seleccionadas, por lo que puede diferir ligeramente del modelo completo que utiliza todas las caracter√≠sticas.
                    """)

                    # Advertencia sobre dimensionalidad
                    if len(st.session_state.feature_names) > 2:
                        st.warning("""
                        ‚ö†Ô∏è Esta visualizaci√≥n solo muestra 2 caracter√≠sticas seleccionadas. El modelo real utiliza todas 
                        las caracter√≠sticas para hacer predicciones. Las fronteras pueden variar si se seleccionan 
                        diferentes pares de caracter√≠sticas.
                        """)

                    # Mostrar c√≥digo para generar esta visualizaci√≥n
                    code_boundary = f"""
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from decision_boundary import plot_decision_boundary

# Datos de entrenamiento (solo las primeras 2 caracter√≠sticas)
X_2d = X_train[:, [0, 1]]  # Usar las caracter√≠sticas seleccionadas
y_train = y_train

# Crear figura
fig, ax = plt.subplots(figsize=({fig_width}, {fig_height}))

# Visualizar frontera de decisi√≥n
plot_decision_boundary(
    tree_model,
    X_2d,
    y_train,
    ax=ax,
    feature_names={feature_names_boundary},
    class_names={st.session_state.class_names if st.session_state.class_names else None}
)

plt.tight_layout()
plt.show()

# Para guardar a un archivo:
# plt.savefig('frontera_decision.png', dpi=300, bbox_inches='tight')
"""

                    show_code_with_download(
                        code_boundary, "C√≥digo para generar la frontera de decisi√≥n", "frontera_decision.py")

                except Exception as e:
                    st.error(
                        f"Error al mostrar la visualizaci√≥n de frontera de decisi√≥n: {str(e)}")
                    st.info("""
                    La frontera de decisi√≥n requiere:
                    - Un modelo de clasificaci√≥n entrenado
                    - Exactamente 2 caracter√≠sticas para visualizar
                    - Datos de entrenamiento v√°lidos
                    """)
                    st.exception(
                        e)  # Mostrar detalles del error para debugging

    # Pesta√±a de Caracter√≠sticas
    elif st.session_state.active_tab == 4:
        st.header("Importancia de Caracter√≠sticas")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Mostrar importancia de caracter√≠sticas
            display_feature_importance(
                st.session_state.tree_model,
                st.session_state.feature_names
            )

    # Pesta√±a de Predicciones
    elif st.session_state.active_tab == 5:
        st.header("Predicciones con Nuevos Datos")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Interfaz para hacer predicciones
            create_prediction_interface(
                st.session_state.tree_model,
                st.session_state.feature_names,
                st.session_state.class_names,
                st.session_state.get('tree_type', 'Clasificaci√≥n'),
                # Pasar datos de entrenamiento para rangos din√°micos
                st.session_state.get('X_train', None),
                # Pasar nombre del dataset para metadata
                st.session_state.get('selected_dataset', 'Titanic')
            )

    # Pesta√±a de Exportar Modelo
    elif st.session_state.active_tab == 6:
        st.header("Exportar Modelo")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Opciones para exportar el modelo
            display_model_export_options(
                st.session_state.tree_model,
                st.session_state.feature_names,
                st.session_state.class_names,
                st.session_state.get('tree_type', 'Clasificaci√≥n'),
                st.session_state.get('max_depth', 3),
                st.session_state.get('min_samples_split', 2),
                st.session_state.get('criterion', 'gini')
            )


def run_linear_regression_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de regresi√≥n (lineal y log√≠stica)."""
    st.header("üìä Regresi√≥n")
    st.markdown(
        "Aprende sobre regresi√≥n lineal y log√≠stica de forma interactiva")

    # Informaci√≥n sobre regresi√≥n
    with st.expander("‚ÑπÔ∏è ¬øQu√© es la Regresi√≥n?", expanded=False):
        st.markdown("""
        La regresi√≥n es un conjunto de algoritmos de aprendizaje supervisado utilizados para predecir valores num√©ricos continuos (regresi√≥n lineal) o clasificar elementos en categor√≠as (regresi√≥n log√≠stica).

        **Caracter√≠sticas principales:**
        - **Regresi√≥n Lineal**: Establece una relaci√≥n lineal entre las variables independientes (caracter√≠sticas) y la variable dependiente (objetivo)
        - **Regresi√≥n Log√≠stica**: Utiliza la funci√≥n log√≠stica para modelar la probabilidad de pertenencia a una clase
        - Ambos tipos minimizan funciones de costo espec√≠ficas para encontrar los mejores par√°metros
        - Son interpretables: los coeficientes indican la importancia y direcci√≥n del efecto de cada caracter√≠stica
        - No requieren escalado de datos, aunque puede mejorar la convergencia

        **Tipos de regresi√≥n:**
        - **Regresi√≥n Lineal Simple**: Una sola caracter√≠stica predictora
        - **Regresi√≥n Lineal M√∫ltiple**: M√∫ltiples caracter√≠sticas predictoras
        - **Regresi√≥n Log√≠stica**: Para problemas de clasificaci√≥n binaria o multiclase

        **Limitaciones:**
        - Asume una relaci√≥n lineal entre variables (regresi√≥n lineal)
        - Sensible a valores at√≠picos (outliers)
        - Puede sufrir de multicolinealidad cuando las caracter√≠sticas est√°n correlacionadas
        """)

    # Variables para almacenar datos
    dataset_loaded = False
    X, y, feature_names, class_names, dataset_info, task_type = None, None, None, None, None, None

    # Inicializar el estado de la pesta√±a activa si no existe
    if 'active_tab_lr' not in st.session_state:
        st.session_state.active_tab_lr = 0

    # Crear pesta√±as para organizar la informaci√≥n
    tab_options = [
        "üìä Datos",
        "üèãÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üìâ Visualizaci√≥n",
        "üîç Coeficientes",
        "üîÆ Predicciones",
        "üíæ Exportar Modelo"
    ]

    # Crear contenedor para los botones de las pesta√±as
    tab_cols = st.columns(len(tab_options))

    # Estilo CSS para los botones de pesta√±as (Regresi√≥n)
    st.markdown("""
    <style>
    div.tab-button-lr > button {
        border-radius: 4px 4px 0 0;
        padding: 10px;
        width: 100%;
        white-space: nowrap;
        background-color: #F0F2F6;
        border-bottom: 2px solid #E0E0E0;
        color: #333333;
    }
    div.tab-button-lr-active > button {
        background-color: #E3F2FD !important;
        border-bottom: 2px solid #1E88E5 !important;
        font-weight: bold !important;
        color: #1E88E5 !important;
    }
    div.tab-button-lr > button:hover {
        background-color: #E8EAF6;
    }
    </style>
    """, unsafe_allow_html=True)

    # Crear botones para las pesta√±as
    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_lr_{i}"
        button_style = "tab-button-lr-active" if st.session_state.active_tab_lr == i else "tab-button-lr"
        is_active = st.session_state.active_tab_lr == i

        with col:
            st.markdown(f"<div class='{button_style}'>",
                        unsafe_allow_html=True)
            # Usar type="primary" para el bot√≥n activo
            if st.button(tab_name, key=button_key, use_container_width=True,
                         type="primary" if is_active else "secondary"):
                st.session_state.active_tab_lr = i
                st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    # Separador visual
    st.markdown("---")

    # SELECTOR UNIFICADO DE DATASET (solo mostrar en pesta√±as que lo necesiten)
    if st.session_state.active_tab_lr in [0, 1]:  # Exploraci√≥n y Entrenamiento
        st.markdown("### üìä Selecci√≥n de Dataset")

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset_lr' not in st.session_state:
            st.session_state.selected_dataset_lr = "üí∞ Propinas - Predicci√≥n de propinas"

        # Lista de datasets adecuados para regresi√≥n
        regression_datasets = [
            "üí∞ Propinas - Predicci√≥n de propinas",
            "üè† Viviendas California - Precios",
            "üå∏ Iris - Clasificaci√≥n de flores",  # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üç∑ Vino - Clasificaci√≥n de vinos",   # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üî¨ C√°ncer - Diagn√≥stico binario",   # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üö¢ Titanic - Supervivencia",        # Tambi√©n √∫til para regresi√≥n log√≠stica
            # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üêß Ping√ºinos - Clasificaci√≥n de especies"
        ]

        # A√±adir datasets CSV cargados si existen
        available_datasets = regression_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado est√© en la lista disponible
        if st.session_state.selected_dataset_lr not in available_datasets:
            st.session_state.selected_dataset_lr = regression_datasets[0]

        # Selector unificado
        dataset_option = st.selectbox(
            "Dataset:",
            available_datasets,
            index=available_datasets.index(
                st.session_state.selected_dataset_lr),
            key="unified_dataset_selector_lr",
            help="El dataset seleccionado se mantendr√° entre las pesta√±as de Exploraci√≥n y Entrenamiento"
        )

        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset_lr = dataset_option

        # Separador despu√©s del selector
        st.markdown("---")
    else:
        # Para otras pesta√±as, mostrar qu√© dataset est√° seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset_lr'):
            st.info(
                f"üìä **Dataset actual:** {st.session_state.selected_dataset_lr}")
            st.markdown("---")

    # Pesta√±a de Datos
    if st.session_state.active_tab_lr == 0:
        st.header("Exploraci√≥n de Datos")

        try:
            # Cargar datos para exploraci√≥n
            X, y, feature_names, class_names, dataset_info, task_type = load_data(
                st.session_state.selected_dataset_lr)

            # Convertir a DataFrames para facilitar el manejo
            if isinstance(X, pd.DataFrame):
                X_df = X.copy()
                column_mapping = {}
                if len(feature_names) == len(X_df.columns):
                    column_mapping = dict(zip(X_df.columns, feature_names))
            else:
                X_df = pd.DataFrame(X, columns=feature_names)
                column_mapping = {}

            y_df = pd.Series(y, name="target")

            # Para regresi√≥n log√≠stica, mapear nombres de clases si est√°n disponibles
            if task_type == "Clasificaci√≥n" and class_names is not None:
                y_df = y_df.map(
                    {i: name for i, name in enumerate(class_names)})

            df = pd.concat([X_df, y_df], axis=1)

            # Renombrar columnas para mostrar nombres amigables si existe el mapeo
            if column_mapping:
                df_display = df.rename(columns=column_mapping)
            else:
                df_display = df

            # Mostrar informaci√≥n del dataset
            st.markdown("### Informaci√≥n del Dataset")
            st.markdown(create_info_box(dataset_info), unsafe_allow_html=True)

            # Mostrar las primeras filas de los datos
            st.markdown("### Vista previa de datos")
            st.dataframe(df_display.head(10))

            # Estad√≠sticas descriptivas
            st.markdown("### Estad√≠sticas Descriptivas")
            st.dataframe(df_display.describe())

            # Distribuci√≥n de clases o valores objetivo
            st.markdown("### Distribuci√≥n del Objetivo")

            fig, ax = plt.subplots(figsize=(10, 6))

            if task_type == "Clasificaci√≥n":
                # Gr√°fico de barras para clasificaci√≥n (regresi√≥n log√≠stica)
                value_counts = y_df.value_counts().sort_index()
                try:
                    import seaborn as sns
                    sns.barplot(x=value_counts.index,
                                y=value_counts.values, ax=ax)
                except ImportError:
                    # Fallback to matplotlib if seaborn is not available
                    ax.bar(value_counts.index, value_counts.values)
                ax.set_title("Distribuci√≥n de Clases")
                ax.set_xlabel("Clase")
                ax.set_ylabel("Cantidad")

                # Rotar etiquetas si son muchas
                if len(value_counts) > 3:
                    plt.xticks(rotation=45, ha='right')
            else:
                # Histograma para regresi√≥n
                # Convertir a num√©rico en caso de que sean strings
                y_numeric = pd.to_numeric(y_df, errors='coerce')
                # Usar matplotlib directamente para evitar problemas de tipo
                ax.hist(y_numeric.dropna(), bins=30,
                        alpha=0.7, edgecolor='black')
                ax.set_title("Distribuci√≥n de Valores Objetivo")
                ax.set_xlabel("Valor")
                ax.set_ylabel("Frecuencia")

            # Mostrar la figura
            col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
            with col2:
                st.pyplot(fig, use_container_width=True)

            # An√°lisis de correlaci√≥n
            st.markdown("### Matriz de Correlaci√≥n")

            # Matriz de correlaci√≥n
            corr = X_df.corr()

            # Generar m√°scara para el tri√°ngulo superior
            mask = np.triu(np.ones_like(corr, dtype=bool))

            # Generar mapa de calor
            fig_corr, ax = plt.subplots(figsize=(10, 8))
            try:
                import seaborn as sns
                sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
                            square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
            except ImportError:
                # Fallback to matplotlib if seaborn is not available
                im = ax.imshow(corr.where(~mask),
                               cmap="coolwarm", aspect="auto")
                ax.set_xticks(range(len(corr.columns)))
                ax.set_yticks(range(len(corr.columns)))
                ax.set_xticklabels(corr.columns, rotation=45, ha='right')
                ax.set_yticklabels(corr.columns)
                # Add text annotations
                for i in range(len(corr.columns)):
                    for j in range(len(corr.columns)):
                        if not mask[i, j]:
                            text = ax.text(j, i, f'{corr.iloc[i, j]:.2f}',
                                           ha="center", va="center", color="black")
            ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

            # Mostrar la figura
            col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
            with col2:
                st.pyplot(fig_corr, use_container_width=True)

            # Matriz de dispersi√≥n (Scatterplot Matrix)
            st.markdown("### Matriz de Dispersi√≥n (Pairplot)")

            # Opciones de visualizaci√≥n
            st.markdown("#### Opciones de visualizaci√≥n")
            col1, col2 = st.columns(2)

            with col1:
                # Seleccionar tipo de gr√°fico para la diagonal
                diag_kind = st.radio(
                    "Tipo de gr√°fico en la diagonal:",
                    ["Histograma", "KDE (Estimaci√≥n de Densidad)"],
                    index=1,
                    horizontal=True
                )
                diag_kind = "hist" if diag_kind == "Histograma" else "kde"

            with col2:
                # Seleccionar n√∫mero m√°ximo de caracter√≠sticas
                max_features_selected = st.slider(
                    "N√∫mero m√°ximo de caracter√≠sticas:",
                    min_value=2,
                    max_value=min(6, len(X_df.columns)),
                    value=min(4, len(X_df.columns)),
                    help="Un n√∫mero mayor de caracter√≠sticas puede hacer que el gr√°fico sea m√°s dif√≠cil de interpretar."
                )

            # Permitir al usuario seleccionar las caracter√≠sticas espec√≠ficas
            st.markdown("#### Selecciona las caracter√≠sticas para visualizar")

            # Usar nombres amigables si est√°n disponibles
            if column_mapping:
                available_features = list(column_mapping.values())
                display_to_original = {v: k for k, v in column_mapping.items()}
            else:
                available_features = X_df.columns.tolist()
                display_to_original = {}

            # Usar multiselect para seleccionar caracter√≠sticas
            selected_features = st.multiselect(
                "Caracter√≠sticas a incluir en la matriz de dispersi√≥n:",
                available_features,
                default=available_features[:max_features_selected],
                max_selections=max_features_selected,
                help=f"Selecciona hasta {max_features_selected} caracter√≠sticas para incluir en la visualizaci√≥n."
            )

            # Si no se seleccion√≥ ninguna caracter√≠stica, usar las primeras por defecto
            if not selected_features:
                selected_features = available_features[:max_features_selected]
                st.info(
                    f"No se seleccionaron caracter√≠sticas. Usando las primeras {max_features_selected} por defecto.")

            # Convertir nombres amigables a nombres originales si es necesario
            if column_mapping:
                original_features = [display_to_original[feat]
                                     for feat in selected_features]
            else:
                original_features = selected_features

            # Crear el dataframe para la visualizaci√≥n
            plot_df = X_df[original_features].copy()
            # Renombrar a nombres amigables para visualizaci√≥n
            if column_mapping:
                plot_df = plot_df.rename(columns=column_mapping)
            # A√±adir la variable objetivo para colorear
            plot_df['target'] = y_df

            # Generar el pairplot
            with st.spinner("Generando matriz de dispersi√≥n..."):
                try:
                    import seaborn as sns
                    pair_plot = sns.pairplot(
                        plot_df,
                        hue='target' if task_type == "Clasificaci√≥n" else None,
                        diag_kind=diag_kind,
                        plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
                        diag_kws={'alpha': 0.5},
                        height=2.0
                    )
                    pair_plot.fig.suptitle(
                        "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=14)

                    # Mostrar la figura
                    col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                    with col2:
                        st.pyplot(pair_plot.fig, use_container_width=True)

                    # Enlace para descargar
                    st.markdown(
                        get_image_download_link(
                            pair_plot.fig, "matriz_dispersion_lr", "üì• Descargar matriz de dispersi√≥n"),
                        unsafe_allow_html=True
                    )
                except ImportError:
                    st.error(
                        "Seaborn no est√° disponible. Por favor, instala seaborn para usar la matriz de dispersi√≥n.")
                    st.info(
                        "Puedes instalar seaborn ejecutando: pip install seaborn")

        except Exception as e:
            st.error(f"Error al cargar el dataset: {str(e)}")
            st.info(
                "Por favor, selecciona un dataset v√°lido para continuar con la exploraci√≥n.")

    # Pesta√±a de Entrenamiento
    elif st.session_state.active_tab_lr == 1:
        st.header("Configuraci√≥n del Modelo")

        # Inicializar session state variables
        if 'dataset_option_lr' not in st.session_state:
            st.session_state.dataset_option_lr = st.session_state.selected_dataset_lr
        if 'model_type_lr' not in st.session_state:
            st.session_state.model_type_lr = "Linear"
        if 'is_trained_lr' not in st.session_state:
            st.session_state.is_trained_lr = False

        # Cargar datos para la vista previa si cambia el dataset o si no se ha cargado
        if st.session_state.selected_dataset_lr != st.session_state.dataset_option_lr or not dataset_loaded:
            try:
                X, y, feature_names, class_names, dataset_info, task_type = load_data(
                    st.session_state.selected_dataset_lr)

                st.session_state.dataset_option_lr = st.session_state.selected_dataset_lr
                dataset_loaded = True

                # Mostrar informaci√≥n del dataset
                st.markdown("### Informaci√≥n del Dataset")
                st.markdown(create_info_box(dataset_info),
                            unsafe_allow_html=True)

                # Determinar el tipo de modelo seg√∫n el task_type detectado
                st.markdown("### Tipo de Modelo Lineal")

                # Usar botones para seleccionar el tipo de modelo
                tipo_col1, tipo_col2 = st.columns(2)

                with tipo_col1:
                    is_linear = True
                    if "model_type_lr" in st.session_state:
                        is_linear = st.session_state.model_type_lr == "Linear"

                    if st.button("üìà Regresi√≥n Lineal",
                                 key="btn_linear",
                                 type="primary" if is_linear else "secondary",
                                 use_container_width=True,
                                 help="Para predecir valores num√©ricos continuos"):
                        model_type = "Linear"
                        st.session_state.model_type_lr = model_type
                        st.rerun()

                with tipo_col2:
                    is_logistic = False
                    if "model_type_lr" in st.session_state:
                        is_logistic = st.session_state.model_type_lr == "Logistic"

                    if st.button("üè∑Ô∏è Regresi√≥n Log√≠stica",
                                 key="btn_logistic",
                                 type="primary" if is_logistic else "secondary",
                                 use_container_width=True,
                                 help="Para predecir categor√≠as o clases"):
                        model_type = "Logistic"
                        st.session_state.model_type_lr = model_type
                        st.rerun()

                # Obtener el valor actual del tipo de modelo
                model_type = st.session_state.get('model_type_lr', "Linear")

                # Mostrar sugerencia basada en el tipo de tarea detectado
                if task_type == "Clasificaci√≥n" and model_type == "Linear":
                    st.warning(
                        "Este dataset parece ser m√°s adecuado para Regresi√≥n Log√≠stica. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")
                elif task_type == "Regresi√≥n" and model_type == "Logistic":
                    st.warning(
                        "Este dataset parece ser m√°s adecuado para Regresi√≥n Lineal. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")

            except Exception as e:
                st.error(f"Error al cargar el dataset: {str(e)}")
                dataset_loaded = False

        # Par√°metros del modelo
        st.markdown("### Par√°metros del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            # Para regresi√≥n log√≠stica, mostrar par√°metro max_iter
            if st.session_state.get('model_type_lr', 'Linear') == "Logistic":
                max_iter = st.slider(
                    "M√°ximo de Iteraciones:",
                    min_value=100,
                    max_value=2000,
                    value=1000,
                    step=100,
                    help="N√∫mero m√°ximo de iteraciones para el optimizador de regresi√≥n log√≠stica."
                )
            else:
                st.info(
                    "La regresi√≥n lineal no requiere configuraci√≥n adicional de iteraciones.")

        with col2:
            # Configuraciones adicionales pueden ir aqu√≠ en el futuro
            st.empty()

        if st.button("üöÄ Entrenar Modelo", key="train_lr_button", type="primary"):
            if dataset_loaded and X is not None and y is not None:
                with st.spinner("Entrenando modelo..."):
                    try:
                        # Entrenar el modelo
                        if model_type == "Logistic":
                            result = train_linear_model(
                                X, y,
                                model_type=model_type,
                                max_iter=max_iter,
                                test_size=0.2,
                                random_state=42
                            )
                        else:
                            result = train_linear_model(
                                X, y,
                                model_type=model_type,
                                test_size=0.2,
                                random_state=42
                            )

                        # Extraer el modelo y m√©tricas del resultado
                        model = result["model"]
                        metrics = result["test_results"]

                        # Guardar en session state
                        st.session_state.model_lr = model
                        st.session_state.metrics_lr = metrics
                        st.session_state.X_train_lr = result["X_train"]
                        st.session_state.X_test_lr = result["X_test"]
                        st.session_state.y_train_lr = result["y_train"]
                        st.session_state.y_test_lr = result["y_test"]
                        st.session_state.feature_names_lr = feature_names
                        st.session_state.class_names_lr = class_names
                        st.session_state.task_type_lr = task_type
                        st.session_state.model_trained_lr = True

                        st.success("¬°Modelo entrenado exitosamente!")

                    except Exception as e:
                        st.error(f"Error al entrenar el modelo: {str(e)}")
            else:
                st.error("Por favor, carga un dataset v√°lido primero.")

    # Pesta√±a de Evaluaci√≥n
    elif st.session_state.active_tab_lr == 2:
        st.header("Evaluaci√≥n del Modelo")

        if st.session_state.get('model_trained_lr', False):
            metrics = st.session_state.get('metrics_lr', {})
            model_type = st.session_state.get('model_type_lr', 'Linear')

            # An√°lisis de balance de clases para regresi√≥n log√≠stica
            if model_type == "Logistic":
                y_test = st.session_state.get('y_test_lr')
                if y_test is not None:
                    # Verificar balance de clases
                    class_counts = pd.Series(y_test).value_counts()
                    total_samples = len(y_test)

                    st.markdown("### ‚öñÔ∏è An√°lisis de Balance de Clases")

                    col1, col2 = st.columns(2)
                    with col1:
                        # Mostrar distribuci√≥n de clases
                        for class_val, count in class_counts.items():
                            percentage = (count / total_samples) * 100
                            class_name = st.session_state.get(
                                'class_names_lr', [])
                            display_name = class_name[int(class_val)] if class_name and int(
                                class_val) < len(class_name) else f"Clase {class_val}"
                            st.metric(f"{display_name}",
                                      f"{count} ({percentage:.1f}%)")

                    with col2:
                        # Evaluar balance
                        min_class_ratio = class_counts.min() / class_counts.max()
                        if min_class_ratio < 0.1:
                            st.error(
                                "‚ùå **Clases muy desbalanceadas** (ratio < 10%)")
                            st.markdown("**Recomendaciones:**")
                            st.markdown(
                                "‚Ä¢ Considera t√©cnicas de balanceo (SMOTE, undersampling)")
                            st.markdown(
                                "‚Ä¢ Usa m√©tricas como F1-Score en lugar de Accuracy")
                            st.markdown(
                                "‚Ä¢ Ajusta los pesos de las clases en el modelo")
                        elif min_class_ratio < 0.3:
                            st.warning(
                                "‚ö†Ô∏è **Clases moderadamente desbalanceadas**")
                            st.markdown(
                                "‚Ä¢ Presta especial atenci√≥n a Precision y Recall")
                            st.markdown(
                                "‚Ä¢ Considera la curva Precision-Recall")
                        else:
                            st.success(
                                "‚úÖ **Clases relativamente balanceadas**")
                            st.markdown("‚Ä¢ Accuracy es una m√©trica confiable")
                            st.markdown(
                                "‚Ä¢ Todas las m√©tricas son representativas")

            # Informaci√≥n sobre las m√©tricas
            with st.expander("‚ÑπÔ∏è ¬øQu√© significan estas m√©tricas?", expanded=False):
                if model_type == "Linear":
                    st.markdown("""
                    **M√©tricas de Regresi√≥n Lineal:**
                    
                    **R¬≤ Score (Coeficiente de Determinaci√≥n):**
                    - Mide qu√© tan bien el modelo explica la variabilidad de los datos
                    - Rango: 0 a 1 (valores negativos indican un modelo muy malo)
                    - **Interpretaci√≥n:**
                      - R¬≤ = 1.0: El modelo explica perfectamente toda la variabilidad
                      - R¬≤ = 0.8: El modelo explica el 80% de la variabilidad (muy bueno)
                      - R¬≤ = 0.5: El modelo explica el 50% de la variabilidad (moderado)
                      - R¬≤ = 0.0: El modelo no explica nada de la variabilidad
                    
                    **MAE (Error Absoluto Medio):**
                    - Promedio de las diferencias absolutas entre valores reales y predichos
                    - Se expresa en las mismas unidades que la variable objetivo
                    - **Interpretaci√≥n:** Valores m√°s bajos = mejor modelo
                    
                    **RMSE (Ra√≠z del Error Cuadr√°tico Medio):**
                    - Similar al MAE pero penaliza m√°s los errores grandes
                    - Se expresa en las mismas unidades que la variable objetivo
                    - **Interpretaci√≥n:** Valores m√°s bajos = mejor modelo
                    """)
                else:
                    st.markdown("""
                    **M√©tricas de Regresi√≥n Log√≠stica:**
                    
                    **Accuracy (Exactitud):**
                    - Porcentaje de predicciones correctas del total
                    - Rango: 0 a 1 (0% a 100%)
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor modelo
                    - **Cuidado:** Puede ser enga√±osa con clases desbalanceadas
                    
                    **Precision (Precisi√≥n):**
                    - De todas las predicciones positivas, cu√°ntas fueron correctas
                    - F√≥rmula: VP / (VP + FP)
                    - Importante cuando los falsos positivos son costosos
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor modelo
                    
                    **Recall (Sensibilidad o Exhaustividad):**
                    - De todos los casos positivos reales, cu√°ntos detect√≥ el modelo
                    - F√≥rmula: VP / (VP + FN)
                    - Importante cuando los falsos negativos son costosos
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor modelo
                    
                    **F1-Score:**
                    - Media arm√≥nica entre precisi√≥n y recall
                    - F√≥rmula: 2 √ó (Precisi√≥n √ó Recall) / (Precisi√≥n + Recall)
                    - √ötil cuando necesitas balance entre precisi√≥n y recall
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor balance
                    
                    **Curva ROC:**
                    - Muestra el rendimiento en diferentes umbrales de decisi√≥n
                    - AUC (√Årea bajo la curva): 0.5 = aleatorio, 1.0 = perfecto
                    
                    **Curva Precision-Recall:**
                    - Especialmente √∫til para clases desbalanceadas
                    - Muestra el trade-off entre precisi√≥n y recall
                    
                    **VP = Verdaderos Positivos, FP = Falsos Positivos, FN = Falsos Negativos**
                    """)

            st.markdown("### üìä Resultados de Evaluaci√≥n")

            if model_type == "Linear":
                col1, col2, col3 = st.columns(3)
                with col1:
                    r2_value = metrics.get('r2', 0)
                    st.metric("R¬≤ Score", f"{r2_value:.4f}")
                    # Indicador de calidad
                    if r2_value >= 0.8:
                        st.success("üéØ Excelente ajuste")
                    elif r2_value >= 0.6:
                        st.info("üëç Buen ajuste")
                    elif r2_value >= 0.4:
                        st.warning("‚ö†Ô∏è Ajuste moderado")
                    else:
                        st.error("‚ùå Ajuste pobre")

                with col2:
                    mae_value = metrics.get('mae', 0)
                    st.metric("MAE", f"{mae_value:.4f}")

                with col3:
                    rmse_value = metrics.get('rmse', 0)
                    st.metric("RMSE", f"{rmse_value:.4f}")

            else:
                col1, col2, col3 = st.columns(3)
                with col1:
                    acc_value = metrics.get('accuracy', 0)
                    st.metric("Accuracy", f"{acc_value:.4f}")
                    # Indicador de calidad
                    if acc_value >= 0.9:
                        st.success("üéØ Excelente")
                    elif acc_value >= 0.8:
                        st.info("üëç Muy bueno")
                    elif acc_value >= 0.7:
                        st.warning("‚ö†Ô∏è Bueno")
                    else:
                        st.error("‚ùå Necesita mejora")

                with col2:
                    st.metric(
                        "Precision", f"{metrics.get('precision', 0):.4f}")

                with col3:
                    st.metric("Recall", f"{metrics.get('recall', 0):.4f}")

                # A√±adir F1-Score si est√° disponible
                if 'report' in metrics and 'weighted avg' in metrics['report']:
                    f1_score = metrics['report']['weighted avg'].get(
                        'f1-score', 0)
                    st.markdown("### üéØ M√©tricas Adicionales")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("F1-Score", f"{f1_score:.4f}")
                        if f1_score >= 0.8:
                            st.success("üéØ Excelente balance")
                        elif f1_score >= 0.7:
                            st.info("üëç Buen balance")
                        else:
                            st.warning("‚ö†Ô∏è Balance mejorable")

                    # Mostrar m√©tricas por clase si es clasificaci√≥n multiclase
                    if 'report' in metrics:
                        class_names = st.session_state.get(
                            'class_names_lr', [])
                        if class_names and len(class_names) > 2:
                            st.markdown("### üìä M√©tricas por Clase")

                            report_data = []
                            for class_name in class_names:
                                if class_name in metrics['report']:
                                    class_metrics = metrics['report'][class_name]
                                    report_data.append({
                                        'Clase': class_name,
                                        'Precision': f"{class_metrics.get('precision', 0):.3f}",
                                        'Recall': f"{class_metrics.get('recall', 0):.3f}",
                                        'F1-Score': f"{class_metrics.get('f1-score', 0):.3f}",
                                        'Soporte': int(class_metrics.get('support', 0))
                                    })

                            if report_data:
                                df_report = pd.DataFrame(report_data)
                                st.dataframe(
                                    df_report, use_container_width=True, hide_index=True)

            # Mostrar interpretaci√≥n contextual
            st.markdown("### üéØ Interpretaci√≥n de Resultados")

            if model_type == "Linear":
                r2_value = metrics.get('r2', 0)
                mae_value = metrics.get('mae', 0)
                rmse_value = metrics.get('rmse', 0)

                interpretation = f"""
                **Resumen del Modelo:**
                - Tu modelo de regresi√≥n lineal explica **{r2_value*100:.1f}%** de la variabilidad en los datos
                - En promedio, las predicciones se desv√≠an **{mae_value:.2f} unidades** del valor real (MAE)
                - La ra√≠z del error cuadr√°tico medio es **{rmse_value:.2f} unidades** (RMSE)
                """

                if rmse_value > mae_value * 1.5:
                    interpretation += "\n- ‚ö†Ô∏è El RMSE es significativamente mayor que el MAE, lo que indica la presencia de algunos errores grandes"

                st.info(interpretation)

            else:
                acc_value = metrics.get('accuracy', 0)
                prec_value = metrics.get('precision', 0)
                rec_value = metrics.get('recall', 0)
                f1_value = 0

                # Obtener F1-score si est√° disponible
                if 'report' in metrics and 'weighted avg' in metrics['report']:
                    f1_value = metrics['report']['weighted avg'].get(
                        'f1-score', 0)

                interpretation = f"""
                **Resumen del Modelo:**
                - Tu modelo clasifica correctamente **{acc_value*100:.1f}%** de los casos
                - De las predicciones positivas, **{prec_value*100:.1f}%** son correctas (Precisi√≥n)
                - Detecta **{rec_value*100:.1f}%** de todos los casos positivos reales (Recall)
                """

                if f1_value > 0:
                    interpretation += f"\n- El F1-Score (balance entre precisi√≥n y recall) es **{f1_value:.3f}**"

                # An√°lisis de balance entre precisi√≥n y recall
                if abs(prec_value - rec_value) > 0.1:
                    if prec_value > rec_value:
                        interpretation += "\n\n‚öñÔ∏è **Balance:** El modelo es m√°s preciso pero menos sensible (m√°s conservador)"
                        interpretation += "\nüí° **Sugerencia:** Si es importante detectar todos los casos positivos, considera ajustar el umbral de decisi√≥n"
                    else:
                        interpretation += "\n\n‚öñÔ∏è **Balance:** El modelo es m√°s sensible pero menos preciso (m√°s liberal)"
                        interpretation += "\nüí° **Sugerencia:** Si es importante evitar falsos positivos, considera ajustar el umbral de decisi√≥n"
                else:
                    interpretation += "\n\n‚öñÔ∏è **Balance:** Bueno equilibrio entre precisi√≥n y recall"

                # An√°lisis espec√≠fico del accuracy
                if acc_value < 0.6:
                    interpretation += "\n\nüîç **Recomendaciones para mejorar:**"
                    interpretation += "\n‚Ä¢ Revisar la calidad y cantidad de datos de entrenamiento"
                    interpretation += "\n‚Ä¢ Considerar ingenier√≠a de caracter√≠sticas adicionales"
                    interpretation += "\n‚Ä¢ Probar diferentes algoritmos de clasificaci√≥n"
                    interpretation += "\n‚Ä¢ Verificar si hay desbalance de clases"

                st.info(interpretation)

        else:
            st.info("Entrena un modelo primero para ver las m√©tricas de evaluaci√≥n.")

    # Pesta√±a de Visualizaci√≥n
    elif st.session_state.active_tab_lr == 3:
        st.header("Visualizaciones")

        if st.session_state.get('model_trained_lr', False):
            model_type = st.session_state.get('model_type_lr', 'Linear')
            X_test = st.session_state.get('X_test_lr')
            y_test = st.session_state.get('y_test_lr')
            X_train = st.session_state.get('X_train_lr')
            y_train = st.session_state.get('y_train_lr')
            model = st.session_state.get('model_lr')

            # Informaci√≥n sobre las visualizaciones
            with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar estas visualizaciones?", expanded=False):
                if model_type == "Linear":
                    st.markdown("""
                    **Gr√°fico de Predicciones vs Valores Reales:**
                    - Cada punto representa una predicci√≥n del modelo
                    - La l√≠nea roja diagonal representa predicciones perfectas
                    - **Interpretaci√≥n:**
                      - Puntos cerca de la l√≠nea roja = buenas predicciones
                      - Puntos dispersos = predicciones menos precisas
                      - Patrones sistem√°ticos fuera de la l√≠nea pueden indicar problemas del modelo
                    
                    **Gr√°fico de Residuos:**
                    - Muestra la diferencia entre valores reales y predicciones
                    - **Interpretaci√≥n:**
                      - Residuos cerca de cero = buenas predicciones
                      - Patrones en los residuos pueden indicar que el modelo lineal no es adecuado
                      - Distribuci√≥n aleatoria alrededor de cero es ideal
                    """)
                else:
                    st.markdown("""
                    **Matriz de Confusi√≥n:**
                    - Muestra predicciones correctas e incorrectas por clase
                    - **Interpretaci√≥n:**
                      - Diagonal principal = predicciones correctas
                      - Fuera de la diagonal = errores del modelo
                      - Colores m√°s intensos = mayor cantidad de casos
                    
                    **Curva ROC (si es binaria):**
                    - Muestra el rendimiento del clasificador en diferentes umbrales
                    - **Interpretaci√≥n:**
                      - L√≠nea m√°s cerca de la esquina superior izquierda = mejor modelo
                      - √Årea bajo la curva (AUC) cercana a 1 = excelente modelo
                    """)

            if model_type == "Linear" and X_test is not None and y_test is not None and model is not None:
                y_pred = model.predict(X_test)

                # Crear visualizaciones con mejor tama√±o
                st.markdown("### üìä Gr√°fico de Predicciones vs Valores Reales")

                fig, ax = plt.subplots(figsize=(12, 8))

                # Scatter plot con mejor estilo
                ax.scatter(y_test, y_pred, alpha=0.6, s=50,
                           edgecolors='black', linewidth=0.5)

                # L√≠nea de predicci√≥n perfecta
                min_val = min(y_test.min(), y_pred.min())
                max_val = max(y_test.max(), y_pred.max())
                ax.plot([min_val, max_val], [min_val, max_val],
                        'r--', lw=2, label='Predicci√≥n Perfecta')

                # Personalizaci√≥n del gr√°fico
                ax.set_xlabel('Valores Reales', fontsize=12)
                ax.set_ylabel('Predicciones', fontsize=12)
                ax.set_title('Predicciones vs Valores Reales',
                             fontsize=14, fontweight='bold')
                ax.legend()
                ax.grid(True, alpha=0.3)

                # A√±adir estad√≠sticas al gr√°fico
                r2_value = st.session_state.get('metrics_lr', {}).get('r2', 0)
                ax.text(0.05, 0.95, f'R¬≤ = {r2_value:.4f}',
                        transform=ax.transAxes, fontsize=12,
                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Gr√°fico de residuos
                st.markdown("### üìà An√°lisis de Residuos")

                # Informaci√≥n explicativa sobre los residuos
                with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar el an√°lisis de residuos?", expanded=False):
                    st.markdown("""
                    **¬øQu√© son los residuos?**
                    Los residuos son las diferencias entre los valores reales y las predicciones del modelo:
                    `Residuo = Valor Real - Predicci√≥n`
                    
                    **Gr√°fico de Residuos vs Predicciones:**
                    - **Ideal:** Los puntos deben estar distribuidos aleatoriamente alrededor de la l√≠nea y=0
                    - **Problema:** Si ves patrones (curvas, abanicos), puede indicar:
                      - El modelo no captura relaciones no lineales
                      - Heterocedasticidad (varianza no constante)
                      - Variables importantes omitidas
                    
                    **Histograma de Residuos:**
                    - **Ideal:** Distribuci√≥n normal (campana) centrada en 0
                    - **Problema:** Si la distribuci√≥n est√° sesgada o tiene m√∫ltiples picos:
                      - Puede indicar que el modelo no es apropiado
                      - Sugiere la presencia de outliers o datos problem√°ticos
                    
                    **L√≠nea roja punteada:** Marca el residuo = 0 (predicci√≥n perfecta)
                    **Media de residuos:** Deber√≠a estar cerca de 0 para un modelo bien calibrado
                    """)

                residuals = y_test - y_pred

                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

                # Residuos vs Predicciones
                ax1.scatter(y_pred, residuals, alpha=0.6, s=50,
                            edgecolors='black', linewidth=0.5)
                ax1.axhline(y=0, color='r', linestyle='--',
                            lw=2, label='Residuo = 0')
                ax1.set_xlabel('Predicciones', fontsize=12)
                ax1.set_ylabel('Residuos (Real - Predicci√≥n)', fontsize=12)
                ax1.set_title('Residuos vs Predicciones',
                              fontsize=14, fontweight='bold')
                ax1.legend()
                ax1.grid(True, alpha=0.3)

                # A√±adir estad√≠sticas al gr√°fico
                residual_std = residuals.std()
                ax1.text(0.05, 0.95, f'Desv. Est√°ndar: {residual_std:.3f}',
                         transform=ax1.transAxes, fontsize=10,
                         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))

                # Histograma de residuos
                ax2.hist(residuals, bins=20, alpha=0.7,
                         edgecolor='black', color='skyblue')
                ax2.axvline(residuals.mean(), color='red', linestyle='--',
                            lw=2, label=f'Media: {residuals.mean():.3f}')
                ax2.axvline(0, color='green', linestyle='-',
                            lw=2, alpha=0.7, label='Ideal (0)')
                ax2.set_xlabel('Residuos', fontsize=12)
                ax2.set_ylabel('Frecuencia', fontsize=12)
                ax2.set_title('Distribuci√≥n de Residuos',
                              fontsize=14, fontweight='bold')
                ax2.legend()
                ax2.grid(True, alpha=0.3)

                plt.tight_layout()

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Interpretaci√≥n autom√°tica de los residuos
                st.markdown("### üîç Interpretaci√≥n de los Residuos")

                mean_residual = abs(residuals.mean())
                std_residual = residuals.std()

                interpretation = []

                if mean_residual < 0.1 * std_residual:
                    interpretation.append(
                        "‚úÖ **Media de residuos cercana a 0:** El modelo est√° bien calibrado")
                else:
                    interpretation.append(
                        "‚ö†Ô∏è **Media de residuos alejada de 0:** El modelo puede tener sesgo sistem√°tico")

                # Calcular R¬≤ de los residuos para detectar patrones
                from scipy import stats
                if len(residuals) > 10:
                    slope, _, r_value, _, _ = stats.linregress(
                        y_pred, residuals)
                    if abs(r_value) < 0.1:
                        interpretation.append(
                            "‚úÖ **Sin correlaci√≥n entre residuos y predicciones:** Buen ajuste lineal")
                    else:
                        interpretation.append(
                            "‚ö†Ô∏è **Correlaci√≥n detectada en residuos:** Puede haber relaciones no lineales")

                # Test de normalidad simplificado (basado en asimetr√≠a)
                skewness = abs(stats.skew(residuals))
                if skewness < 1:
                    interpretation.append(
                        "‚úÖ **Distribuci√≥n de residuos aproximadamente normal**")
                else:
                    interpretation.append(
                        "‚ö†Ô∏è **Distribuci√≥n de residuos sesgada:** Revisar outliers o transformaciones")

                for item in interpretation:
                    st.markdown(f"- {item}")

                if mean_residual >= 0.1 * std_residual or abs(r_value) >= 0.1 or skewness >= 1:
                    st.info(
                        "üí° **Sugerencias de mejora:** Considera probar transformaciones de variables, a√±adir caracter√≠sticas polin√≥micas, o usar modelos no lineales.")

            elif model_type == "Logistic" and X_test is not None and y_test is not None and model is not None:
                from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve

                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)

                # Matriz de Confusi√≥n
                st.markdown("### üìä Matriz de Confusi√≥n")

                cm = confusion_matrix(y_test, y_pred)
                class_names = st.session_state.get('class_names_lr', [])

                fig, ax = plt.subplots(figsize=(10, 8))

                # Crear mapa de calor
                try:
                    import seaborn as sns
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                                ax=ax, cbar_kws={'shrink': 0.8},
                                xticklabels=class_names if class_names else True,
                                yticklabels=class_names if class_names else True)
                except ImportError:
                    # Fallback to matplotlib if seaborn is not available
                    im = ax.imshow(cm, cmap='Blues', aspect='auto')
                    # Add text annotations
                    for i in range(cm.shape[0]):
                        for j in range(cm.shape[1]):
                            text = ax.text(j, i, f'{cm[i, j]}',
                                           ha="center", va="center", color="white" if cm[i, j] > cm.max()/2 else "black")
                    ax.set_xticks(range(cm.shape[1]))
                    ax.set_yticks(range(cm.shape[0]))
                    if class_names:
                        ax.set_xticklabels(class_names)
                        ax.set_yticklabels(class_names)
                ax.set_title('Matriz de Confusi√≥n',
                             fontsize=14, fontweight='bold')
                ax.set_xlabel('Predicciones', fontsize=12)
                ax.set_ylabel('Valores Reales', fontsize=12)

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # An√°lisis detallado de la matriz de confusi√≥n
                if len(np.unique(y_test)) == 2:
                    tn, fp, fn, tp = cm.ravel()

                    # M√©tricas derivadas de la matriz de confusi√≥n
                    st.markdown("### üîç An√°lisis Detallado de la Matriz")
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric("Verdaderos Positivos", f"{tp}")
                        st.caption(
                            "Casos positivos correctamente identificados")
                    with col2:
                        st.metric("Falsos Positivos", f"{fp}")
                        st.caption(
                            "Casos negativos clasificados como positivos")
                    with col3:
                        st.metric("Falsos Negativos", f"{fn}")
                        st.caption(
                            "Casos positivos clasificados como negativos")
                    with col4:
                        st.metric("Verdaderos Negativos", f"{tn}")
                        st.caption(
                            "Casos negativos correctamente identificados")

                    # Interpretaci√≥n de errores
                    if fp > fn:
                        st.warning(
                            "‚ö†Ô∏è El modelo tiende a clasificar m√°s casos como positivos (m√°s falsos positivos que falsos negativos)")
                    elif fn > fp:
                        st.warning(
                            "‚ö†Ô∏è El modelo tiende a ser m√°s conservador (m√°s falsos negativos que falsos positivos)")
                    else:
                        st.success(
                            "‚úÖ El modelo tiene un balance equilibrado entre falsos positivos y negativos")

                # Curvas ROC y Precision-Recall
                if len(np.unique(y_test)) == 2:
                    from sklearn.metrics import roc_curve, auc, average_precision_score

                    # Crear subplots para ROC y Precision-Recall
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

                    # Curva ROC
                    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])
                    roc_auc = auc(fpr, tpr)

                    ax1.plot(fpr, tpr, color='darkorange', lw=2,
                             label=f'Curva ROC (AUC = {roc_auc:.3f})')
                    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',
                             label='Clasificador Aleatorio')

                    ax1.set_xlim([0.0, 1.0])
                    ax1.set_ylim([0.0, 1.05])
                    ax1.set_xlabel('Tasa de Falsos Positivos', fontsize=12)
                    ax1.set_ylabel('Tasa de Verdaderos Positivos', fontsize=12)
                    ax1.set_title('Curva ROC', fontsize=14, fontweight='bold')
                    ax1.legend(loc="lower right")
                    ax1.grid(True, alpha=0.3)

                    # Curva Precision-Recall
                    precision, recall, _ = precision_recall_curve(
                        y_test, y_pred_proba[:, 1])
                    avg_precision = average_precision_score(
                        y_test, y_pred_proba[:, 1])

                    ax2.plot(recall, precision, color='darkgreen', lw=2,
                             label=f'Curva P-R (AP = {avg_precision:.3f})')
                    ax2.axhline(y=np.sum(y_test)/len(y_test), color='navy', lw=2, linestyle='--',
                                label=f'Baseline ({np.sum(y_test)/len(y_test):.3f})')

                    ax2.set_xlim([0.0, 1.0])
                    ax2.set_ylim([0.0, 1.05])
                    ax2.set_xlabel('Recall (Sensibilidad)', fontsize=12)
                    ax2.set_ylabel('Precision (Precisi√≥n)', fontsize=12)
                    ax2.set_title('Curva Precision-Recall',
                                  fontsize=14, fontweight='bold')
                    ax2.legend(loc="lower left")
                    ax2.grid(True, alpha=0.3)

                    plt.tight_layout()

                    st.markdown("### üìà Curvas de Rendimiento")

                    # Explicaci√≥n detallada sobre las curvas de rendimiento
                    with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar las Curvas de Rendimiento?", expanded=False):
                        st.markdown("""
                        **Curva ROC (Receiver Operating Characteristic)**
                        
                        **¬øQu√© muestra?**
                        - **Eje X:** Tasa de Falsos Positivos (FPR) = FP / (FP + TN)
                        - **Eje Y:** Tasa de Verdaderos Positivos (TPR) = TP / (TP + FN) = Sensibilidad/Recall
                        - **L√≠nea diagonal:** Rendimiento de un clasificador aleatorio
                        - **AUC (√Årea Bajo la Curva):** M√©trica resumen del rendimiento
                        
                        **Interpretaci√≥n:**
                        - **AUC = 1.0:** Clasificador perfecto
                        - **AUC = 0.9-1.0:** Excelente discriminaci√≥n
                        - **AUC = 0.8-0.9:** Buena discriminaci√≥n  
                        - **AUC = 0.7-0.8:** Discriminaci√≥n aceptable
                        - **AUC = 0.5:** Equivalente a adivinar al azar
                        - **AUC < 0.5:** Peor que adivinar (pero se puede invertir)
                        
                        **¬øCu√°ndo usar ROC?**
                        - Cuando las clases est√°n relativamente balanceadas
                        - Para comparar modelos r√°pidamente
                        - Cuando te importa el rendimiento general
                        
                        ---
                        
                        **Curva Precision-Recall (P-R)**
                        
                        **¬øQu√© muestra?**
                        - **Eje X:** Recall (Sensibilidad) = TP / (TP + FN)
                        - **Eje Y:** Precision (Precisi√≥n) = TP / (TP + FP)
                        - **L√≠nea horizontal:** Baseline (proporci√≥n de casos positivos)
                        - **AP (Average Precision):** M√©trica resumen del rendimiento
                        
                        **Interpretaci√≥n:**
                        - **AP alto:** Buen balance entre precisi√≥n y recall
                        - **Curva cerca del √°ngulo superior derecho:** Excelente rendimiento
                        - **Por encima del baseline:** Mejor que una predicci√≥n aleatoria
                        
                        **¬øCu√°ndo usar P-R?**
                        - ‚úÖ **Clases desbalanceadas** (muchos m√°s negativos que positivos)
                        - ‚úÖ Cuando los **falsos positivos son costosos**
                        - ‚úÖ Para datasets con **pocos casos positivos**
                        - ‚úÖ En problemas como **detecci√≥n de fraude, diagn√≥stico m√©dico**
                        
                        **Comparaci√≥n ROC vs P-R:**
                        - **ROC** es m√°s optimista con clases desbalanceadas
                        - **P-R** es m√°s conservadora y realista
                        - **P-R** se enfoca m√°s en el rendimiento de la clase minoritaria
                        - Usar **ambas** para una evaluaci√≥n completa
                        """)

                    # Mostrar con 80% del ancho
                    col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                    with col2:
                        st.pyplot(fig, use_container_width=True)

                    # Interpretaci√≥n de las curvas
                    st.markdown("### üìã Interpretaci√≥n de las Curvas")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**Curva ROC:**")
                        if roc_auc >= 0.9:
                            st.success(
                                f"üéØ Excelente discriminaci√≥n (AUC = {roc_auc:.3f})")
                        elif roc_auc >= 0.8:
                            st.info(
                                f"üëç Buena discriminaci√≥n (AUC = {roc_auc:.3f})")
                        elif roc_auc >= 0.7:
                            st.warning(
                                f"‚ö†Ô∏è Discriminaci√≥n moderada (AUC = {roc_auc:.3f})")
                        else:
                            st.error(
                                f"‚ùå Discriminaci√≥n pobre (AUC = {roc_auc:.3f})")

                    with col2:
                        st.markdown("**Curva Precision-Recall:**")
                        baseline_precision = np.sum(y_test)/len(y_test)
                        if avg_precision >= baseline_precision + 0.3:
                            st.success(
                                f"üéØ Excelente (AP = {avg_precision:.3f})")
                        elif avg_precision >= baseline_precision + 0.1:
                            st.info(
                                f"üëç Buena mejora sobre baseline (AP = {avg_precision:.3f})")
                        elif avg_precision >= baseline_precision:
                            st.warning(
                                f"‚ö†Ô∏è Mejora marginal (AP = {avg_precision:.3f})")
                        else:
                            st.error(
                                f"‚ùå Por debajo del baseline (AP = {avg_precision:.3f})")

                # An√°lisis de probabilidades de predicci√≥n
                st.markdown("### üìä Distribuci√≥n de Probabilidades")

                # Explicaci√≥n detallada sobre distribuci√≥n de probabilidades
                with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar la Distribuci√≥n de Probabilidades?", expanded=False):
                    st.markdown("""
                    **¬øQu√© muestra este gr√°fico?**
                    
                    Este histograma muestra c√≥mo el modelo asigna probabilidades a cada muestra del conjunto de prueba, 
                    separado por la clase real a la que pertenece cada muestra.
                    
                    **Elementos del gr√°fico:**
                    - **Histograma azul:** Distribuci√≥n de probabilidades para muestras que realmente pertenecen a la clase positiva
                    - **Histograma rojo:** Distribuci√≥n de probabilidades para muestras que realmente pertenecen a la clase negativa  
                    - **L√≠nea roja vertical:** Umbral de decisi√≥n (0.5 por defecto)
                    - **Eje X:** Probabilidad asignada por el modelo (0 = clase negativa, 1 = clase positiva)
                    - **Eje Y:** Cantidad de muestras
                    
                    **Interpretaci√≥n ideal:**
                    - ‚úÖ **Buena separaci√≥n:** Los histogramas no se superponen mucho
                    - ‚úÖ **Clase negativa:** Concentrada cerca de 0 (izquierda)
                    - ‚úÖ **Clase positiva:** Concentrada cerca de 1 (derecha)
                    - ‚úÖ **Pocas muestras cerca del umbral (0.5):** Indica confianza en las predicciones
                    
                    **Problemas a identificar:**
                    - ‚ö†Ô∏è **Mucha superposici√≥n:** Indica dificultad para separar las clases
                    - ‚ö†Ô∏è **Concentraci√≥n en el centro (0.3-0.7):** El modelo est√° inseguro
                    - ‚ö†Ô∏è **Distribuci√≥n uniforme:** El modelo no est√° aprendiendo patrones √∫tiles
                    
                    **Aplicaciones pr√°cticas:**
                    - Identificar si el modelo est√° confiado en sus predicciones
                    - Evaluar si cambiar el umbral de decisi√≥n podr√≠a mejorar el rendimiento
                    - Detectar casos donde el modelo necesita m√°s datos o caracter√≠sticas
                    """)

                # Verificar que tenemos datos v√°lidos
                if y_pred_proba is not None and len(y_pred_proba) > 0:
                    unique_classes = np.unique(y_test)

                    # Para clasificaci√≥n binaria
                    if len(unique_classes) == 2:
                        fig, ax = plt.subplots(figsize=(12, 6))

                        # Obtener probabilidades de la clase positiva
                        prob_class_1 = y_pred_proba[:, 1]

                        # Separar por clase real - usar los valores √∫nicos reales
                        mask_class_0 = (y_test == unique_classes[0])
                        mask_class_1 = (y_test == unique_classes[1])

                        prob_class_0_real = prob_class_1[mask_class_0]
                        prob_class_1_real = prob_class_1[mask_class_1]

                        # Crear histogramas solo si hay datos
                        if len(prob_class_0_real) > 0:
                            ax.hist(prob_class_0_real, bins=20, alpha=0.7,
                                    label=f'Clase {class_names[0] if class_names and len(class_names) > 0 else unique_classes[0]} (Real)',
                                    color='lightcoral', edgecolor='black')

                        if len(prob_class_1_real) > 0:
                            ax.hist(prob_class_1_real, bins=20, alpha=0.7,
                                    label=f'Clase {class_names[1] if class_names and len(class_names) > 1 else unique_classes[1]} (Real)',
                                    color='lightblue', edgecolor='black')

                        # L√≠nea del umbral de decisi√≥n
                        ax.axvline(x=0.5, color='red', linestyle='--',
                                   linewidth=2, label='Umbral de decisi√≥n (0.5)')

                        # Configurar el gr√°fico
                        ax.set_xlabel(
                            'Probabilidad de Clase Positiva', fontsize=12)
                        ax.set_ylabel('Frecuencia', fontsize=12)
                        ax.set_title('Distribuci√≥n de Probabilidades Predichas por Clase Real',
                                     fontsize=14, fontweight='bold')
                        ax.legend()
                        ax.grid(True, alpha=0.3)

                        # Asegurar l√≠mites apropiados
                        ax.set_xlim(0, 1)

                        plt.tight_layout()

                        # Mostrar el gr√°fico
                        col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                        with col2:
                            st.pyplot(fig, use_container_width=True)

                        # Limpiar la figura
                        plt.close(fig)

                        # An√°lisis de separaci√≥n
                        if len(prob_class_0_real) > 0 and len(prob_class_1_real) > 0:
                            # Contar solapamiento en la zona de incertidumbre (0.3-0.7)
                            overlap_0 = np.sum(
                                (prob_class_0_real > 0.3) & (prob_class_0_real < 0.7))
                            overlap_1 = np.sum(
                                (prob_class_1_real > 0.3) & (prob_class_1_real < 0.7))
                            total_overlap = overlap_0 + overlap_1

                            overlap_percentage = total_overlap / len(y_test)

                            # M√©tricas adicionales de separaci√≥n
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Muestras en zona incierta",
                                          f"{total_overlap}/{len(y_test)}")
                            with col2:
                                st.metric("Porcentaje de incertidumbre",
                                          f"{overlap_percentage:.1%}")
                            with col3:
                                conf_threshold = 0.8  # 80% de confianza
                                high_conf = np.sum((prob_class_1 < 0.2) | (
                                    prob_class_1 > conf_threshold))
                                st.metric("Predicciones confiables",
                                          f"{high_conf}/{len(y_test)}")

                            # Interpretaci√≥n
                            if overlap_percentage < 0.2:
                                st.success(
                                    "‚úÖ Excelente separaci√≥n entre clases - El modelo est√° muy confiado en sus predicciones")
                            elif overlap_percentage < 0.4:
                                st.info("üëç Buena separaci√≥n entre clases")
                            else:
                                st.warning(
                                    "‚ö†Ô∏è Las clases se superponen significativamente - Considera ajustar el umbral de decisi√≥n")

                    elif len(unique_classes) > 2:
                        # Para clasificaci√≥n multiclase
                        st.info(
                            "**Nota:** Clasificaci√≥n multiclase detectada. Mostrando distribuci√≥n de probabilidades para cada clase.")

                        n_classes = len(unique_classes)
                        n_cols = min(3, n_classes)
                        n_rows = (n_classes + n_cols - 1) // n_cols

                        fig, axes = plt.subplots(
                            n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))

                        # Manejar caso de una sola clase
                        if n_classes == 1:
                            axes = [axes]
                        elif n_rows == 1:
                            axes = axes if n_cols > 1 else [axes]
                        else:
                            axes = axes.flatten()

                        for i, class_val in enumerate(unique_classes):
                            if i < len(axes):
                                ax_sub = axes[i]

                                # Probabilidades para esta clase
                                class_probs = y_pred_proba[:, i]

                                ax_sub.hist(class_probs, bins=20, alpha=0.7,
                                            color=plt.cm.Set3(i), edgecolor='black')

                                class_label = class_names[i] if class_names and i < len(
                                    class_names) else f"Clase {class_val}"
                                ax_sub.set_title(
                                    f'Probabilidades para {class_label}')
                                ax_sub.set_xlabel('Probabilidad')
                                ax_sub.set_ylabel('Frecuencia')
                                ax_sub.grid(True, alpha=0.3)
                                ax_sub.set_xlim(0, 1)

                        # Ocultar subplots vac√≠os
                        for i in range(n_classes, len(axes)):
                            axes[i].set_visible(False)

                        plt.tight_layout()

                        col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                        with col2:
                            st.pyplot(fig, use_container_width=True)

                        plt.close(fig)
                    else:
                        st.error(
                            "Error: Datos de clasificaci√≥n insuficientes para crear la visualizaci√≥n")

                else:
                    st.error(
                        "Error: No hay probabilidades predichas disponibles. Aseg√∫rate de que el modelo est√© entrenado correctamente.")

                # An√°lisis de umbrales de decisi√≥n para clasificaci√≥n binaria
                if len(np.unique(y_test)) == 2:
                    st.markdown("### üéØ An√°lisis de Umbrales de Decisi√≥n")

                    # Explicaci√≥n detallada sobre umbrales de decisi√≥n
                    with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar el An√°lisis de Umbrales?", expanded=False):
                        st.markdown("""
                        **¬øQu√© es el umbral de decisi√≥n?**
                        
                        El umbral de decisi√≥n es el valor que determina cu√°ndo el modelo clasifica una muestra como 
                        positiva o negativa. Por defecto, este umbral es **0.5**:
                        - **Probabilidad ‚â• 0.5** ‚Üí Clase Positiva
                        - **Probabilidad < 0.5** ‚Üí Clase Negativa
                        
                        **¬øPor qu√© cambiar el umbral?**
                        
                        El umbral por defecto (0.5) no siempre es √≥ptimo. Dependiendo del problema, 
                        puede ser beneficioso ajustarlo:
                        
                        **üìà Umbral m√°s alto (0.6, 0.7, 0.8):**
                        - ‚úÖ **Mayor Precisi√≥n:** Menos falsos positivos
                        - ‚úÖ **Predicciones m√°s conservadoras:** Solo clasifica como positivo cuando est√° muy seguro
                        - ‚ö†Ô∏è **Menor Recall:** Puede perder casos positivos reales
                        - **√ötil cuando:** Los falsos positivos son muy costosos (ej: diagn√≥stico m√©dico, inversiones)
                        
                        **üìâ Umbral m√°s bajo (0.3, 0.4):**
                        - ‚úÖ **Mayor Recall:** Detecta m√°s casos positivos reales
                        - ‚úÖ **Predicciones m√°s sensibles:** No se pierde tantos casos positivos
                        - ‚ö†Ô∏è **Menor Precisi√≥n:** M√°s falsos positivos
                        - **√ötil cuando:** Los falsos negativos son muy costosos (ej: detecci√≥n de fraude, seguridad)
                        
                        **M√©tricas mostradas:**
                        - **Accuracy:** Porcentaje total de predicciones correctas
                        - **Precision:** De las predicciones positivas, cu√°ntas son correctas
                        - **Recall:** De los casos positivos reales, cu√°ntos detectamos
                        - **F1-Score:** Balance entre precisi√≥n y recall
                        
                        **¬øC√≥mo elegir el umbral √≥ptimo?**
                        1. **Maximizar F1-Score:** Balance general entre precisi√≥n y recall
                        2. **Maximizar Precision:** Si los falsos positivos son costosos
                        3. **Maximizar Recall:** Si los falsos negativos son costosos
                        4. **Considerar el contexto:** Costos reales de errores en tu dominio
                        
                        **Ejemplo pr√°ctico:**
                        - **Email spam:** Prefiere falsos positivos (email importante en spam) que falsos negativos
                        - **Diagn√≥stico m√©dico:** Prefiere falsos positivos (m√°s pruebas) que falsos negativos (enfermedad no detectada)
                        - **Recomendaciones:** Balance entre no molestar (precisi√≥n) y no perder oportunidades (recall)
                        """)

                    # Calcular m√©tricas para diferentes umbrales
                    thresholds = np.arange(0.1, 1.0, 0.1)
                    threshold_metrics = []

                    for threshold in thresholds:
                        y_pred_thresh = (
                            y_pred_proba[:, 1] >= threshold).astype(int)

                        if len(np.unique(y_pred_thresh)) > 1:  # Evitar divisi√≥n por cero
                            from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
                            precision = precision_score(
                                y_test, y_pred_thresh, zero_division=0)
                            recall = recall_score(
                                y_test, y_pred_thresh, zero_division=0)
                            f1 = f1_score(y_test, y_pred_thresh,
                                          zero_division=0)
                            accuracy = accuracy_score(y_test, y_pred_thresh)

                            threshold_metrics.append({
                                'Umbral': threshold,
                                'Accuracy': accuracy,
                                'Precision': precision,
                                'Recall': recall,
                                'F1-Score': f1
                            })

                    if threshold_metrics:
                        df_thresholds = pd.DataFrame(threshold_metrics)

                        # Encontrar el mejor umbral por F1-Score
                        best_f1_idx = df_thresholds['F1-Score'].idxmax()
                        best_threshold = df_thresholds.loc[best_f1_idx, 'Umbral']

                        col1, col2 = st.columns(2)

                        with col1:
                            st.metric("Umbral Actual", "0.50")
                            st.metric("Umbral √ìptimo (F1)",
                                      f"{best_threshold:.2f}")

                            if abs(best_threshold - 0.5) > 0.1:
                                st.info(
                                    f"üí° Considera ajustar el umbral a {best_threshold:.2f} para mejorar el F1-Score")

                        with col2:
                            # Mostrar tabla de umbrales (seleccionados)
                            display_thresholds = df_thresholds[df_thresholds['Umbral'].isin(
                                [0.3, 0.5, 0.7])].copy()
                            for col in ['Accuracy', 'Precision', 'Recall', 'F1-Score']:
                                display_thresholds[col] = display_thresholds[col].apply(
                                    lambda x: f"{x:.3f}")

                            st.markdown("**Comparaci√≥n de Umbrales:**")
                            st.dataframe(
                                display_thresholds, hide_index=True, use_container_width=True)

        else:
            st.info("Entrena un modelo primero para ver las visualizaciones.")

    # Pesta√±a de Coeficientes
    elif st.session_state.active_tab_lr == 4:
        st.header("Coeficientes del Modelo")

        if st.session_state.get('model_trained_lr', False):
            model = st.session_state.get('model_lr')
            feature_names = st.session_state.get('feature_names_lr', [])
            model_type = st.session_state.get('model_type_lr', 'Linear')

            # Informaci√≥n sobre los coeficientes
            with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar los coeficientes?", expanded=False):
                if model_type == "Linear":
                    st.markdown("""
                    # üìà **Coeficientes en Regresi√≥n Lineal**
                    
                    ## üéØ **¬øQu√© representan los coeficientes?**
                    
                    Los coeficientes son los **par√°metros aprendidos** por el modelo que determinan c√≥mo cada caracter√≠stica 
                    influye en la predicci√≥n final. La f√≥rmula de regresi√≥n lineal es:
                    
                    ```
                    Predicci√≥n = Œ≤‚ÇÄ + Œ≤‚ÇÅ√óX‚ÇÅ + Œ≤‚ÇÇ√óX‚ÇÇ + ... + Œ≤‚Çô√óX‚Çô
                    ```
                    
                    Donde cada **Œ≤·µ¢** es un coeficiente que indica el cambio en la variable objetivo 
                    por cada unidad de cambio en la caracter√≠stica correspondiente.
                    
                    ## üîç **Interpretaci√≥n Detallada:**
                    
                    ### **Valor del Coeficiente (Magnitud):**
                    - **Valor absoluto grande (ej: |5.2|):** La caracter√≠stica tiene **alta influencia**
                    - **Valor absoluto peque√±o (ej: |0.1|):** La caracter√≠stica tiene **baja influencia**
                    - **Valor cero (0.0):** La caracter√≠stica **no influye** en la predicci√≥n
                    
                    ### **Signo del Coeficiente (Direcci√≥n):**
                    - **Positivo (+):** üìà **Relaci√≥n directa** - A mayor valor de X, mayor valor de Y
                    - **Negativo (-):** üìâ **Relaci√≥n inversa** - A mayor valor de X, menor valor de Y
                    
                    ### **Unidades:**
                    Los coeficientes mantienen las **unidades originales**. Si predices precios en euros 
                    y una caracter√≠stica est√° en metros¬≤, un coeficiente de 150 significa 
                    **+150 euros por cada metro¬≤ adicional**.
                    
                    ## üí° **Ejemplos Pr√°cticos:**
                    
                    **üè† Predicci√≥n de Precios de Casas:**
                    - `Tama√±o = +150`: Cada m¬≤ adicional aumenta el precio en 150‚Ç¨
                    - `Antig√ºedad = -500`: Cada a√±o adicional reduce el precio en 500‚Ç¨
                    - `Habitaciones = +2000`: Cada habitaci√≥n adicional aumenta el precio en 2000‚Ç¨
                    
                    **üìä Predicci√≥n de Ventas:**
                    - `Presupuesto_Marketing = +1.5`: Cada euro en marketing genera 1.5‚Ç¨ en ventas
                    - `Competencia = -0.8`: Cada competidor adicional reduce ventas en 0.8‚Ç¨
                    
                    ## ‚ö†Ô∏è **Limitaciones y Consideraciones:**
                    
                    1. **Correlaci√≥n ‚â† Causalidad:** Un coeficiente alto no implica que la caracter√≠stica cause el resultado
                    2. **Escalas diferentes:** Caracter√≠sticas con diferentes escalas pueden tener coeficientes incomparables
                    3. **Multicolinealidad:** Caracter√≠sticas correlacionadas pueden tener coeficientes inestables
                    4. **Outliers:** Valores extremos pueden afectar significativamente los coeficientes
                    
                    ## üéõÔ∏è **C√≥mo usar esta informaci√≥n:**
                    
                    - **Identificar factores clave:** Coeficientes con mayor valor absoluto
                    - **Validar intuici√≥n:** ¬øLos signos coinciden con el conocimiento del dominio?
                    - **Tomar decisiones:** ¬øEn qu√© caracter√≠sticas enfocar esfuerzos?
                    - **Detectar problemas:** ¬øHay coeficientes que no tienen sentido?
                    """)
                else:
                    st.markdown("""
                    # üéØ **Coeficientes en Regresi√≥n Log√≠stica**
                    
                    ## üéØ **¬øQu√© representan los coeficientes?**
                    
                    En regresi√≥n log√≠stica, los coeficientes representan el **cambio en log-odds** 
                    (logaritmo de las probabilidades) por cada unidad de cambio en la caracter√≠stica. 
                    La f√≥rmula es:
                    
                    ```
                    log(odds) = Œ≤‚ÇÄ + Œ≤‚ÇÅ√óX‚ÇÅ + Œ≤‚ÇÇ√óX‚ÇÇ + ... + Œ≤‚Çô√óX‚Çô
                    odds = e^(Œ≤‚ÇÄ + Œ≤‚ÇÅ√óX‚ÇÅ + Œ≤‚ÇÇ√óX‚ÇÇ + ... + Œ≤‚Çô√óX‚Çô)
                    probabilidad = odds / (1 + odds)
                    ```
                    
                    ## üîç **Interpretaci√≥n de Log-Odds:**
                    
                    ### **Valor del Coeficiente:**
                    - **Positivo (+):** üìà **Aumenta** la probabilidad de la clase positiva
                    - **Negativo (-):** üìâ **Disminuye** la probabilidad de la clase positiva
                    - **Cero (0.0):** **No afecta** la probabilidad
                    
                    ### **Magnitud del Coeficiente:**
                    - **|Œ≤| > 2:** **Efecto muy fuerte** (odds ratio > 7.4)
                    - **1 < |Œ≤| < 2:** **Efecto fuerte** (odds ratio entre 2.7 y 7.4)
                    - **0.5 < |Œ≤| < 1:** **Efecto moderado** (odds ratio entre 1.6 y 2.7)
                    - **|Œ≤| < 0.5:** **Efecto d√©bil** (odds ratio < 1.6)
                    
                    ## üìä **Conversi√≥n a Odds Ratios (M√°s Intuitivo):**
                    
                    Los **Odds Ratios** se calculan como `e^Œ≤` y son m√°s f√°ciles de interpretar:
                    
                    ### **Interpretaci√≥n de Odds Ratios:**
                    - **OR = 1:** La caracter√≠stica **no tiene efecto**
                    - **OR > 1:** La caracter√≠stica **aumenta** las odds de la clase positiva
                    - **OR < 1:** La caracter√≠stica **disminuye** las odds de la clase positiva
                    
                    ### **Ejemplos de Odds Ratios:**
                    - **OR = 2.0:** Duplica las odds (100% de aumento)
                    - **OR = 1.5:** Aumenta las odds en 50%
                    - **OR = 0.5:** Reduce las odds a la mitad (50% de reducci√≥n)
                    - **OR = 0.2:** Reduce las odds en 80%
                    
                    ## üí° **Ejemplos Pr√°cticos:**
                    
                    **üè• Diagn√≥stico M√©dico (Predicci√≥n de Enfermedad):**
                    - `Edad = +0.05 (OR=1.05)`: Cada a√±o adicional aumenta las odds en 5%
                    - `Ejercicio = -1.2 (OR=0.30)`: Hacer ejercicio reduce las odds en 70%
                    - `Fumador = +1.8 (OR=6.05)`: Ser fumador multiplica las odds por 6
                    
                    **üìß Clasificaci√≥n de Spam:**
                    - `Palabras_Sospechosas = +2.3 (OR=10.0)`: Multiplica las odds de spam por 10
                    - `Remitente_Conocido = -1.5 (OR=0.22)`: Reduce las odds de spam en 78%
                    
                    **üí≥ Detecci√≥n de Fraude:**
                    - `Hora_Inusual = +1.1 (OR=3.0)`: Triplica las odds de fraude
                    - `Ubicacion_Habitual = -2.0 (OR=0.14)`: Reduce las odds de fraude en 86%
                    
                    ## ‚ö†Ô∏è **Limitaciones y Consideraciones:**
                    
                    1. **Interpretaci√≥n no lineal:** El efecto en probabilidades no es constante
                    2. **Asunciones de linealidad:** En el espacio log-odds, no en probabilidades
                    3. **Interacciones ignoradas:** Los efectos pueden depender de otras variables
                    4. **Escalas importantes:** Normalizar puede facilitar la interpretaci√≥n
                    
                    ## üéõÔ∏è **C√≥mo usar esta informaci√≥n:**
                    
                    ### **Para el Negocio:**
                    - **Identificar factores de riesgo:** Coeficientes positivos altos
                    - **Encontrar factores protectores:** Coeficientes negativos altos
                    - **Priorizar intervenciones:** Enfocarse en variables con mayor impacto
                    
                    ### **Para el Modelo:**
                    - **Validar coherencia:** ¬øLos signos tienen sentido del dominio?
                    - **Detectar overfitting:** ¬øCoeficientes extremadamente grandes?
                    - **Selecci√≥n de caracter√≠sticas:** ¬øCoeficientes cerca de cero?
                    
                    ## üßÆ **F√≥rmula de Conversi√≥n:**
                    ```python
                    # De coeficiente a odds ratio
                    odds_ratio = np.exp(coeficiente)
                    
                    # Cambio porcentual en odds
                    cambio_porcentual = (odds_ratio - 1) * 100
                    ```
                    """)

            if model is not None and hasattr(model, 'coef_'):
                try:
                    # Preparar datos de coeficientes de forma robusta
                    coef_raw = model.coef_
                    class_names = st.session_state.get('class_names_lr', [])

                    # Para regresi√≥n log√≠stica binaria, coef_ tiene forma (1, n_features)
                    # Para regresi√≥n log√≠stica multiclase, coef_ tiene forma (n_classes, n_features)
                    # Para regresi√≥n lineal, coef_ tiene forma (n_features,)

                    if len(coef_raw.shape) == 2:
                        # Es una matriz 2D (regresi√≥n log√≠stica)
                        if coef_raw.shape[0] == 1:
                            # Clasificaci√≥n binaria: tomar la primera (y √∫nica) fila
                            coefficients = coef_raw[0]
                            is_multiclass = False
                        else:
                            # Clasificaci√≥n multiclase: mostrar nota informativa
                            # Usar primera clase por defecto
                            coefficients = coef_raw[0]
                            is_multiclass = True

                            st.info(
                                f"**Nota:** Este es un modelo de clasificaci√≥n multiclase con {coef_raw.shape[0]} clases. Mostrando los coeficientes para la primera clase ({class_names[0] if class_names else 'Clase 0'}).")

                            # Opci√≥n para seleccionar qu√© clase mostrar
                            if class_names and len(class_names) == coef_raw.shape[0]:
                                selected_class = st.selectbox(
                                    "Selecciona la clase para mostrar coeficientes:",
                                    options=range(len(class_names)),
                                    format_func=lambda x: class_names[x],
                                    index=0
                                )
                                coefficients = coef_raw[selected_class]
                    else:
                        # Es un vector 1D (regresi√≥n lineal)
                        coefficients = coef_raw
                        is_multiclass = False

                    # Asegurar que coefficients es un array 1D
                    coefficients = np.array(coefficients).flatten()

                    # Verificar que las longitudes coincidan
                    if len(coefficients) != len(feature_names):
                        st.error(
                            f"Error: Se encontraron {len(coefficients)} coeficientes pero {len(feature_names)} caracter√≠sticas.")
                        st.error(f"Forma de coef_: {coef_raw.shape}")
                        st.error(f"Caracter√≠sticas: {feature_names}")
                        return

                    coef_df = pd.DataFrame({
                        'Caracter√≠stica': feature_names,
                        'Coeficiente': coefficients,
                        'Valor_Absoluto': np.abs(coefficients)
                    })

                except Exception as e:
                    st.error(f"Error al procesar los coeficientes: {str(e)}")
                    st.error(f"Forma de model.coef_: {model.coef_.shape}")
                    st.error(
                        f"N√∫mero de caracter√≠sticas: {len(feature_names)}")
                    return
                coef_df = coef_df.sort_values(
                    'Valor_Absoluto', ascending=False)

                # A√±adir interpretaci√≥n
                coef_df['Efecto'] = coef_df['Coeficiente'].apply(
                    lambda x: 'üìà Positivo' if x > 0 else 'üìâ Negativo'
                )
                coef_df['Importancia'] = coef_df['Valor_Absoluto'].apply(
                    lambda x: 'üî• Alta' if x > coef_df['Valor_Absoluto'].quantile(0.75)
                    else ('üî∂ Media' if x > coef_df['Valor_Absoluto'].quantile(0.25) else 'üîπ Baja')
                )

                # Mostrar tabla de coeficientes
                st.markdown("### üìä Tabla de Coeficientes")

                # Crear tabla mejorada con informaci√≥n adicional para regresi√≥n log√≠stica
                if model_type == "Logistic":
                    # Agregar odds ratios y cambios porcentuales
                    coef_df['Odds_Ratio'] = np.exp(coef_df['Coeficiente'])
                    coef_df['Cambio_Porcentual'] = (
                        coef_df['Odds_Ratio'] - 1) * 100

                    # Interpretaci√≥n de la magnitud del efecto
                    def interpretar_efecto_logistico(odds_ratio):
                        if odds_ratio > 7.4:  # |coef| > 2
                            return 'üî• Muy Fuerte'
                        elif odds_ratio > 2.7:  # |coef| > 1
                            return 'üî• Fuerte'
                        elif odds_ratio > 1.6 or odds_ratio < 0.625:  # |coef| > 0.5
                            return 'üî∂ Moderado'
                        else:
                            return 'üîπ D√©bil'

                    coef_df['Fuerza_Efecto'] = coef_df['Odds_Ratio'].apply(
                        interpretar_efecto_logistico)

                    # Formatear la tabla para regresi√≥n log√≠stica
                    display_df = coef_df[[
                        'Caracter√≠stica', 'Coeficiente', 'Odds_Ratio', 'Cambio_Porcentual', 'Efecto', 'Fuerza_Efecto']].copy()
                    display_df['Coeficiente'] = display_df['Coeficiente'].apply(
                        lambda x: f"{x:.4f}")
                    display_df['Odds_Ratio'] = display_df['Odds_Ratio'].apply(
                        lambda x: f"{x:.3f}")
                    display_df['Cambio_Porcentual'] = display_df['Cambio_Porcentual'].apply(
                        lambda x: f"{x:+.1f}%")

                    # Renombrar columnas para mayor claridad
                    display_df = display_df.rename(columns={
                        'Odds_Ratio': 'Odds Ratio',
                        'Cambio_Porcentual': 'Cambio en Odds',
                        'Fuerza_Efecto': 'Fuerza del Efecto'
                    })

                    st.dataframe(
                        display_df, use_container_width=True, hide_index=True)

                    # Explicaci√≥n de la tabla para regresi√≥n log√≠stica
                    with st.expander("üìñ ¬øC√≥mo leer esta tabla?", expanded=False):
                        st.markdown("""
                        **Columnas de la tabla:**
                        
                        - **Coeficiente:** Valor original del modelo (log-odds)
                        - **Odds Ratio:** `e^coeficiente` - M√°s f√°cil de interpretar
                        - **Cambio en Odds:** Cambio porcentual en las odds
                        - **Efecto:** Direcci√≥n del efecto (positivo/negativo)
                        - **Fuerza del Efecto:** Magnitud del impacto
                        
                        **Interpretaci√≥n de Odds Ratio:**
                        - **OR = 1.0:** Sin efecto
                        - **OR > 1.0:** Aumenta las odds (efecto positivo)
                        - **OR < 1.0:** Disminuye las odds (efecto negativo)
                        
                        **Ejemplos:**
                        - **OR = 2.0:** Duplica las odds (+100%)
                        - **OR = 1.5:** Aumenta las odds en 50%
                        - **OR = 0.5:** Reduce las odds a la mitad (-50%)
                        - **OR = 0.2:** Reduce las odds en 80%
                        """)

                else:
                    # Tabla est√°ndar para regresi√≥n lineal
                    display_df = coef_df[[
                        'Caracter√≠stica', 'Coeficiente', 'Efecto', 'Importancia']].copy()
                    display_df['Coeficiente'] = display_df['Coeficiente'].apply(
                        lambda x: f"{x:.4f}")

                    st.dataframe(
                        display_df, use_container_width=True, hide_index=True)

                    # Explicaci√≥n de la tabla para regresi√≥n lineal
                    with st.expander("üìñ ¬øC√≥mo leer esta tabla?", expanded=False):
                        st.markdown("""
                        **Columnas de la tabla:**
                        
                        - **Coeficiente:** Cambio en la variable objetivo por unidad de cambio en la caracter√≠stica
                        - **Efecto:** Direcci√≥n de la relaci√≥n (positiva/negativa)
                        - **Importancia:** Magnitud relativa del efecto
                        
                        **Interpretaci√≥n directa:**
                        - Un coeficiente de **+50** significa que cada unidad adicional de esa caracter√≠stica 
                          aumenta la predicci√≥n en 50 unidades
                        - Un coeficiente de **-20** significa que cada unidad adicional de esa caracter√≠stica 
                          disminuye la predicci√≥n en 20 unidades
                        """)

                # Mostrar intercepto si existe
                if hasattr(model, 'intercept_'):
                    st.markdown("### üéØ Intercepto del Modelo")
                    intercept = model.intercept_[0] if hasattr(
                        model.intercept_, '__len__') else model.intercept_

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Intercepto", f"{intercept:.4f}")

                    if model_type == "Logistic":
                        with col2:
                            intercept_odds_ratio = np.exp(intercept)
                            st.metric("Odds Ratio Base",
                                      f"{intercept_odds_ratio:.3f}")

                        st.info(
                            f"**Interpretaci√≥n:** Cuando todas las caracter√≠sticas son 0, el log-odds base es {intercept:.4f} "
                            f"(Odds Ratio = {intercept_odds_ratio:.3f})")
                    else:
                        st.info(
                            f"**Interpretaci√≥n:** Cuando todas las caracter√≠sticas son 0, el modelo predice un valor de {intercept:.4f}")

                # Gr√°fico de coeficientes
                st.markdown("### üìà Visualizaci√≥n de Coeficientes")

                fig, ax = plt.subplots(
                    figsize=(12, max(6, len(feature_names) * 0.4)))

                # Crear gr√°fico de barras horizontal
                colors = ['#ff6b6b' if x <
                          0 else '#4ecdc4' for x in coef_df['Coeficiente']]
                bars = ax.barh(range(
                    len(coef_df)), coef_df['Coeficiente'], color=colors, alpha=0.7, edgecolor='black')

                # Personalizaci√≥n
                ax.set_yticks(range(len(coef_df)))
                ax.set_yticklabels(coef_df['Caracter√≠stica'], fontsize=10)
                ax.set_xlabel('Valor del Coeficiente', fontsize=12)
                ax.set_title(
                    'Coeficientes del Modelo (ordenados por importancia)', fontsize=14, fontweight='bold')
                ax.axvline(x=0, color='black', linestyle='-',
                           alpha=0.8, linewidth=1)
                ax.grid(True, alpha=0.3, axis='x')

                # A√±adir valores en las barras
                for i, (bar, coef) in enumerate(zip(bars, coef_df['Coeficiente'])):
                    width = bar.get_width()
                    ax.text(width + (0.01 * (max(coef_df['Coeficiente']) - min(coef_df['Coeficiente']))) if width >= 0
                            else width - (0.01 * (max(coef_df['Coeficiente']) - min(coef_df['Coeficiente']))),
                            bar.get_y() + bar.get_height()/2,
                            f'{coef:.3f}', ha='left' if width >= 0 else 'right', va='center', fontsize=9)

                # Leyenda
                from matplotlib.patches import Patch
                legend_elements = [
                    Patch(facecolor='#4ecdc4', alpha=0.7,
                          label='Efecto Positivo'),
                    Patch(facecolor='#ff6b6b', alpha=0.7,
                          label='Efecto Negativo')
                ]
                ax.legend(handles=legend_elements, loc='upper right')

                plt.tight_layout()

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # An√°lisis de importancia
                st.markdown("### üîç An√°lisis Detallado de Importancia")

                # Identificar las caracter√≠sticas m√°s importantes
                top_features = coef_df.head(5)  # Mostrar top 5 en lugar de 3

                # An√°lisis diferenciado por tipo de modelo
                if model_type == "Logistic":
                    st.markdown(
                        "#### üéØ **Caracter√≠sticas que M√ÅS aumentan la probabilidad:**")
                    positive_features = coef_df[coef_df['Coeficiente'] > 0].head(
                        3)

                    if len(positive_features) > 0:
                        for i, row in positive_features.iterrows():
                            odds_ratio = np.exp(row['Coeficiente'])
                            cambio_pct = (odds_ratio - 1) * 100

                            # Determinar la intensidad del efecto
                            if odds_ratio > 3:
                                intensidad = "üî• **FUERTE**"
                            elif odds_ratio > 1.5:
                                intensidad = "üî∂ **MODERADO**"
                            else:
                                intensidad = "üîπ **D√âBIL**"

                            st.markdown(f"""
                            **{i+1}. {row['Caracter√≠stica']}** {intensidad}
                            - Coeficiente: `{row['Coeficiente']:.4f}`
                            - Odds Ratio: `{odds_ratio:.3f}`
                            - **Impacto:** Cada unidad adicional **multiplica las odds por {odds_ratio:.2f}** (aumenta {cambio_pct:+.1f}%)
                            """)
                    else:
                        st.info(
                            "No hay caracter√≠sticas que aumenten significativamente la probabilidad.")

                    st.markdown(
                        "#### üìâ **Caracter√≠sticas que M√ÅS disminuyen la probabilidad:**")
                    negative_features = coef_df[coef_df['Coeficiente'] < 0].head(
                        3)

                    if len(negative_features) > 0:
                        for i, row in negative_features.iterrows():
                            odds_ratio = np.exp(row['Coeficiente'])
                            reduccion_pct = (1 - odds_ratio) * 100

                            # Determinar la intensidad del efecto
                            if odds_ratio < 0.33:  # Reduce a menos de 1/3
                                intensidad = "üî• **FUERTE**"
                            elif odds_ratio < 0.67:  # Reduce a menos de 2/3
                                intensidad = "üî∂ **MODERADO**"
                            else:
                                intensidad = "üîπ **D√âBIL**"

                            st.markdown(f"""
                            **{i+1}. {row['Caracter√≠stica']}** {intensidad}
                            - Coeficiente: `{row['Coeficiente']:.4f}`
                            - Odds Ratio: `{odds_ratio:.3f}`
                            - **Impacto:** Cada unidad adicional **reduce las odds en {reduccion_pct:.1f}%**
                            """)
                    else:
                        st.info(
                            "No hay caracter√≠sticas que disminuyan significativamente la probabilidad.")

                    # Resumen ejecutivo para regresi√≥n log√≠stica
                    st.markdown("#### üìã **Resumen Ejecutivo:**")

                    # Caracter√≠stica m√°s influyente
                    most_influential = coef_df.iloc[0]
                    odds_ratio_most = np.exp(most_influential['Coeficiente'])

                    if most_influential['Coeficiente'] > 0:
                        impacto_desc = f"multiplica las odds por {odds_ratio_most:.2f}"
                    else:
                        reduccion = (1 - odds_ratio_most) * 100
                        impacto_desc = f"reduce las odds en {reduccion:.1f}%"

                    st.success(f"""
                    üéØ **Factor m√°s determinante:** `{most_influential['Caracter√≠stica']}`
                    
                    Esta caracter√≠stica es la que mayor impacto tiene en las predicciones del modelo.
                    Cada unidad adicional {impacto_desc}.
                    """)

                    # Verificar balance de efectos
                    n_positive = len(coef_df[coef_df['Coeficiente'] > 0])
                    n_negative = len(coef_df[coef_df['Coeficiente'] < 0])

                    if n_positive == 0:
                        st.warning(
                            "‚ö†Ô∏è **Atenci√≥n:** Todas las caracter√≠sticas reducen la probabilidad. Verifica que el modelo est√© bien entrenado.")
                    elif n_negative == 0:
                        st.warning(
                            "‚ö†Ô∏è **Atenci√≥n:** Todas las caracter√≠sticas aumentan la probabilidad. Verifica que el modelo est√© bien entrenado.")
                    else:
                        st.info(
                            f"‚úÖ **Balance:** {n_positive} caracter√≠sticas aumentan y {n_negative} disminuyen la probabilidad.")

                else:  # Regresi√≥n lineal
                    st.markdown(
                        "#### üìà **Caracter√≠sticas que M√ÅS aumentan el valor predicho:**")
                    positive_features = coef_df[coef_df['Coeficiente'] > 0].head(
                        3)

                    if len(positive_features) > 0:
                        for i, row in positive_features.iterrows():
                            coef_val = row['Coeficiente']

                            # Determinar la intensidad del efecto
                            abs_coef = abs(coef_val)
                            if abs_coef > coef_df['Valor_Absoluto'].quantile(0.8):
                                intensidad = "üî• **FUERTE**"
                            elif abs_coef > coef_df['Valor_Absoluto'].quantile(0.6):
                                intensidad = "üî∂ **MODERADO**"
                            else:
                                intensidad = "üîπ **D√âBIL**"

                            st.markdown(f"""
                            **{i+1}. {row['Caracter√≠stica']}** {intensidad}
                            - Coeficiente: `{coef_val:.4f}`
                            - **Impacto:** Cada unidad adicional **aumenta la predicci√≥n en {coef_val:.3f} unidades**
                            """)
                    else:
                        st.info(
                            "No hay caracter√≠sticas que aumenten significativamente el valor predicho.")

                    st.markdown(
                        "#### üìâ **Caracter√≠sticas que M√ÅS disminuyen el valor predicho:**")
                    negative_features = coef_df[coef_df['Coeficiente'] < 0].head(
                        3)

                    if len(negative_features) > 0:
                        for i, row in negative_features.iterrows():
                            coef_val = row['Coeficiente']

                            # Determinar la intensidad del efecto
                            abs_coef = abs(coef_val)
                            if abs_coef > coef_df['Valor_Absoluto'].quantile(0.8):
                                intensidad = "üî• **FUERTE**"
                            elif abs_coef > coef_df['Valor_Absoluto'].quantile(0.6):
                                intensidad = "üî∂ **MODERADO**"
                            else:
                                intensidad = "üîπ **D√âBIL**"

                            st.markdown(f"""
                            **{i+1}. {row['Caracter√≠stica']}** {intensidad}
                            - Coeficiente: `{coef_val:.4f}`
                            - **Impacto:** Cada unidad adicional **disminuye la predicci√≥n en {abs(coef_val):.3f} unidades**
                            """)
                    else:
                        st.info(
                            "No hay caracter√≠sticas que disminuyan significativamente el valor predicho.")

                    # Resumen ejecutivo para regresi√≥n lineal
                    st.markdown("#### üìã **Resumen Ejecutivo:**")

                    most_influential = coef_df.iloc[0]
                    coef_val = most_influential['Coeficiente']

                    if coef_val > 0:
                        impacto_desc = f"aumenta la predicci√≥n en {coef_val:.3f} unidades"
                    else:
                        impacto_desc = f"disminuye la predicci√≥n en {abs(coef_val):.3f} unidades"

                    st.success(f"""
                    üéØ **Factor m√°s determinante:** `{most_influential['Caracter√≠stica']}`
                    
                    Esta caracter√≠stica tiene el mayor impacto absoluto en las predicciones.
                    Cada unidad adicional {impacto_desc}.
                    """)

                # Recomendaciones generales
                st.markdown("#### üí° **Recomendaciones para la Acci√≥n:**")

                # Identificar caracter√≠sticas controlables vs no controlables
                top_3 = coef_df.head(3)

                recommendations = []
                for i, row in top_3.iterrows():
                    feature_name = row['Caracter√≠stica']
                    effect_direction = "aumentar" if row['Coeficiente'] > 0 else "reducir"
                    target = "probabilidad positiva" if model_type == "Logistic" else "valor predicho"

                    recommendations.append(
                        f"**{feature_name}:** {effect_direction.capitalize()} esta caracter√≠stica para {'incrementar' if row['Coeficiente'] > 0 else 'decrementar'} la {target}")

                for i, rec in enumerate(recommendations, 1):
                    st.markdown(f"{i}. {rec}")

                # Warning para coeficientes extremos
                extreme_coefs = coef_df[coef_df['Valor_Absoluto']
                                        > coef_df['Valor_Absoluto'].quantile(0.95)]
                if len(extreme_coefs) > 0:
                    st.warning(f"""
                    ‚ö†Ô∏è **Atenci√≥n - Coeficientes Extremos Detectados:**
                    
                    Las siguientes caracter√≠sticas tienen coeficientes muy altos: {', '.join(extreme_coefs['Caracter√≠stica'].tolist())}
                    
                    Esto podr√≠a indicar:
                    - Overfitting del modelo
                    - Escalas muy diferentes entre caracter√≠sticas
                    - Multicolinealidad entre variables
                    - Outliers en los datos
                    
                    **Recomendaci√≥n:** Considera normalizar las caracter√≠sticas o revisar la calidad de los datos.
                    """)

            else:
                st.error("El modelo no tiene coeficientes disponibles.")
        else:
            st.info("Entrena un modelo primero para ver los coeficientes.")

    # Pesta√±a de Predicciones
    elif st.session_state.active_tab_lr == 5:
        st.header("Hacer Predicciones")

        if st.session_state.get('model_trained_lr', False):
            model = st.session_state.get('model_lr')
            feature_names = st.session_state.get('feature_names_lr', [])
            dataset_name = st.session_state.get('selected_dataset_lr', '')
            X_train = st.session_state.get('X_train_lr')
            class_names = st.session_state.get('class_names_lr', [])
            model_type = st.session_state.get('model_type_lr', 'Linear')
            task_type = st.session_state.get('task_type_lr', 'Regresi√≥n')

            # Obtener metadata del dataset para adaptar los inputs
            from dataset_metadata import get_dataset_metadata
            metadata = get_dataset_metadata(dataset_name)
            feature_descriptions = metadata.get('feature_descriptions', {})
            value_mappings = metadata.get('value_mappings', {})
            original_to_display = metadata.get('original_to_display', {})
            categorical_features = metadata.get('categorical_features', [])

            st.markdown("### Ingresa los valores para hacer una predicci√≥n")

            # Analizar caracter√≠sticas si tenemos datos de entrenamiento
            feature_info = {}
            if X_train is not None:
                # Convertir a DataFrame si es necesario
                if hasattr(X_train, 'columns'):
                    column_names = X_train.columns
                else:
                    column_names = range(len(feature_names))

                for i, feature_display_name in enumerate(feature_names):
                    # Obtener el nombre original de la columna
                    if i < len(column_names):
                        original_col_name = column_names[i]
                    else:
                        original_col_name = feature_display_name

                    # Encontrar el nombre original usando reverse mapping
                    reverse_mapping = {v: k for k,
                                       v in original_to_display.items()}
                    if feature_display_name in reverse_mapping:
                        original_col_name = reverse_mapping[feature_display_name]

                    # Usar el √≠ndice para acceder a las columnas
                    if hasattr(X_train, 'iloc'):
                        feature_col = X_train.iloc[:, i]
                    else:
                        feature_col = X_train[:, i]

                    # Determinar tipo de caracter√≠stica
                    unique_values = len(set(feature_col)) if hasattr(
                        feature_col, '__iter__') else 10
                    unique_vals = sorted(list(set(feature_col))) if hasattr(
                        feature_col, '__iter__') else [0, 1]

                    # Verificar si es categ√≥rica seg√∫n metadata
                    is_categorical_by_metadata = original_col_name in categorical_features

                    if unique_values <= 2:
                        feature_type = 'binary'
                    elif unique_values <= 10 and (all(isinstance(x, (int, float)) and x == int(x) for x in unique_vals) or is_categorical_by_metadata):
                        feature_type = 'categorical'
                    else:
                        feature_type = 'continuous'

                    # Preparar informaci√≥n de la caracter√≠stica
                    if feature_type in ['binary', 'categorical'] and original_col_name in value_mappings:
                        display_values = []
                        value_to_original = {}
                        for orig_val in unique_vals:
                            if orig_val in value_mappings[original_col_name]:
                                display_val = value_mappings[original_col_name][orig_val]
                                display_values.append(display_val)
                                value_to_original[display_val] = orig_val
                            else:
                                display_values.append(str(orig_val))
                                value_to_original[str(orig_val)] = orig_val

                        feature_info[i] = {
                            'type': feature_type,
                            'values': unique_vals,
                            'display_values': display_values,
                            'value_to_original': value_to_original,
                            'original_column': original_col_name,
                            'display_name': feature_display_name
                        }
                    else:
                        feature_info[i] = {
                            'type': feature_type,
                            'values': unique_vals,
                            'min': float(min(unique_vals)) if feature_type == 'continuous' else min(unique_vals),
                            'max': float(max(unique_vals)) if feature_type == 'continuous' else max(unique_vals),
                            'mean': float(sum(feature_col) / len(feature_col)) if feature_type == 'continuous' and hasattr(feature_col, '__iter__') else None,
                            'original_column': original_col_name,
                            'display_name': feature_display_name
                        }
            else:
                # Valores por defecto si no hay datos de entrenamiento
                for i, feature in enumerate(feature_names):
                    feature_info[i] = {
                        'type': 'continuous',
                        'min': 0.0,
                        'max': 10.0,
                        'mean': 5.0,
                        'original_column': feature,
                        'display_name': feature
                    }

            # Crear controles adaptativos para cada caracter√≠stica
            input_values = []
            cols = st.columns(min(3, len(feature_names)))

            for i, feature in enumerate(feature_names):
                with cols[i % len(cols)]:
                    info = feature_info.get(
                        i, {'type': 'continuous', 'min': 0.0, 'max': 10.0, 'mean': 5.0})

                    # Crear etiqueta con descripci√≥n si est√° disponible
                    original_col = info.get('original_column', feature)
                    description = feature_descriptions.get(original_col, '')
                    if description:
                        label = f"**{feature}**\n\n*{description}*"
                    else:
                        label = feature

                    if info['type'] == 'binary':
                        # Control para caracter√≠sticas binarias
                        if 'display_values' in info and 'value_to_original' in info:
                            selected_display = st.selectbox(
                                label,
                                options=info['display_values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                            value = info['value_to_original'][selected_display]
                        elif len(info['values']) == 2 and 0 in info['values'] and 1 in info['values']:
                            value = st.checkbox(label, key=f"pred_input_{i}")
                            value = 1 if value else 0
                        else:
                            value = st.selectbox(
                                label,
                                options=info['values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                        input_values.append(value)

                    elif info['type'] == 'categorical':
                        # Control para caracter√≠sticas categ√≥ricas
                        if 'display_values' in info and 'value_to_original' in info:
                            selected_display = st.selectbox(
                                label,
                                options=info['display_values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                            value = info['value_to_original'][selected_display]
                        else:
                            value = st.selectbox(
                                label,
                                options=info['values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                        input_values.append(value)

                    else:  # continuous
                        # Control para caracter√≠sticas continuas
                        if 'min' in info and 'max' in info:
                            step = (info['max'] - info['min']) / \
                                100 if info['max'] != info['min'] else 0.1
                            default_val = info.get(
                                'mean', (info['min'] + info['max']) / 2)
                            value = st.slider(
                                label,
                                min_value=info['min'],
                                max_value=info['max'],
                                value=default_val,
                                step=step,
                                key=f"pred_input_{i}"
                            )
                        else:
                            value = st.number_input(
                                label,
                                value=0.0,
                                key=f"pred_input_{i}"
                            )
                        input_values.append(value)

            if st.button("üîÆ Predecir", key="predict_lr_button"):
                try:
                    if model is not None:
                        prediction = model.predict([input_values])[0]

                        # For logistic regression, convert numeric prediction to class label
                        if task_type == 'Clasificaci√≥n' and class_names is not None:
                            prediction_label = class_names[int(prediction)]
                            st.success(f"Predicci√≥n: {prediction_label}")
                        else:
                            # For regression, show numeric prediction
                            st.success(f"Predicci√≥n: {prediction:.4f}")
                    else:
                        st.error("Modelo no disponible")
                except Exception as e:
                    st.error(f"Error en la predicci√≥n: {str(e)}")
        else:
            st.info("Entrena un modelo primero para hacer predicciones.")

    # Pesta√±a de Exportar
    elif st.session_state.active_tab_lr == 6:
        st.header("Exportar Modelo")

        if st.session_state.get('model_trained_lr', False):
            model = st.session_state.get('model_lr')

            col1, col2 = st.columns(2)

            with col2:
                if st.button("üì• Descargar Modelo (Pickle)", key="download_pickle_lr"):
                    pickle_data = export_model_pickle(model)
                    st.download_button(
                        label="Descargar modelo.pkl",
                        data=pickle_data,
                        file_name="linear_regression_model.pkl",
                        mime="application/octet-stream"
                    )

            with col1:
                if st.button("üìÑ Generar C√≥digo", key="generate_code_lr"):
                    # Generate complete code for linear models
                    model_type = st.session_state.get(
                        'model_type_lr', 'Linear')
                    feature_names = st.session_state.get(
                        'feature_names_lr', [])
                    class_names = st.session_state.get('class_names_lr', [])

                    if model_type == "Logistic":
                        code = generate_logistic_regression_code(
                            feature_names, class_names)
                    else:
                        code = generate_linear_regression_code(feature_names)

                    st.code(code, language="python")

                    # Download button for the code
                    st.download_button(
                        label="üì• Descargar c√≥digo",
                        data=code,
                        file_name=f"{'logistic' if model_type == 'Logistic' else 'linear'}_regression_code.py",
                        mime="text/plain"
                    )
        else:
            st.info("Entrena un modelo primero para exportarlo.")


def run_csv_loader_app():
    """Ejecuta la aplicaci√≥n espec√≠fica para cargar archivos CSV personalizados."""
    st.header("üìÅ Cargar CSV Personalizado")
    st.markdown(
        "Carga tu propio dataset en formato CSV para an√°lisis personalizado")

    # Informaci√≥n sobre cargar CSV
    with st.expander("‚ÑπÔ∏è ¬øC√≥mo usar esta herramienta?", expanded=True):
        st.markdown("""
        **Esta herramienta te permite cargar tus propios datasets CSV para an√°lisis con Machine Learning.**

        ### üìã Requisitos del archivo CSV:
        - Formato CSV con encabezados (primera fila con nombres de columnas)
        - Al menos 2 columnas (caracter√≠sticas + variable objetivo)
        - Datos limpios y estructurados
        - Codificaci√≥n UTF-8 preferible

        ### üîß Funcionalidades:
        - **Vista previa autom√°tica** del dataset cargado
        - **Detecci√≥n autom√°tica** del tipo de tarea (Clasificaci√≥n/Regresi√≥n)
        - **Selecci√≥n de columna objetivo** personalizable
        - **Estad√≠sticas descriptivas** del dataset
        - **Integraci√≥n completa** con todos los algoritmos disponibles

        ### üí° Consejos:
        - Aseg√∫rate de que los datos num√©ricos est√©n en formato correcto
        - Para clasificaci√≥n, la columna objetivo debe contener categor√≠as
        - Para regresi√≥n, la columna objetivo debe contener valores num√©ricos continuos
        """)

    # Usar la funci√≥n existente de dataset_manager
    st.markdown("---")

    # Llamar a la funci√≥n de carga de CSV sin mostrar datasets predefinidos
    result = create_dataset_selector(show_predefined=False)

    if result is not None:
        if isinstance(result, tuple):
            # CSV cargado exitosamente
            file_path, target_col, task_type = result

            st.markdown("---")
            st.success("‚úÖ ¬°Dataset CSV cargado exitosamente!")

            # Mostrar opciones de an√°lisis
            st.markdown("### üöÄ Pr√≥ximos pasos:")

            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button("üå≤ Analizar con √Årboles de Decisi√≥n",
                             key="analyze_trees",
                             use_container_width=True,
                             type="primary"):
                    st.session_state.navigation = "üå≤ √Årboles de Decisi√≥n"
                    st.rerun()

            with col2:
                if st.button("üìä Analizar con Regresi√≥n",
                             key="analyze_linear",
                             use_container_width=True,
                             type="primary"):
                    st.session_state.navigation = "üìä Regresi√≥n"
                    st.rerun()

            with col3:
                if st.button("üîÑ Cargar otro archivo",
                             key="load_another",
                             use_container_width=True):
                    # Limpiar el estado del CSV cargado
                    if 'csv_datasets' in st.session_state:
                        st.session_state.csv_datasets.clear()
                    if 'selected_dataset' in st.session_state:
                        del st.session_state.selected_dataset
                    st.rerun()

            # Informaci√≥n adicional sobre el dataset cargado
            st.markdown("### üìä Informaci√≥n del Dataset Cargado:")

            try:
                # Leer el archivo para mostrar estad√≠sticas
                df = pd.read_csv(file_path)

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìè Filas", df.shape[0])
                with col2:
                    st.metric("üìä Columnas", df.shape[1])
                with col3:
                    st.metric("üéØ Variable Objetivo", target_col)
                with col4:
                    task_icon = "üè∑Ô∏è" if task_type == "Clasificaci√≥n" else "üìà"
                    st.metric(f"{task_icon} Tipo de Tarea", task_type)

                # Mostrar estad√≠sticas descriptivas
                with st.expander("üìà Estad√≠sticas Descriptivas", expanded=False):
                    st.dataframe(df.describe(), use_container_width=True)

                # Mostrar distribuci√≥n de la variable objetivo
                with st.expander("üéØ Distribuci√≥n de la Variable Objetivo", expanded=False):
                    if task_type == "Clasificaci√≥n":
                        value_counts = df[target_col].value_counts()

                        col1, col2 = st.columns(2)
                        with col1:
                            st.dataframe(value_counts.to_frame(
                                "Cantidad"), use_container_width=True)

                        with col2:
                            fig, ax = plt.subplots(figsize=(8, 6))
                            value_counts.plot(kind='bar', ax=ax)
                            ax.set_title(f'Distribuci√≥n de {target_col}')
                            ax.set_ylabel('Cantidad')
                            plt.xticks(rotation=45)
                            plt.tight_layout()
                            st.pyplot(fig)
                    else:
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write("**Estad√≠sticas:**")
                            st.write(f"‚Ä¢ M√≠nimo: {df[target_col].min():.4f}")
                            st.write(f"‚Ä¢ M√°ximo: {df[target_col].max():.4f}")
                            st.write(f"‚Ä¢ Media: {df[target_col].mean():.4f}")
                            st.write(
                                f"‚Ä¢ Mediana: {df[target_col].median():.4f}")
                            st.write(
                                f"‚Ä¢ Desv. Est√°ndar: {df[target_col].std():.4f}")

                        with col2:
                            fig, ax = plt.subplots(figsize=(8, 6))
                            df[target_col].hist(bins=30, ax=ax, alpha=0.7)
                            ax.set_title(f'Distribuci√≥n de {target_col}')
                            ax.set_xlabel(target_col)
                            ax.set_ylabel('Frecuencia')
                            plt.tight_layout()
                            st.pyplot(fig)

            except Exception as e:
                st.warning(
                    f"No se pudieron cargar las estad√≠sticas adicionales: {str(e)}")

    else:
        # Mostrar consejos mientras no hay archivo cargado
        st.markdown("### üí° Ejemplos de Datasets que puedes cargar:")

        examples = [
            {
                "name": "Dataset de Ventas",
                "description": "Datos de ventas con caracter√≠sticas como precio, descuento, temporada ‚Üí Predictor de ventas",
                "task": "Regresi√≥n",
                "icon": "üí∞"
            },
            {
                "name": "Dataset de Clientes",
                "description": "Datos de clientes con edad, ingresos, historial ‚Üí Clasificaci√≥n de segmentos",
                "task": "Clasificaci√≥n",
                "icon": "üë•"
            },
            {
                "name": "Dataset de Productos",
                "description": "Caracter√≠sticas de productos con ratings ‚Üí Predicci√≥n de popularidad",
                "task": "Regresi√≥n",
                "icon": "üì¶"
            },
            {
                "name": "Dataset M√©dico",
                "description": "S√≠ntomas y caracter√≠sticas del paciente ‚Üí Diagn√≥stico binario",
                "task": "Clasificaci√≥n",
                "icon": "üè•"
            }
        ]

        for example in examples:
            with st.container():
                col1, col2 = st.columns([1, 10])
                with col1:
                    st.markdown(f"## {example['icon']}")
                with col2:
                    st.markdown(f"**{example['name']}** ({example['task']})")
                    st.markdown(f"_{example['description']}_")
                st.markdown("---")


def generate_linear_regression_code(feature_names):
    """Generate complete Python code for linear regression."""
    feature_names_str = str(feature_names)

    code = f"""# C√≥digo completo para Regresi√≥n Lineal
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt

# 1. CARGAR Y PREPARAR LOS DATOS
# Reemplaza esta secci√≥n con tu m√©todo de carga de datos
# df = pd.read_csv('tu_archivo.csv')  # Cargar desde CSV
# O usa datos de ejemplo:

# Datos de ejemplo (reemplaza con tus datos reales)
# X = df[{feature_names_str}]  # Caracter√≠sticas
# y = df['variable_objetivo']  # Variable objetivo

# 2. DIVIDIR LOS DATOS
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 3. CREAR Y ENTRENAR EL MODELO
model = LinearRegression()
model.fit(X_train, y_train)

# 4. HACER PREDICCIONES
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# 5. EVALUAR EL MODELO
r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)
mae_test = mean_absolute_error(y_test, y_pred_test)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))

print("=== RESULTADOS DEL MODELO ===")
print(f"R¬≤ Score (Entrenamiento): {{r2_train:.4f}}")
print(f"R¬≤ Score (Prueba): {{r2_test:.4f}}")
print(f"MAE (Error Absoluto Medio): {{mae_test:.4f}}")
print(f"RMSE (Ra√≠z Error Cuadr√°tico Medio): {{rmse_test:.4f}}")

# 6. MOSTRAR COEFICIENTES
print("\\n=== COEFICIENTES DEL MODELO ===")
feature_names = {feature_names_str}
for i, coef in enumerate(model.coef_):
    print(f"{{feature_names[i]}}: {{coef:.4f}}")
print(f"Intercepto: {{model.intercept_:.4f}}")

# 7. VISUALIZAR RESULTADOS
plt.figure(figsize=(12, 5))

# Gr√°fico 1: Predicciones vs Valores Reales
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_test, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Valores Reales')
plt.ylabel('Predicciones')
plt.title('Predicciones vs Valores Reales')
plt.grid(True, alpha=0.3)

# Gr√°fico 2: Residuos
plt.subplot(1, 2, 2)
residuals = y_test - y_pred_test
plt.scatter(y_pred_test, residuals, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicciones')
plt.ylabel('Residuos')
plt.title('An√°lisis de Residuos')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 8. FUNCI√ìN PARA NUEVAS PREDICCIONES
def predecir_nuevo_valor(nuevo_ejemplo):
    \"\"\"
    Funci√≥n para hacer predicciones con nuevos datos.
    
    Par√°metros:
    nuevo_ejemplo: lista con valores para cada caracter√≠stica
                  en el orden: {feature_names_str}
    \"\"\"
    nuevo_ejemplo = np.array(nuevo_ejemplo).reshape(1, -1)
    prediccion = model.predict(nuevo_ejemplo)[0]
    return prediccion

# Ejemplo de uso para nuevas predicciones:
# nuevo_ejemplo = [valor1, valor2, valor3, ...]  # Reemplaza con tus valores
# resultado = predecir_nuevo_valor(nuevo_ejemplo)
# print(f"Predicci√≥n para nuevo ejemplo: {{resultado:.4f}}")

# 9. GUARDAR EL MODELO (OPCIONAL)
import pickle

# Guardar modelo
with open('modelo_regresion_lineal.pkl', 'wb') as f:
    pickle.dump(model, f)

# Cargar modelo guardado
# with open('modelo_regresion_lineal.pkl', 'rb') as f:
#     modelo_cargado = pickle.load(f)
"""
    return code


def generate_logistic_regression_code(feature_names, class_names):
    """Generate complete Python code for logistic regression."""
    feature_names_str = str(feature_names)
    class_names_str = str(class_names)

    code = f"""# C√≥digo completo para Regresi√≥n Log√≠stica
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1. CARGAR Y PREPARAR LOS DATOS
# Reemplaza esta secci√≥n con tu m√©todo de carga de datos
# df = pd.read_csv('tu_archivo.csv')  # Cargar desde CSV
# O usa datos de ejemplo:

# Datos de ejemplo (reemplaza con tus datos reales)
# X = df[{feature_names_str}]  # Caracter√≠sticas
# y = df['variable_objetivo']  # Variable objetivo (0, 1, 2, ...)

# 2. DIVIDIR LOS DATOS
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 3. CREAR Y ENTRENAR EL MODELO
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)

# 4. HACER PREDICCIONES
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# 5. EVALUAR EL MODELO
accuracy_train = accuracy_score(y_train, y_pred_train)
accuracy_test = accuracy_score(y_test, y_pred_test)

print("=== RESULTADOS DEL MODELO ===")
print(f"Accuracy (Entrenamiento): {{accuracy_train:.4f}}")
print(f"Accuracy (Prueba): {{accuracy_test:.4f}}")

# Reporte detallado de clasificaci√≥n
class_names = {class_names_str}
print("\\n=== REPORTE DE CLASIFICACI√ìN ===")
print(classification_report(y_test, y_pred_test, target_names=class_names))

# 6. MATRIZ DE CONFUSI√ìN
plt.figure(figsize=(12, 5))

# Gr√°fico 1: Matriz de Confusi√≥n
plt.subplot(1, 2, 1)
cm = confusion_matrix(y_test, y_pred_test)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=class_names, yticklabels=class_names)
plt.title('Matriz de Confusi√≥n')
plt.xlabel('Predicciones')
plt.ylabel('Valores Reales')

# Gr√°fico 2: Importancia de caracter√≠sticas (coeficientes)
plt.subplot(1, 2, 2)
feature_names = {feature_names_str}
coef = model.coef_.flatten() if len(model.coef_.shape) > 1 else model.coef_
colors = ['red' if x < 0 else 'blue' for x in coef]
plt.barh(range(len(coef)), coef, color=colors, alpha=0.7)
plt.yticks(range(len(coef)), feature_names)
plt.xlabel('Coeficientes')
plt.title('Importancia de Caracter√≠sticas')
plt.axvline(x=0, color='black', linestyle='-', alpha=0.8)
plt.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.show()

# 7. MOSTRAR COEFICIENTES DETALLADOS
print("\\n=== COEFICIENTES DEL MODELO ===")
for i, coef in enumerate(coef):
    effect = "aumenta" if coef > 0 else "disminuye"
    print(f"{{feature_names[i]}}: {{coef:.4f}} ({{effect}} la probabilidad)")
print(f"Intercepto: {{model.intercept_[0]:.4f}}")

# 8. FUNCI√ìN PARA NUEVAS PREDICCIONES
def predecir_nueva_muestra(nuevo_ejemplo):
    \"\"\"
    Funci√≥n para hacer predicciones con nuevos datos.
    
    Par√°metros:
    nuevo_ejemplo: lista con valores para cada caracter√≠stica
                  en el orden: {feature_names_str}
    
    Retorna:
    prediccion: clase predicha
    probabilidades: probabilidades para cada clase
    \"\"\"
    nuevo_ejemplo = np.array(nuevo_ejemplo).reshape(1, -1)
    prediccion = model.predict(nuevo_ejemplo)[0]
    probabilidades = model.predict_proba(nuevo_ejemplo)[0]
    
    clase_predicha = class_names[prediccion]
    return clase_predicha, probabilidades

# Ejemplo de uso para nuevas predicciones:
# nuevo_ejemplo = [valor1, valor2, valor3, ...]  # Reemplaza con tus valores
# clase, probas = predecir_nueva_muestra(nuevo_ejemplo)
# print(f"Clase predicha: {{clase}}")
# print("Probabilidades por clase:")
# for i, prob in enumerate(probas):
#     print(f"  {{class_names[i]}}: {{prob:.4f}} ({{prob*100:.1f}}%)")

# 9. GUARDAR EL MODELO (OPCIONAL)
import pickle

# Guardar modelo
with open('modelo_regresion_logistica.pkl', 'wb') as f:
    pickle.dump(model, f)

# Cargar modelo guardado
# with open('modelo_regresion_logistica.pkl', 'rb') as f:
#     modelo_cargado = pickle.load(f)

# 10. FUNCI√ìN PARA INTERPRETAR PROBABILIDADES
def interpretar_prediccion(nuevo_ejemplo, umbral_confianza=0.8):
    \"\"\"
    Interpreta una predicci√≥n mostrando la confianza del modelo.
    \"\"\"
    clase, probabilidades = predecir_nueva_muestra(nuevo_ejemplo)
    max_prob = max(probabilidades)
    
    print(f"Predicci√≥n: {{clase}}")
    print(f"Confianza: {{max_prob:.4f}} ({{max_prob*100:.1f}}%)")
    
    if max_prob >= umbral_confianza:
        print("‚úÖ Alta confianza en la predicci√≥n")
    elif max_prob >= 0.6:
        print("‚ö†Ô∏è Confianza moderada en la predicci√≥n")
    else:
        print("‚ùå Baja confianza en la predicci√≥n")
    
    return clase, max_prob

# Ejemplo de interpretaci√≥n:
# interpretar_prediccion([valor1, valor2, valor3, ...])
"""
    return code


if __name__ == "__main__":
    main()
