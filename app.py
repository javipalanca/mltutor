from utils import (
    get_image_download_link, generate_model_code, export_model_pickle, export_model_onnx,
    create_info_box, format_number, show_code_with_download
)
from tree_visualizer import (
    render_tree_visualization,
    create_tree_visualization, get_tree_text
)
from ui import (
    setup_page, init_session_state, show_welcome_page,
    display_feature_importance, display_model_export_options, create_prediction_interface
)
from sklearn.model_selection import train_test_split
from decision_boundary import plot_decision_boundary
from model_evaluation import evaluate_classification_model, evaluate_regression_model, show_detailed_evaluation
from model_training import train_decision_tree, predict_sample, train_linear_model, train_knn_model
from dataset_manager import load_data, preprocess_data, create_dataset_selector, load_dataset_from_file
import streamlit.components.v1 as components
import plotly.express as px
import io
import base64
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import streamlit as st


def run_knn_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de K-Nearest Neighbors (KNN) para clasificaci√≥n y regresi√≥n."""
    import streamlit as st
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt

    st.header("üîç K-Nearest Neighbors (KNN)")
    st.markdown("Aprende sobre K-vecinos m√°s cercanos de forma interactiva.")

    # Explicaci√≥n te√≥rica
    with st.expander("‚ÑπÔ∏è ¬øQu√© es K-Nearest Neighbors?", expanded=False):
        st.markdown("""
        K-Nearest Neighbors (KNN) es un algoritmo supervisado que predice la clase o el valor de una muestra bas√°ndose en las muestras m√°s cercanas en el espacio de caracter√≠sticas.

        **Caracter√≠sticas principales:**
        - No requiere entrenamiento expl√≠cito (modelo perezoso)
        - Puede usarse para clasificaci√≥n y regresi√≥n
        - La predicci√≥n depende de la distancia a los vecinos m√°s cercanos
        - Sensible a la escala de los datos y a la elecci√≥n de K
        """)

    # Variables para almacenar datos
    dataset_loaded = False
    X, y, feature_names, class_names, dataset_info, task_type = None, None, None, None, None, None

    # Inicializar el estado de la pesta√±a activa si no existe
    if 'active_tab_knn' not in st.session_state:
        st.session_state.active_tab_knn = 0

    # Crear pesta√±as para organizar la informaci√≥n
    tab_options = [
        "üìä Datos",
        "üèãÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üìâ Visualizaci√≥n",
        "üîÆ Predicciones"
    ]

    tab_cols = st.columns(len(tab_options))

    # Estilo CSS para los botones de pesta√±as (KNN)
    st.markdown("""
    <style>
    div.tab-button-knn > button {
        border-radius: 4px 4px 0 0;
        padding: 10px;
        width: 100%;
        white-space: nowrap;
        background-color: #F0F2F6;
        border-bottom: 2px solid #E0E0E0;
        color: #333333;
    }
    div.tab-button-knn-active > button {
        background-color: #E3F2FD !important;
        border-bottom: 2px solid #1E88E5 !important;
        font-weight: bold !important;
        color: #1E88E5 !important;
    }
    div.tab-button-knn > button:hover {
        background-color: #E8EAF6;
    }
    </style>
    """, unsafe_allow_html=True)

    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_knn_{i}"
        button_style = "tab-button-knn-active" if st.session_state.active_tab_knn == i else "tab-button-knn"
        is_active = st.session_state.active_tab_knn == i
        with col:
            st.markdown(f"<div class='{button_style}'>",
                        unsafe_allow_html=True)
            if st.button(tab_name, key=button_key, use_container_width=True, type="primary" if is_active else "secondary"):
                st.session_state.active_tab_knn = i
                st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    # Separador visual
    st.markdown("---")

    # SELECTOR UNIFICADO DE DATASET (solo mostrar en pesta√±as que lo necesiten)
    # Exploraci√≥n y Entrenamiento
    if st.session_state.active_tab_knn in [0, 1]:
        st.markdown("### üìä Selecci√≥n de Dataset")

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset_knn' not in st.session_state:
            st.session_state.selected_dataset_knn = "üå∏ Iris - Clasificaci√≥n de flores"

        # Lista base de datasets predefinidos
        builtin_datasets = [
            "üå∏ Iris - Clasificaci√≥n de flores",
            "üç∑ Vino - Clasificaci√≥n de vinos",
            "üî¨ C√°ncer - Diagn√≥stico binario",
            "üö¢ Titanic - Supervivencia",
            "üí∞ Propinas - Predicci√≥n de propinas",
            "üè† Viviendas California - Precios",
            "üêß Ping√ºinos - Clasificaci√≥n de especies"
        ]

        # A√±adir datasets CSV cargados si existen
        available_datasets = builtin_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado est√© en la lista disponible
        if st.session_state.selected_dataset_knn not in available_datasets:
            st.session_state.selected_dataset_knn = builtin_datasets[0]

        # Selector unificado
        dataset_option = st.selectbox(
            "Dataset:",
            available_datasets,
            index=available_datasets.index(
                st.session_state.selected_dataset_knn),
            key="unified_dataset_selector_knn",
            help="El dataset seleccionado se mantendr√° entre las pesta√±as de Exploraci√≥n y Entrenamiento"
        )

        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset_knn = dataset_option

        # Separador despu√©s del selector
        st.markdown("---")
    else:
        # Para otras pesta√±as, mostrar qu√© dataset est√° seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset_knn'):
            st.info(
                f"üìä **Dataset actual:** {st.session_state.selected_dataset_knn}")
            st.markdown("---")

    # L√≥gica de cada pesta√±a (similar a los otros algoritmos)
    from dataset_manager import create_dataset_selector, load_data
    from model_training import train_knn_model
    from model_evaluation import evaluate_classification_model, evaluate_regression_model, show_detailed_evaluation
    from ui import create_prediction_interface
    import seaborn as sns

    # Estado de datos y modelo
    if 'knn_dataset' not in st.session_state:
        st.session_state.knn_dataset = None
    if 'knn_X' not in st.session_state:
        st.session_state.knn_X = None
    if 'knn_y' not in st.session_state:
        st.session_state.knn_y = None
    if 'knn_feature_names' not in st.session_state:
        st.session_state.knn_feature_names = None
    if 'knn_class_names' not in st.session_state:
        st.session_state.knn_class_names = None
    if 'knn_task_type' not in st.session_state:
        st.session_state.knn_task_type = 'Clasificaci√≥n'
    if 'knn_model' not in st.session_state:
        st.session_state.knn_model = None
    if 'knn_metrics' not in st.session_state:
        st.session_state.knn_metrics = None
    if 'knn_trained' not in st.session_state:
        st.session_state.knn_trained = False

    tab = st.session_state.active_tab_knn

    # Pesta√±a 0: Datos
    if tab == 0:
        st.header("Exploraci√≥n de Datos")

        try:
            # Cargar datos para exploraci√≥n usando el dataset seleccionado
            X, y, feature_names, class_names, info, task_type = load_data(
                st.session_state.selected_dataset_knn)

            # Crear DataFrame para mostrar los datos
            import pandas as pd
            if isinstance(X, pd.DataFrame):
                data = X.copy()
            else:
                data = pd.DataFrame(X, columns=feature_names)

            # A√±adir la variable objetivo
            target_name = 'target'
            if isinstance(info, dict):
                target_name = info.get('target', 'target')
            data[target_name] = y

            # Actualizar el estado de la sesi√≥n
            st.session_state.knn_dataset = st.session_state.selected_dataset_knn
            st.session_state.knn_X = X
            st.session_state.knn_y = y
            st.session_state.knn_feature_names = feature_names
            st.session_state.knn_class_names = class_names
            st.session_state.knn_task_type = task_type

            # Mostrar informaci√≥n del dataset
            st.markdown("### Informaci√≥n del Dataset")
            from utils import create_info_box
            st.markdown(create_info_box(info), unsafe_allow_html=True)

            # Mostrar las primeras filas de los datos
            st.markdown("### Vista previa de datos")
            st.dataframe(data.head(20), use_container_width=True)
            st.markdown(f"**Caracter√≠sticas:** {', '.join(feature_names)}")

            # Determinar el nombre de la variable objetivo
            if isinstance(info, dict):
                target_display = info.get('target', 'target')
            else:
                target_display = 'target'
            st.markdown(f"**Variable objetivo:** {target_display}")

            st.markdown(f"**Tipo de tarea:** {task_type}")

            # Mostrar clases correctamente
            if class_names is not None:
                if isinstance(class_names, list):
                    st.markdown(
                        f"**Clases:** {', '.join(map(str, class_names))}")
                else:
                    st.markdown(f"**Clases:** {class_names}")
            else:
                st.markdown("**Clases:** N/A (regresi√≥n)")

            if X is not None and hasattr(X, 'shape') and len(X.shape) >= 2:
                st.markdown(
                    f"**Tama√±o del dataset:** {X.shape[0]} muestras, {X.shape[1]} caracter√≠sticas")
            elif X is not None and hasattr(X, 'shape') and len(X.shape) == 1:
                st.markdown(
                    f"**Tama√±o del dataset:** {X.shape[0]} muestras, 1 caracter√≠stica")
            else:
                st.markdown("**Tama√±o del dataset:** No disponible")
            st.session_state.knn_trained = False

        except Exception as e:
            st.error(f"Error al cargar el dataset: {str(e)}")
            st.info(
                "Por favor, selecciona un dataset v√°lido para continuar con la exploraci√≥n.")

    # Pesta√±a 1: Entrenamiento
    elif tab == 1:
        st.header("Configuraci√≥n del Modelo KNN")

        # Inicializar variables de sesi√≥n necesarias
        if 'dataset_option_knn' not in st.session_state:
            st.session_state.dataset_option_knn = st.session_state.selected_dataset_knn

        # Cargar datos para la vista previa si cambia el dataset o si no se ha cargado
        if st.session_state.selected_dataset_knn != st.session_state.dataset_option_knn or st.session_state.knn_X is None:
            try:
                X, y, feature_names, class_names, info, task_type = load_data(
                    st.session_state.selected_dataset_knn)

                st.session_state.dataset_option_knn = st.session_state.selected_dataset_knn

                # Actualizar informaci√≥n del dataset
                st.session_state.knn_dataset = st.session_state.selected_dataset_knn
                st.session_state.knn_X = X
                st.session_state.knn_y = y
                st.session_state.knn_feature_names = feature_names
                st.session_state.knn_class_names = class_names
                st.session_state.knn_task_type = task_type

                # Mostrar informaci√≥n del dataset
                st.markdown("### Informaci√≥n del Dataset")
                from utils import create_info_box
                st.markdown(create_info_box(info), unsafe_allow_html=True)

            except Exception as e:
                st.error(f"Error al cargar el dataset: {str(e)}")

        # Verificar que los datos est√©n disponibles
        if st.session_state.knn_X is not None and st.session_state.knn_y is not None:
            st.markdown("### Par√°metros del Modelo")
            st.markdown("Configura los hiperpar√°metros del modelo KNN:")

            col1, col2, col3 = st.columns(3)
            with col1:
                n_neighbors = st.number_input(
                    "Vecinos (K)", min_value=1, max_value=20, value=5, step=1, key="knn_n_neighbors")
            with col2:
                weights = st.selectbox(
                    "Pesos", options=["uniform", "distance"], key="knn_weights")
            with col3:
                metric = st.selectbox("M√©trica", options=[
                                      "minkowski", "euclidean", "manhattan"], key="knn_metric")

            if st.button("üöÄ Entrenar Modelo KNN", key="train_knn_button", type="primary"):
                with st.spinner("Entrenando modelo..."):
                    try:
                        result = train_knn_model(
                            st.session_state.knn_X,
                            st.session_state.knn_y,
                            task_type=st.session_state.knn_task_type,
                            n_neighbors=n_neighbors,
                            weights=weights,
                            metric=metric
                        )
                        st.session_state.knn_model = result["model"]
                        st.session_state.knn_metrics = result["evaluation"]
                        st.session_state.knn_trained = True
                        st.success("¬°Modelo KNN entrenado correctamente!")

                        # Sugerir ir a la pesta√±a de evaluaci√≥n
                        st.info(
                            "üëâ Ve a la pesta√±a 'üìà Evaluaci√≥n' para ver los resultados del modelo.")

                    except Exception as e:
                        st.error(f"Error al entrenar el modelo: {str(e)}")
        else:
            st.info("Primero selecciona y carga un dataset en la pesta√±a de Datos.")

    # Pesta√±a 2: Evaluaci√≥n
    elif tab == 2:
        st.header("üìà Evaluaci√≥n del Modelo KNN")
        if st.session_state.knn_trained and st.session_state.knn_metrics is not None:
            # Obtener las predicciones del modelo
            if hasattr(st.session_state, 'knn_X') and hasattr(st.session_state, 'knn_y'):
                from sklearn.model_selection import train_test_split

                # Recrear el split de entrenamiento/prueba con los mismos par√°metros
                X_train, X_test, y_train, y_test = train_test_split(
                    st.session_state.knn_X,
                    st.session_state.knn_y,
                    test_size=0.3,
                    random_state=42
                )

                # Obtener las predicciones
                y_pred = st.session_state.knn_model.predict(X_test)

                # Mostrar evaluaci√≥n detallada del modelo usando la misma funci√≥n que otros algoritmos
                show_detailed_evaluation(
                    y_test,
                    y_pred,
                    st.session_state.knn_class_names if st.session_state.knn_task_type == "Clasificaci√≥n" else None,
                    st.session_state.knn_task_type
                )
            else:
                st.error(
                    "No se encontraron los datos necesarios para la evaluaci√≥n.")
        else:
            st.info("Primero entrena un modelo KNN.")

    # Pesta√±a 3: Visualizaci√≥n
    elif tab == 3:
        st.header("üìâ Visualizaci√≥n de KNN")
        if st.session_state.knn_trained and st.session_state.knn_model is not None:
            X = st.session_state.knn_X
            y = st.session_state.knn_y
            model = st.session_state.knn_model
            feature_names = st.session_state.knn_feature_names
            task_type = st.session_state.knn_task_type

            st.markdown("### Opciones de Visualizaci√≥n")

            # Selector de tipo de visualizaci√≥n
            viz_options = []

            # Siempre disponible: Distribuci√≥n de predicciones
            viz_options.append("üìä Distribuci√≥n de Predicciones")

            # Si hay al menos 2 caracter√≠sticas: Frontera de decisi√≥n/superficie
            if X.shape[1] >= 2:
                if task_type == "Clasificaci√≥n":
                    viz_options.append("üéØ Frontera de Decisi√≥n")
                    viz_options.append("üéÆ Visualizaci√≥n Interactiva")
                else:
                    viz_options.append("üèîÔ∏è Superficie de Predicci√≥n")

            # Si es clasificaci√≥n: Matriz de distancias
            if task_type == "Clasificaci√≥n":
                viz_options.append("üìè An√°lisis de Distancias")

            viz_type = st.selectbox("Tipo de visualizaci√≥n:", viz_options)

            if viz_type == "üìä Distribuci√≥n de Predicciones":
                # Recrear el split para obtener predicciones
                from sklearn.model_selection import train_test_split
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.3, random_state=42
                )
                y_pred = model.predict(X_test)

                if task_type == "Clasificaci√≥n":
                    # Mostrar distribuci√≥n de clases predichas vs reales
                    import pandas as pd

                    col1, col2 = st.columns(2)

                    with col1:
                        st.markdown("#### Distribuci√≥n Real")
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        real_counts = pd.Series(
                            y_test).value_counts().sort_index()
                        ax1.bar(range(len(real_counts)),
                                real_counts.values, alpha=0.7, color='skyblue')
                        ax1.set_xlabel('Clase')
                        ax1.set_ylabel('Frecuencia')
                        ax1.set_title('Distribuci√≥n Real')
                        if st.session_state.knn_class_names:
                            ax1.set_xticks(range(len(real_counts)))
                            ax1.set_xticklabels(
                                [st.session_state.knn_class_names[i] for i in real_counts.index], rotation=45)
                        st.pyplot(fig1)

                    with col2:
                        st.markdown("#### Distribuci√≥n Predicha")
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        pred_counts = pd.Series(
                            y_pred).value_counts().sort_index()
                        ax2.bar(range(len(pred_counts)), pred_counts.values,
                                alpha=0.7, color='lightcoral')
                        ax2.set_xlabel('Clase')
                        ax2.set_ylabel('Frecuencia')
                        ax2.set_title('Distribuci√≥n Predicha')
                        if st.session_state.knn_class_names:
                            ax2.set_xticks(range(len(pred_counts)))
                            ax2.set_xticklabels(
                                [st.session_state.knn_class_names[i] for i in pred_counts.index], rotation=45)
                        st.pyplot(fig2)

                else:  # Regresi√≥n
                    col1, col2 = st.columns(2)

                    with col1:
                        st.markdown("#### Valores Reales vs Predichos")
                        fig1, ax1 = plt.subplots(figsize=(6, 5))
                        ax1.scatter(y_test, y_pred, alpha=0.6)
                        ax1.plot([y_test.min(), y_test.max()], [
                                 y_test.min(), y_test.max()], 'r--', lw=2)
                        ax1.set_xlabel('Valores Reales')
                        ax1.set_ylabel('Valores Predichos')
                        ax1.set_title('Predicciones vs Realidad')
                        st.pyplot(fig1)

                    with col2:
                        st.markdown("#### Distribuci√≥n de Errores")
                        fig2, ax2 = plt.subplots(figsize=(6, 5))
                        errors = y_test - y_pred
                        ax2.hist(errors, bins=20, alpha=0.7,
                                 color='lightgreen', edgecolor='black')
                        ax2.axvline(x=0, color='red',
                                    linestyle='--', linewidth=2)
                        ax2.set_xlabel('Error (Real - Predicho)')
                        ax2.set_ylabel('Frecuencia')
                        ax2.set_title('Distribuci√≥n de Errores')
                        st.pyplot(fig2)

            elif viz_type in ["üéØ Frontera de Decisi√≥n", "üèîÔ∏è Superficie de Predicci√≥n"]:
                st.markdown("### Selecci√≥n de Caracter√≠sticas")
                st.markdown("Selecciona 2 caracter√≠sticas para visualizar:")

                col1, col2 = st.columns(2)

                with col1:
                    feature1 = st.selectbox(
                        "Primera caracter√≠stica:",
                        feature_names,
                        index=0,
                        key="viz_feature1"
                    )

                with col2:
                    feature2 = st.selectbox(
                        "Segunda caracter√≠stica:",
                        feature_names,
                        index=min(1, len(feature_names) - 1),
                        key="viz_feature2"
                    )

                if feature1 != feature2:
                    # Obtener √≠ndices de las caracter√≠sticas seleccionadas
                    feature_idx = [feature_names.index(
                        feature1), feature_names.index(feature2)]

                    # Extraer las caracter√≠sticas seleccionadas
                    if hasattr(X, 'iloc'):  # DataFrame
                        X_2d = X.iloc[:, feature_idx].values
                    else:  # numpy array
                        X_2d = X[:, feature_idx]

                    # Entrenar un modelo KNN con solo estas 2 caracter√≠sticas
                    from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor

                    if task_type == "Clasificaci√≥n":
                        model_2d = KNeighborsClassifier(
                            n_neighbors=model.n_neighbors,
                            weights=model.weights,
                            metric=model.metric
                        )
                    else:
                        model_2d = KNeighborsRegressor(
                            n_neighbors=model.n_neighbors,
                            weights=model.weights,
                            metric=model.metric
                        )

                    model_2d.fit(X_2d, y)

                    # Crear la visualizaci√≥n
                    fig, ax = plt.subplots(figsize=(10, 8))

                    # Crear malla de puntos
                    h = 0.02
                    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1
                    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1
                    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                                         np.arange(y_min, y_max, h))

                    # Predecir en la malla
                    Z = model_2d.predict(np.c_[xx.ravel(), yy.ravel()])
                    Z = Z.reshape(xx.shape)

                    if task_type == "Clasificaci√≥n":
                        # Frontera de decisi√≥n para clasificaci√≥n
                        n_classes = len(np.unique(y))

                        # Usar diferentes mapas de colores seg√∫n el n√∫mero de clases
                        if n_classes == 2:
                            contour = ax.contourf(
                                xx, yy, Z, alpha=0.3, cmap='RdBu', levels=50)
                            scatter_cmap = 'RdBu'
                        else:
                            contour = ax.contourf(
                                xx, yy, Z, alpha=0.3, cmap='Set3', levels=n_classes)
                            scatter_cmap = 'Set3'

                        # Scatter plot de los datos
                        scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y,
                                             cmap=scatter_cmap, edgecolor='black', s=50, alpha=0.8)

                        # Leyenda para clasificaci√≥n
                        if st.session_state.knn_class_names and n_classes <= 10:
                            import matplotlib.patches as mpatches
                            if n_classes == 2:
                                colors = ['#d7191c', '#2c7bb6']  # RdBu colors
                            else:
                                colors = plt.cm.Set3(
                                    np.linspace(0, 1, n_classes))

                            patches = [mpatches.Patch(color=colors[i],
                                                      label=st.session_state.knn_class_names[i])
                                       for i in range(min(len(st.session_state.knn_class_names), n_classes))]
                            ax.legend(handles=patches,
                                      loc='best', title='Clases')

                        ax.set_title(
                            f'Frontera de Decisi√≥n KNN (K={model.n_neighbors})')

                    else:
                        # Superficie de predicci√≥n para regresi√≥n
                        contour = ax.contourf(
                            xx, yy, Z, alpha=0.6, cmap='viridis', levels=20)
                        scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y,
                                             cmap='viridis', edgecolor='black', s=50, alpha=0.8)

                        # Barra de colores
                        cbar = plt.colorbar(scatter, ax=ax, shrink=0.8)
                        cbar.set_label('Valor Objetivo')

                        ax.set_title(
                            f'Superficie de Predicci√≥n KNN (K={model.n_neighbors})')

                    ax.set_xlabel(feature1)
                    ax.set_ylabel(feature2)
                    ax.grid(True, alpha=0.3)

                    st.pyplot(fig)

                    # Informaci√≥n adicional
                    st.info(f"""
                    üîç **Informaci√≥n de la visualizaci√≥n:**
                    - **Caracter√≠sticas:** {feature1} vs {feature2}
                    - **N√∫mero de vecinos (K):** {model.n_neighbors}
                    - **Tipo de peso:** {model.weights}
                    - **M√©trica de distancia:** {model.metric}
                    - **Tipo de tarea:** {task_type}
                    """)

                else:
                    st.warning(
                        "Por favor selecciona dos caracter√≠sticas diferentes.")

            elif viz_type == "üéÆ Visualizaci√≥n Interactiva":
                st.markdown("### Visualizaci√≥n Interactiva de KNN")
                st.markdown(
                    "Explora c√≥mo el algoritmo KNN toma decisiones en tiempo real")

                # Importar las funciones necesarias
                import plotly.graph_objects as go
                import plotly.express as px
                from plotly.subplots import make_subplots

                # Selecci√≥n de caracter√≠sticas para la visualizaci√≥n
                col1, col2 = st.columns(2)

                with col1:
                    feature1 = st.selectbox(
                        "Primera caracter√≠stica:",
                        feature_names,
                        index=0,
                        key="interactive_feature1"
                    )

                with col2:
                    feature2 = st.selectbox(
                        "Segunda caracter√≠stica:",
                        feature_names,
                        index=min(1, len(feature_names) - 1),
                        key="interactive_feature2"
                    )

                if feature1 != feature2:
                    # Obtener √≠ndices de caracter√≠sticas
                    feature_idx = [feature_names.index(
                        feature1), feature_names.index(feature2)]

                    # Extraer datos para 2D
                    if hasattr(X, 'iloc'):
                        X_2d = X.iloc[:, feature_idx].values
                    else:
                        X_2d = X[:, feature_idx]

                    # Inicializar puntos de prueba en session_state si no existen
                    if 'test_points' not in st.session_state:
                        st.session_state.test_points = []

                    # Crear visualizaci√≥n interactiva (con controles integrados)
                    create_interactive_knn_visualization(
                        X_2d, y, model,
                        feature1, feature2,
                        st.session_state.knn_class_names,
                        True, True  # show_confidence, animate_distances por defecto
                    )

                else:
                    st.warning(
                        "Por favor selecciona dos caracter√≠sticas diferentes.")

            elif viz_type == "üìè An√°lisis de Distancias":
                st.markdown("### An√°lisis de Distancias entre Clases")

                # Calcular distancias promedio entre clases
                from sklearn.metrics.pairwise import pairwise_distances

                # Recrear el split para an√°lisis
                from sklearn.model_selection import train_test_split
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.3, random_state=42
                )

                classes = np.unique(y_train)
                n_classes = len(classes)

                if n_classes > 1:
                    # Matriz de distancias promedio entre clases
                    dist_matrix = np.zeros((n_classes, n_classes))

                    for i, class1 in enumerate(classes):
                        for j, class2 in enumerate(classes):
                            if i != j:
                                X_class1 = X_train[y_train == class1]
                                X_class2 = X_train[y_train == class2]

                                # Calcular distancia promedio entre las dos clases
                                distances = pairwise_distances(
                                    X_class1, X_class2, metric=model.metric)
                                dist_matrix[i, j] = np.mean(distances)

                    # Visualizar matriz de distancias
                    fig, ax = plt.subplots(figsize=(8, 6))
                    im = ax.imshow(dist_matrix, cmap='viridis', aspect='auto')

                    # A√±adir valores a las celdas
                    for i in range(n_classes):
                        for j in range(n_classes):
                            if i != j:
                                text = ax.text(j, i, f'{dist_matrix[i, j]:.2f}',
                                               ha="center", va="center", color="white")

                    # Configurar etiquetas
                    if st.session_state.knn_class_names:
                        class_labels = [
                            st.session_state.knn_class_names[int(c)] for c in classes]
                    else:
                        class_labels = [f'Clase {int(c)}' for c in classes]

                    ax.set_xticks(range(n_classes))
                    ax.set_yticks(range(n_classes))
                    ax.set_xticklabels(class_labels, rotation=45)
                    ax.set_yticklabels(class_labels)
                    ax.set_title(
                        f'Distancias Promedio entre Clases\n(M√©trica: {model.metric})')

                    plt.colorbar(im, ax=ax, label='Distancia Promedio')
                    plt.tight_layout()
                    st.pyplot(fig)

                    # An√°lisis de separabilidad
                    min_dist = np.min(dist_matrix[dist_matrix > 0])
                    max_dist = np.max(dist_matrix)

                    st.markdown("### An√°lisis de Separabilidad")
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("Distancia M√≠nima", f"{min_dist:.3f}")
                    with col2:
                        st.metric("Distancia M√°xima", f"{max_dist:.3f}")
                    with col3:
                        ratio = max_dist / min_dist if min_dist > 0 else 0
                        st.metric("Ratio Max/Min", f"{ratio:.2f}")

                    if ratio > 5:
                        st.success(
                            "üü¢ Las clases est√°n bien separadas (ratio > 5)")
                    elif ratio > 2:
                        st.warning(
                            "üü° Separaci√≥n moderada entre clases (2 < ratio ‚â§ 5)")
                    else:
                        st.error("üî¥ Las clases est√°n muy pr√≥ximas (ratio ‚â§ 2)")
                else:
                    st.info(
                        "Se necesitan al menos 2 clases para el an√°lisis de distancias.")

        else:
            st.info("Primero entrena un modelo KNN.")

    # Pesta√±a 4: Predicciones
    elif tab == 4:
        st.header("üîÆ Predicciones con KNN")
        if st.session_state.knn_trained and st.session_state.knn_model is not None:
            create_prediction_interface(
                st.session_state.knn_model,
                st.session_state.knn_feature_names,
                st.session_state.knn_class_names,
                st.session_state.knn_task_type,
                st.session_state.knn_X,
                st.session_state.knn_dataset
            )
        else:
            st.info("Primero entrena un modelo KNN.")


#!/usr/bin/env python3
"""
MLTutor: Plataforma educativa para el aprendizaje de Machine Learning.
"""


# Importar m√≥dulos refactorizados


def main():
    """Funci√≥n principal que ejecuta la aplicaci√≥n MLTutor."""
    # Configuraci√≥n de la p√°gina
    setup_page()

    # Inicializar estado de la sesi√≥n
    init_session_state()

    # Configurar navegaci√≥n principal con botones en lugar de radio
    st.sidebar.markdown("### Navegaci√≥n:")

    # Estilo para los botones de navegaci√≥n
    button_style = """
    <style>
    div.stButton > button {
        width: 100%;
        text-align: left;
        padding: 10px;
        margin-bottom: 5px;
        border-radius: 5px;
        font-weight: normal;
    }
    div.stButton > button:hover {
        background-color: #E3F2FD;
        border-color: #90CAF9;
    }
    </style>
    """
    st.sidebar.markdown(button_style, unsafe_allow_html=True)

    # Crear los botones de navegaci√≥n
    if st.sidebar.button("üè† Inicio",
                         key="nav_home",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üè† Inicio" else "primary"):
        st.session_state.navigation = "üè† Inicio"
        st.rerun()

    if st.sidebar.button("üå≤ √Årboles de Decisi√≥n",
                         key="nav_trees",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üå≤ √Årboles de Decisi√≥n" else "primary"):
        st.session_state.navigation = "üå≤ √Årboles de Decisi√≥n"
        st.rerun()

    if st.sidebar.button("üìä Regresi√≥n",
                         key="nav_linear",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üìä Regresi√≥n" else "primary"):
        st.session_state.navigation = "üìä Regresi√≥n"
        st.rerun()

    if st.sidebar.button("üîç K-Nearest Neighbors",
                         key="nav_knn",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üîç K-Nearest Neighbors" else "primary"):
        st.session_state.navigation = "üîç K-Nearest Neighbors"
        st.rerun()

    if st.sidebar.button("üß† Redes Neuronales",
                         key="nav_nn",
                         use_container_width=True,
                         type="primary" if st.session_state.navigation == "üß† Redes Neuronales" else "secondary"):
        st.session_state.navigation = "üß† Redes Neuronales"
        st.rerun()

    # Separador
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üîß Herramientas:")

    if st.sidebar.button("üìÅ Cargar CSV Personalizado",
                         key="nav_csv",
                         use_container_width=True):
        st.session_state.navigation = "üìÅ Cargar CSV Personalizado"
        st.rerun()

    # P√°gina de inicio
    if st.session_state.navigation == "üè† Inicio":
        show_welcome_page()
        return

    # P√°ginas de algoritmos
    if st.session_state.navigation == "üå≤ √Årboles de Decisi√≥n":
        run_decision_trees_app()
    elif st.session_state.navigation == "üìä Regresi√≥n":
        run_linear_regression_app()
    elif st.session_state.navigation == "üîç K-Nearest Neighbors":
        run_knn_app()
    elif st.session_state.navigation == "üß† Redes Neuronales":
        run_neural_networks_app()
    elif st.session_state.navigation == "üìÅ Cargar CSV Personalizado":
        run_csv_loader_app()
    elif st.session_state.navigation in ["üß† Redes Neuronales (pr√≥ximamente)"]:
        algorithm_name = st.session_state.navigation.split(" ")[1]
        st.header(f"{algorithm_name} (pr√≥ximamente)")
        st.info(
            f"La funcionalidad de {algorithm_name} estar√° disponible pr√≥ximamente. Por ahora, puedes explorar los √Årboles de Decisi√≥n.")

        # Mostrar una imagen ilustrativa seg√∫n el algoritmo
        if "Regresi√≥n Log√≠stica" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_logistic_001.png",
                     caption="Ilustraci√≥n de Regresi√≥n Log√≠stica")
        elif "K-Nearest Neighbors" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_classification_001.png",
                     caption="Ilustraci√≥n de K-Nearest Neighbors")
        elif "Redes Neuronales" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_mlp_001.png",
                     caption="Ilustraci√≥n de Redes Neuronales")


def run_decision_trees_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de √°rboles de decisi√≥n."""
    st.header("üå≤ √Årboles de Decisi√≥n")
    st.markdown("Aprende sobre los √°rboles de decisi√≥n de forma interactiva")

    # Informaci√≥n sobre √°rboles de decisi√≥n
    with st.expander("‚ÑπÔ∏è ¬øQu√© son los √Årboles de Decisi√≥n?", expanded=False):
        st.markdown("""
        Los √°rboles de decisi√≥n son algoritmos de aprendizaje supervisado que se pueden usar tanto para tareas de clasificaci√≥n como de regresi√≥n.

        **Caracter√≠sticas principales:**
        - Funcionan dividiendo el conjunto de datos en subconjuntos m√°s peque√±os bas√°ndose en condiciones sobre las caracter√≠sticas
        - Son f√°ciles de interpretar y visualizar
        - Pueden manejar tanto datos num√©ricos como categ√≥ricos
        - No requieren escalado de datos

        **Limitaciones:**
        - Pueden sobreajustarse f√°cilmente (esto se puede controlar con par√°metros como max_depth)
        - Pueden ser inestables (peque√±os cambios en los datos pueden generar √°rboles muy diferentes)
        - No son tan precisos como algoritmos m√°s complejos para algunas tareas

        Experimenta con diferentes configuraciones para ver c√≥mo afectan al rendimiento del modelo.
        """)

    # Variables para almacenar datos
    dataset_loaded = False
    X, y, feature_names, class_names, dataset_info, task_type = None, None, None, None, None, None

    # Inicializar el estado de la pesta√±a activa si no existe
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = 0

    # Crear pesta√±as para organizar la informaci√≥n
    tab_options = [
        "üìä Datos",
        "üèãÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üå≤ Visualizaci√≥n",
        "üîç Caracter√≠sticas",
        "üîÆ Predicciones",
        "üíæ Exportar Modelo"
    ]

    # Crear contenedor para los botones de las pesta√±as
    tab_cols = st.columns(len(tab_options))

    # Estilo CSS para los botones de pesta√±as (Decision Trees)
    st.markdown("""
    <style>
    div.tab-button-dt > button {
        border-radius: 4px 4px 0 0;
        padding: 10px;
        width: 100%;
        white-space: nowrap;
        background-color: #F0F2F6;
        border-bottom: 2px solid #E0E0E0;
        color: #333333;
    }
    div.tab-button-dt-active > button {
        background-color: #E3F2FD !important;
        border-bottom: 2px solid #1E88E5 !important;
        font-weight: bold !important;
        color: #1E88E5 !important;
    }
    div.tab-button-dt > button:hover {
        background-color: #E8EAF6;
    }
    </style>
    """, unsafe_allow_html=True)

    # Crear botones para las pesta√±as
    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_{i}"
        button_style = "tab-button-dt-active" if st.session_state.active_tab == i else "tab-button-dt"

    # Crear botones para las pesta√±as
    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_{i}"
        button_style = "tab-button-dt-active" if st.session_state.active_tab == i else "tab-button-dt"
        is_active = st.session_state.active_tab == i

        with col:
            st.markdown(f"<div class='{button_style}'>",
                        unsafe_allow_html=True)
            # Usar type="primary" para el bot√≥n activo
            if st.button(tab_name, key=button_key, use_container_width=True,
                         type="primary" if is_active else "secondary"):
                st.session_state.active_tab = i
                st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    # Separador visual
    st.markdown("---")

    # SELECTOR UNIFICADO DE DATASET (solo mostrar en pesta√±as que lo necesiten)
    if st.session_state.active_tab in [0, 1]:  # Exploraci√≥n y Entrenamiento
        st.markdown("### üìä Selecci√≥n de Dataset")

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset' not in st.session_state:
            st.session_state.selected_dataset = "üå∏ Iris - Clasificaci√≥n de flores"

        # Lista base de datasets predefinidos
        builtin_datasets = [
            "üå∏ Iris - Clasificaci√≥n de flores",
            "üç∑ Vino - Clasificaci√≥n de vinos",
            "üî¨ C√°ncer - Diagn√≥stico binario",
            "üö¢ Titanic - Supervivencia",
            "üí∞ Propinas - Predicci√≥n de propinas",
            "üè† Viviendas California - Precios",
            "üêß Ping√ºinos - Clasificaci√≥n de especies"
        ]

        # A√±adir datasets CSV cargados si existen
        available_datasets = builtin_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado est√© en la lista disponible
        if st.session_state.selected_dataset not in available_datasets:
            st.session_state.selected_dataset = builtin_datasets[0]

        # Selector unificado
        dataset_option = st.selectbox(
            "Dataset:",
            available_datasets,
            index=available_datasets.index(st.session_state.selected_dataset),
            key="unified_dataset_selector",
            help="El dataset seleccionado se mantendr√° entre las pesta√±as de Exploraci√≥n y Entrenamiento"
        )

        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset = dataset_option

        # Separador despu√©s del selector
        st.markdown("---")
    else:
        # Para otras pesta√±as, mostrar qu√© dataset est√° seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset'):
            st.info(
                f"üìä **Dataset actual:** {st.session_state.selected_dataset}")
            st.markdown("---")

    # Pesta√±a de Datos
    if st.session_state.active_tab == 0:
        st.header("Exploraci√≥n de Datos")

        try:
            # Cargar datos para exploraci√≥n
            X, y, feature_names, class_names, dataset_info, task_type = load_data(
                st.session_state.selected_dataset)

            # Convertir a DataFrames para facilitar el manejo
            # FIXED: No sobrescribir las columnas si X ya es DataFrame para evitar NaN
            if isinstance(X, pd.DataFrame):
                X_df = X.copy()  # Usar las columnas originales
                # Crear mapeo de nombres para mostrar
                column_mapping = {}
                if len(feature_names) == len(X_df.columns):
                    column_mapping = dict(zip(X_df.columns, feature_names))
            else:
                X_df = pd.DataFrame(X, columns=feature_names)
                column_mapping = {}

            y_df = pd.Series(y, name="target")

            # Mapear nombres de clases si est√°n disponibles
            if task_type == "Clasificaci√≥n" and class_names is not None:
                y_df = y_df.map(
                    {i: name for i, name in enumerate(class_names)})

            df = pd.concat([X_df, y_df], axis=1)

            # Renombrar columnas para mostrar nombres amigables si existe el mapeo
            if column_mapping:
                df_display = df.rename(columns=column_mapping)
            else:
                df_display = df

            # Mostrar informaci√≥n del dataset
            st.markdown("### Informaci√≥n del Dataset")
            st.markdown(create_info_box(dataset_info), unsafe_allow_html=True)

            # Mostrar las primeras filas de los datos
            st.markdown("### Vista previa de datos")
            st.dataframe(df_display.head(10))

            # Estad√≠sticas descriptivas
            st.markdown("### Estad√≠sticas Descriptivas")
            st.dataframe(df_display.describe())

            # Distribuci√≥n de clases o valores objetivo
            st.markdown("### Distribuci√≥n del Objetivo")

            fig, ax = plt.subplots(figsize=(10, 6))

            if task_type == "Clasificaci√≥n":
                # Gr√°fico de barras para clasificaci√≥n
                value_counts = y_df.value_counts().sort_index()
                sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
                ax.set_title("Distribuci√≥n de Clases")
                ax.set_xlabel("Clase")
                ax.set_ylabel("Cantidad")

                # Rotar etiquetas si son muchas
                if len(value_counts) > 3:
                    plt.xticks(rotation=45, ha='right')
            else:
                # Histograma para regresi√≥n
                # Convertir a num√©rico en caso de que sean strings
                y_numeric = pd.to_numeric(y_df, errors='coerce')
                # Usar matplotlib directamente para evitar problemas de tipo
                ax.hist(y_numeric.dropna(), bins=30,
                        alpha=0.7, edgecolor='black')
                ax.set_title("Distribuci√≥n de Valores Objetivo")
                ax.set_xlabel("Valor")
                ax.set_ylabel("Frecuencia")

            # Mostrar la figura con tama√±o reducido pero expandible
            col1, col2, col3 = st.columns([1, 3, 1])
            with col2:
                st.pyplot(fig, use_container_width=True)

            # An√°lisis de correlaci√≥n
            st.markdown("### Matriz de Correlaci√≥n")

            # Matriz de correlaci√≥n
            corr = X_df.corr()

            # Generar m√°scara para el tri√°ngulo superior
            mask = np.triu(np.ones_like(corr, dtype=bool))

            # Generar mapa de calor
            fig_corr, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
                        square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
            ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

            # Mostrar la figura con tama√±o reducido pero expandible
            col1, col2, col3 = st.columns([1, 3, 1])
            with col2:
                st.pyplot(fig_corr, use_container_width=True)

            # Matriz de dispersi√≥n (Scatterplot Matrix)
            st.markdown("### Matriz de Dispersi√≥n (Pairplot)")

            # Opciones de visualizaci√≥n
            st.markdown("#### Opciones de visualizaci√≥n")
            col1, col2 = st.columns(2)

            with col1:
                # Seleccionar tipo de gr√°fico para la diagonal
                diag_kind = st.radio(
                    "Tipo de gr√°fico en la diagonal:",
                    ["Histograma", "KDE (Estimaci√≥n de Densidad)"],
                    index=1,
                    horizontal=True
                )
                diag_kind = "hist" if diag_kind == "Histograma" else "kde"

            with col2:
                # Seleccionar n√∫mero m√°ximo de caracter√≠sticas
                max_features_selected = st.slider(
                    "N√∫mero m√°ximo de caracter√≠sticas:",
                    min_value=2,
                    max_value=min(6, len(X_df.columns)),
                    value=min(4, len(X_df.columns)),
                    help="Un n√∫mero mayor de caracter√≠sticas puede hacer que el gr√°fico sea m√°s dif√≠cil de interpretar."
                )

            # Permitir al usuario seleccionar las caracter√≠sticas espec√≠ficas
            st.markdown("#### Selecciona las caracter√≠sticas para visualizar")

            # Limitar a max_features_selected
            # Usar nombres amigables si est√°n disponibles, sino usar originales
            if column_mapping:
                available_features = list(
                    column_mapping.values())  # Nombres amigables
                display_to_original = {
                    v: k for k, v in column_mapping.items()}  # Mapeo inverso
            else:
                available_features = X_df.columns.tolist()
                display_to_original = {}

            # Usar multiselect para seleccionar caracter√≠sticas
            selected_features = st.multiselect(
                "Caracter√≠sticas a incluir en la matriz de dispersi√≥n:",
                available_features,
                default=available_features[:max_features_selected],
                max_selections=max_features_selected,
                help=f"Selecciona hasta {max_features_selected} caracter√≠sticas para incluir en la visualizaci√≥n."
            )

            # Si no se seleccion√≥ ninguna caracter√≠stica, usar las primeras por defecto
            if not selected_features:
                selected_features = available_features[:max_features_selected]
                st.info(
                    f"No se seleccionaron caracter√≠sticas. Usando las primeras {max_features_selected} por defecto.")

            # Convertir nombres amigables a nombres originales si es necesario
            if column_mapping:
                original_features = [display_to_original[feat]
                                     for feat in selected_features]
            else:
                original_features = selected_features

            # Crear el dataframe para la visualizaci√≥n
            plot_df = X_df[original_features].copy()
            # Renombrar a nombres amigables para visualizaci√≥n
            if column_mapping:
                plot_df = plot_df.rename(columns=column_mapping)
            # A√±adir la variable objetivo para colorear
            plot_df['target'] = y_df

            # Generar el pairplot
            with st.spinner("Generando matriz de dispersi√≥n..."):
                pair_plot = sns.pairplot(
                    plot_df,
                    hue='target',
                    diag_kind=diag_kind,
                    plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
                    diag_kws={'alpha': 0.5},
                    height=2.0  # Reducir altura para que sea m√°s compacto
                )
                pair_plot.fig.suptitle(
                    "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=14)

                # Mostrar la figura con tama√±o reducido pero expandible
                col1, col2, col3 = st.columns([1, 3, 1])
                with col2:
                    st.pyplot(pair_plot.fig, use_container_width=True)

                # Enlace para descargar
                st.markdown(
                    get_image_download_link(
                        pair_plot.fig, "matriz_dispersion", "üì• Descargar matriz de dispersi√≥n"),
                    unsafe_allow_html=True
                )

            # Generar c√≥digo para este an√°lisis
            code = """
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar tus datos (reemplaza esto con tu m√©todo de carga)
# df = pd.read_csv('tu_archivo.csv')

# Separar caracter√≠sticas y objetivo
X = df.iloc[:, :-1]  # Todas las columnas excepto la √∫ltima
y = df.iloc[:, -1]   # √öltima columna como objetivo

# Estad√≠sticas descriptivas
print(df.describe())

# Distribuci√≥n del objetivo
fig, ax = plt.subplots(figsize=(10, 6))

# Para clasificaci√≥n:
if len(np.unique(y)) <= 10:  # Si hay pocas clases √∫nicas
    value_counts = y.value_counts().sort_index()
    sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
    ax.set_title("Distribuci√≥n de Clases")
    ax.set_xlabel("Clase")
    ax.set_ylabel("Cantidad")
else:  # Para regresi√≥n
    sns.histplot(y, kde=True, ax=ax)
    ax.set_title("Distribuci√≥n de Valores Objetivo")
    ax.set_xlabel("Valor")
    ax.set_ylabel("Frecuencia")

plt.tight_layout()
plt.show()

# Matriz de correlaci√≥n
corr = X.corr()
# M√°scara para tri√°ngulo superior
mask = np.triu(np.ones_like(corr, dtype=bool))

fig, ax = plt.subplots(figsize=(12, 10))
sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
           square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

plt.tight_layout()
plt.show()

# Matriz de dispersi√≥n (Scatterplot Matrix)
# Seleccionar caracter√≠sticas espec√≠ficas para visualizar
# Reemplaza con tus caracter√≠sticas de inter√©s
selected_features = ['feature1', 'feature2', 'feature3']
max_features = min(6, len(selected_features))

# Crear el dataframe para la visualizaci√≥n
plot_df = X[selected_features].copy()
plot_df['target'] = y  # A√±adir la variable objetivo para colorear

# Generar el pairplot
pair_plot = sns.pairplot(
    plot_df,
    hue='target',
    diag_kind='kde',  # Opciones: 'hist' para histograma o 'kde' para densidad
    plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
    diag_kws={'alpha': 0.5},
    height=2.5
)
pair_plot.fig.suptitle(
    "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=16)
plt.tight_layout()
plt.show()
"""

            show_code_with_download(
                code, "C√≥digo para an√°lisis exploratorio", "analisis_exploratorio.py")

        except Exception as e:
            st.error(f"Error al cargar el dataset: {str(e)}")
            st.info(
                "Por favor, selecciona un dataset v√°lido para continuar con la exploraci√≥n.")

    # Pesta√±a de Entrenamiento
    elif st.session_state.active_tab == 1:
        st.header("Configuraci√≥n del Modelo")

        # Inicializar session state variables
        if 'dataset_option' not in st.session_state:
            st.session_state.dataset_option = st.session_state.selected_dataset
        if 'tree_type' not in st.session_state:
            st.session_state.tree_type = "Clasificaci√≥n"
        if 'is_trained' not in st.session_state:
            st.session_state.is_trained = False

        # Cargar datos para la vista previa si cambia el dataset o si no se ha cargado
        if st.session_state.selected_dataset != st.session_state.dataset_option or not dataset_loaded:
            try:
                X, y, feature_names, class_names, dataset_info, task_type = load_data(
                    st.session_state.selected_dataset)

                st.session_state.dataset_option = st.session_state.selected_dataset
                dataset_loaded = True

                # Mostrar informaci√≥n del dataset
                st.markdown("### Informaci√≥n del Dataset")
                st.markdown(create_info_box(dataset_info),
                            unsafe_allow_html=True)

                # Usar el tipo de tarea detectado por la funci√≥n load_data
                st.markdown("### Tipo de √Årbol de Decisi√≥n")

                # Usar botones en lugar de radio para seleccionar el tipo de √°rbol
                tipo_col1, tipo_col2 = st.columns(2)

                with tipo_col1:
                    is_classification = True
                    if "tree_type" in st.session_state:
                        is_classification = st.session_state.tree_type == "Clasificaci√≥n"

                    if st.button("üè∑Ô∏è Clasificaci√≥n",
                                 key="btn_classification",
                                 type="primary" if is_classification else "secondary",
                                 use_container_width=True,
                                 help="Para predecir categor√≠as o clases"):
                        tree_type = "Clasificaci√≥n"
                        st.session_state.tree_type = tree_type
                        st.rerun()

                with tipo_col2:
                    is_regression = False
                    if "tree_type" in st.session_state:
                        is_regression = st.session_state.tree_type == "Regresi√≥n"

                    if st.button("üìà Regresi√≥n",
                                 key="btn_regression",
                                 type="primary" if is_regression else "secondary",
                                 use_container_width=True,
                                 help="Para predecir valores num√©ricos continuos"):
                        tree_type = "Regresi√≥n"
                        st.session_state.tree_type = tree_type
                        st.rerun()

                # Obtener el valor actual del tipo de √°rbol
                tree_type = st.session_state.get('tree_type', task_type)

                # Si no hay tree_type definido, usar el detectado
                if 'tree_type' not in st.session_state:
                    st.session_state.tree_type = task_type

                # Mostrar advertencia si la selecci√≥n no coincide con el tipo de tarea detectado
                if tree_type != task_type:
                    st.warning(
                        f"Este dataset parece ser m√°s adecuado para {task_type}. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")

            except Exception as e:
                st.error(f"Error al cargar el dataset: {str(e)}")
                dataset_loaded = False

        # Par√°metros del modelo
        st.markdown("### Par√°metros del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            criterion = st.selectbox(
                "Criterio de Divisi√≥n:",
                ["gini", "entropy"] if st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" else [
                    "squared_error", "friedman_mse", "absolute_error"],
                index=0,
                help="Medida de la calidad de una divisi√≥n. Gini o Entropy para clasificaci√≥n, MSE para regresi√≥n."
            )

            max_depth = st.slider(
                "Profundidad M√°xima:",
                min_value=1,
                max_value=10,
                value=3,
                help="La profundidad m√°xima del √°rbol. A mayor profundidad, m√°s complejo el modelo."
            )

        with col2:
            min_samples_split = st.slider(
                "Muestras M√≠nimas para Divisi√≥n:",
                min_value=2,
                max_value=10,
                value=2,
                help="N√∫mero m√≠nimo de muestras para dividir un nodo."
            )

            test_size = st.slider(
                "Tama√±o del Conjunto de Prueba:",
                min_value=0.1,
                max_value=0.5,
                value=0.3,
                step=0.05,
                help="Proporci√≥n de datos que se usar√° para evaluar el modelo."
            )

        # Guardar par√°metros en el estado de la sesi√≥n
        st.session_state.criterion = criterion
        st.session_state.max_depth = max_depth
        st.session_state.min_samples_split = min_samples_split
        st.session_state.test_size = test_size

        # Bot√≥n para entrenar el modelo
        train_button = st.button("Entrenar Modelo", type="primary")

        if train_button:
            with st.spinner("Entrenando modelo..."):
                try:
                    # Cargar y preprocesar datos
                    X, y, feature_names, class_names, dataset_info, task_type = load_data(
                        st.session_state.selected_dataset)
                    X_train, X_test, y_train, y_test = preprocess_data(
                        X, y, test_size=test_size)

                    # Entrenar el modelo
                    model_results = train_decision_tree(
                        X_train, y_train,
                        criterion=criterion,
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        tree_type=tree_type
                    )

                    # Extraer el modelo del diccionario de resultados
                    tree_model = model_results["model"]

                    # Guardar en el estado de la sesi√≥n
                    st.session_state.tree_model = tree_model
                    st.session_state.X_train = X_train
                    st.session_state.X_test = X_test
                    st.session_state.y_train = y_train
                    st.session_state.y_test = y_test
                    st.session_state.feature_names = feature_names
                    st.session_state.class_names = class_names
                    st.session_state.dataset_info = dataset_info
                    st.session_state.is_trained = True

                    # Evaluar el modelo
                    if tree_type == "Clasificaci√≥n":
                        # Obtener predicciones del modelo
                        y_pred = tree_model.predict(X_test)
                        st.session_state.test_results = evaluate_classification_model(
                            y_test, y_pred, class_names
                        )
                    else:
                        # Obtener predicciones del modelo
                        y_pred = tree_model.predict(X_test)
                        st.session_state.test_results = evaluate_regression_model(
                            y_test, y_pred
                        )

                    st.success(
                        "¬°Modelo entrenado con √©xito! Ahora puedes explorar las otras pesta√±as.")

                    # Sugerir ir a la pesta√±a de visualizaci√≥n
                    st.info(
                        "üëâ Ve a la pesta√±a 'üå≤ Visualizaci√≥n' para ver el √°rbol generado.")

                except Exception as e:
                    st.error(f"Error al entrenar el modelo: {str(e)}")

    # Pesta√±a de Evaluaci√≥n
    elif st.session_state.active_tab == 2:
        st.header("Evaluaci√≥n del Modelo")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Obtener predicciones del modelo
            y_pred = st.session_state.tree_model.predict(
                st.session_state.X_test)

            # Mostrar evaluaci√≥n detallada del modelo
            show_detailed_evaluation(
                st.session_state.y_test,
                y_pred,
                st.session_state.class_names if st.session_state.get(
                    'tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" else None,
                st.session_state.get('tree_type', 'Clasificaci√≥n')
            )

            # Decisi√≥n boundary si es clasificaci√≥n y tiene 2 caracter√≠sticas
            if st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" and st.session_state.X_train.shape[1] <= 2:
                st.markdown("### Frontera de Decisi√≥n")

                if st.session_state.X_train.shape[1] == 1:
                    # Caso especial: solo una caracter√≠stica - agregar una segunda artificial
                    if hasattr(st.session_state.X_train, 'values'):
                        # DataFrame
                        X_values = st.session_state.X_train.values
                    else:
                        # numpy array
                        X_values = st.session_state.X_train
                    X_plot = np.column_stack(
                        [X_values, np.zeros_like(X_values)])
                    feature_idx = [0]
                    feature_names_plot = [
                        st.session_state.feature_names[0], "Caracter√≠stica artificial"]
                else:
                    # Dos caracter√≠sticas - dejar seleccionar cu√°les usar
                    st.markdown(
                        "Selecciona las caracter√≠sticas para visualizar la frontera de decisi√≥n:")
                    col1, col2 = st.columns(2)

                    with col1:
                        feature1 = st.selectbox(
                            "Primera caracter√≠stica:",
                            st.session_state.feature_names,
                            index=0
                        )

                    with col2:
                        feature2 = st.selectbox(
                            "Segunda caracter√≠stica:",
                            st.session_state.feature_names,
                            index=min(
                                1, len(st.session_state.feature_names) - 1)
                        )

                    feature_idx = [st.session_state.feature_names.index(feature1),
                                   st.session_state.feature_names.index(feature2)]

                    # Manejar DataFrame vs numpy array
                    if hasattr(st.session_state.X_train, 'iloc'):
                        # DataFrame
                        X_plot = st.session_state.X_train.iloc[:,
                                                               feature_idx].values
                    else:
                        # numpy array
                        X_plot = st.session_state.X_train[:, feature_idx]
                    feature_names_plot = [feature1, feature2]

                # Generar y mostrar el plot en tama√±o reducido
                try:
                    fig, ax = plot_decision_boundary(
                        st.session_state.tree_model,
                        X_plot,
                        st.session_state.y_train,
                        feature_names=feature_names_plot,
                        class_names=st.session_state.class_names
                    )

                    # Mostrar en columnas para reducir el tama√±o al 75%
                    col1, col2, col3 = st.columns([1, 3, 1])
                    with col2:
                        # Mostrar la figura directamente
                        plt.tight_layout()
                        st.pyplot(fig, clear_figure=True,
                                  use_container_width=True)

                    # Enlace para descargar
                    st.markdown(
                        get_image_download_link(
                            fig, "frontera_decision", "üì• Descargar visualizaci√≥n de la frontera"),
                        unsafe_allow_html=True
                    )
                except Exception as e:
                    st.error(
                        f"Error al mostrar la visualizaci√≥n de frontera de decisi√≥n: {str(e)}")
                    st.info(
                        "La frontera de decisi√≥n requiere exactamente 2 caracter√≠sticas para visualizarse.")

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_boundary = """
import numpy as np
import matplotlib.pyplot as plt
from sklearn.inspection import DecisionBoundaryDisplay

def plot_decision_boundary(model, X, y, feature_names=None, class_names=None):
    \"\"\"
    Visualiza la frontera de decisi√≥n para un modelo con 2 caracter√≠sticas.

    Parameters:
    -----------
    model : Modelo de scikit-learn
        Modelo entrenado con m√©todo predict
    X : array-like
        Datos de caracter√≠sticas (solo se usan las primeras 2 columnas)
    y : array-like
        Etiquetas de clase
    feature_names : list, opcional
        Nombres de las caracter√≠sticas
    class_names : list, opcional
        Nombres de las clases

    Returns:
    --------
    fig : Figura de matplotlib
    \"\"\"
    # Asegurar que solo usamos 2 caracter√≠sticas
    X_plot = X[:, :2] if X.shape[1] > 2 else X

    # Crear figura
    fig, ax = plt.subplots(figsize=(8, 6))

    # Crear objeto de visualizaci√≥n de frontera
    disp = DecisionBoundaryDisplay.from_estimator(
        model,
        X_plot,
        alpha=0.5,
        ax=ax,
        response_method="predict"
    )

    # Colorear los puntos seg√∫n su clase
    scatter = ax.scatter(
        X_plot[:, 0],
        X_plot[:, 1],
        c=y,
        edgecolor="k",
        s=50
    )

    # Configurar etiquetas
    if feature_names and len(feature_names) >= 2:
        ax.set_xlabel(feature_names[0])
        ax.set_ylabel(feature_names[1])
    else:
        ax.set_xlabel("Caracter√≠stica 1")
        ax.set_ylabel("Caracter√≠stica 2")

    # Configurar leyenda
    if class_names:
        legend_labels = class_names
    else:
        legend_labels = [f"Clase {i}" for i in range(len(np.unique(y)))]

    legend = ax.legend(
        handles=scatter.legend_elements()[0],
        labels=legend_labels,
        title="Clases"
    )

    ax.add_artist(legend)
    ax.set_title("Frontera de Decisi√≥n")

    return fig

# Para usar:
# fig = plot_decision_boundary(model, X, y, feature_names, class_names)
# plt.show()
"""

                show_code_with_download(
                    code_boundary, "C√≥digo para generar la frontera de decisi√≥n",
                    "frontera_decision.py"
                )

    # Pesta√±a de Visualizaci√≥n
    elif st.session_state.active_tab == 3:
        st.header("Visualizaci√≥n del √Årbol")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Configuraci√≥n de la visualizaci√≥n
            st.markdown("### Tipo de visualizaci√≥n")

            # Usar botones para seleccionar el tipo de visualizaci√≥n
            if "viz_type" not in st.session_state:
                st.session_state.viz_type = "Est√°ndar"

            # Determinar si mostrar la opci√≥n de frontera de decisi√≥n
            show_boundary = (st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n"
                             and len(st.session_state.get('feature_names', [])) >= 2)

            if show_boundary:
                viz_col1, viz_col2, viz_col3 = st.columns(3)
            else:
                viz_col1, viz_col2 = st.columns(2)
                viz_col3 = None

            with viz_col1:
                if st.button("üìä Est√°ndar",
                             key="viz_standard",
                             type="primary" if st.session_state.viz_type == "Est√°ndar" else "secondary",
                             use_container_width=True):
                    st.session_state.viz_type = "Est√°ndar"
                    st.rerun()

            with viz_col2:
                if st.button("üìù Texto",
                             key="viz_text",
                             type="primary" if st.session_state.viz_type == "Texto" else "secondary",
                             use_container_width=True):
                    st.session_state.viz_type = "Texto"
                    st.rerun()

            if show_boundary and viz_col3:
                with viz_col3:
                    if st.button("üåà Frontera",
                                 key="viz_boundary",
                                 type="primary" if st.session_state.viz_type == "Frontera" else "secondary",
                                 use_container_width=True):
                        st.session_state.viz_type = "Frontera"
                        st.rerun()

            viz_type = st.session_state.viz_type

            # Opciones de tama√±o para la visualizaci√≥n
            col1, col2 = st.columns(2)

            with col1:
                fig_width = st.slider("Ancho de figura:", 8, 20, 14)

            with col2:
                fig_height = st.slider("Alto de figura:", 6, 15, 10)

            # Mostrar la visualizaci√≥n seg√∫n el tipo seleccionado
            if viz_type == "Est√°ndar":
                # Visualizaci√≥n est√°ndar de scikit-learn
                fig, ax = plt.subplots(figsize=(fig_width, fig_height))
                from sklearn.tree import plot_tree

                plot_tree(
                    st.session_state.tree_model,
                    feature_names=st.session_state.feature_names,
                    class_names=st.session_state.class_names if st.session_state.tree_type == "Clasificaci√≥n" else None,
                    filled=True,
                    rounded=True,
                    ax=ax,
                    proportion=True,
                    impurity=True
                )

                # Mostrar con tama√±o reducido pero expandible
                col1, col2, col3 = st.columns([1, 4, 1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Enlace para descargar
                st.markdown(
                    get_image_download_link(
                        fig, "arbol_decision", "üì• Descargar visualizaci√≥n del √°rbol"),
                    unsafe_allow_html=True
                )

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_tree = """
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# Suponiendo que ya tienes un modelo entrenado (tree_model)
# y los nombres de las caracter√≠sticas (feature_names) y clases (class_names)

fig, ax = plt.subplots(figsize=(14, 10))

plot_tree(
    tree_model,
    feature_names=feature_names,
    class_names=class_names,  # Solo para clasificaci√≥n
    filled=True,
    rounded=True,
    ax=ax,
    proportion=True,
    impurity=True
)

plt.tight_layout()
plt.show()

# Para guardar a un archivo:
# plt.savefig('arbol_decision.png', dpi=300, bbox_inches='tight')
"""

                show_code_with_download(
                    code_tree, "C√≥digo para visualizar el √°rbol", "visualizar_arbol.py")

            elif viz_type == "Texto":
                # Obtener representaci√≥n de texto
                tree_text = get_tree_text(
                    st.session_state.tree_model,
                    st.session_state.feature_names,
                )

                # Mostrar en un √°rea de texto
                st.text(tree_text)

                # Bot√≥n para descargar
                text_bytes = tree_text.encode()
                b64 = base64.b64encode(text_bytes).decode()
                href = f'<a href="data:text/plain;base64,{b64}" download="arbol_texto.txt">üì• Descargar texto del √°rbol</a>'
                st.markdown(href, unsafe_allow_html=True)

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_text = """
from sklearn.tree import export_text

def get_tree_text(model, feature_names, show_class_name=True):
    \"\"\"
    Obtiene una representaci√≥n de texto de un √°rbol de decisi√≥n.

    Parameters:
    -----------
    model : DecisionTreeClassifier o DecisionTreeRegressor
        Modelo de √°rbol entrenado
    feature_names : list
        Nombres de las caracter√≠sticas
    show_class_name : bool
        Si es True, muestra los nombres de las clases (para clasificaci√≥n)

    Returns:
    --------
    str
        Representaci√≥n de texto del √°rbol
    \"\"\"
    return export_text(
        model,
        feature_names=feature_names,
        show_weights=True
    )

# Ejemplo de uso:
tree_text = get_tree_text(tree_model, feature_names)
print(tree_text)

# Para guardar a un archivo:
# with open('arbol_texto.txt', 'w') as f:
#     f.write(tree_text)
"""

                show_code_with_download(
                    code_text, "C√≥digo para obtener el texto del √°rbol", "texto_arbol.py")

            elif viz_type == "Frontera":
                # Visualizaci√≥n de frontera de decisi√≥n
                st.markdown("### Visualizaci√≥n de Frontera de Decisi√≥n")

                st.info("""
                **C√≥mo interpretar esta visualizaci√≥n:**
                - Las √°reas coloreadas muestran las regiones de decisi√≥n para cada clase
                - Los puntos representan las muestras de entrenamiento
                - Las l√≠neas entre colores son las fronteras de decisi√≥n
                - Solo se muestran las primeras dos caracter√≠sticas para crear la visualizaci√≥n 2D
                """)

                # Selecci√≥n de caracter√≠sticas para la visualizaci√≥n
                if len(st.session_state.feature_names) > 2:
                    cols = st.columns(2)
                    with cols[0]:
                        feature1 = st.selectbox(
                            "Primera caracter√≠stica:",
                            st.session_state.feature_names,
                            index=0,
                            key="feature1_boundary_viz"
                        )
                    with cols[1]:
                        feature2 = st.selectbox(
                            "Segunda caracter√≠stica:",
                            st.session_state.feature_names,
                            index=1,
                            key="feature2_boundary_viz"
                        )

                    # Obtener √≠ndices de las caracter√≠sticas seleccionadas
                    feature_names_list = list(st.session_state.feature_names)
                    f1_idx = feature_names_list.index(feature1)
                    f2_idx = feature_names_list.index(feature2)

                    # Crear array con solo las dos caracter√≠sticas seleccionadas
                    # Verificar si X_train es DataFrame o numpy array
                    if hasattr(st.session_state.X_train, 'iloc'):
                        # Es un DataFrame, usar iloc para indexaci√≥n posicional
                        X_boundary = st.session_state.X_train.iloc[:, [
                            f1_idx, f2_idx]].values
                    else:
                        # Es un numpy array, usar indexaci√≥n normal
                        X_boundary = st.session_state.X_train[:, [
                            f1_idx, f2_idx]]
                    feature_names_boundary = [feature1, feature2]
                else:
                    # Si solo hay dos caracter√≠sticas, usarlas directamente
                    if hasattr(st.session_state.X_train, 'values'):
                        # Es un DataFrame, convertir a numpy array
                        X_boundary = st.session_state.X_train.values
                    else:
                        # Es un numpy array
                        X_boundary = st.session_state.X_train
                    feature_names_boundary = st.session_state.feature_names

                # Crear figura y dibujar frontera de decisi√≥n
                try:
                    fig, ax = plt.subplots(figsize=(fig_width, fig_height))
                    plot_decision_boundary(
                        st.session_state.tree_model,
                        X_boundary,
                        st.session_state.y_train,
                        ax=ax,
                        feature_names=feature_names_boundary,
                        class_names=st.session_state.class_names,
                        show_code=False
                    )

                    # Mostrar la figura
                    col1, col2, col3 = st.columns([1, 4, 1])
                    with col2:
                        st.pyplot(fig, use_container_width=True)

                    # Enlace para descargar
                    st.markdown(
                        get_image_download_link(
                            fig, "frontera_decision", "üì• Descargar visualizaci√≥n de frontera"),
                        unsafe_allow_html=True
                    )

                    # Explicaci√≥n adicional
                    st.markdown("""
                    **Nota:** Esta visualizaci√≥n muestra c√≥mo el √°rbol de decisi√≥n divide el espacio de caracter√≠sticas
                    en regiones de decisi√≥n. Cada color representa una clase diferente. 
                    
                    Para crear esta visualizaci√≥n 2D, se entrena un nuevo √°rbol utilizando solo las dos caracter√≠sticas 
                    seleccionadas, por lo que puede diferir ligeramente del modelo completo que utiliza todas las caracter√≠sticas.
                    """)

                    # Advertencia sobre dimensionalidad
                    if len(st.session_state.feature_names) > 2:
                        st.warning("""
                        ‚ö†Ô∏è Esta visualizaci√≥n solo muestra 2 caracter√≠sticas seleccionadas. El modelo real utiliza todas 
                        las caracter√≠sticas para hacer predicciones. Las fronteras pueden variar si se seleccionan 
                        diferentes pares de caracter√≠sticas.
                        """)

                    # Mostrar c√≥digo para generar esta visualizaci√≥n
                    code_boundary = f"""
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from decision_boundary import plot_decision_boundary

# Datos de entrenamiento (solo las primeras 2 caracter√≠sticas)
X_2d = X_train[:, [0, 1]]  # Usar las caracter√≠sticas seleccionadas
y_train = y_train

# Crear figura
fig, ax = plt.subplots(figsize=({fig_width}, {fig_height}))

# Visualizar frontera de decisi√≥n
plot_decision_boundary(
    tree_model,
    X_2d,
    y_train,
    ax=ax,
    feature_names={feature_names_boundary},
    class_names={st.session_state.class_names if st.session_state.class_names else None}
)

plt.tight_layout()
plt.show()

# Para guardar a un archivo:
# plt.savefig('frontera_decision.png', dpi=300, bbox_inches='tight')
"""

                    show_code_with_download(
                        code_boundary, "C√≥digo para generar la frontera de decisi√≥n", "frontera_decision.py")

                except Exception as e:
                    st.error(
                        f"Error al mostrar la visualizaci√≥n de frontera de decisi√≥n: {str(e)}")
                    st.info("""
                    La frontera de decisi√≥n requiere:
                    - Un modelo de clasificaci√≥n entrenado
                    - Exactamente 2 caracter√≠sticas para visualizar
                    - Datos de entrenamiento v√°lidos
                    """)
                    st.exception(
                        e)  # Mostrar detalles del error para debugging

    # Pesta√±a de Caracter√≠sticas
    elif st.session_state.active_tab == 4:
        st.header("Importancia de Caracter√≠sticas")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Mostrar importancia de caracter√≠sticas
            display_feature_importance(
                st.session_state.tree_model,
                st.session_state.feature_names
            )

    # Pesta√±a de Predicciones
    elif st.session_state.active_tab == 5:
        st.header("Predicciones con Nuevos Datos")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Interfaz para hacer predicciones
            create_prediction_interface(
                st.session_state.tree_model,
                st.session_state.feature_names,
                st.session_state.class_names,
                st.session_state.get('tree_type', 'Clasificaci√≥n'),
                # Pasar datos de entrenamiento para rangos din√°micos
                st.session_state.get('X_train', None),
                # Pasar nombre del dataset para metadata
                st.session_state.get('selected_dataset', 'Titanic')
            )

    # Pesta√±a de Exportar Modelo
    elif st.session_state.active_tab == 6:
        st.header("Exportar Modelo")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Opciones para exportar el modelo
            display_model_export_options(
                st.session_state.tree_model,
                st.session_state.feature_names,
                st.session_state.class_names,
                st.session_state.get('tree_type', 'Clasificaci√≥n'),
                st.session_state.get('max_depth', 3),
                st.session_state.get('min_samples_split', 2),
                st.session_state.get('criterion', 'gini')
            )


def run_neural_networks_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de redes neuronales."""
    st.header("üß† Redes Neuronales")
    st.markdown(
        "Aprende sobre redes neuronales artificiales de forma visual e interactiva")

    # Informaci√≥n sobre redes neuronales
    with st.expander("‚ÑπÔ∏è ¬øQu√© son las Redes Neuronales?", expanded=False):
        st.markdown("""
        Las redes neuronales artificiales son modelos computacionales inspirados en el funcionamiento del cerebro humano.
        Est√°n compuestas por nodos (neuronas) interconectados que procesan informaci√≥n de manera paralela.

        **Caracter√≠sticas principales:**
        - **Neuronas**: Unidades b√°sicas que reciben entradas, las procesan y generan salidas
        - **Capas**: Organizan las neuronas en estructuras jer√°rquicas (entrada, ocultas, salida)
        - **Pesos y Sesgos**: Par√°metros que se ajustan durante el entrenamiento
        - **Funciones de Activaci√≥n**: Determinan la salida de cada neurona
        - **Backpropagation**: Algoritmo para entrenar la red ajustando pesos y sesgos

        **Ventajas:**
        - Pueden modelar relaciones no lineales complejas
        - Excelentes para reconocimiento de patrones
        - Adaptables a diferentes tipos de problemas
        - Capaces de aproximar cualquier funci√≥n continua

        **Desventajas:**
        - Requieren grandes cantidades de datos
        - Pueden ser "cajas negras" (dif√≠ciles de interpretar)
        - Propensos al sobreajuste
        - Requieren mucho poder computacional
        """)

    # Sistema de pesta√±as
    tab_names = [
        "üìä Datos",
        "üèóÔ∏è Arquitectura",
        "‚öôÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üéØ Visualizaciones",
        "üîÆ Predicciones",
        "üíæ Exportar"
    ]

    # Inicializar estado de pesta√±as si no existe
    if 'active_tab_nn' not in st.session_state:
        st.session_state.active_tab_nn = 0

    # Crear pesta√±as visuales personalizadas
    cols = st.columns(len(tab_names))
    for i, (col, tab_name) in enumerate(zip(cols, tab_names)):
        with col:
            if st.button(
                tab_name,
                key=f"tab_nn_{i}",
                use_container_width=True,
                type="primary" if st.session_state.active_tab_nn == i else "secondary"
            ):
                st.session_state.active_tab_nn = i
                st.rerun()

    st.markdown("---")

    # Pesta√±a de Datos
    if st.session_state.active_tab_nn == 0:
        st.header("üìä Selecci√≥n y Preparaci√≥n de Datos")

        # Tips educativos sobre datos para redes neuronales
        st.info("""
        üéì **Tips para Redes Neuronales:**
        - Las redes neuronales funcionan mejor con **datos normalizados** (valores entre 0 y 1 o -1 y 1)
        - Necesitan **suficientes datos** para entrenar bien (m√≠nimo 100 ejemplos por clase)
        - Son excelentes para **patrones complejos** y **relaciones no lineales**
        - Pueden funcionar tanto para **clasificaci√≥n** como para **regresi√≥n**
        """)

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset_nn' not in st.session_state:
            st.session_state.selected_dataset_nn = "üå∏ Iris - Clasificaci√≥n de flores"

        # Lista base de datasets predefinidos
        builtin_datasets = [
            "üå∏ Iris - Clasificaci√≥n de flores",
            "üç∑ Vino - Clasificaci√≥n de vinos",
            "üî¨ C√°ncer - Diagn√≥stico binario",
            "üö¢ Titanic - Supervivencia",
            "üí∞ Propinas - Predicci√≥n de propinas",
            "üè† Viviendas California - Precios",
            "üêß Ping√ºinos - Clasificaci√≥n de especies"
        ]

        # A√±adir datasets CSV cargados si existen
        available_datasets = builtin_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado est√© en la lista disponible
        if st.session_state.selected_dataset_nn not in available_datasets:
            st.session_state.selected_dataset_nn = builtin_datasets[0]

        # Selector unificado con explicaci√≥n
        with st.container():
            st.markdown("### üéØ Selecci√≥n del Dataset")
            dataset_option = st.selectbox(
                "Elige tu dataset:",
                available_datasets,
                index=available_datasets.index(
                    st.session_state.selected_dataset_nn),
                key="unified_dataset_selector_nn",
                help="üí° Cada dataset presenta diferentes retos de aprendizaje para tu red neuronal"
            )

            # Explicaci√≥n sobre el dataset seleccionado
            if "Iris" in dataset_option:
                st.markdown(
                    "üå∏ **Iris**: Perfecto para empezar. 3 clases de flores, 4 caracter√≠sticas simples.")
            elif "Vino" in dataset_option:
                st.markdown(
                    "üç∑ **Vino**: Clasificaci√≥n multiclase con 13 caracter√≠sticas qu√≠micas.")
            elif "C√°ncer" in dataset_option:
                st.markdown(
                    "üî¨ **C√°ncer**: Problema binario m√©dico con 30 caracter√≠sticas.")
            elif "Titanic" in dataset_option:
                st.markdown(
                    "üö¢ **Titanic**: Predicci√≥n de supervivencia con datos categ√≥ricos y num√©ricos.")
            elif "Propinas" in dataset_option:
                st.markdown(
                    "üí∞ **Propinas**: Regresi√≥n para predecir cantidad de propina.")
            elif "Viviendas" in dataset_option:
                st.markdown(
                    "üè† **Viviendas**: Regresi√≥n para predecir precios de casas.")
            elif "Ping√ºinos" in dataset_option:
                st.markdown(
                    "üêß **Ping√ºinos**: Clasificaci√≥n de especies con datos biol√≥gicos.")

        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset_nn = dataset_option

        # Separador despu√©s del selector
        st.markdown("---")

        # Mostrar informaci√≥n del dataset seleccionado
        if 'selected_dataset_nn' in st.session_state:
            dataset_name = st.session_state.selected_dataset_nn
            st.success(f"‚úÖ Dataset seleccionado: **{dataset_name}**")

            # Cargar y mostrar datos
            try:
                # Cargar datos usando la funci√≥n load_data com√∫n
                X, y, feature_names, class_names, dataset_info, task_type = load_data(
                    dataset_name)

                # Crear DataFrame
                df = pd.DataFrame(X, columns=feature_names)

                # Determinar el nombre de la columna objetivo
                if class_names is not None and len(class_names) > 0:
                    # Para clasificaci√≥n, usar el nombre de la variable objetivo del dataset_info
                    target_col = 'target'  # Nombre por defecto
                    if hasattr(dataset_info, 'target_names'):
                        target_col = 'target'
                    df[target_col] = y
                else:
                    # Para regresi√≥n
                    target_col = 'target'
                    df[target_col] = y

                # Almacenar informaci√≥n del dataset
                st.session_state.nn_df = df
                st.session_state.nn_target_col = target_col
                st.session_state.nn_feature_names = feature_names
                st.session_state.nn_class_names = class_names
                st.session_state.nn_task_type = task_type
                st.session_state.nn_dataset_info = dataset_info

                # Mostrar informaci√≥n b√°sica con explicaciones
                st.markdown("### üìä Informaci√≥n del Dataset")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(
                        "üìè Filas", df.shape[0], help="N√∫mero total de ejemplos para entrenar")
                with col2:
                    st.metric(
                        "üìä Columnas", df.shape[1], help="Caracter√≠sticas + variable objetivo")
                with col3:
                    st.metric("üéØ Variable Objetivo", target_col,
                              help="Lo que la red va a predecir")
                with col4:
                    task_icon = "üè∑Ô∏è" if task_type == "Clasificaci√≥n" else "üìà"
                    st.metric(f"{task_icon} Tipo de Tarea",
                              task_type, help="Clasificaci√≥n o Regresi√≥n")

                # Mostrar muestra de datos con explicaci√≥n
                st.markdown("### üëÄ Vista Previa de los Datos")
                st.markdown("üìã **Primeras 10 filas de tu dataset:**")
                st.dataframe(df.head(10), use_container_width=True)

                # Tip sobre los datos
                with st.expander("üí° ¬øQu√© significan estos datos?"):
                    st.markdown(f"""
                    - **Filas**: Cada fila es un ejemplo que la red usar√° para aprender
                    - **Columnas de caracter√≠sticas**: Las variables que la red analiza para hacer predicciones
                    - **Variable objetivo ({target_col})**: Lo que queremos predecir
                    - **Preprocesamiento**: Los datos se normalizar√°n autom√°ticamente para la red neuronal
                    """)

                # An√°lisis de la variable objetivo con explicaciones
                if task_type == "Clasificaci√≥n":
                    st.markdown("### üéØ Distribuci√≥n de Clases")
                    st.markdown("üìä **¬øCu√°ntos ejemplos hay de cada clase?**")
                    class_counts = df[target_col].value_counts()

                    # Usar nombres de clases si est√°n disponibles
                    if class_names is not None:
                        # Mapear valores num√©ricos a nombres de clases
                        class_labels = [class_names[int(idx)] if int(idx) < len(class_names) else f"Clase {idx}"
                                        for idx in class_counts.index]
                        fig = px.bar(x=class_labels, y=class_counts.values,
                                     labels={'x': target_col, 'y': 'Cantidad'},
                                     title=f"Distribuci√≥n de {target_col}")
                    else:
                        fig = px.bar(x=class_counts.index, y=class_counts.values,
                                     labels={'x': target_col, 'y': 'Cantidad'},
                                     title=f"Distribuci√≥n de {target_col}")

                    st.plotly_chart(fig, use_container_width=True)

                    # Explicaci√≥n sobre balance de clases
                    balance_ratio = class_counts.max() / class_counts.min()
                    if balance_ratio > 3:
                        st.warning(
                            f"‚ö†Ô∏è **Dataset desbalanceado**: La clase m√°s frecuente tiene {balance_ratio:.1f}x m√°s ejemplos que la menos frecuente")
                        st.info(
                            "üí° Las redes neuronales funcionan mejor con clases balanceadas. Considera t√©cnicas de balanceo si es necesario.")
                    else:
                        st.success(
                            "‚úÖ **Dataset bien balanceado**: Las clases tienen cantidad similar de ejemplos")

                else:
                    st.markdown("### üìä Distribuci√≥n de la Variable Objetivo")
                    st.markdown(
                        "üìà **Distribuci√≥n de los valores que queremos predecir:**")
                    fig = px.histogram(df, x=target_col, nbins=30,
                                       title=f"Distribuci√≥n de {target_col}")
                    st.plotly_chart(fig, use_container_width=True)

                    # Estad√≠sticas b√°sicas para regresi√≥n
                    with st.expander("üìä Estad√≠sticas de la Variable Objetivo"):
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric(
                                "üéØ Media", f"{df[target_col].mean():.2f}")
                        with col2:
                            st.metric("üìè Desv. Est√°ndar",
                                      f"{df[target_col].std():.2f}")
                        with col3:
                            st.metric(
                                "üìâ M√≠nimo", f"{df[target_col].min():.2f}")
                        with col4:
                            st.metric(
                                "üìà M√°ximo", f"{df[target_col].max():.2f}")

                # Informaci√≥n adicional del dataset
                if dataset_info and hasattr(dataset_info, 'DESCR'):
                    with st.expander("üìñ Descripci√≥n Detallada del Dataset"):
                        st.text(dataset_info.DESCR)

                # Bot√≥n para continuar con explicaci√≥n
                st.markdown("---")
                st.markdown("### ‚û°Ô∏è Siguiente Paso")
                st.markdown(
                    "Una vez que entiendas tus datos, es hora de **dise√±ar la arquitectura** de tu red neuronal.")
                if st.button("üèóÔ∏è Continuar a Arquitectura", type="primary", use_container_width=True):
                    st.session_state.active_tab_nn = 1
                    st.rerun()

            except Exception as e:
                st.error(f"Error cargando dataset: {str(e)}")
                st.info("Por favor, selecciona un dataset v√°lido.")

        else:
            st.warning("‚ö†Ô∏è Por favor, selecciona un dataset para continuar.")

    # Pesta√±a de Arquitectura
    elif st.session_state.active_tab_nn == 1:
        st.header("üèóÔ∏è Dise√±o de la Arquitectura de la Red")

        if 'nn_df' not in st.session_state or 'nn_task_type' not in st.session_state:
            st.warning(
                "‚ö†Ô∏è Primero debes seleccionar un dataset en la pesta√±a de Datos.")
            if st.button("üîô Ir a Datos"):
                st.session_state.active_tab_nn = 0
                st.rerun()
            return

        # Tips educativos sobre arquitectura
        st.info("""
        üéì **Conceptos Clave de Arquitectura:**
        - **Capas ocultas**: M√°s capas = mayor capacidad de aprender patrones complejos
        - **Neuronas por capa**: M√°s neuronas = mayor capacidad, pero riesgo de sobreajuste
        - **Funciones de activaci√≥n**: Determinan c√≥mo las neuronas procesan la informaci√≥n
        - **Arquitectura √≥ptima**: Depende del problema y cantidad de datos
        """)

        st.markdown("### üéõÔ∏è Configuraci√≥n de la Red Neuronal")

        # Informaci√≥n b√°sica del dataset
        df = st.session_state.nn_df
        target_col = st.session_state.nn_target_col
        task_type = st.session_state.nn_task_type

        # Preparar datos b√°sicos para mostrar dimensiones
        X = df.drop(columns=[target_col])
        y = df[target_col]
        input_size = X.shape[1]

        if task_type == "Clasificaci√≥n":
            num_classes = len(y.unique())
            if num_classes == 2:
                output_size = 1  # Para clasificaci√≥n binaria
                st.info(
                    f"üìä **Entrada**: {input_size} caracter√≠sticas ‚Üí **Salida**: {output_size} neurona (clasificaci√≥n binaria)")
            else:
                output_size = num_classes  # Para clasificaci√≥n multiclase
                st.info(
                    f"üìä **Entrada**: {input_size} caracter√≠sticas ‚Üí **Salida**: {output_size} clases")
        else:
            output_size = 1
            st.info(
                f"üìä **Entrada**: {input_size} caracter√≠sticas ‚Üí **Salida**: {output_size} valor num√©rico")

        # Tips sobre dimensiones
        with st.expander("üí° ¬øC√≥mo decidir el tama√±o de la red?"):
            st.markdown(f"""
            **Reglas generales para tu dataset ({df.shape[0]} muestras, {input_size} caracter√≠sticas):**
            
            üî¢ **Neuronas por capa oculta:**
            - Peque√±o: {input_size//2} - {input_size} neuronas
            - Mediano: {input_size} - {input_size*2} neuronas  
            - Grande: {input_size*2} - {input_size*4} neuronas
            
            üìö **N√∫mero de capas:**
            - 1-2 capas: Problemas simples, linealmente separables
            - 2-3 capas: Problemas moderadamente complejos (recomendado para empezar)
            - 4+ capas: Problemas muy complejos (requiere muchos datos)
            
            ‚öñÔ∏è **Balance capacidad vs. datos:**
            - M√°s par√°metros que datos ‚Üí riesgo de sobreajuste
            - Tu dataset: {df.shape[0]} muestras, mant√©n par√°metros < {df.shape[0]//10}
            """)

        # Configuraci√≥n de arquitectura
        col1, col2 = st.columns([1, 1])

        with col1:
            st.markdown("#### ‚öôÔ∏è Configuraci√≥n de Capas")

            # N√∫mero de capas ocultas con explicaci√≥n
            num_hidden_layers = st.slider(
                "N√∫mero de capas ocultas",
                min_value=1, max_value=5, value=2,
                help="üí° M√°s capas = mayor capacidad de aprender patrones complejos, pero tambi√©n mayor riesgo de sobreajuste"
            )

            # Sugerencia basada en el n√∫mero de capas
            if num_hidden_layers == 1:
                st.caption(
                    "üü¶ **1 capa**: Ideal para problemas linealmente separables")
            elif num_hidden_layers == 2:
                st.caption(
                    "üü® **2 capas**: Recomendado para la mayor√≠a de problemas")
            elif num_hidden_layers >= 3:
                st.caption(
                    "üü• **3+ capas**: Solo para problemas muy complejos con muchos datos")

            # Configuraci√≥n de cada capa oculta con explicaciones
            hidden_layers = []
            for i in range(num_hidden_layers):
                # Calcular sugerencia inteligente
                suggested_size = max(10, input_size // (i+1))
                if task_type == "Clasificaci√≥n" and num_classes > 2:
                    suggested_size = max(suggested_size, num_classes * 2)

                neurons = st.slider(
                    f"Neuronas en capa oculta {i+1}",
                    min_value=1, max_value=256,
                    value=min(suggested_size, 64),  # Limitar valor por defecto
                    key=f"layer_{i}",
                    help=f"üí° Sugerencia para capa {i+1}: {suggested_size} neuronas"
                )
                hidden_layers.append(neurons)

            # Funci√≥n de activaci√≥n con explicaciones detalladas
            st.markdown("#### üßÆ Funci√≥n de Activaci√≥n (Capas Ocultas)")
            activation = st.selectbox(
                "Funci√≥n de activaci√≥n",
                ["relu", "tanh", "sigmoid"],
                help="üí° ReLU es la m√°s popular y efectiva para la mayor√≠a de problemas"
            )

            # Explicaciones sobre funciones de activaci√≥n
            if activation == "relu":
                st.success(
                    "‚úÖ **ReLU**: R√°pida, evita el problema del gradiente que desaparece. Recomendada.")
            elif activation == "tanh":
                st.info(
                    "‚ÑπÔ∏è **Tanh**: Salida entre -1 y 1. Buena para datos normalizados.")
            elif activation == "sigmoid":
                st.warning(
                    "‚ö†Ô∏è **Sigmoid**: Puede causar gradientes que desaparecen. √ösala solo si es necesario.")

            # Funci√≥n de activaci√≥n de salida - AHORA SELECCIONABLE
            st.markdown("#### üéØ Funci√≥n de Activaci√≥n de Salida")

            # Opciones disponibles seg√∫n el tipo de tarea
            if task_type == "Clasificaci√≥n":
                output_options = ["sigmoid", "softmax", "linear", "tanh"]
                if output_size == 1:  # Clasificaci√≥n binaria
                    recommended = "sigmoid"
                    default_index = 0
                else:  # Clasificaci√≥n multiclase
                    recommended = "softmax"
                    default_index = 1
            else:
                output_options = ["linear", "sigmoid", "tanh", "softmax"]
                recommended = "linear"
                default_index = 0

            output_activation = st.selectbox(
                "Funci√≥n de activaci√≥n de salida",
                output_options,
                index=default_index,
                help=f"üí° Funci√≥n recomendada para {task_type.lower()}: **{recommended}**"
            )

            # Validaciones y avisos
            show_warning = False
            warning_message = ""

            if task_type == "Clasificaci√≥n":
                if output_size == 1:  # Clasificaci√≥n binaria
                    if output_activation == "sigmoid":
                        st.success(
                            "‚úÖ Sigmoid es ideal para clasificaci√≥n binaria")
                    elif output_activation == "softmax":
                        show_warning = True
                        warning_message = "‚ö†Ô∏è Softmax no es recomendada para clasificaci√≥n binaria (1 neurona). Considera usar Sigmoid."
                    elif output_activation == "linear":
                        show_warning = True
                        warning_message = "‚ö†Ô∏è Linear puede causar problemas en clasificaci√≥n. Considera usar Sigmoid."
                    elif output_activation == "tanh":
                        show_warning = True
                        warning_message = "‚ö†Ô∏è Tanh puede funcionar pero Sigmoid es m√°s est√°ndar para clasificaci√≥n binaria."

                else:  # Clasificaci√≥n multiclase
                    if output_activation == "softmax":
                        st.success(
                            "‚úÖ Softmax es ideal para clasificaci√≥n multiclase")
                    elif output_activation == "sigmoid":
                        st.warning(
                            "‚ö†Ô∏è Sigmoid en multiclase requiere 'binary_crossentropy' por clase. Softmax es m√°s est√°ndar.")
                    elif output_activation == "linear":
                        show_warning = True
                        warning_message = "‚ö†Ô∏è Linear no es apropiada para clasificaci√≥n. Usa Softmax."
                    elif output_activation == "tanh":
                        show_warning = True
                        warning_message = "‚ö†Ô∏è Tanh no es est√°ndar para clasificaci√≥n multiclase. Softmax es recomendada."

            else:  # Regresi√≥n
                if output_activation == "linear":
                    st.success("‚úÖ Linear es ideal para regresi√≥n")
                elif output_activation == "sigmoid":
                    st.warning(
                        "‚ö†Ô∏è Sigmoid limita la salida a [0,1]. Solo √∫til si tus valores objetivo est√°n en este rango.")
                elif output_activation == "tanh":
                    st.warning(
                        "‚ö†Ô∏è Tanh limita la salida a [-1,1]. Solo √∫til si tus valores objetivo est√°n en este rango.")
                elif output_activation == "softmax":
                    show_warning = True
                    warning_message = "‚ö†Ô∏è Softmax no es apropiada para regresi√≥n. Las salidas suman 1. Usa Linear."

            # Mostrar advertencia cr√≠tica si es necesario
            if show_warning:
                st.error(warning_message)

        with col2:
            st.markdown("#### üé® Visualizaci√≥n de la Arquitectura")

            # Crear arquitectura completa
            architecture = [input_size] + hidden_layers + [output_size]

            # Guardar configuraci√≥n en session state
            st.session_state.nn_architecture = {
                'layers': architecture,
                'activation': activation,
                'output_activation': output_activation,
                'input_size': input_size,
                'output_size': output_size,
                'task_type': task_type
            }

            # Visualizar la red neuronal din√°micamente
            create_neural_network_visualization(
                architecture, activation, output_activation, task_type)

        # Configuraci√≥n adicional con explicaciones detalladas
        st.markdown("### ‚öôÔ∏è Configuraci√≥n Adicional")

        st.markdown("üìö **Par√°metros importantes para el entrenamiento:**")

        col3, col4, col5 = st.columns(3)

        with col3:
            st.markdown("#### üõ°Ô∏è Regularizaci√≥n")
            dropout_rate = st.slider(
                "Tasa de Dropout",
                min_value=0.0, max_value=0.8, value=0.2, step=0.1,
                help="üí° Dropout previene sobreajuste eliminando aleatoriamente neuronas durante entrenamiento"
            )

            # Explicaci√≥n del dropout
            if dropout_rate == 0.0:
                st.caption("üî¥ **Sin Dropout**: Mayor riesgo de sobreajuste")
            elif dropout_rate <= 0.2:
                st.caption("üü¢ **Dropout Ligero**: Bueno para datasets grandes")
            elif dropout_rate <= 0.5:
                st.caption(
                    "üü° **Dropout Moderado**: Recomendado para la mayor√≠a de casos")
            else:
                st.caption(
                    "üü† **Dropout Alto**: Solo para datasets muy peque√±os")

        with col4:
            st.markdown("#### üì¶ Procesamiento")
            batch_size = st.selectbox(
                "Tama√±o de Batch",
                [16, 32, 64, 128, 256],
                index=2,  # 64 por defecto
                help="üí° N√∫mero de muestras procesadas antes de actualizar los pesos"
            )

            # Sugerencias seg√∫n el tama√±o del dataset
            dataset_size = df.shape[0]
            if batch_size >= dataset_size // 4:
                st.caption(
                    "üî¥ **Batch Grande**: Puede ser lento pero m√°s estable")
            elif batch_size >= 32:
                st.caption(
                    "üü¢ **Batch √ìptimo**: Buen balance velocidad/estabilidad")
            else:
                st.caption("üü° **Batch Peque√±o**: M√°s r√°pido pero m√°s ruidoso")

        with col5:
            st.markdown("#### üöÄ Optimizaci√≥n")
            optimizer = st.selectbox(
                "Optimizador",
                ["adam", "sgd", "rmsprop"],
                help="üí° Algoritmo para actualizar los pesos de la red"
            )

            # Explicaciones sobre optimizadores
            if optimizer == "adam":
                st.caption(
                    "üü¢ **Adam**: Adaptativo, recomendado para la mayor√≠a de casos")
            elif optimizer == "sgd":
                st.caption(
                    "üü° **SGD**: Cl√°sico, requiere ajuste fino del learning rate")
            elif optimizer == "rmsprop":
                st.caption(
                    "üü¶ **RMSprop**: Bueno para RNNs y problemas espec√≠ficos")

        # Tips sobre la configuraci√≥n
        with st.expander("üí° Tips para optimizar tu configuraci√≥n"):
            st.markdown(f"""
            **Para tu dataset espec√≠fico ({dataset_size} muestras):**
            
            üéØ **Batch Size recomendado:**
            - Dataset peque√±o (<1000): 16-32
            - Dataset mediano (1000-10000): 32-64
            - Dataset grande (>10000): 64-128
            - Tu dataset: {dataset_size} muestras ‚Üí Recomendado: {32 if dataset_size < 1000 else 64 if dataset_size < 10000 else 128}
            
            üõ°Ô∏è **Dropout recomendado:**
            - Pocos datos: 0.3-0.5 (m√°s regularizaci√≥n)
            - Muchos datos: 0.1-0.2 (menos regularizaci√≥n)
            - Dataset balanceado: 0.2-0.3
            
            üöÄ **Optimizador:**
            - **Adam**: Mejor opci√≥n general, se adapta autom√°ticamente
            - **SGD**: √ösalo solo si tienes experiencia ajustando learning rates
            - **RMSprop**: Alternativa a Adam, a veces funciona mejor en problemas espec√≠ficos
            """)

        # Guardar configuraci√≥n completa
        st.session_state.nn_config = {
            'architecture': architecture,
            'activation': activation,
            'output_activation': output_activation,
            'dropout_rate': dropout_rate,
            'batch_size': batch_size,
            'optimizer': optimizer,
            'task_type': task_type,
            'input_size': input_size,
            'output_size': output_size
        }

        # Resumen de la configuraci√≥n con an√°lisis
        st.markdown("### üìã Resumen de la Arquitectura")

        total_params = calculate_network_parameters(architecture)

        col6, col7, col8 = st.columns(3)
        with col6:
            st.metric("üî¢ Total de Par√°metros", f"{total_params:,}",
                      help="N√∫mero total de pesos y sesgos que la red aprender√°")
        with col7:
            st.metric("üìö Capas Totales", len(architecture),
                      help="Entrada + Ocultas + Salida")
        with col8:
            complexity_ratio = total_params / dataset_size if dataset_size > 0 else 0
            complexity_level = "Baja" if complexity_ratio < 0.1 else "Media" if complexity_ratio < 1 else "Alta"
            st.metric("‚öñÔ∏è Complejidad", complexity_level,
                      help=f"Ratio par√°metros/datos: {complexity_ratio:.2f}")
        with col8:
            st.metric("üß† Tipo de Red", "Perceptr√≥n Multicapa")

        # Mostrar detalles de cada capa
        st.markdown("#### üìä Detalles por Capa")
        layer_details = []
        for i, (current, next_size) in enumerate(zip(architecture[:-1], architecture[1:])):
            if i == 0:
                layer_type = "Entrada"
                params = 0
            elif i == len(architecture) - 2:
                layer_type = "Salida"
                params = current * next_size + next_size
            else:
                layer_type = f"Oculta {i}"
                params = current * next_size + next_size

            layer_details.append({
                "Capa": layer_type,
                "Neuronas": current if i < len(architecture) - 1 else next_size,
                "Par√°metros": params,
                "Activaci√≥n": "Entrada" if i == 0 else (output_activation if i == len(architecture) - 2 else activation)
            })

        st.dataframe(pd.DataFrame(layer_details), use_container_width=True)

        # An√°lisis de complejidad y recomendaciones
        st.markdown("#### üîç An√°lisis de Complejidad")

        # An√°lisis del ratio par√°metros/datos
        if complexity_ratio < 0.1:
            st.success(
                f"‚úÖ **Complejidad √ìptima**: Tu red tiene {total_params:,} par√°metros para {dataset_size} muestras (ratio: {complexity_ratio:.3f}). Bajo riesgo de sobreajuste.")
        elif complexity_ratio < 1:
            st.warning(
                f"‚ö†Ô∏è **Complejidad Media**: Tu red tiene {total_params:,} par√°metros para {dataset_size} muestras (ratio: {complexity_ratio:.3f}). Monitorea el sobreajuste.")
        else:
            st.error(
                f"üö® **Complejidad Alta**: Tu red tiene {total_params:,} par√°metros para {dataset_size} muestras (ratio: {complexity_ratio:.3f}). Alto riesgo de sobreajuste. Considera reducir el tama√±o de la red.")

        # Bot√≥n para generar c√≥digo Python
        st.markdown("### üíª C√≥digo Python")
        if st.button("üìù Generar C√≥digo de la Arquitectura", use_container_width=True):
            # Generar c√≥digo Python para la arquitectura
            code = generate_neural_network_architecture_code(
                architecture, activation, output_activation, dropout_rate,
                optimizer, batch_size, task_type, st.session_state.nn_feature_names
            )

            st.markdown("#### üêç C√≥digo Python Generado")
            st.code(code, language='python')

            # Bot√≥n para descargar el c√≥digo
            st.download_button(
                label="üíæ Descargar C√≥digo Python",
                data=code,
                file_name=f"red_neuronal_arquitectura_{task_type.lower()}.py",
                mime="text/plain"
            )

        # Botones de navegaci√≥n
        st.markdown("---")
        st.markdown("### üß≠ Navegaci√≥n")
        col_nav1, col_nav2 = st.columns(2)
        with col_nav1:
            if st.button("üîô Volver a Datos", use_container_width=True):
                st.session_state.active_tab_nn = 0
                st.rerun()
        with col_nav2:
            st.markdown(
                "**¬øListo para entrenar?** ¬°Tu arquitectura est√° configurada!")
            if st.button("üöÄ Continuar a Entrenamiento", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 2
                st.rerun()

    # Pesta√±a de Entrenamiento
    elif st.session_state.active_tab_nn == 2:
        st.header("‚öôÔ∏è Entrenamiento de la Red Neuronal")

        if 'nn_config' not in st.session_state:
            st.warning("‚ö†Ô∏è Primero debes configurar la arquitectura de la red.")
            if st.button("üîô Ir a Arquitectura"):
                st.session_state.active_tab_nn = 1
                st.rerun()
            return

        # Tips educativos sobre entrenamiento
        st.info("""
        üéì **Conceptos Clave del Entrenamiento:**
        - **Learning Rate**: Controla qu√© tan r√°pido aprende la red (muy alto = inestable, muy bajo = lento)
        - **√âpocas**: Cu√°ntas veces la red ve todos los datos (m√°s √©pocas ‚â† siempre mejor)
        - **Validaci√≥n**: Datos separados para monitorear si la red est√° generalizando bien
        - **Early Stopping**: Para evitar sobreajuste, para cuando la validaci√≥n no mejora
        """)

        st.markdown("### üéõÔ∏è Par√°metros de Entrenamiento")

        # Informaci√≥n del dataset para sugerencias
        df = st.session_state.nn_df
        dataset_size = df.shape[0]

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("#### üìà **Learning Rate**")
            learning_rate = st.selectbox(
                "Tasa de Aprendizaje",
                [0.001, 0.01, 0.1, 0.3],
                index=0,
                help="üí° 0.001 es seguro para empezar. Valores m√°s altos pueden acelerar el entrenamiento pero causar inestabilidad"
            )

            # Explicaci√≥n del learning rate seleccionado
            if learning_rate == 0.001:
                st.caption("üü¢ **Conservador**: Aprendizaje lento pero estable")
            elif learning_rate == 0.01:
                st.caption(
                    "üü° **Moderado**: Buen balance velocidad/estabilidad")
            elif learning_rate == 0.1:
                st.caption("üü† **Agresivo**: R√°pido pero puede ser inestable")
            else:
                st.caption("üî¥ **Muy Alto**: Solo para casos especiales")

        with col2:
            st.markdown("#### üîÑ **√âpocas**")
            # Sugerir √©pocas basado en tama√±o del dataset
            suggested_epochs = min(200, max(50, dataset_size // 10))
            epochs = st.slider(
                "√âpocas",
                min_value=10, max_value=500, value=min(100, suggested_epochs), step=10,
                help=f"üí° Sugerencia para tu dataset: ~{suggested_epochs} √©pocas"
            )

            # Explicaci√≥n sobre las √©pocas
            if epochs < 50:
                st.caption(
                    "üü° **Pocas √©pocas**: Puede que no aprenda completamente")
            elif epochs <= 150:
                st.caption("üü¢ **√âpocas adecuadas**: Buen balance")
            else:
                st.caption("üü† **Muchas √©pocas**: Monitorea el sobreajuste")

        with col3:
            st.markdown("#### üéØ **Validaci√≥n**")
            validation_split = st.slider(
                "% Datos de Validaci√≥n",
                min_value=10, max_value=40, value=20,
                help="üí° 20% es est√°ndar. M√°s datos = mejor validaci√≥n, menos datos para entrenar"
            )

            # Calcular tama√±os efectivos
            # 80% del total para entrenamiento
            train_size = int(
                dataset_size * (100 - validation_split) / 100 * 0.8)
            val_size = int(dataset_size * validation_split / 100)
            test_size = dataset_size - train_size - val_size

            st.caption(
                f"üìä **Distribuci√≥n**: Train={train_size}, Val={val_size}, Test={test_size}")

        # Configuraci√≥n avanzada con explicaciones detalladas
        with st.expander("‚öôÔ∏è Configuraci√≥n Avanzada - T√©cnicas para Mejorar el Entrenamiento", expanded=False):
            st.markdown("#### üõ°Ô∏è T√©cnicas de Regularizaci√≥n y Optimizaci√≥n")

            col4, col5 = st.columns(2)

            with col4:
                st.markdown("##### üõë Early Stopping")
                early_stopping = st.checkbox(
                    "Activar Parada Temprana",
                    value=True,
                    help="üí° Recomendado: Evita sobreajuste parando cuando la validaci√≥n no mejora"
                )

                if early_stopping:
                    st.success(
                        "‚úÖ **Early Stopping activado**: La red parar√° autom√°ticamente cuando deje de mejorar")
                    patience = st.slider(
                        "Paciencia (√©pocas)",
                        min_value=5, max_value=50, value=10,
                        help="√âpocas a esperar sin mejora antes de parar. M√°s paciencia = m√°s oportunidades de mejorar"
                    )

                    if patience <= 5:
                        st.caption(
                            "üî¥ **Impatiente**: Para r√°pido, puede interrumpir mejoras tard√≠as")
                    elif patience <= 15:
                        st.caption("üü¢ **Balanceado**: Buen equilibrio")
                    else:
                        st.caption(
                            "üü° **Paciente**: Da muchas oportunidades, pero puede sobreajustar")
                else:
                    st.warning(
                        "‚ö†Ô∏è **Sin Early Stopping**: La red entrenar√° todas las √©pocas. Riesgo de sobreajuste.")

            with col5:
                st.markdown("##### üìâ Learning Rate Scheduler")
                reduce_lr = st.checkbox(
                    "Reducir Learning Rate Autom√°ticamente",
                    value=True,
                    help="üí° Recomendado: Reduce la tasa de aprendizaje cuando no mejora"
                )

                if reduce_lr:
                    st.success(
                        "‚úÖ **Scheduler activado**: La tasa de aprendizaje se reducir√° autom√°ticamente")
                    lr_factor = st.slider(
                        "Factor de Reducci√≥n",
                        min_value=0.1, max_value=0.9, value=0.5,
                        help="Factor por el que se multiplica la tasa. 0.5 = reduce a la mitad"
                    )

                    if lr_factor <= 0.3:
                        st.caption(
                            "üî¥ **Reducci√≥n agresiva**: Cambios dram√°ticos")
                    elif lr_factor <= 0.7:
                        st.caption("üü¢ **Reducci√≥n moderada**: Recomendado")
                    else:
                        st.caption("üü° **Reducci√≥n suave**: Cambios graduales")
                else:
                    st.info(
                        "‚ÑπÔ∏è **Learning rate fijo**: Se mantendr√° constante durante todo el entrenamiento")

            # Explicaci√≥n sobre las t√©cnicas
            st.markdown("---")
            st.markdown("#### üìö ¬øPor qu√© usar estas t√©cnicas?")
            st.markdown("""
            - **Early Stopping**: Evita que la red memorice los datos (sobreajuste) parando cuando la performance en validaci√≥n deja de mejorar
            - **Learning Rate Reduction**: Permite un ajuste fino hacia el final del entrenamiento cuando se est√° cerca del √≥ptimo
            - **Combinadas**: Estas t√©cnicas trabajan juntas para lograr el mejor modelo posible autom√°ticamente
            """)

        # Bot√≥n de entrenamiento con explicaci√≥n
        st.markdown("### üöÄ Iniciar Entrenamiento")
        st.markdown(
            "**¬øTodo listo?** Tu red est√° configurada y lista para aprender de los datos.")

        if st.button("üß† Entrenar Red Neuronal", type="primary", use_container_width=True):
            with st.spinner("üß† Entrenando la red neuronal... Esto puede tomar unos minutos."):
                # Preparar datos
                df = st.session_state.nn_df
                target_col = st.session_state.nn_target_col
                task_type = st.session_state.nn_task_type

                try:
                    # Mostrar progreso del entrenamiento con pasos
                    progress_container = st.empty()

                    # Paso 1: Preparando datos
                    with progress_container.container():
                        st.info(
                            "üîÑ **Paso 1/4**: Preparando y dividiendo los datos...")

                    # Llamar funci√≥n de entrenamiento con callback de progreso
                    def update_progress(step, message):
                        with progress_container.container():
                            if step == 2:
                                st.info(f"üß† **Paso {step}/4**: {message}")
                            elif step == 3:
                                st.info(f"‚öôÔ∏è **Paso {step}/4**: {message}")
                            elif step == 4:
                                st.info(f"üöÄ **Paso {step}/4**: {message}")
                            else:
                                st.info(f"üîÑ **Paso {step}/4**: {message}")

                    # Entrenar el modelo con callback de progreso
                    model, history, X_test, y_test, scaler, label_encoder = train_neural_network(
                        df, target_col, st.session_state.nn_config,
                        learning_rate, epochs, validation_split/100,
                        early_stopping, patience if early_stopping else None,
                        reduce_lr, lr_factor if reduce_lr else None,
                        progress_callback=update_progress
                    )

                    # Guardar resultados
                    st.session_state.nn_model = model
                    st.session_state.nn_history = history
                    st.session_state.nn_test_data = (X_test, y_test)
                    st.session_state.nn_scaler = scaler
                    st.session_state.nn_label_encoder = label_encoder
                    st.session_state.model_trained_nn = True

                    # Limpiar el progreso y mostrar finalizaci√≥n
                    with progress_container.container():
                        st.success(
                            "‚úÖ **¬°Entrenamiento completado!** Red neuronal lista para usar")

                    st.success("üéâ ¬°Red neuronal entrenada exitosamente!")

                    # Mostrar m√©tricas b√°sicas con explicaciones
                    st.markdown("#### üìä Resultados del Entrenamiento")
                    if task_type == "Clasificaci√≥n":
                        test_loss, test_acc = model.evaluate(
                            X_test, y_test, verbose=0)
                        col_m1, col_m2 = st.columns(2)
                        with col_m1:
                            st.metric("üéØ Precisi√≥n en Test", f"{test_acc:.3f}",
                                      help="Porcentaje de predicciones correctas en datos nunca vistos")
                        with col_m2:
                            st.metric("üìâ P√©rdida en Test", f"{test_loss:.3f}",
                                      help="Qu√© tan 'equivocada' est√° la red en promedio")
                    else:
                        test_loss = model.evaluate(X_test, y_test, verbose=0)
                        st.metric("üìâ Error en Test", f"{test_loss:.3f}")

                    # Gr√°fico de entrenamiento en tiempo real
                    st.markdown("### üìà Progreso del Entrenamiento")
                    plot_training_history(history, task_type)

                except Exception as e:
                    # Limpiar el progreso en caso de error
                    with progress_container.container():
                        st.error("‚ùå **Error durante el entrenamiento**")

                    st.error(f"‚ùå Error durante el entrenamiento: {str(e)}")
                    st.info(
                        "Intenta ajustar los par√°metros o verificar el dataset.")

        # Botones de navegaci√≥n
        if st.session_state.get('model_trained_nn', False):
            col_nav1, col_nav2 = st.columns(2)
            with col_nav1:
                if st.button("üîô Volver a Arquitectura", use_container_width=True):
                    st.session_state.active_tab_nn = 1
                    st.rerun()
            with col_nav2:
                if st.button("‚û°Ô∏è Ver Evaluaci√≥n", type="primary", use_container_width=True):
                    st.session_state.active_tab_nn = 3
                    st.rerun()

    # Pesta√±as restantes (Evaluaci√≥n, Visualizaciones, Predicciones, Exportar)
    elif st.session_state.active_tab_nn == 3:
        st.header("üìà Evaluaci√≥n del Modelo")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("‚ö†Ô∏è Primero debes entrenar un modelo.")
            if st.button("üîô Ir a Entrenamiento"):
                st.session_state.active_tab_nn = 2
                st.rerun()
        else:
            show_neural_network_evaluation()

    elif st.session_state.active_tab_nn == 4:
        st.header("üéØ Visualizaciones")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("‚ö†Ô∏è Primero debes entrenar un modelo.")
        else:
            show_neural_network_visualizations()

    elif st.session_state.active_tab_nn == 5:
        st.header("üîÆ Predicciones")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("‚ö†Ô∏è Primero debes entrenar un modelo.")
        else:
            show_neural_network_predictions()

    elif st.session_state.active_tab_nn == 6:
        st.header("üíæ Exportar Modelo")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("‚ö†Ô∏è Primero debes entrenar un modelo.")
        else:
            show_neural_network_export()


def run_linear_regression_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de regresi√≥n (lineal y log√≠stica)."""
    st.header("üìä Regresi√≥n")
    st.markdown(
        "Aprende sobre regresi√≥n lineal y log√≠stica de forma interactiva")

    # Informaci√≥n sobre regresi√≥n
    with st.expander("‚ÑπÔ∏è ¬øQu√© es la Regresi√≥n?", expanded=False):
        st.markdown("""
        La regresi√≥n es un conjunto de algoritmos de aprendizaje supervisado utilizados para predecir valores num√©ricos continuos (regresi√≥n lineal) o clasificar elementos en categor√≠as (regresi√≥n log√≠stica).

        **Caracter√≠sticas principales:**
        - **Regresi√≥n Lineal**: Establece una relaci√≥n lineal entre las variables independientes (caracter√≠sticas) y la variable dependiente (objetivo)
        - **Regresi√≥n Log√≠stica**: Utiliza la funci√≥n log√≠stica para modelar la probabilidad de pertenencia a una clase
        - Ambos tipos minimizan funciones de costo espec√≠ficas para encontrar los mejores par√°metros
        - Son interpretables: los coeficientes indican la importancia y direcci√≥n del efecto de cada caracter√≠stica
        - No requieren escalado de datos, aunque puede mejorar la convergencia

        **Tipos de regresi√≥n:**
        - **Regresi√≥n Lineal Simple**: Una sola caracter√≠stica predictora
        - **Regresi√≥n Lineal M√∫ltiple**: M√∫ltiples caracter√≠sticas predictoras
        - **Regresi√≥n Log√≠stica**: Para problemas de clasificaci√≥n binaria o multiclase

        **Limitaciones:**
        - Asume una relaci√≥n lineal entre variables (regresi√≥n lineal)
        - Sensible a valores at√≠picos (outliers)
        - Puede sufrir de multicolinealidad cuando las caracter√≠sticas est√°n correlacionadas
        """)

    # Variables para almacenar datos
    dataset_loaded = False
    X, y, feature_names, class_names, dataset_info, task_type = None, None, None, None, None, None

    # Inicializar el estado de la pesta√±a activa si no existe
    if 'active_tab_lr' not in st.session_state:
        st.session_state.active_tab_lr = 0

    # Crear pesta√±as para organizar la informaci√≥n
    tab_options = [
        "üìä Datos",
        "üèãÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üìâ Visualizaci√≥n",
        "üîç Coeficientes",
        "üîÆ Predicciones",
        "üíæ Exportar Modelo"
    ]

    # Crear contenedor para los botones de las pesta√±as
    tab_cols = st.columns(len(tab_options))

    # Estilo CSS para los botones de pesta√±as (Regresi√≥n)
    st.markdown("""
    <style>
    div.tab-button-lr > button {
        border-radius: 4px 4px 0 0;
        padding: 10px;
        width: 100%;
        white-space: nowrap;
        background-color: #F0F2F6;
        border-bottom: 2px solid #E0E0E0;
        color: #333333;
    }
    div.tab-button-lr-active > button {
        background-color: #E3F2FD !important;
        border-bottom: 2px solid #1E88E5 !important;
        font-weight: bold !important;
        color: #1E88E5 !important;
    }
    div.tab-button-lr > button:hover {
        background-color: #E8EAF6;
    }
    </style>
    """, unsafe_allow_html=True)

    # Crear botones para las pesta√±as
    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_lr_{i}"
        button_style = "tab-button-lr-active" if st.session_state.active_tab_lr == i else "tab-button-lr"
        is_active = st.session_state.active_tab_lr == i

        with col:
            st.markdown(f"<div class='{button_style}'>",
                        unsafe_allow_html=True)
            # Usar type="primary" para el bot√≥n activo
            if st.button(tab_name, key=button_key, use_container_width=True,
                         type="primary" if is_active else "secondary"):
                st.session_state.active_tab_lr = i
                st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    # Separador visual
    st.markdown("---")

    # SELECTOR UNIFICADO DE DATASET (solo mostrar en pesta√±as que lo necesiten)
    if st.session_state.active_tab_lr in [0, 1]:  # Exploraci√≥n y Entrenamiento
        st.markdown("### üìä Selecci√≥n de Dataset")

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset_lr' not in st.session_state:
            st.session_state.selected_dataset_lr = "üí∞ Propinas - Predicci√≥n de propinas"

        # Lista de datasets adecuados para regresi√≥n
        regression_datasets = [
            "üí∞ Propinas - Predicci√≥n de propinas",
            "üè† Viviendas California - Precios",
            "üå∏ Iris - Clasificaci√≥n de flores",  # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üç∑ Vino - Clasificaci√≥n de vinos",   # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üî¨ C√°ncer - Diagn√≥stico binario",   # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üö¢ Titanic - Supervivencia",        # Tambi√©n √∫til para regresi√≥n log√≠stica
            # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üêß Ping√ºinos - Clasificaci√≥n de especies"
        ]

        # A√±adir datasets CSV cargados si existen
        available_datasets = regression_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado est√© en la lista disponible
        if st.session_state.selected_dataset_lr not in available_datasets:
            st.session_state.selected_dataset_lr = regression_datasets[0]

        # Selector unificado
        dataset_option = st.selectbox(
            "Dataset:",
            available_datasets,
            index=available_datasets.index(
                st.session_state.selected_dataset_lr),
            key="unified_dataset_selector_lr",
            help="El dataset seleccionado se mantendr√° entre las pesta√±as de Exploraci√≥n y Entrenamiento"
        )

        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset_lr = dataset_option

        # Separador despu√©s del selector
        st.markdown("---")
    else:
        # Para otras pesta√±as, mostrar qu√© dataset est√° seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset_lr'):
            st.info(
                f"üìä **Dataset actual:** {st.session_state.selected_dataset_lr}")
            st.markdown("---")

    # Pesta√±a de Datos
    if st.session_state.active_tab_lr == 0:
        st.header("Exploraci√≥n de Datos")

        try:
            # Cargar datos para exploraci√≥n
            X, y, feature_names, class_names, dataset_info, task_type = load_data(
                st.session_state.selected_dataset_lr)

            # Convertir a DataFrames para facilitar el manejo
            if isinstance(X, pd.DataFrame):
                X_df = X.copy()
                column_mapping = {}
                if len(feature_names) == len(X_df.columns):
                    column_mapping = dict(zip(X_df.columns, feature_names))
            else:
                X_df = pd.DataFrame(X, columns=feature_names)
                column_mapping = {}

            y_df = pd.Series(y, name="target")

            # Para regresi√≥n log√≠stica, mapear nombres de clases si est√°n disponibles
            if task_type == "Clasificaci√≥n" and class_names is not None:
                y_df = y_df.map(
                    {i: name for i, name in enumerate(class_names)})

            df = pd.concat([X_df, y_df], axis=1)

            # Renombrar columnas para mostrar nombres amigables si existe el mapeo
            if column_mapping:
                df_display = df.rename(columns=column_mapping)
            else:
                df_display = df

            # Mostrar informaci√≥n del dataset
            st.markdown("### Informaci√≥n del Dataset")
            st.markdown(create_info_box(dataset_info), unsafe_allow_html=True)

            # Mostrar las primeras filas de los datos
            st.markdown("### Vista previa de datos")
            st.dataframe(df_display.head(10))

            # Estad√≠sticas descriptivas
            st.markdown("### Estad√≠sticas Descriptivas")
            st.dataframe(df_display.describe())

            # Distribuci√≥n de clases o valores objetivo
            st.markdown("### Distribuci√≥n del Objetivo")

            fig, ax = plt.subplots(figsize=(10, 6))

            if task_type == "Clasificaci√≥n":
                # Gr√°fico de barras para clasificaci√≥n (regresi√≥n log√≠stica)
                value_counts = y_df.value_counts().sort_index()
                try:
                    import seaborn as sns
                    sns.barplot(x=value_counts.index,
                                y=value_counts.values, ax=ax)
                except ImportError:
                    # Fallback to matplotlib if seaborn is not available
                    ax.bar(value_counts.index, value_counts.values)
                ax.set_title("Distribuci√≥n de Clases")
                ax.set_xlabel("Clase")
                ax.set_ylabel("Cantidad")

                # Rotar etiquetas si son muchas
                if len(value_counts) > 3:
                    plt.xticks(rotation=45, ha='right')
            else:
                # Histograma para regresi√≥n
                # Convertir a num√©rico en caso de que sean strings
                y_numeric = pd.to_numeric(y_df, errors='coerce')
                # Usar matplotlib directamente para evitar problemas de tipo
                ax.hist(y_numeric.dropna(), bins=30,
                        alpha=0.7, edgecolor='black')
                ax.set_title("Distribuci√≥n de Valores Objetivo")
                ax.set_xlabel("Valor")
                ax.set_ylabel("Frecuencia")

            # Mostrar la figura
            col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
            with col2:
                st.pyplot(fig, use_container_width=True)

            # An√°lisis de correlaci√≥n
            st.markdown("### Matriz de Correlaci√≥n")

            # Matriz de correlaci√≥n
            corr = X_df.corr()

            # Generar m√°scara para el tri√°ngulo superior
            mask = np.triu(np.ones_like(corr, dtype=bool))

            # Generar mapa de calor
            fig_corr, ax = plt.subplots(figsize=(10, 8))
            try:
                import seaborn as sns
                sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
                            square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
            except ImportError:
                # Fallback to matplotlib if seaborn is not available
                im = ax.imshow(corr.where(~mask),
                               cmap="coolwarm", aspect="auto")
                ax.set_xticks(range(len(corr.columns)))
                ax.set_yticks(range(len(corr.columns)))
                ax.set_xticklabels(corr.columns, rotation=45, ha='right')
                ax.set_yticklabels(corr.columns)
                # Add text annotations
                for i in range(len(corr.columns)):
                    for j in range(len(corr.columns)):
                        if not mask[i, j]:
                            text = ax.text(j, i, f'{corr.iloc[i, j]:.2f}',
                                           ha="center", va="center", color="black")
            ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

            # Mostrar la figura
            col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
            with col2:
                st.pyplot(fig_corr, use_container_width=True)

            # Matriz de dispersi√≥n (Scatterplot Matrix)
            st.markdown("### Matriz de Dispersi√≥n (Pairplot)")

            # Opciones de visualizaci√≥n
            st.markdown("#### Opciones de visualizaci√≥n")
            col1, col2 = st.columns(2)

            with col1:
                # Seleccionar tipo de gr√°fico para la diagonal
                diag_kind = st.radio(
                    "Tipo de gr√°fico en la diagonal:",
                    ["Histograma", "KDE (Estimaci√≥n de Densidad)"],
                    index=1,
                    horizontal=True
                )
                diag_kind = "hist" if diag_kind == "Histograma" else "kde"

            with col2:
                # Seleccionar n√∫mero m√°ximo de caracter√≠sticas
                max_features_selected = st.slider(
                    "N√∫mero m√°ximo de caracter√≠sticas:",
                    min_value=2,
                    max_value=min(6, len(X_df.columns)),
                    value=min(4, len(X_df.columns)),
                    help="Un n√∫mero mayor de caracter√≠sticas puede hacer que el gr√°fico sea m√°s dif√≠cil de interpretar."
                )

            # Permitir al usuario seleccionar las caracter√≠sticas espec√≠ficas
            st.markdown("#### Selecciona las caracter√≠sticas para visualizar")

            # Usar nombres amigables si est√°n disponibles
            if column_mapping:
                available_features = list(column_mapping.values())
                display_to_original = {v: k for k, v in column_mapping.items()}
            else:
                available_features = X_df.columns.tolist()
                display_to_original = {}

            # Usar multiselect para seleccionar caracter√≠sticas
            selected_features = st.multiselect(
                "Caracter√≠sticas a incluir en la matriz de dispersi√≥n:",
                available_features,
                default=available_features[:max_features_selected],
                max_selections=max_features_selected,
                help=f"Selecciona hasta {max_features_selected} caracter√≠sticas para incluir en la visualizaci√≥n."
            )

            # Si no se seleccion√≥ ninguna caracter√≠stica, usar las primeras por defecto
            if not selected_features:
                selected_features = available_features[:max_features_selected]
                st.info(
                    f"No se seleccionaron caracter√≠sticas. Usando las primeras {max_features_selected} por defecto.")

            # Convertir nombres amigables a nombres originales si es necesario
            if column_mapping:
                original_features = [display_to_original[feat]
                                     for feat in selected_features]
            else:
                original_features = selected_features

            # Crear el dataframe para la visualizaci√≥n
            plot_df = X_df[original_features].copy()
            # Renombrar a nombres amigables para visualizaci√≥n
            if column_mapping:
                plot_df = plot_df.rename(columns=column_mapping)
            # A√±adir la variable objetivo para colorear
            plot_df['target'] = y_df

            # Generar el pairplot
            with st.spinner("Generando matriz de dispersi√≥n..."):
                try:
                    import seaborn as sns
                    pair_plot = sns.pairplot(
                        plot_df,
                        hue='target' if task_type == "Clasificaci√≥n" else None,
                        diag_kind=diag_kind,
                        plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
                        diag_kws={'alpha': 0.5},
                        height=2.0
                    )
                    pair_plot.fig.suptitle(
                        "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=14)

                    # Mostrar la figura
                    col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                    with col2:
                        st.pyplot(pair_plot.fig, use_container_width=True)

                    # Enlace para descargar
                    st.markdown(
                        get_image_download_link(
                            pair_plot.fig, "matriz_dispersion_lr", "üì• Descargar matriz de dispersi√≥n"),
                        unsafe_allow_html=True
                    )
                except ImportError:
                    st.error(
                        "Seaborn no est√° disponible. Por favor, instala seaborn para usar la matriz de dispersi√≥n.")
                    st.info(
                        "Puedes instalar seaborn ejecutando: pip install seaborn")

        except Exception as e:
            st.error(f"Error al cargar el dataset: {str(e)}")
            st.info(
                "Por favor, selecciona un dataset v√°lido para continuar con la exploraci√≥n.")

    # Pesta√±a de Entrenamiento
    elif st.session_state.active_tab_lr == 1:
        st.header("Configuraci√≥n del Modelo")

        # Inicializar session state variables
        if 'dataset_option_lr' not in st.session_state:
            st.session_state.dataset_option_lr = st.session_state.selected_dataset_lr
        if 'model_type_lr' not in st.session_state:
            st.session_state.model_type_lr = "Linear"
        if 'is_trained_lr' not in st.session_state:
            st.session_state.is_trained_lr = False

        # Cargar datos para la vista previa si cambia el dataset o si no se ha cargado
        if st.session_state.selected_dataset_lr != st.session_state.dataset_option_lr or not dataset_loaded:
            try:
                X, y, feature_names, class_names, dataset_info, task_type = load_data(
                    st.session_state.selected_dataset_lr)

                st.session_state.dataset_option_lr = st.session_state.selected_dataset_lr
                dataset_loaded = True

                # Mostrar informaci√≥n del dataset
                st.markdown("### Informaci√≥n del Dataset")
                st.markdown(create_info_box(dataset_info),
                            unsafe_allow_html=True)

                # Determinar el tipo de modelo seg√∫n el task_type detectado
                st.markdown("### Tipo de Modelo Lineal")

                # Usar botones para seleccionar el tipo de modelo
                tipo_col1, tipo_col2 = st.columns(2)

                with tipo_col1:
                    is_linear = True
                    if "model_type_lr" in st.session_state:
                        is_linear = st.session_state.model_type_lr == "Linear"

                    if st.button("üìà Regresi√≥n Lineal",
                                 key="btn_linear",
                                 type="primary" if is_linear else "secondary",
                                 use_container_width=True,
                                 help="Para predecir valores num√©ricos continuos"):
                        model_type = "Linear"
                        st.session_state.model_type_lr = model_type
                        st.rerun()

                with tipo_col2:
                    is_logistic = False
                    if "model_type_lr" in st.session_state:
                        is_logistic = st.session_state.model_type_lr == "Logistic"

                    if st.button("üè∑Ô∏è Regresi√≥n Log√≠stica",
                                 key="btn_logistic",
                                 type="primary" if is_logistic else "secondary",
                                 use_container_width=True,
                                 help="Para predecir categor√≠as o clases"):
                        model_type = "Logistic"
                        st.session_state.model_type_lr = model_type
                        st.rerun()

                # Obtener el valor actual del tipo de modelo
                model_type = st.session_state.get('model_type_lr', "Linear")

                # Mostrar sugerencia basada en el tipo de tarea detectado
                if task_type == "Clasificaci√≥n" and model_type == "Linear":
                    st.warning(
                        "Este dataset parece ser m√°s adecuado para Regresi√≥n Log√≠stica. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")
                elif task_type == "Regresi√≥n" and model_type == "Logistic":
                    st.warning(
                        "Este dataset parece ser m√°s adecuado para Regresi√≥n Lineal. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")

            except Exception as e:
                st.error(f"Error al cargar el dataset: {str(e)}")
                dataset_loaded = False

        # Par√°metros del modelo
        st.markdown("### Par√°metros del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            # Para regresi√≥n log√≠stica, mostrar par√°metro max_iter
            if st.session_state.get('model_type_lr', 'Linear') == "Logistic":
                max_iter = st.slider(
                    "M√°ximo de Iteraciones:",
                    min_value=100,
                    max_value=2000,
                    value=1000,
                    step=100,
                    help="N√∫mero m√°ximo de iteraciones para el optimizador de regresi√≥n log√≠stica."
                )
            else:
                st.info(
                    "La regresi√≥n lineal no requiere configuraci√≥n adicional de iteraciones.")

        with col2:
            # Configuraciones adicionales pueden ir aqu√≠ en el futuro
            st.empty()

        if st.button("üöÄ Entrenar Modelo", key="train_lr_button", type="primary"):
            if dataset_loaded and X is not None and y is not None:
                with st.spinner("Entrenando modelo..."):
                    try:
                        # Entrenar el modelo
                        if model_type == "Logistic":
                            result = train_linear_model(
                                X, y,
                                model_type=model_type,
                                max_iter=max_iter,
                                test_size=0.2,
                                random_state=42
                            )
                        else:
                            result = train_linear_model(
                                X, y,
                                model_type=model_type,
                                test_size=0.2,
                                random_state=42
                            )

                        # Extraer el modelo y m√©tricas del resultado
                        model = result["model"]
                        metrics = result["test_results"]

                        # Guardar en session state
                        st.session_state.model_lr = model
                        st.session_state.metrics_lr = metrics
                        st.session_state.X_train_lr = result["X_train"]
                        st.session_state.X_test_lr = result["X_test"]
                        st.session_state.y_train_lr = result["y_train"]
                        st.session_state.y_test_lr = result["y_test"]
                        st.session_state.feature_names_lr = feature_names
                        st.session_state.class_names_lr = class_names
                        st.session_state.task_type_lr = task_type
                        st.session_state.model_trained_lr = True

                        st.success("¬°Modelo entrenado exitosamente!")

                    except Exception as e:
                        st.error(f"Error al entrenar el modelo: {str(e)}")
            else:
                st.error("Por favor, carga un dataset v√°lido primero.")

    # Pesta√±a de Evaluaci√≥n
    elif st.session_state.active_tab_lr == 2:
        st.header("Evaluaci√≥n del Modelo")

        if st.session_state.get('model_trained_lr', False):
            metrics = st.session_state.get('metrics_lr', {})
            model_type = st.session_state.get('model_type_lr', 'Linear')

            # An√°lisis de balance de clases para regresi√≥n log√≠stica
            if model_type == "Logistic":
                y_test = st.session_state.get('y_test_lr')
                if y_test is not None:
                    # Verificar balance de clases
                    class_counts = pd.Series(y_test).value_counts()
                    total_samples = len(y_test)

                    st.markdown("### ‚öñÔ∏è An√°lisis de Balance de Clases")

                    col1, col2 = st.columns(2)
                    with col1:
                        # Mostrar distribuci√≥n de clases
                        for class_val, count in class_counts.items():
                            percentage = (count / total_samples) * 100
                            class_name = st.session_state.get(
                                'class_names_lr', [])
                            display_name = class_name[int(class_val)] if class_name and int(
                                class_val) < len(class_name) else f"Clase {class_val}"
                            st.metric(f"{display_name}",
                                      f"{count} ({percentage:.1f}%)")

                    with col2:
                        # Evaluar balance
                        min_class_ratio = class_counts.min() / class_counts.max()
                        if min_class_ratio < 0.1:
                            st.error(
                                "‚ùå **Clases muy desbalanceadas** (ratio < 10%)")
                            st.markdown("**Recomendaciones:**")
                            st.markdown(
                                "‚Ä¢ Considera t√©cnicas de balanceo (SMOTE, undersampling)")
                            st.markdown(
                                "‚Ä¢ Usa m√©tricas como F1-Score en lugar de Accuracy")
                            st.markdown(
                                "‚Ä¢ Ajusta los pesos de las clases en el modelo")
                        elif min_class_ratio < 0.3:
                            st.warning(
                                "‚ö†Ô∏è **Clases moderadamente desbalanceadas**")
                            st.markdown(
                                "‚Ä¢ Presta especial atenci√≥n a Precision y Recall")
                            st.markdown(
                                "‚Ä¢ Considera la curva Precision-Recall")
                        else:
                            st.success(
                                "‚úÖ **Clases relativamente balanceadas**")
                            st.markdown("‚Ä¢ Accuracy es una m√©trica confiable")
                            st.markdown(
                                "‚Ä¢ Todas las m√©tricas son representativas")

            # Informaci√≥n sobre las m√©tricas
            with st.expander("‚ÑπÔ∏è ¬øQu√© significan estas m√©tricas?", expanded=False):
                if model_type == "Linear":
                    st.markdown("""
                    **M√©tricas de Regresi√≥n Lineal:**
                    
                    **R¬≤ Score (Coeficiente de Determinaci√≥n):**
                    - Mide qu√© tan bien el modelo explica la variabilidad de los datos
                    - Rango: 0 a 1 (valores negativos indican un modelo muy malo)
                    - **Interpretaci√≥n:**
                      - R¬≤ = 1.0: El modelo explica perfectamente toda la variabilidad
                      - R¬≤ = 0.8: El modelo explica el 80% de la variabilidad (muy bueno)
                      - R¬≤ = 0.5: El modelo explica el 50% de la variabilidad (moderado)
                      - R¬≤ = 0.0: El modelo no explica nada de la variabilidad
                    
                    **MAE (Error Absoluto Medio):**
                    - Promedio de las diferencias absolutas entre valores reales y predichos
                    - Se expresa en las mismas unidades que la variable objetivo
                    - **Interpretaci√≥n:** Valores m√°s bajos = mejor modelo
                    
                    **RMSE (Ra√≠z del Error Cuadr√°tico Medio):**
                    - Similar al MAE pero penaliza m√°s los errores grandes
                    - Se expresa en las mismas unidades que la variable objetivo
                    - **Interpretaci√≥n:** Valores m√°s bajos = mejor modelo
                    """)
                else:
                    st.markdown("""
                    **M√©tricas de Regresi√≥n Log√≠stica:**
                    
                    **Accuracy (Exactitud):**
                    - Porcentaje de predicciones correctas del total
                    - Rango: 0 a 1 (0% a 100%)
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor modelo
                    - **Cuidado:** Puede ser enga√±osa con clases desbalanceadas
                    
                    **Precision (Precisi√≥n):**
                    - De todas las predicciones positivas, cu√°ntas fueron correctas
                    - F√≥rmula: VP / (VP + FP)
                    - Importante cuando los falsos positivos son costosos
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor modelo
                    
                    **Recall (Sensibilidad o Exhaustividad):**
                    - De todos los casos positivos reales, cu√°ntos detect√≥ el modelo
                    - F√≥rmula: VP / (VP + FN)
                    - Importante cuando los falsos negativos son costosos
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor modelo
                    
                    **F1-Score:**
                    - Media arm√≥nica entre precisi√≥n y recall
                    - F√≥rmula: 2 √ó (Precisi√≥n √ó Recall) / (Precisi√≥n + Recall)
                    - √ötil cuando necesitas balance entre precisi√≥n y recall
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor balance
                    
                    **Curva ROC:**
                    - Muestra el rendimiento en diferentes umbrales de decisi√≥n
                    - AUC (√Årea bajo la curva): 0.5 = aleatorio, 1.0 = perfecto
                    
                    **Curva Precision-Recall:**
                    - Especialmente √∫til para clases desbalanceadas
                    - Muestra el trade-off entre precisi√≥n y recall
                    
                    **VP = Verdaderos Positivos, FP = Falsos Positivos, FN = Falsos Negativos**
                    """)

            st.markdown("### üìä Resultados de Evaluaci√≥n")

            if model_type == "Linear":
                col1, col2, col3 = st.columns(3)
                with col1:
                    r2_value = metrics.get('r2', 0)
                    st.metric("R¬≤ Score", f"{r2_value:.4f}")
                    # Indicador de calidad
                    if r2_value >= 0.8:
                        st.success("üéØ Excelente ajuste")
                    elif r2_value >= 0.6:
                        st.info("üëç Buen ajuste")
                    elif r2_value >= 0.4:
                        st.warning("‚ö†Ô∏è Ajuste moderado")
                    else:
                        st.error("‚ùå Ajuste pobre")

                with col2:
                    mae_value = metrics.get('mae', 0)
                    st.metric("MAE", f"{mae_value:.4f}")

                with col3:
                    rmse_value = metrics.get('rmse', 0)
                    st.metric("RMSE", f"{rmse_value:.4f}")

            else:
                col1, col2, col3 = st.columns(3)
                with col1:
                    acc_value = metrics.get('accuracy', 0)
                    st.metric("Accuracy", f"{acc_value:.4f}")
                    # Indicador de calidad
                    if acc_value >= 0.9:
                        st.success("üéØ Excelente")
                    elif acc_value >= 0.8:
                        st.info("üëç Muy bueno")
                    elif acc_value >= 0.7:
                        st.warning("‚ö†Ô∏è Bueno")
                    else:
                        st.error("‚ùå Necesita mejora")

                with col2:
                    st.metric(
                        "Precision", f"{metrics.get('precision', 0):.4f}")

                with col3:
                    st.metric("Recall", f"{metrics.get('recall', 0):.4f}")

                # A√±adir F1-Score si est√° disponible
                if 'report' in metrics and 'weighted avg' in metrics['report']:
                    f1_score = metrics['report']['weighted avg'].get(
                        'f1-score', 0)
                    st.markdown("### üéØ M√©tricas Adicionales")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("F1-Score", f"{f1_score:.4f}")
                        if f1_score >= 0.8:
                            st.success("üéØ Excelente balance")
                        elif f1_score >= 0.7:
                            st.info("üëç Buen balance")
                        else:
                            st.warning("‚ö†Ô∏è Balance mejorable")

                    # Mostrar m√©tricas por clase si es clasificaci√≥n multiclase
                    if 'report' in metrics:
                        class_names = st.session_state.get(
                            'class_names_lr', [])
                        if class_names and len(class_names) > 2:
                            st.markdown("### üìä M√©tricas por Clase")

                            report_data = []
                            for class_name in class_names:
                                if class_name in metrics['report']:
                                    class_metrics = metrics['report'][class_name]
                                    report_data.append({
                                        'Clase': class_name,
                                        'Precision': f"{class_metrics.get('precision', 0):.3f}",
                                        'Recall': f"{class_metrics.get('recall', 0):.3f}",
                                        'F1-Score': f"{class_metrics.get('f1-score', 0):.3f}",
                                        'Soporte': int(class_metrics.get('support', 0))
                                    })

                            if report_data:
                                df_report = pd.DataFrame(report_data)
                                st.dataframe(
                                    df_report, use_container_width=True, hide_index=True)

            # Mostrar interpretaci√≥n contextual
            st.markdown("### üéØ Interpretaci√≥n de Resultados")

            if model_type == "Linear":
                r2_value = metrics.get('r2', 0)
                mae_value = metrics.get('mae', 0)
                rmse_value = metrics.get('rmse', 0)

                interpretation = f"""
                **Resumen del Modelo:**
                - Tu modelo de regresi√≥n lineal explica **{r2_value*100:.1f}%** de la variabilidad en los datos
                - En promedio, las predicciones se desv√≠an **{mae_value:.2f} unidades** del valor real (MAE)
                - La ra√≠z del error cuadr√°tico medio es **{rmse_value:.2f} unidades** (RMSE)
                """

                if rmse_value > mae_value * 1.5:
                    interpretation += "\n- ‚ö†Ô∏è El RMSE es significativamente mayor que el MAE, lo que indica la presencia de algunos errores grandes"

                st.info(interpretation)

            else:
                acc_value = metrics.get('accuracy', 0)
                prec_value = metrics.get('precision', 0)
                rec_value = metrics.get('recall', 0)
                f1_value = 0

                # Obtener F1-score si est√° disponible
                if 'report' in metrics and 'weighted avg' in metrics['report']:
                    f1_value = metrics['report']['weighted avg'].get(
                        'f1-score', 0)

                interpretation = f"""
                **Resumen del Modelo:**
                - Tu modelo clasifica correctamente **{acc_value*100:.1f}%** de los casos
                - De las predicciones positivas, **{prec_value*100:.1f}%** son correctas (Precisi√≥n)
                - Detecta **{rec_value*100:.1f}%** de todos los casos positivos reales (Recall)
                """

                if f1_value > 0:
                    interpretation += f"\n- El F1-Score (balance entre precisi√≥n y recall) es **{f1_value:.3f}**"

                # An√°lisis de balance entre precisi√≥n y recall
                if abs(prec_value - rec_value) > 0.1:
                    if prec_value > rec_value:
                        interpretation += "\n\n‚öñÔ∏è **Balance:** El modelo es m√°s preciso pero menos sensible (m√°s conservador)"
                        interpretation += "\nüí° **Sugerencia:** Si es importante detectar todos los casos positivos, considera ajustar el umbral de decisi√≥n"
                    else:
                        interpretation += "\n\n‚öñÔ∏è **Balance:** El modelo es m√°s sensible pero menos preciso (m√°s liberal)"
                        interpretation += "\nüí° **Sugerencia:** Si es importante evitar falsos positivos, considera ajustar el umbral de decisi√≥n"
                else:
                    interpretation += "\n\n‚öñÔ∏è **Balance:** Bueno equilibrio entre precisi√≥n y recall"

                # An√°lisis espec√≠fico del accuracy
                if acc_value < 0.6:
                    interpretation += "\n\nüîç **Recomendaciones para mejorar:**"
                    interpretation += "\n‚Ä¢ Revisar la calidad y cantidad de datos de entrenamiento"
                    interpretation += "\n‚Ä¢ Considerar ingenier√≠a de caracter√≠sticas adicionales"
                    interpretation += "\n‚Ä¢ Probar diferentes algoritmos de clasificaci√≥n"
                    interpretation += "\n‚Ä¢ Verificar si hay desbalance de clases"

                st.info(interpretation)

        else:
            st.info("Entrena un modelo primero para ver las m√©tricas de evaluaci√≥n.")

    # Pesta√±a de Visualizaci√≥n
    elif st.session_state.active_tab_lr == 3:
        st.header("Visualizaciones")

        if st.session_state.get('model_trained_lr', False):
            model_type = st.session_state.get('model_type_lr', 'Linear')
            X_test = st.session_state.get('X_test_lr')
            y_test = st.session_state.get('y_test_lr')
            X_train = st.session_state.get('X_train_lr')
            y_train = st.session_state.get('y_train_lr')
            model = st.session_state.get('model_lr')

            # Informaci√≥n sobre las visualizaciones
            with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar estas visualizaciones?", expanded=False):
                if model_type == "Linear":
                    st.markdown("""
                    **Gr√°fico de Predicciones vs Valores Reales:**
                    - Cada punto representa una predicci√≥n del modelo
                    - La l√≠nea roja diagonal representa predicciones perfectas
                    - **Interpretaci√≥n:**
                      - Puntos cerca de la l√≠nea roja = buenas predicciones
                      - Puntos dispersos = predicciones menos precisas
                      - Patrones sistem√°ticos fuera de la l√≠nea pueden indicar problemas del modelo
                    
                    **Gr√°fico de Residuos:**
                    - Muestra la diferencia entre valores reales y predicciones
                    - **Interpretaci√≥n:**
                      - Residuos cerca de cero = buenas predicciones
                      - Patrones en los residuos pueden indicar que el modelo lineal no es adecuado
                      - Distribuci√≥n aleatoria alrededor de cero es ideal
                    """)
                else:
                    st.markdown("""
                    **Matriz de Confusi√≥n:**
                    - Muestra predicciones correctas e incorrectas por clase
                    - **Interpretaci√≥n:**
                      - Diagonal principal = predicciones correctas
                      - Fuera de la diagonal = errores del modelo
                      - Colores m√°s intensos = mayor cantidad de casos
                    
                    **Curva ROC (si es binaria):**
                    - Muestra el rendimiento del clasificador en diferentes umbrales
                    - **Interpretaci√≥n:**
                      - L√≠nea m√°s cerca de la esquina superior izquierda = mejor modelo
                      - √Årea bajo la curva (AUC) cercana a 1 = excelente modelo
                    """)

            if model_type == "Linear" and X_test is not None and y_test is not None and model is not None:
                y_pred = model.predict(X_test)

                # Crear visualizaciones con mejor tama√±o
                st.markdown("### üìä Gr√°fico de Predicciones vs Valores Reales")

                fig, ax = plt.subplots(figsize=(12, 8))

                # Scatter plot con mejor estilo
                ax.scatter(y_test, y_pred, alpha=0.6, s=50,
                           edgecolors='black', linewidth=0.5)

                # L√≠nea de predicci√≥n perfecta
                min_val = min(y_test.min(), y_pred.min())
                max_val = max(y_test.max(), y_pred.max())
                ax.plot([min_val, max_val], [min_val, max_val],
                        'r--', lw=2, label='Predicci√≥n Perfecta')

                # Personalizaci√≥n del gr√°fico
                ax.set_xlabel('Valores Reales', fontsize=12)
                ax.set_ylabel('Predicciones', fontsize=12)
                ax.set_title('Predicciones vs Valores Reales',
                             fontsize=14, fontweight='bold')
                ax.legend()
                ax.grid(True, alpha=0.3)

                # A√±adir estad√≠sticas al gr√°fico
                r2_value = st.session_state.get('metrics_lr', {}).get('r2', 0)
                ax.text(0.05, 0.95, f'R¬≤ = {r2_value:.4f}',
                        transform=ax.transAxes, fontsize=12,
                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Gr√°fico de residuos
                st.markdown("### üìà An√°lisis de Residuos")

                # Informaci√≥n explicativa sobre los residuos
                with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar el an√°lisis de residuos?", expanded=False):
                    st.markdown("""
                    **¬øQu√© son los residuos?**
                    Los residuos son las diferencias entre los valores reales y las predicciones del modelo:
                    `Residuo = Valor Real - Predicci√≥n`
                    
                    **Gr√°fico de Residuos vs Predicciones:**
                    - **Ideal:** Los puntos deben estar distribuidos aleatoriamente alrededor de la l√≠nea y=0
                    - **Problema:** Si ves patrones (curvas, abanicos), puede indicar:
                      - El modelo no captura relaciones no lineales
                      - Heterocedasticidad (varianza no constante)
                      - Variables importantes omitidas
                    
                    **Histograma de Residuos:**
                    - **Ideal:** Distribuci√≥n normal (campana) centrada en 0
                    - **Problema:** Si la distribuci√≥n est√° sesgada o tiene m√∫ltiples picos:
                      - Puede indicar que el modelo no es apropiado
                      - Sugiere la presencia de outliers o datos problem√°ticos
                    
                    **L√≠nea roja punteada:** Marca el residuo = 0 (predicci√≥n perfecta)
                    **Media de residuos:** Deber√≠a estar cerca de 0 para un modelo bien calibrado
                    """)

                residuals = y_test - y_pred

                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

                # Residuos vs Predicciones
                ax1.scatter(y_pred, residuals, alpha=0.6, s=50,
                            edgecolors='black', linewidth=0.5)
                ax1.axhline(y=0, color='r', linestyle='--',
                            lw=2, label='Residuo = 0')
                ax1.set_xlabel('Predicciones', fontsize=12)
                ax1.set_ylabel('Residuos (Real - Predicci√≥n)', fontsize=12)
                ax1.set_title('Residuos vs Predicciones',
                              fontsize=14, fontweight='bold')
                ax1.legend()
                ax1.grid(True, alpha=0.3)

                # A√±adir estad√≠sticas al gr√°fico
                residual_std = residuals.std()
                ax1.text(0.05, 0.95, f'Desv. Est√°ndar: {residual_std:.3f}',
                         transform=ax1.transAxes, fontsize=10,
                         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))

                # Histograma de residuos
                ax2.hist(residuals, bins=20, alpha=0.7,
                         edgecolor='black', color='skyblue')
                ax2.axvline(residuals.mean(), color='red', linestyle='--',
                            lw=2, label=f'Media: {residuals.mean():.3f}')
                ax2.axvline(0, color='green', linestyle='-',
                            lw=2, alpha=0.7, label='Ideal (0)')
                ax2.set_xlabel('Residuos', fontsize=12)
                ax2.set_ylabel('Frecuencia', fontsize=12)
                ax2.set_title('Distribuci√≥n de Residuos',
                              fontsize=14, fontweight='bold')
                ax2.legend()
                ax2.grid(True, alpha=0.3)

                plt.tight_layout()

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Interpretaci√≥n autom√°tica de los residuos
                st.markdown("### üîç Interpretaci√≥n de los Residuos")

                mean_residual = abs(residuals.mean())
                std_residual = residuals.std()

                interpretation = []

                if mean_residual < 0.1 * std_residual:
                    interpretation.append(
                        "‚úÖ **Media de residuos cercana a 0:** El modelo est√° bien calibrado")
                else:
                    interpretation.append(
                        "‚ö†Ô∏è **Media de residuos alejada de 0:** El modelo puede tener sesgo sistem√°tico")

                # Calcular R¬≤ de los residuos para detectar patrones
                from scipy import stats
                if len(residuals) > 10:
                    slope, _, r_value, _, _ = stats.linregress(
                        y_pred, residuals)
                    if abs(r_value) < 0.1:
                        interpretation.append(
                            "‚úÖ **Sin correlaci√≥n entre residuos y predicciones:** Buen ajuste lineal")
                    else:
                        interpretation.append(
                            "‚ö†Ô∏è **Correlaci√≥n detectada en residuos:** Puede haber relaciones no lineales")

                # Test de normalidad simplificado (basado en asimetr√≠a)
                skewness = abs(stats.skew(residuals))
                if skewness < 1:
                    interpretation.append(
                        "‚úÖ **Distribuci√≥n de residuos aproximadamente normal**")
                else:
                    interpretation.append(
                        "‚ö†Ô∏è **Distribuci√≥n de residuos sesgada:** Revisar outliers o transformaciones")

                for item in interpretation:
                    st.markdown(f"- {item}")

                if mean_residual >= 0.1 * std_residual or abs(r_value) >= 0.1 or skewness >= 1:
                    st.info(
                        "üí° **Sugerencias de mejora:** Considera probar transformaciones de variables, a√±adir caracter√≠sticas polin√≥micas, o usar modelos no lineales.")

            elif model_type == "Logistic" and X_test is not None and y_test is not None and model is not None:
                from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve

                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)

                # Matriz de Confusi√≥n
                st.markdown("### üìä Matriz de Confusi√≥n")

                cm = confusion_matrix(y_test, y_pred)
                class_names = st.session_state.get('class_names_lr', [])

                fig, ax = plt.subplots(figsize=(10, 8))

                # Crear mapa de calor
                try:
                    import seaborn as sns
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                                ax=ax, cbar_kws={'shrink': 0.8},
                                xticklabels=class_names if class_names else True,
                                yticklabels=class_names if class_names else True)
                except ImportError:
                    # Fallback to matplotlib if seaborn is not available
                    im = ax.imshow(cm, cmap='Blues', aspect='auto')
                    # Add text annotations
                    for i in range(cm.shape[0]):
                        for j in range(cm.shape[1]):
                            text = ax.text(j, i, f'{cm[i, j]}',
                                           ha="center", va="center", color="white" if cm[i, j] > cm.max()/2 else "black")
                    ax.set_xticks(range(cm.shape[1]))
                    ax.set_yticks(range(cm.shape[0]))
                    if class_names:
                        ax.set_xticklabels(class_names)
                        ax.set_yticklabels(class_names)
                ax.set_title('Matriz de Confusi√≥n',
                             fontsize=14, fontweight='bold')
                ax.set_xlabel('Predicciones', fontsize=12)
                ax.set_ylabel('Valores Reales', fontsize=12)

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # An√°lisis detallado de la matriz de confusi√≥n
                if len(np.unique(y_test)) == 2:
                    tn, fp, fn, tp = cm.ravel()

                    # M√©tricas derivadas de la matriz de confusi√≥n
                    st.markdown("### üîç An√°lisis Detallado de la Matriz")
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric("Verdaderos Positivos", f"{tp}")
                        st.caption(
                            "Casos positivos correctamente identificados")
                    with col2:
                        st.metric("Falsos Positivos", f"{fp}")
                        st.caption(
                            "Casos negativos clasificados como positivos")
                    with col3:
                        st.metric("Falsos Negativos", f"{fn}")
                        st.caption(
                            "Casos positivos clasificados como negativos")
                    with col4:
                        st.metric("Verdaderos Negativos", f"{tn}")
                        st.caption(
                            "Casos negativos correctamente identificados")

                    # Interpretaci√≥n de errores
                    if fp > fn:
                        st.warning(
                            "‚ö†Ô∏è El modelo tiende a clasificar m√°s casos como positivos (m√°s falsos positivos que falsos negativos)")
                    elif fn > fp:
                        st.warning(
                            "‚ö†Ô∏è El modelo tiende a ser m√°s conservador (m√°s falsos negativos que falsos positivos)")
                    else:
                        st.success(
                            "‚úÖ El modelo tiene un balance equilibrado entre falsos positivos y negativos")

                # Curvas ROC y Precision-Recall
                if len(np.unique(y_test)) == 2:
                    from sklearn.metrics import roc_curve, auc, average_precision_score

                    # Crear subplots para ROC y Precision-Recall
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

                    # Curva ROC
                    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])
                    roc_auc = auc(fpr, tpr)

                    ax1.plot(fpr, tpr, color='darkorange', lw=2,
                             label=f'Curva ROC (AUC = {roc_auc:.3f})')
                    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',
                             label='Clasificador Aleatorio')

                    ax1.set_xlim([0.0, 1.0])
                    ax1.set_ylim([0.0, 1.05])
                    ax1.set_xlabel('Tasa de Falsos Positivos', fontsize=12)
                    ax1.set_ylabel('Tasa de Verdaderos Positivos', fontsize=12)
                    ax1.set_title('Curva ROC', fontsize=14, fontweight='bold')
                    ax1.legend(loc="lower right")
                    ax1.grid(True, alpha=0.3)

                    # Curva Precision-Recall
                    precision, recall, _ = precision_recall_curve(
                        y_test, y_pred_proba[:, 1])
                    avg_precision = average_precision_score(
                        y_test, y_pred_proba[:, 1])

                    ax2.plot(recall, precision, color='darkgreen', lw=2,
                             label=f'Curva P-R (AP = {avg_precision:.3f})')
                    ax2.axhline(y=np.sum(y_test)/len(y_test), color='navy', lw=2, linestyle='--',
                                label=f'Baseline ({np.sum(y_test)/len(y_test):.3f})')

                    ax2.set_xlim([0.0, 1.0])
                    ax2.set_ylim([0.0, 1.05])
                    ax2.set_xlabel('Recall (Sensibilidad)', fontsize=12)
                    ax2.set_ylabel('Precision (Precisi√≥n)', fontsize=12)
                    ax2.set_title('Curva Precision-Recall',
                                  fontsize=14, fontweight='bold')
                    ax2.legend(loc="lower left")
                    ax2.grid(True, alpha=0.3)

                    plt.tight_layout()

                    st.markdown("### üìà Curvas de Rendimiento")

                    # Explicaci√≥n detallada sobre las curvas de rendimiento
                    with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar las Curvas de Rendimiento?", expanded=False):
                        st.markdown("""
                        **Curva ROC (Receiver Operating Characteristic)**
                        
                        **¬øQu√© muestra?**
                        - **Eje X:** Tasa de Falsos Positivos (FPR) = FP / (FP + TN)
                        - **Eje Y:** Tasa de Verdaderos Positivos (TPR) = TP / (TP + FN) = Sensibilidad/Recall
                        - **L√≠nea diagonal:** Rendimiento de un clasificador aleatorio
                        - **AUC (√Årea Bajo la Curva):** M√©trica resumen del rendimiento
                        
                        **Interpretaci√≥n:**
                        - **AUC = 1.0:** Clasificador perfecto
                        - **AUC = 0.9-1.0:** Excelente discriminaci√≥n
                        - **AUC = 0.8-0.9:** Buena discriminaci√≥n  
                        - **AUC = 0.7-0.8:** Discriminaci√≥n aceptable
                        - **AUC = 0.5:** Equivalente a adivinar al azar
                        - **AUC < 0.5:** Peor que adivinar (pero se puede invertir)
                        
                        **¬øCu√°ndo usar ROC?**
                        - Cuando las clases est√°n relativamente balanceadas
                        - Para comparar modelos r√°pidamente
                        - Cuando te importa el rendimiento general
                        
                        ---
                        
                        **Curva Precision-Recall (P-R)**
                        
                        **¬øQu√© muestra?**
                        - **Eje X:** Recall (Sensibilidad) = TP / (TP + FN)
                        - **Eje Y:** Precision (Precisi√≥n) = TP / (TP + FP)
                        - **L√≠nea horizontal:** Baseline (proporci√≥n de casos positivos)
                        - **AP (Average Precision):** M√©trica resumen del rendimiento
                        
                        **Interpretaci√≥n:**
                        - **AP alto:** Buen balance entre precisi√≥n y recall
                        - **Curva cerca del √°ngulo superior derecho:** Excelente rendimiento
                        - **Por encima del baseline:** Mejor que una predicci√≥n aleatoria
                        
                        **¬øCu√°ndo usar P-R?**
                        - ‚úÖ **Clases desbalanceadas** (muchos m√°s negativos que positivos)
                        - ‚úÖ Cuando los **falsos positivos son costosos**
                        - ‚úÖ Para datasets con **pocos casos positivos**
                        - ‚úÖ En problemas como **detecci√≥n de fraude, diagn√≥stico m√©dico**
                        
                        **Comparaci√≥n ROC vs P-R:**
                        - **ROC** es m√°s optimista con clases desbalanceadas
                        - **P-R** es m√°s conservadora y realista
                        - **P-R** se enfoca m√°s en el rendimiento de la clase minoritaria
                        - Usar **ambas** para una evaluaci√≥n completa
                        """)

                    # Mostrar con 80% del ancho
                    col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                    with col2:
                        st.pyplot(fig, use_container_width=True)

                    # Interpretaci√≥n de las curvas
                    st.markdown("### üìã Interpretaci√≥n de las Curvas")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**Curva ROC:**")
                        if roc_auc >= 0.9:
                            st.success(
                                f"üéØ Excelente discriminaci√≥n (AUC = {roc_auc:.3f})")
                        elif roc_auc >= 0.8:
                            st.info(
                                f"üëç Buena discriminaci√≥n (AUC = {roc_auc:.3f})")
                        elif roc_auc >= 0.7:
                            st.warning(
                                f"‚ö†Ô∏è Discriminaci√≥n moderada (AUC = {roc_auc:.3f})")
                        else:
                            st.error(
                                f"‚ùå Discriminaci√≥n pobre (AUC = {roc_auc:.3f})")

                    with col2:
                        st.markdown("**Curva Precision-Recall:**")
                        baseline_precision = np.sum(y_test)/len(y_test)
                        if avg_precision >= baseline_precision + 0.3:
                            st.success(
                                f"üéØ Excelente (AP = {avg_precision:.3f})")
                        elif avg_precision >= baseline_precision + 0.1:
                            st.info(
                                f"üëç Buena mejora sobre baseline (AP = {avg_precision:.3f})")
                        elif avg_precision >= baseline_precision:
                            st.warning(
                                f"‚ö†Ô∏è Mejora marginal (AP = {avg_precision:.3f})")
                        else:
                            st.error(
                                f"‚ùå Por debajo del baseline (AP = {avg_precision:.3f})")

                # An√°lisis de probabilidades de predicci√≥n
                st.markdown("### üìä Distribuci√≥n de Probabilidades")

                # Explicaci√≥n detallada sobre distribuci√≥n de probabilidades
                with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar la Distribuci√≥n de Probabilidades?", expanded=False):
                    st.markdown("""
                    **¬øQu√© muestra este gr√°fico?**
                    
                    Este histograma muestra c√≥mo el modelo asigna probabilidades a cada muestra del conjunto de prueba, 
                    separado por la clase real a la que pertenece cada muestra.
                    
                    **Elementos del gr√°fico:**
                    - **Histograma azul:** Distribuci√≥n de probabilidades para muestras que realmente pertenecen a la clase positiva
                    - **Histograma rojo:** Distribuci√≥n de probabilidades para muestras que realmente pertenecen a la clase negativa  
                    - **L√≠nea roja vertical:** Umbral de decisi√≥n (0.5 por defecto)
                    - **Eje X:** Probabilidad asignada por el modelo (0 = clase negativa, 1 = clase positiva)
                    - **Eje Y:** Cantidad de muestras
                    
                    **Interpretaci√≥n ideal:**
                    - ‚úÖ **Buena separaci√≥n:** Los histogramas no se superponen mucho
                    - ‚úÖ **Clase negativa:** Concentrada cerca de 0 (izquierda)
                    - ‚úÖ **Clase positiva:** Concentrada cerca de 1 (derecha)
                    - ‚úÖ **Pocas muestras cerca del umbral (0.5):** Indica confianza en las predicciones
                    
                    **Problemas a identificar:**
                    - ‚ö†Ô∏è **Mucha superposici√≥n:** Indica dificultad para separar las clases
                    - ‚ö†Ô∏è **Concentraci√≥n en el centro (0.3-0.7):** El modelo est√° inseguro
                    - ‚ö†Ô∏è **Distribuci√≥n uniforme:** El modelo no est√° aprendiendo patrones √∫tiles
                    
                    **Aplicaciones pr√°cticas:**
                    - Identificar si el modelo est√° confiado en sus predicciones
                    - Evaluar si cambiar el umbral de decisi√≥n podr√≠a mejorar el rendimiento
                    - Detectar casos donde el modelo necesita m√°s datos o caracter√≠sticas
                    """)

                # Verificar que tenemos datos v√°lidos
                if y_pred_proba is not None and len(y_pred_proba) > 0:
                    unique_classes = np.unique(y_test)

                    # Para clasificaci√≥n binaria
                    if len(unique_classes) == 2:
                        fig, ax = plt.subplots(figsize=(12, 6))

                        # Obtener probabilidades de la clase positiva
                        prob_class_1 = y_pred_proba[:, 1]

                        # Separar por clase real - usar los valores √∫nicos reales
                        mask_class_0 = (y_test == unique_classes[0])
                        mask_class_1 = (y_test == unique_classes[1])

                        prob_class_0_real = prob_class_1[mask_class_0]
                        prob_class_1_real = prob_class_1[mask_class_1]

                        # Crear histogramas solo si hay datos
                        if len(prob_class_0_real) > 0:
                            ax.hist(prob_class_0_real, bins=20, alpha=0.7,
                                    label=f'Clase {class_names[0] if class_names and len(class_names) > 0 else unique_classes[0]} (Real)',
                                    color='lightcoral', edgecolor='black')

                        if len(prob_class_1_real) > 0:
                            ax.hist(prob_class_1_real, bins=20, alpha=0.7,
                                    label=f'Clase {class_names[1] if class_names and len(class_names) > 1 else unique_classes[1]} (Real)',
                                    color='lightblue', edgecolor='black')

                        # L√≠nea del umbral de decisi√≥n
                        ax.axvline(x=0.5, color='red', linestyle='--',
                                   linewidth=2, label='Umbral de decisi√≥n (0.5)')

                        # Configurar el gr√°fico
                        ax.set_xlabel(
                            'Probabilidad de Clase Positiva', fontsize=12)
                        ax.set_ylabel('Frecuencia', fontsize=12)
                        ax.set_title('Distribuci√≥n de Probabilidades Predichas por Clase Real',
                                     fontsize=14, fontweight='bold')
                        ax.legend()
                        ax.grid(True, alpha=0.3)

                        # Asegurar l√≠mites apropiados
                        ax.set_xlim(0, 1)

                        plt.tight_layout()

                        # Mostrar el gr√°fico
                        col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                        with col2:
                            st.pyplot(fig, use_container_width=True)

                        # Limpiar la figura
                        plt.close(fig)

                        # An√°lisis de separaci√≥n
                        if len(prob_class_0_real) > 0 and len(prob_class_1_real) > 0:
                            # Contar solapamiento en la zona de incertidumbre (0.3-0.7)
                            overlap_0 = np.sum(
                                (prob_class_0_real > 0.3) & (prob_class_0_real < 0.7))
                            overlap_1 = np.sum(
                                (prob_class_1_real > 0.3) & (prob_class_1_real < 0.7))
                            total_overlap = overlap_0 + overlap_1

                            overlap_percentage = total_overlap / len(y_test)

                            # M√©tricas adicionales de separaci√≥n
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Muestras en zona incierta",
                                          f"{total_overlap}/{len(y_test)}")
                            with col2:
                                st.metric("Porcentaje de incertidumbre",
                                          f"{overlap_percentage:.1%}")
                            with col3:
                                conf_threshold = 0.8  # 80% de confianza
                                high_conf = np.sum((prob_class_1 < 0.2) | (
                                    prob_class_1 > conf_threshold))
                                st.metric("Predicciones confiables",
                                          f"{high_conf}/{len(y_test)}")

                            # Interpretaci√≥n
                            if overlap_percentage < 0.2:
                                st.success(
                                    "‚úÖ Excelente separaci√≥n entre clases - El modelo est√° muy confiado en sus predicciones")
                            elif overlap_percentage < 0.4:
                                st.info("üëç Buena separaci√≥n entre clases")
                            else:
                                st.warning(
                                    "‚ö†Ô∏è Las clases se superponen significativamente - Considera ajustar el umbral de decisi√≥n")

                    elif len(unique_classes) > 2:
                        # Para clasificaci√≥n multiclase
                        st.info(
                            "**Nota:** Clasificaci√≥n multiclase detectada. Mostrando distribuci√≥n de probabilidades para cada clase.")

                        n_classes = len(unique_classes)
                        n_cols = min(3, n_classes)
                        n_rows = (n_classes + n_cols - 1) // n_cols

                        fig, axes = plt.subplots(
                            n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))

                        # Manejar caso de una sola clase
                        if n_classes == 1:
                            axes = [axes]
                        elif n_rows == 1:
                            axes = axes if n_cols > 1 else [axes]
                        else:
                            axes = axes.flatten()

                        for i, class_val in enumerate(unique_classes):
                            if i < len(axes):
                                ax_sub = axes[i]

                                # Probabilidades para esta clase
                                class_probs = y_pred_proba[:, i]

                                ax_sub.hist(class_probs, bins=20, alpha=0.7,
                                            color=plt.cm.Set3(i), edgecolor='black')

                                class_label = class_names[i] if class_names and i < len(
                                    class_names) else f"Clase {class_val}"
                                ax_sub.set_title(
                                    f'Probabilidades para {class_label}')
                                ax_sub.set_xlabel('Probabilidad')
                                ax_sub.set_ylabel('Frecuencia')
                                ax_sub.grid(True, alpha=0.3)
                                ax_sub.set_xlim(0, 1)

                        # Ocultar subplots vac√≠os
                        for i in range(n_classes, len(axes)):
                            axes[i].set_visible(False)

                        plt.tight_layout()

                        col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                        with col2:
                            st.pyplot(fig, use_container_width=True)

                        plt.close(fig)
                    else:
                        st.error(
                            "Error: Datos de clasificaci√≥n insuficientes para crear la visualizaci√≥n")

                else:
                    st.error(
                        "Error: No hay probabilidades predichas disponibles. Aseg√∫rate de que el modelo est√© entrenado correctamente.")

                # An√°lisis de umbrales de decisi√≥n para clasificaci√≥n binaria
                if len(np.unique(y_test)) == 2:
                    st.markdown("### üéØ An√°lisis de Umbrales de Decisi√≥n")

                    # Explicaci√≥n detallada sobre umbrales de decisi√≥n
                    with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar el An√°lisis de Umbrales?", expanded=False):
                        st.markdown("""
                        **¬øQu√© es el umbral de decisi√≥n?**
                        
                        El umbral de decisi√≥n es el valor que determina cu√°ndo el modelo clasifica una muestra como 
                        positiva o negativa. Por defecto, este umbral es **0.5**:
                        - **Probabilidad ‚â• 0.5** ‚Üí Clase Positiva
                        - **Probabilidad < 0.5** ‚Üí Clase Negativa
                        
                        **¬øPor qu√© cambiar el umbral?**
                        
                        El umbral por defecto (0.5) no siempre es √≥ptimo. Dependiendo del problema, 
                        puede ser beneficioso ajustarlo:
                        
                        **üìà Umbral m√°s alto (0.6, 0.7, 0.8):**
                        - ‚úÖ **Mayor Precisi√≥n:** Menos falsos positivos
                        - ‚úÖ **Predicciones m√°s conservadoras:** Solo clasifica como positivo cuando est√° muy seguro
                        - ‚ö†Ô∏è **Menor Recall:** Puede perder casos positivos reales
                        - **√ötil cuando:** Los falsos positivos son muy costosos (ej: diagn√≥stico m√©dico, inversiones)
                        
                        **üìâ Umbral m√°s bajo (0.3, 0.4):**
                        - ‚úÖ **Mayor Recall:** Detecta m√°s casos positivos reales
                        - ‚úÖ **Predicciones m√°s sensibles:** No se pierde tantos casos positivos
                        - ‚ö†Ô∏è **Menor Precisi√≥n:** M√°s falsos positivos
                        - **√ötil cuando:** Los falsos negativos son muy costosos (ej: detecci√≥n de fraude, seguridad)
                        
                        **M√©tricas mostradas:**
                        - **Accuracy:** Porcentaje total de predicciones correctas
                        - **Precision:** De las predicciones positivas, cu√°ntas son correctas
                        - **Recall:** De los casos positivos reales, cu√°ntos detectamos
                        - **F1-Score:** Balance entre precisi√≥n y recall
                        
                        **¬øC√≥mo elegir el umbral √≥ptimo?**
                        1. **Maximizar F1-Score:** Balance general entre precisi√≥n y recall
                        2. **Maximizar Precision:** Si los falsos positivos son costosos
                        3. **Maximizar Recall:** Si los falsos negativos son costosos
                        4. **Considerar el contexto:** Costos reales de errores en tu dominio
                        
                        **Ejemplo pr√°ctico:**
                        - **Email spam:** Prefiere falsos positivos (email importante en spam) que falsos negativos
                        - **Diagn√≥stico m√©dico:** Prefiere falsos positivos (m√°s pruebas) que falsos negativos (enfermedad no detectada)
                        - **Recomendaciones:** Balance entre no molestar (precisi√≥n) y no perder oportunidades (recall)
                        """)

                    # Calcular m√©tricas para diferentes umbrales
                    thresholds = np.arange(0.1, 1.0, 0.1)
                    threshold_metrics = []

                    for threshold in thresholds:
                        y_pred_thresh = (
                            y_pred_proba[:, 1] >= threshold).astype(int)

                        if len(np.unique(y_pred_thresh)) > 1:  # Evitar divisi√≥n por cero
                            from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
                            precision = precision_score(
                                y_test, y_pred_thresh, zero_division=0)
                            recall = recall_score(
                                y_test, y_pred_thresh, zero_division=0)
                            f1 = f1_score(y_test, y_pred_thresh,
                                          zero_division=0)
                            accuracy = accuracy_score(y_test, y_pred_thresh)

                            threshold_metrics.append({
                                'Umbral': threshold,
                                'Accuracy': accuracy,
                                'Precision': precision,
                                'Recall': recall,
                                'F1-Score': f1
                            })

                    if threshold_metrics:
                        df_thresholds = pd.DataFrame(threshold_metrics)

                        # Encontrar el mejor umbral por F1-Score
                        best_f1_idx = df_thresholds['F1-Score'].idxmax()
                        best_threshold = df_thresholds.loc[best_f1_idx, 'Umbral']

                        col1, col2 = st.columns(2)

                        with col1:
                            st.metric("Umbral Actual", "0.50")
                            st.metric("Umbral √ìptimo (F1)",
                                      f"{best_threshold:.2f}")

                            if abs(best_threshold - 0.5) > 0.1:
                                st.info(
                                    f"üí° Considera ajustar el umbral a {best_threshold:.2f} para mejorar el F1-Score")

                        with col2:
                            # Mostrar tabla de umbrales (seleccionados)
                            display_thresholds = df_thresholds[df_thresholds['Umbral'].isin(
                                [0.3, 0.5, 0.7])].copy()
                            for col in ['Accuracy', 'Precision', 'Recall', 'F1-Score']:
                                display_thresholds[col] = display_thresholds[col].apply(
                                    lambda x: f"{x:.3f}")

                            st.markdown("**Comparaci√≥n de Umbrales:**")
                            st.dataframe(
                                display_thresholds, hide_index=True, use_container_width=True)

        else:
            st.info("Entrena un modelo primero para ver las visualizaciones.")

    # Pesta√±a de Coeficientes
    elif st.session_state.active_tab_lr == 4:
        st.header("Coeficientes del Modelo")

        if st.session_state.get('model_trained_lr', False):
            model = st.session_state.get('model_lr')
            feature_names = st.session_state.get('feature_names_lr', [])
            model_type = st.session_state.get('model_type_lr', 'Linear')

            # Informaci√≥n sobre los coeficientes
            with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar los coeficientes?", expanded=False):
                if model_type == "Linear":
                    st.markdown("""
                    # üìà **Coeficientes en Regresi√≥n Lineal**
                    
                    ## üéØ **¬øQu√© representan los coeficientes?**
                    
                    Los coeficientes son los **par√°metros aprendidos** por el modelo que determinan c√≥mo cada caracter√≠stica 
                    influye en la predicci√≥n final. La f√≥rmula de regresi√≥n lineal es:
                    
                    ```
                    Predicci√≥n = Œ≤‚ÇÄ + Œ≤‚ÇÅ√óX‚ÇÅ + Œ≤‚ÇÇ√óX‚ÇÇ + ... + Œ≤‚Çô√óX‚Çô
                    ```
                    
                    Donde cada **Œ≤·µ¢** es un coeficiente que indica el cambio en la variable objetivo 
                    por cada unidad de cambio en la caracter√≠stica correspondiente.
                    
                    ## üîç **Interpretaci√≥n Detallada:**
                    
                    ### **Valor del Coeficiente (Magnitud):**
                    - **Valor absoluto grande (ej: |5.2|):** La caracter√≠stica tiene **alta influencia**
                    - **Valor absoluto peque√±o (ej: |0.1|):** La caracter√≠stica tiene **baja influencia**
                    - **Valor cero (0.0):** La caracter√≠stica **no influye** en la predicci√≥n
                    
                    ### **Signo del Coeficiente (Direcci√≥n):**
                    - **Positivo (+):** üìà **Relaci√≥n directa** - A mayor valor de X, mayor valor de Y
                    - **Negativo (-):** üìâ **Relaci√≥n inversa** - A mayor valor de X, menor valor de Y
                    
                    ### **Unidades:**
                    Los coeficientes mantienen las **unidades originales**. Si predices precios en euros 
                    y una caracter√≠stica est√° en metros¬≤, un coeficiente de 150 significa 
                    **+150 euros por cada metro¬≤ adicional**.
                    
                    ## üí° **Ejemplos Pr√°cticos:**
                    
                    **üè† Predicci√≥n de Precios de Casas:**
                    - `Tama√±o = +150`: Cada m¬≤ adicional aumenta el precio en 150‚Ç¨
                    - `Antig√ºedad = -500`: Cada a√±o adicional reduce el precio en 500‚Ç¨
                    - `Habitaciones = +2000`: Cada habitaci√≥n adicional aumenta el precio en 2000‚Ç¨
                    
                    **üìä Predicci√≥n de Ventas:**
                    - `Presupuesto_Marketing = +1.5`: Cada euro en marketing genera 1.5‚Ç¨ en ventas
                    - `Competencia = -0.8`: Cada competidor adicional reduce ventas en 0.8‚Ç¨
                    
                    ## ‚ö†Ô∏è **Limitaciones y Consideraciones:**
                    
                    1. **Correlaci√≥n ‚â† Causalidad:** Un coeficiente alto no implica que la caracter√≠stica cause el resultado
                    2. **Escalas diferentes:** Caracter√≠sticas con diferentes escalas pueden tener coeficientes incomparables
                    3. **Multicolinealidad:** Caracter√≠sticas correlacionadas pueden tener coeficientes inestables
                    4. **Outliers:** Valores extremos pueden afectar significativamente los coeficientes
                    
                    ## üéõÔ∏è **C√≥mo usar esta informaci√≥n:**
                    
                    - **Identificar factores clave:** Coeficientes con mayor valor absoluto
                    - **Validar intuici√≥n:** ¬øLos signos coinciden con el conocimiento del dominio?
                    - **Tomar decisiones:** ¬øEn qu√© caracter√≠sticas enfocar esfuerzos?
                    - **Detectar problemas:** ¬øHay coeficientes que no tienen sentido?
                    """)
                else:
                    st.markdown("""
                    # üéØ **Coeficientes en Regresi√≥n Log√≠stica**
                    
                    ## üéØ **¬øQu√© representan los coeficientes?**
                    
                    En regresi√≥n log√≠stica, los coeficientes representan el **cambio en log-odds** 
                    (logaritmo de las probabilidades) por cada unidad de cambio en la caracter√≠stica. 
                    La f√≥rmula es:
                    
                    ```
                    log(odds) = Œ≤‚ÇÄ + Œ≤‚ÇÅ√óX‚ÇÅ + Œ≤‚ÇÇ√óX‚ÇÇ + ... + Œ≤‚Çô√óX‚Çô
                    odds = e^(Œ≤‚ÇÄ + Œ≤‚ÇÅ√óX‚ÇÅ + Œ≤‚ÇÇ√óX‚ÇÇ + ... + Œ≤‚Çô√óX‚Çô)
                    probabilidad = odds / (1 + odds)
                    ```
                    
                    ## üîç **Interpretaci√≥n de Log-Odds:**
                    
                    ### **Valor del Coeficiente:**
                    - **Positivo (+):** üìà **Aumenta** la probabilidad de la clase positiva
                    - **Negativo (-):** üìâ **Disminuye** la probabilidad de la clase positiva
                    - **Cero (0.0):** **No afecta** la probabilidad
                    
                    ### **Magnitud del Coeficiente:**
                    - **|Œ≤| > 2:** **Efecto muy fuerte** (odds ratio > 7.4)
                    - **1 < |Œ≤| < 2:** **Efecto fuerte** (odds ratio entre 2.7 y 7.4)
                    - **0.5 < |Œ≤| < 1:** **Efecto moderado** (odds ratio entre 1.6 y 2.7)
                    - **|Œ≤| < 0.5:** **Efecto d√©bil** (odds ratio < 1.6)
                    
                    ## üìä **Conversi√≥n a Odds Ratios (M√°s Intuitivo):**
                    
                    Los **Odds Ratios** se calculan como `e^Œ≤` y son m√°s f√°ciles de interpretar:
                    
                    ### **Interpretaci√≥n de Odds Ratios:**
                    - **OR = 1:** La caracter√≠stica **no tiene efecto**
                    - **OR > 1:** La caracter√≠stica **aumenta** las odds de la clase positiva
                    - **OR < 1:** La caracter√≠stica **disminuye** las odds de la clase positiva
                    
                    ### **Ejemplos de Odds Ratios:**
                    - **OR = 2.0:** Duplica las odds (100% de aumento)
                    - **OR = 1.5:** Aumenta las odds en 50%
                    - **OR = 0.5:** Reduce las odds a la mitad (50% de reducci√≥n)
                    - **OR = 0.2:** Reduce las odds en 80%
                    
                    ## üí° **Ejemplos Pr√°cticos:**
                    
                    **üè• Diagn√≥stico M√©dico (Predicci√≥n de Enfermedad):**
                    - `Edad = +0.05 (OR=1.05)`: Cada a√±o adicional aumenta las odds en 5%
                    - `Ejercicio = -1.2 (OR=0.30)`: Hacer ejercicio reduce las odds en 70%
                    - `Fumador = +1.8 (OR=6.05)`: Ser fumador multiplica las odds por 6
                    
                    **üìß Clasificaci√≥n de Spam:**
                    - `Palabras_Sospechosas = +2.3 (OR=10.0)`: Multiplica las odds de spam por 10
                    - `Remitente_Conocido = -1.5 (OR=0.22)`: Reduce las odds de spam en 78%
                    
                    **üí≥ Detecci√≥n de Fraude:**
                    - `Hora_Inusual = +1.1 (OR=3.0)`: Triplica las odds de fraude
                    - `Ubicacion_Habitual = -2.0 (OR=0.14)`: Reduce las odds de fraude en 86%
                    
                    ## ‚ö†Ô∏è **Limitaciones y Consideraciones:**
                    
                    1. **Interpretaci√≥n no lineal:** El efecto en probabilidades no es constante
                    2. **Asunciones de linealidad:** En el espacio log-odds, no en probabilidades
                    3. **Interacciones ignoradas:** Los efectos pueden depender de otras variables
                    4. **Escalas importantes:** Normalizar puede facilitar la interpretaci√≥n
                    
                    ## üéõÔ∏è **C√≥mo usar esta informaci√≥n:**
                    
                    ### **Para el Negocio:**
                    - **Identificar factores de riesgo:** Coeficientes positivos altos
                    - **Encontrar factores protectores:** Coeficientes negativos altos
                    - **Priorizar intervenciones:** Enfocarse en variables con mayor impacto
                    
                    ### **Para el Modelo:**
                    - **Validar coherencia:** ¬øLos signos tienen sentido del dominio?
                    - **Detectar overfitting:** ¬øCoeficientes extremadamente grandes?
                    - **Selecci√≥n de caracter√≠sticas:** ¬øCoeficientes cerca de cero?
                    
                    ## üßÆ **F√≥rmula de Conversi√≥n:**
                    ```python
                    # De coeficiente a odds ratio
                    odds_ratio = np.exp(coeficiente)
                    
                    # Cambio porcentual en odds
                    cambio_porcentual = (odds_ratio - 1) * 100
                    ```
                    """)

            if model is not None and hasattr(model, 'coef_'):
                try:
                    # Preparar datos de coeficientes de forma robusta
                    coef_raw = model.coef_
                    class_names = st.session_state.get('class_names_lr', [])

                    # Para regresi√≥n log√≠stica binaria, coef_ tiene forma (1, n_features)
                    # Para regresi√≥n log√≠stica multiclase, coef_ tiene forma (n_classes, n_features)
                    # Para regresi√≥n lineal, coef_ tiene forma (n_features,)

                    if len(coef_raw.shape) == 2:
                        # Es una matriz 2D (regresi√≥n log√≠stica)
                        if coef_raw.shape[0] == 1:
                            # Clasificaci√≥n binaria: tomar la primera (y √∫nica) fila
                            coefficients = coef_raw[0]
                            is_multiclass = False
                        else:
                            # Clasificaci√≥n multiclase: mostrar nota informativa
                            # Usar primera clase por defecto
                            coefficients = coef_raw[0]
                            is_multiclass = True

                            st.info(
                                f"**Nota:** Este es un modelo de clasificaci√≥n multiclase con {coef_raw.shape[0]} clases. Mostrando los coeficientes para la primera clase ({class_names[0] if class_names else 'Clase 0'}).")

                            # Opci√≥n para seleccionar qu√© clase mostrar
                            if class_names and len(class_names) == coef_raw.shape[0]:
                                selected_class = st.selectbox(
                                    "Selecciona la clase para mostrar coeficientes:",
                                    options=range(len(class_names)),
                                    format_func=lambda x: class_names[x],
                                    index=0
                                )
                                coefficients = coef_raw[selected_class]
                    else:
                        # Es un vector 1D (regresi√≥n lineal)
                        coefficients = coef_raw
                        is_multiclass = False

                    # Asegurar que coefficients es un array 1D
                    coefficients = np.array(coefficients).flatten()

                    # Verificar que las longitudes coincidan
                    if len(coefficients) != len(feature_names):
                        st.error(
                            f"Error: Se encontraron {len(coefficients)} coeficientes pero {len(feature_names)} caracter√≠sticas.")
                        st.error(f"Forma de coef_: {coef_raw.shape}")
                        st.error(f"Caracter√≠sticas: {feature_names}")
                        return

                    coef_df = pd.DataFrame({
                        'Caracter√≠stica': feature_names,
                        'Coeficiente': coefficients,
                        'Valor_Absoluto': np.abs(coefficients)
                    })

                except Exception as e:
                    st.error(f"Error al procesar los coeficientes: {str(e)}")
                    st.error(f"Forma de model.coef_: {model.coef_.shape}")
                    st.error(
                        f"N√∫mero de caracter√≠sticas: {len(feature_names)}")
                    return
                coef_df = coef_df.sort_values(
                    'Valor_Absoluto', ascending=False)

                # A√±adir interpretaci√≥n
                coef_df['Efecto'] = coef_df['Coeficiente'].apply(
                    lambda x: 'üìà Positivo' if x > 0 else 'üìâ Negativo'
                )
                coef_df['Importancia'] = coef_df['Valor_Absoluto'].apply(
                    lambda x: 'üî• Alta' if x > coef_df['Valor_Absoluto'].quantile(0.75)
                    else ('üî∂ Media' if x > coef_df['Valor_Absoluto'].quantile(0.25) else 'üîπ Baja')
                )

                # Mostrar tabla de coeficientes
                st.markdown("### üìä Tabla de Coeficientes")

                # Crear tabla mejorada con informaci√≥n adicional para regresi√≥n log√≠stica
                if model_type == "Logistic":
                    # Agregar odds ratios y cambios porcentuales
                    coef_df['Odds_Ratio'] = np.exp(coef_df['Coeficiente'])
                    coef_df['Cambio_Porcentual'] = (
                        coef_df['Odds_Ratio'] - 1) * 100

                    # Interpretaci√≥n de la magnitud del efecto
                    def interpretar_efecto_logistico(odds_ratio):
                        if odds_ratio > 7.4:  # |coef| > 2
                            return 'üî• Muy Fuerte'
                        elif odds_ratio > 2.7:  # |coef| > 1
                            return 'üî• Fuerte'
                        elif odds_ratio > 1.6 or odds_ratio < 0.625:  # |coef| > 0.5
                            return 'üî∂ Moderado'
                        else:
                            return 'üîπ D√©bil'

                    coef_df['Fuerza_Efecto'] = coef_df['Odds_Ratio'].apply(
                        interpretar_efecto_logistico)

                    # Formatear la tabla para regresi√≥n log√≠stica
                    display_df = coef_df[[
                        'Caracter√≠stica', 'Coeficiente', 'Odds_Ratio', 'Cambio_Porcentual', 'Efecto', 'Fuerza_Efecto']].copy()
                    display_df['Coeficiente'] = display_df['Coeficiente'].apply(
                        lambda x: f"{x:.4f}")
                    display_df['Odds_Ratio'] = display_df['Odds_Ratio'].apply(
                        lambda x: f"{x:.3f}")
                    display_df['Cambio_Porcentual'] = display_df['Cambio_Porcentual'].apply(
                        lambda x: f"{x:+.1f}%")

                    # Renombrar columnas para mayor claridad
                    display_df = display_df.rename(columns={
                        'Odds_Ratio': 'Odds Ratio',
                        'Cambio_Porcentual': 'Cambio en Odds',
                        'Fuerza_Efecto': 'Fuerza del Efecto'
                    })

                    st.dataframe(
                        display_df, use_container_width=True, hide_index=True)

                    # Explicaci√≥n de la tabla para regresi√≥n log√≠stica
                    with st.expander("üìñ ¬øC√≥mo leer esta tabla?", expanded=False):
                        st.markdown("""
                        **Columnas de la tabla:**
                        
                        - **Coeficiente:** Valor original del modelo (log-odds)
                        - **Odds Ratio:** `e^coeficiente` - M√°s f√°cil de interpretar
                        - **Cambio en Odds:** Cambio porcentual en las odds
                        - **Efecto:** Direcci√≥n del efecto (positivo/negativo)
                        - **Fuerza del Efecto:** Magnitud del impacto
                        
                        **Interpretaci√≥n de Odds Ratio:**
                        - **OR = 1.0:** Sin efecto
                        - **OR > 1.0:** Aumenta las odds (efecto positivo)
                        - **OR < 1.0:** Disminuye las odds (efecto negativo)
                        
                        **Ejemplos:**
                        - **OR = 2.0:** Duplica las odds (+100%)
                        - **OR = 1.5:** Aumenta las odds en 50%
                        - **OR = 0.5:** Reduce las odds a la mitad (-50%)
                        - **OR = 0.2:** Reduce las odds en 80%
                        """)

                else:
                    # Tabla est√°ndar para regresi√≥n lineal
                    display_df = coef_df[[
                        'Caracter√≠stica', 'Coeficiente', 'Efecto', 'Importancia']].copy()
                    display_df['Coeficiente'] = display_df['Coeficiente'].apply(
                        lambda x: f"{x:.4f}")

                    st.dataframe(
                        display_df, use_container_width=True, hide_index=True)

                    # Explicaci√≥n de la tabla para regresi√≥n lineal
                    with st.expander("üìñ ¬øC√≥mo leer esta tabla?", expanded=False):
                        st.markdown("""
                        **Columnas de la tabla:**
                        
                        - **Coeficiente:** Cambio en la variable objetivo por unidad de cambio en la caracter√≠stica
                        - **Efecto:** Direcci√≥n de la relaci√≥n (positiva/negativa)
                        - **Importancia:** Magnitud relativa del efecto
                        
                        **Interpretaci√≥n directa:**
                        - Un coeficiente de **+50** significa que cada unidad adicional de esa caracter√≠stica 
                          aumenta la predicci√≥n en 50 unidades
                        - Un coeficiente de **-20** significa que cada unidad adicional de esa caracter√≠stica 
                          disminuye la predicci√≥n en 20 unidades
                        """)

                # Mostrar intercepto si existe
                if hasattr(model, 'intercept_'):
                    st.markdown("### üéØ Intercepto del Modelo")
                    intercept = model.intercept_[0] if hasattr(
                        model.intercept_, '__len__') else model.intercept_

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Intercepto", f"{intercept:.4f}")

                    if model_type == "Logistic":
                        with col2:
                            intercept_odds_ratio = np.exp(intercept)
                            st.metric("Odds Ratio Base",
                                      f"{intercept_odds_ratio:.3f}")

                        st.info(
                            f"**Interpretaci√≥n:** Cuando todas las caracter√≠sticas son 0, el log-odds base es {intercept:.4f} "
                            f"(Odds Ratio = {intercept_odds_ratio:.3f})")
                    else:
                        st.info(
                            f"**Interpretaci√≥n:** Cuando todas las caracter√≠sticas son 0, el modelo predice un valor de {intercept:.4f}")

                # Gr√°fico de coeficientes
                st.markdown("### üìà Visualizaci√≥n de Coeficientes")

                fig, ax = plt.subplots(
                    figsize=(12, max(6, len(feature_names) * 0.4)))

                # Crear gr√°fico de barras horizontal
                colors = ['#ff6b6b' if x <
                          0 else '#4ecdc4' for x in coef_df['Coeficiente']]
                bars = ax.barh(range(
                    len(coef_df)), coef_df['Coeficiente'], color=colors, alpha=0.7, edgecolor='black')

                # Personalizaci√≥n
                ax.set_yticks(range(len(coef_df)))
                ax.set_yticklabels(coef_df['Caracter√≠stica'], fontsize=10)
                ax.set_xlabel('Valor del Coeficiente', fontsize=12)
                ax.set_title(
                    'Coeficientes del Modelo (ordenados por importancia)', fontsize=14, fontweight='bold')
                ax.axvline(x=0, color='black', linestyle='-',
                           alpha=0.8, linewidth=1)
                ax.grid(True, alpha=0.3, axis='x')

                # A√±adir valores en las barras
                for i, (bar, coef) in enumerate(zip(bars, coef_df['Coeficiente'])):
                    width = bar.get_width()
                    ax.text(width + (0.01 * (max(coef_df['Coeficiente']) - min(coef_df['Coeficiente']))) if width >= 0
                            else width - (0.01 * (max(coef_df['Coeficiente']) - min(coef_df['Coeficiente']))),
                            bar.get_y() + bar.get_height()/2,
                            f'{coef:.3f}', ha='left' if width >= 0 else 'right', va='center', fontsize=9)

                # Leyenda
                from matplotlib.patches import Patch
                legend_elements = [
                    Patch(facecolor='#4ecdc4', alpha=0.7,
                          label='Efecto Positivo'),
                    Patch(facecolor='#ff6b6b', alpha=0.7,
                          label='Efecto Negativo')
                ]
                ax.legend(handles=legend_elements, loc='upper right')

                plt.tight_layout()

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # An√°lisis de importancia
                st.markdown("### üîç An√°lisis Detallado de Importancia")

                # Identificar las caracter√≠sticas m√°s importantes
                top_features = coef_df.head(5)  # Mostrar top 5 en lugar de 3

                # An√°lisis diferenciado por tipo de modelo
                if model_type == "Logistic":
                    st.markdown(
                        "#### üéØ **Caracter√≠sticas que M√ÅS aumentan la probabilidad:**")
                    positive_features = coef_df[coef_df['Coeficiente'] > 0].head(
                        3)

                    if len(positive_features) > 0:
                        for i, row in positive_features.iterrows():
                            odds_ratio = np.exp(row['Coeficiente'])
                            cambio_pct = (odds_ratio - 1) * 100

                            # Determinar la intensidad del efecto
                            if odds_ratio > 3:
                                intensidad = "üî• **FUERTE**"
                            elif odds_ratio > 1.5:
                                intensidad = "üî∂ **MODERADO**"
                            else:
                                intensidad = "üîπ **D√âBIL**"

                            st.markdown(f"""
                            **{i+1}. {row['Caracter√≠stica']}** {intensidad}
                            - Coeficiente: `{row['Coeficiente']:.4f}`
                            - Odds Ratio: `{odds_ratio:.3f}`
                            - **Impacto:** Cada unidad adicional **multiplica las odds por {odds_ratio:.2f}** (aumenta {cambio_pct:+.1f}%)
                            """)
                    else:
                        st.info(
                            "No hay caracter√≠sticas que aumenten significativamente la probabilidad.")

                    st.markdown(
                        "#### üìâ **Caracter√≠sticas que M√ÅS disminuyen la probabilidad:**")
                    negative_features = coef_df[coef_df['Coeficiente'] < 0].head(
                        3)

                    if len(negative_features) > 0:
                        for i, row in negative_features.iterrows():
                            odds_ratio = np.exp(row['Coeficiente'])
                            reduccion_pct = (1 - odds_ratio) * 100

                            # Determinar la intensidad del efecto
                            if odds_ratio < 0.33:  # Reduce a menos de 1/3
                                intensidad = "üî• **FUERTE**"
                            elif odds_ratio < 0.67:  # Reduce a menos de 2/3
                                intensidad = "üî∂ **MODERADO**"
                            else:
                                intensidad = "üîπ **D√âBIL**"

                            st.markdown(f"""
                            **{i+1}. {row['Caracter√≠stica']}** {intensidad}
                            - Coeficiente: `{row['Coeficiente']:.4f}`
                            - Odds Ratio: `{odds_ratio:.3f}`
                            - **Impacto:** Cada unidad adicional **reduce las odds en {reduccion_pct:.1f}%**
                            """)
                    else:
                        st.info(
                            "No hay caracter√≠sticas que disminuyan significativamente la probabilidad.")

                    # Resumen ejecutivo para regresi√≥n log√≠stica
                    st.markdown("#### üìã **Resumen Ejecutivo:**")

                    # Caracter√≠stica m√°s influyente
                    most_influential = coef_df.iloc[0]
                    odds_ratio_most = np.exp(most_influential['Coeficiente'])

                    if most_influential['Coeficiente'] > 0:
                        impacto_desc = f"multiplica las odds por {odds_ratio_most:.2f}"
                    else:
                        reduccion = (1 - odds_ratio_most) * 100
                        impacto_desc = f"reduce las odds en {reduccion:.1f}%"

                    st.success(f"""
                    üéØ **Factor m√°s determinante:** `{most_influential['Caracter√≠stica']}`
                    
                    Esta caracter√≠stica es la que mayor impacto tiene en las predicciones del modelo.
                    Cada unidad adicional {impacto_desc}.
                    """)

                    # Verificar balance de efectos
                    n_positive = len(coef_df[coef_df['Coeficiente'] > 0])
                    n_negative = len(coef_df[coef_df['Coeficiente'] < 0])

                    if n_positive == 0:
                        st.warning(
                            "‚ö†Ô∏è **Atenci√≥n:** Todas las caracter√≠sticas reducen la probabilidad. Verifica que el modelo est√© bien entrenado.")
                    elif n_negative == 0:
                        st.warning(
                            "‚ö†Ô∏è **Atenci√≥n:** Todas las caracter√≠sticas aumentan la probabilidad. Verifica que el modelo est√© bien entrenado.")
                    else:
                        st.info(
                            f"‚úÖ **Balance:** {n_positive} caracter√≠sticas aumentan y {n_negative} disminuyen la probabilidad.")

                else:  # Regresi√≥n lineal
                    st.markdown(
                        "#### üìà **Caracter√≠sticas que M√ÅS aumentan el valor predicho:**")
                    positive_features = coef_df[coef_df['Coeficiente'] > 0].head(
                        3)

                    if len(positive_features) > 0:
                        for i, row in positive_features.iterrows():
                            coef_val = row['Coeficiente']

                            # Determinar la intensidad del efecto
                            abs_coef = abs(coef_val)
                            if abs_coef > coef_df['Valor_Absoluto'].quantile(0.8):
                                intensidad = "üî• **FUERTE**"
                            elif abs_coef > coef_df['Valor_Absoluto'].quantile(0.6):
                                intensidad = "üî∂ **MODERADO**"
                            else:
                                intensidad = "üîπ **D√âBIL**"

                            st.markdown(f"""
                            **{i+1}. {row['Caracter√≠stica']}** {intensidad}
                            - Coeficiente: `{coef_val:.4f}`
                            - **Impacto:** Cada unidad adicional **aumenta la predicci√≥n en {coef_val:.3f} unidades**
                            """)
                    else:
                        st.info(
                            "No hay caracter√≠sticas que aumenten significativamente el valor predicho.")

                    st.markdown(
                        "#### üìâ **Caracter√≠sticas que M√ÅS disminuyen el valor predicho:**")
                    negative_features = coef_df[coef_df['Coeficiente'] < 0].head(
                        3)

                    if len(negative_features) > 0:
                        for i, row in negative_features.iterrows():
                            coef_val = row['Coeficiente']

                            # Determinar la intensidad del efecto
                            abs_coef = abs(coef_val)
                            if abs_coef > coef_df['Valor_Absoluto'].quantile(0.8):
                                intensidad = "üî• **FUERTE**"
                            elif abs_coef > coef_df['Valor_Absoluto'].quantile(0.6):
                                intensidad = "üî∂ **MODERADO**"
                            else:
                                intensidad = "üîπ **D√âBIL**"

                            st.markdown(f"""
                            **{i+1}. {row['Caracter√≠stica']}** {intensidad}
                            - Coeficiente: `{coef_val:.4f}`
                            - **Impacto:** Cada unidad adicional **disminuye la predicci√≥n en {abs(coef_val):.3f} unidades**
                            """)
                    else:
                        st.info(
                            "No hay caracter√≠sticas que disminuyan significativamente el valor predicho.")

                    # Resumen ejecutivo para regresi√≥n lineal
                    st.markdown("#### üìã **Resumen Ejecutivo:**")

                    most_influential = coef_df.iloc[0]
                    coef_val = most_influential['Coeficiente']

                    if coef_val > 0:
                        impacto_desc = f"aumenta la predicci√≥n en {coef_val:.3f} unidades"
                    else:
                        impacto_desc = f"disminuye la predicci√≥n en {abs(coef_val):.3f} unidades"

                    st.success(f"""
                    üéØ **Factor m√°s determinante:** `{most_influential['Caracter√≠stica']}`
                    
                    Esta caracter√≠stica tiene el mayor impacto absoluto en las predicciones.
                    Cada unidad adicional {impacto_desc}.
                    """)

                # Recomendaciones generales
                st.markdown("#### üí° **Recomendaciones para la Acci√≥n:**")

                # Identificar caracter√≠sticas controlables vs no controlables
                top_3 = coef_df.head(3)

                recommendations = []
                for i, row in top_3.iterrows():
                    feature_name = row['Caracter√≠stica']
                    effect_direction = "aumentar" if row['Coeficiente'] > 0 else "reducir"
                    target = "probabilidad positiva" if model_type == "Logistic" else "valor predicho"

                    recommendations.append(
                        f"**{feature_name}:** {effect_direction.capitalize()} esta caracter√≠stica para {'incrementar' if row['Coeficiente'] > 0 else 'decrementar'} la {target}")

                for i, rec in enumerate(recommendations, 1):
                    st.markdown(f"{i}. {rec}")

                # Warning para coeficientes extremos
                extreme_coefs = coef_df[coef_df['Valor_Absoluto']
                                        > coef_df['Valor_Absoluto'].quantile(0.95)]
                if len(extreme_coefs) > 0:
                    st.warning(f"""
                    ‚ö†Ô∏è **Atenci√≥n - Coeficientes Extremos Detectados:**
                    
                    Las siguientes caracter√≠sticas tienen coeficientes muy altos: {', '.join(extreme_coefs['Caracter√≠stica'].tolist())}
                    
                    Esto podr√≠a indicar:
                    - Overfitting del modelo
                    - Escalas muy diferentes entre caracter√≠sticas
                    - Multicolinealidad entre variables
                    - Outliers en los datos
                    
                    **Recomendaci√≥n:** Considera normalizar las caracter√≠sticas o revisar la calidad de los datos.
                    """)

            else:
                st.error("El modelo no tiene coeficientes disponibles.")
        else:
            st.info("Entrena un modelo primero para ver los coeficientes.")

    # Pesta√±a de Predicciones
    elif st.session_state.active_tab_lr == 5:
        st.header("Hacer Predicciones")

        if st.session_state.get('model_trained_lr', False):
            model = st.session_state.get('model_lr')
            feature_names = st.session_state.get('feature_names_lr', [])
            dataset_name = st.session_state.get('selected_dataset_lr', '')
            X_train = st.session_state.get('X_train_lr')
            class_names = st.session_state.get('class_names_lr', [])
            model_type = st.session_state.get('model_type_lr', 'Linear')
            task_type = st.session_state.get('task_type_lr', 'Regresi√≥n')

            # Obtener metadata del dataset para adaptar los inputs
            from dataset_metadata import get_dataset_metadata
            metadata = get_dataset_metadata(dataset_name)
            feature_descriptions = metadata.get('feature_descriptions', {})
            value_mappings = metadata.get('value_mappings', {})
            original_to_display = metadata.get('original_to_display', {})
            categorical_features = metadata.get('categorical_features', [])

            st.markdown("### Ingresa los valores para hacer una predicci√≥n")

            # Analizar caracter√≠sticas si tenemos datos de entrenamiento
            feature_info = {}
            if X_train is not None:
                # Convertir a DataFrame si es necesario
                if hasattr(X_train, 'columns'):
                    column_names = X_train.columns
                else:
                    column_names = range(len(feature_names))

                for i, feature_display_name in enumerate(feature_names):
                    # Obtener el nombre original de la columna
                    if i < len(column_names):
                        original_col_name = column_names[i]
                    else:
                        original_col_name = feature_display_name

                    # Encontrar el nombre original usando reverse mapping
                    reverse_mapping = {v: k for k,
                                       v in original_to_display.items()}
                    if feature_display_name in reverse_mapping:
                        original_col_name = reverse_mapping[feature_display_name]

                    # Usar el √≠ndice para acceder a las columnas
                    if hasattr(X_train, 'iloc'):
                        feature_col = X_train.iloc[:, i]
                    else:
                        feature_col = X_train[:, i]

                    # Determinar tipo de caracter√≠stica
                    unique_values = len(set(feature_col)) if hasattr(
                        feature_col, '__iter__') else 10
                    unique_vals = sorted(list(set(feature_col))) if hasattr(
                        feature_col, '__iter__') else [0, 1]

                    # Verificar si es categ√≥rica seg√∫n metadata
                    is_categorical_by_metadata = original_col_name in categorical_features

                    if unique_values <= 2:
                        feature_type = 'binary'
                    elif unique_values <= 10 and (all(isinstance(x, (int, float)) and x == int(x) for x in unique_vals) or is_categorical_by_metadata):
                        feature_type = 'categorical'
                    else:
                        feature_type = 'continuous'

                    # Preparar informaci√≥n de la caracter√≠stica
                    if feature_type in ['binary', 'categorical'] and original_col_name in value_mappings:
                        display_values = []
                        value_to_original = {}
                        for orig_val in unique_vals:
                            if orig_val in value_mappings[original_col_name]:
                                display_val = value_mappings[original_col_name][orig_val]
                                display_values.append(display_val)
                                value_to_original[display_val] = orig_val
                            else:
                                display_values.append(str(orig_val))
                                value_to_original[str(orig_val)] = orig_val

                        feature_info[i] = {
                            'type': feature_type,
                            'values': unique_vals,
                            'display_values': display_values,
                            'value_to_original': value_to_original,
                            'original_column': original_col_name,
                            'display_name': feature_display_name
                        }
                    else:
                        feature_info[i] = {
                            'type': feature_type,
                            'values': unique_vals,
                            'min': float(min(unique_vals)) if feature_type == 'continuous' else min(unique_vals),
                            'max': float(max(unique_vals)) if feature_type == 'continuous' else max(unique_vals),
                            'mean': float(sum(feature_col) / len(feature_col)) if feature_type == 'continuous' and hasattr(feature_col, '__iter__') else None,
                            'original_column': original_col_name,
                            'display_name': feature_display_name
                        }
            else:
                # Valores por defecto si no hay datos de entrenamiento
                for i, feature in enumerate(feature_names):
                    feature_info[i] = {
                        'type': 'continuous',
                        'min': 0.0,
                        'max': 10.0,
                        'mean': 5.0,
                        'original_column': feature,
                        'display_name': feature
                    }

            # Crear controles adaptativos para cada caracter√≠stica
            input_values = []
            cols = st.columns(min(3, len(feature_names)))

            for i, feature in enumerate(feature_names):
                with cols[i % len(cols)]:
                    info = feature_info.get(
                        i, {'type': 'continuous', 'min': 0.0, 'max': 10.0, 'mean': 5.0})

                    # Crear etiqueta con descripci√≥n si est√° disponible
                    original_col = info.get('original_column', feature)
                    description = feature_descriptions.get(original_col, '')
                    if description:
                        label = f"**{feature}**\n\n*{description}*"
                    else:
                        label = feature

                    if info['type'] == 'binary':
                        # Control para caracter√≠sticas binarias
                        if 'display_values' in info and 'value_to_original' in info:
                            selected_display = st.selectbox(
                                label,
                                options=info['display_values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                            value = info['value_to_original'][selected_display]
                        elif len(info['values']) == 2 and 0 in info['values'] and 1 in info['values']:
                            value = st.checkbox(label, key=f"pred_input_{i}")
                            value = 1 if value else 0
                        else:
                            value = st.selectbox(
                                label,
                                options=info['values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                        input_values.append(value)

                    elif info['type'] == 'categorical':
                        # Control para caracter√≠sticas categ√≥ricas
                        if 'display_values' in info and 'value_to_original' in info:
                            selected_display = st.selectbox(
                                label,
                                options=info['display_values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                            value = info['value_to_original'][selected_display]
                        else:
                            value = st.selectbox(
                                label,
                                options=info['values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                        input_values.append(value)

                    else:  # continuous
                        # Control para caracter√≠sticas continuas
                        if 'min' in info and 'max' in info:
                            step = (info['max'] - info['min']) / \
                                100 if info['max'] != info['min'] else 0.1
                            default_val = info.get(
                                'mean', (info['min'] + info['max']) / 2)
                            value = st.slider(
                                label,
                                min_value=info['min'],
                                max_value=info['max'],
                                value=default_val,
                                step=step,
                                key=f"pred_input_{i}"
                            )
                        else:
                            value = st.number_input(
                                label,
                                value=0.0,
                                key=f"pred_input_{i}"
                            )
                        input_values.append(value)

            if st.button("üîÆ Predecir", key="predict_lr_button"):
                try:
                    if model is not None:
                        prediction = model.predict([input_values])[0]

                        # For logistic regression, convert numeric prediction to class label
                        if task_type == 'Clasificaci√≥n' and class_names is not None:
                            prediction_label = class_names[int(prediction)]
                            st.success(f"Predicci√≥n: {prediction_label}")
                        else:
                            # For regression, show numeric prediction
                            st.success(f"Predicci√≥n: {prediction:.4f}")
                    else:
                        st.error("Modelo no disponible")
                except Exception as e:
                    st.error(f"Error en la predicci√≥n: {str(e)}")
        else:
            st.info("Entrena un modelo primero para hacer predicciones.")

    # Pesta√±a de Exportar
    elif st.session_state.active_tab_lr == 6:
        st.header("Exportar Modelo")

        if st.session_state.get('model_trained_lr', False):
            model = st.session_state.get('model_lr')

            col1, col2 = st.columns(2)

            with col2:
                if st.button("üì• Descargar Modelo (Pickle)", key="download_pickle_lr"):
                    pickle_data = export_model_pickle(model)
                    st.download_button(
                        label="Descargar modelo.pkl",
                        data=pickle_data,
                        file_name="linear_regression_model.pkl",
                        mime="application/octet-stream"
                    )

            with col1:
                if st.button("üìÑ Generar C√≥digo", key="generate_code_lr"):
                    # Generate complete code for linear models
                    model_type = st.session_state.get(
                        'model_type_lr', 'Linear')
                    feature_names = st.session_state.get(
                        'feature_names_lr', [])
                    class_names = st.session_state.get('class_names_lr', [])

                    if model_type == "Logistic":
                        code = generate_logistic_regression_code(
                            feature_names, class_names)
                    else:
                        code = generate_linear_regression_code(feature_names)

                    st.code(code, language="python")

                    # Download button for the code
                    st.download_button(
                        label="üì• Descargar c√≥digo",
                        data=code,
                        file_name=f"{'logistic' if model_type == 'Logistic' else 'linear'}_regression_code.py",
                        mime="text/plain"
                    )
        else:
            st.info("Entrena un modelo primero para exportarlo.")


def run_csv_loader_app():
    """Ejecuta la aplicaci√≥n espec√≠fica para cargar archivos CSV personalizados."""
    st.header("üìÅ Cargar CSV Personalizado")
    st.markdown(
        "Carga tu propio dataset en formato CSV para an√°lisis personalizado")

    # Informaci√≥n sobre cargar CSV
    with st.expander("‚ÑπÔ∏è ¬øC√≥mo usar esta herramienta?", expanded=True):
        st.markdown("""
        **Esta herramienta te permite cargar tus propios datasets CSV para an√°lisis con Machine Learning.**

        ### üìã Requisitos del archivo CSV:
        - Formato CSV con encabezados (primera fila con nombres de columnas)
        - Al menos 2 columnas (caracter√≠sticas + variable objetivo)
        - Datos limpios y estructurados
        - Codificaci√≥n UTF-8 preferible

        ### üîß Funcionalidades:
        - **Vista previa autom√°tica** del dataset cargado
        - **Detecci√≥n autom√°tica** del tipo de tarea (Clasificaci√≥n/Regresi√≥n)
        - **Selecci√≥n de columna objetivo** personalizable
        - **Estad√≠sticas descriptivas** del dataset
        - **Integraci√≥n completa** con todos los algoritmos disponibles

        ### üí° Consejos:
        - Aseg√∫rate de que los datos num√©ricos est√©n en formato correcto
        - Para clasificaci√≥n, la columna objetivo debe contener categor√≠as
        - Para regresi√≥n, la columna objetivo debe contener valores num√©ricos continuos
        """)

    # Usar la funci√≥n existente de dataset_manager
    st.markdown("---")

    # Llamar a la funci√≥n de carga de CSV sin mostrar datasets predefinidos
    result = create_dataset_selector(show_predefined=False)

    if result is not None:
        if isinstance(result, tuple):
            # CSV cargado exitosamente
            file_path, target_col, task_type = result

            st.markdown("---")
            st.success("‚úÖ ¬°Dataset CSV cargado exitosamente!")

            # Mostrar opciones de an√°lisis
            st.markdown("### üöÄ Pr√≥ximos pasos:")

            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button("üå≤ Analizar con √Årboles de Decisi√≥n",
                             key="analyze_trees",
                             use_container_width=True,
                             type="primary"):
                    st.session_state.navigation = "üå≤ √Årboles de Decisi√≥n"
                    st.rerun()

            with col2:
                if st.button("üìä Analizar con Regresi√≥n",
                             key="analyze_linear",
                             use_container_width=True,
                             type="primary"):
                    st.session_state.navigation = "üìä Regresi√≥n"
                    st.rerun()

            with col3:
                if st.button("üîÑ Cargar otro archivo",
                             key="load_another",
                             use_container_width=True):
                    # Limpiar el estado del CSV cargado
                    if 'csv_datasets' in st.session_state:
                        st.session_state.csv_datasets.clear()
                    if 'selected_dataset' in st.session_state:
                        del st.session_state.selected_dataset
                    st.rerun()

            # Informaci√≥n adicional sobre el dataset cargado
            st.markdown("### üìä Informaci√≥n del Dataset Cargado:")

            try:
                # Leer el archivo para mostrar estad√≠sticas
                df = pd.read_csv(file_path)

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìè Filas", df.shape[0])
                with col2:
                    st.metric("üìä Columnas", df.shape[1])
                with col3:
                    st.metric("üéØ Variable Objetivo", target_col)
                with col4:
                    task_icon = "üè∑Ô∏è" if task_type == "Clasificaci√≥n" else "üìà"
                    st.metric(f"{task_icon} Tipo de Tarea", task_type)

                # Mostrar estad√≠sticas descriptivas
                with st.expander("üìà Estad√≠sticas Descriptivas", expanded=False):
                    st.dataframe(df.describe(), use_container_width=True)

                # Mostrar distribuci√≥n de la variable objetivo
                with st.expander("üéØ Distribuci√≥n de la Variable Objetivo", expanded=False):
                    if task_type == "Clasificaci√≥n":
                        value_counts = df[target_col].value_counts()

                        col1, col2 = st.columns(2)
                        with col1:
                            st.dataframe(value_counts.to_frame(
                                "Cantidad"), use_container_width=True)

                        with col2:
                            fig, ax = plt.subplots(figsize=(8, 6))
                            value_counts.plot(kind='bar', ax=ax)
                            ax.set_title(f'Distribuci√≥n de {target_col}')
                            ax.set_ylabel('Cantidad')
                            plt.xticks(rotation=45)
                            plt.tight_layout()
                            st.pyplot(fig)
                    else:
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write("**Estad√≠sticas:**")
                            st.write(f"‚Ä¢ M√≠nimo: {df[target_col].min():.4f}")
                            st.write(f"‚Ä¢ M√°ximo: {df[target_col].max():.4f}")
                            st.write(f"‚Ä¢ Media: {df[target_col].mean():.4f}")
                            st.write(
                                f"‚Ä¢ Mediana: {df[target_col].median():.4f}")
                            st.write(
                                f"‚Ä¢ Desv. Est√°ndar: {df[target_col].std():.4f}")

                        with col2:
                            fig, ax = plt.subplots(figsize=(8, 6))
                            df[target_col].hist(bins=30, ax=ax, alpha=0.7)
                            ax.set_title(f'Distribuci√≥n de {target_col}')
                            ax.set_xlabel(target_col)
                            ax.set_ylabel('Frecuencia')
                            plt.tight_layout()
                            st.pyplot(fig)

            except Exception as e:
                st.warning(
                    f"No se pudieron cargar las estad√≠sticas adicionales: {str(e)}")

    else:
        # Mostrar consejos mientras no hay archivo cargado
        st.markdown("### üí° Ejemplos de Datasets que puedes cargar:")

        examples = [
            {
                "name": "Dataset de Ventas",
                "description": "Datos de ventas con caracter√≠sticas como precio, descuento, temporada ‚Üí Predictor de ventas",
                "task": "Regresi√≥n",
                "icon": "üí∞"
            },
            {
                "name": "Dataset de Clientes",
                "description": "Datos de clientes con edad, ingresos, historial ‚Üí Clasificaci√≥n de segmentos",
                "task": "Clasificaci√≥n",
                "icon": "üë•"
            },
            {
                "name": "Dataset de Productos",
                "description": "Caracter√≠sticas de productos con ratings ‚Üí Predicci√≥n de popularidad",
                "task": "Regresi√≥n",
                "icon": "üì¶"
            },
            {
                "name": "Dataset M√©dico",
                "description": "S√≠ntomas y caracter√≠sticas del paciente ‚Üí Diagn√≥stico binario",
                "task": "Clasificaci√≥n",
                "icon": "üè•"
            }
        ]

        for example in examples:
            with st.container():
                col1, col2 = st.columns([1, 10])
                with col1:
                    st.markdown(f"## {example['icon']}")
                with col2:
                    st.markdown(f"**{example['name']}** ({example['task']})")
                    st.markdown(f"_{example['description']}_")
                st.markdown("---")


def generate_linear_regression_code(feature_names):
    """Generate complete Python code for linear regression."""
    feature_names_str = str(feature_names)

    code = f"""# C√≥digo completo para Regresi√≥n Lineal
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt

# 1. CARGAR Y PREPARAR LOS DATOS
# Reemplaza esta secci√≥n con tu m√©todo de carga de datos
# df = pd.read_csv('tu_archivo.csv')  # Cargar desde CSV
# O usa datos de ejemplo:

# Datos de ejemplo (reemplaza con tus datos reales)
# X = df[{feature_names_str}]  # Caracter√≠sticas
# y = df['variable_objetivo']  # Variable objetivo

# 2. DIVIDIR LOS DATOS
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 3. CREAR Y ENTRENAR EL MODELO
model = LinearRegression()
model.fit(X_train, y_train)

# 4. HACER PREDICCIONES
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# 5. EVALUAR EL MODELO
r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)
mae_test = mean_absolute_error(y_test, y_pred_test)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))

print("=== RESULTADOS DEL MODELO ===")
print(f"R¬≤ Score (Entrenamiento): {{r2_train:.4f}}")
print(f"R¬≤ Score (Prueba): {{r2_test:.4f}}")
print(f"MAE (Error Absoluto Medio): {{mae_test:.4f}}")
print(f"RMSE (Ra√≠z Error Cuadr√°tico Medio): {{rmse_test:.4f}}")

# 6. MOSTRAR COEFICIENTES
print("\\n=== COEFICIENTES DEL MODELO ===")
feature_names = {feature_names_str}
for i, coef in enumerate(model.coef_):
    print(f"{{feature_names[i]}}: {{coef:.4f}}")
print(f"Intercepto: {{model.intercept_:.4f}}")

# 7. VISUALIZAR RESULTADOS
plt.figure(figsize=(12, 5))

# Gr√°fico 1: Predicciones vs Valores Reales
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_test, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Valores Reales')
plt.ylabel('Predicciones')
plt.title('Predicciones vs Valores Reales')
plt.grid(True, alpha=0.3)

# Gr√°fico 2: Residuos
plt.subplot(1, 2, 2)
residuals = y_test - y_pred_test
plt.scatter(y_pred_test, residuals, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicciones')
plt.ylabel('Residuos')
plt.title('An√°lisis de Residuos')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 8. FUNCI√ìN PARA NUEVAS PREDICCIONES
def predecir_nuevo_valor(nuevo_ejemplo):
    \"\"\"
    Funci√≥n para hacer predicciones con nuevos datos.
    
    Par√°metros:
    nuevo_ejemplo: lista con valores para cada caracter√≠stica
                  en el orden: {feature_names_str}
    \"\"\"
    nuevo_ejemplo = np.array(nuevo_ejemplo).reshape(1, -1)
    prediccion = model.predict(nuevo_ejemplo)[0]
    return prediccion

# Ejemplo de uso para nuevas predicciones:
# nuevo_ejemplo = [valor1, valor2, valor3, ...]  # Reemplaza con tus valores
# resultado = predecir_nuevo_valor(nuevo_ejemplo)
# print(f"Predicci√≥n para nuevo ejemplo: {{resultado:.4f}}")

# 9. GUARDAR EL MODELO (OPCIONAL)
import pickle

# Guardar modelo
with open('modelo_regresion_lineal.pkl', 'wb') as f:
    pickle.dump(model, f)

# Cargar modelo guardado
# with open('modelo_regresion_lineal.pkl', 'rb') as f:
#     modelo_cargado = pickle.load(f)
"""
    return code


def generate_logistic_regression_code(feature_names, class_names):
    """Generate complete Python code for logistic regression."""
    feature_names_str = str(feature_names)
    class_names_str = str(class_names)

    code = f"""# C√≥digo completo para Regresi√≥n Log√≠stica
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1. CARGAR Y PREPARAR LOS DATOS
# Reemplaza esta secci√≥n con tu m√©todo de carga de datos
# df = pd.read_csv('tu_archivo.csv')  # Cargar desde CSV
# O usa datos de ejemplo:

# Datos de ejemplo (reemplaza con tus datos reales)
# X = df[{feature_names_str}]  # Caracter√≠sticas
# y = df['variable_objetivo']  # Variable objetivo (0, 1, 2, ...)

# 2. DIVIDIR LOS DATOS
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 3. CREAR Y ENTRENAR EL MODELO
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)

# 4. HACER PREDICCIONES
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# 5. EVALUAR EL MODELO
accuracy_train = accuracy_score(y_train, y_pred_train)
accuracy_test = accuracy_score(y_test, y_pred_test)

print("=== RESULTADOS DEL MODELO ===")
print(f"Accuracy (Entrenamiento): {{accuracy_train:.4f}}")
print(f"Accuracy (Prueba): {{accuracy_test:.4f}}")

# Reporte detallado de clasificaci√≥n
class_names = {class_names_str}
print("\\n=== REPORTE DE CLASIFICACI√ìN ===")
print(classification_report(y_test, y_pred_test, target_names=class_names))

# 6. MATRIZ DE CONFUSI√ìN
plt.figure(figsize=(12, 5))

# Gr√°fico 1: Matriz de Confusi√≥n
plt.subplot(1, 2, 1)
cm = confusion_matrix(y_test, y_pred_test)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=class_names, yticklabels=class_names)
plt.title('Matriz de Confusi√≥n')
plt.xlabel('Predicciones')
plt.ylabel('Valores Reales')

# Gr√°fico 2: Importancia de caracter√≠sticas (coeficientes)
plt.subplot(1, 2, 2)
feature_names = {feature_names_str}
coef = model.coef_.flatten() if len(model.coef_.shape) > 1 else model.coef_
colors = ['red' if x < 0 else 'blue' for x in coef]
plt.barh(range(len(coef)), coef, color=colors, alpha=0.7)
plt.yticks(range(len(coef)), feature_names)
plt.xlabel('Coeficientes')
plt.title('Importancia de Caracter√≠sticas')
plt.axvline(x=0, color='black', linestyle='-', alpha=0.8)
plt.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.show()

# 7. MOSTRAR COEFICIENTES DETALLADOS
print("\\n=== COEFICIENTES DEL MODELO ===")
for i, coef in enumerate(coef):
    effect = "aumenta" if coef > 0 else "disminuye"
    print(f"{{feature_names[i]}}: {{coef:.4f}} ({{effect}} la probabilidad)")
print(f"Intercepto: {{model.intercept_[0]:.4f}}")

# 8. FUNCI√ìN PARA NUEVAS PREDICCIONES
def predecir_nueva_muestra(nuevo_ejemplo):
    \"\"\"
    Funci√≥n para hacer predicciones con nuevos datos.
    
    Par√°metros:
    nuevo_ejemplo: lista con valores para cada caracter√≠stica
                  en el orden: {feature_names_str}
    
    Retorna:
    prediccion: clase predicha
    probabilidades: probabilidades para cada clase
    \"\"\"
    nuevo_ejemplo = np.array(nuevo_ejemplo).reshape(1, -1)
    prediccion = model.predict(nuevo_ejemplo)[0]
    probabilidades = model.predict_proba(nuevo_ejemplo)[0]
    
    clase_predicha = class_names[prediccion]
    return clase_predicha, probabilidades

# Ejemplo de uso para nuevas predicciones:
# nuevo_ejemplo = [valor1, valor2, valor3, ...]  # Reemplaza con tus valores
# clase, probas = predecir_nueva_muestra(nuevo_ejemplo)
# print(f"Clase predicha: {{clase}}")
# print("Probabilidades por clase:")
# for i, prob in enumerate(probas):
#     print(f"  {{class_names[i]}}: {{prob:.4f}} ({{prob*100:.1f}}%)")

# 9. GUARDAR EL MODELO (OPCIONAL)
import pickle

# Guardar modelo
with open('modelo_regresion_logistica.pkl', 'wb') as f:
    pickle.dump(model, f)

# Cargar modelo guardado
# with open('modelo_regresion_logistica.pkl', 'rb') as f:
#     modelo_cargado = pickle.load(f)

# 10. FUNCI√ìN PARA INTERPRETAR PROBABILIDADES
def interpretar_prediccion(nuevo_ejemplo, umbral_confianza=0.8):
    \"\"\"
    Interpreta una predicci√≥n mostrando la confianza del modelo.
    \"\"\"
    clase, probabilidades = predecir_nueva_muestra(nuevo_ejemplo)
    max_prob = max(probabilidades)
    
    print(f"Predicci√≥n: {{clase}}")
    print(f"Confianza: {{max_prob:.4f}} ({{max_prob*100:.1f}}%)")
    
    if max_prob >= umbral_confianza:
        print("‚úÖ Alta confianza en la predicci√≥n")
    elif max_prob >= 0.6:
        print("‚ö†Ô∏è Confianza moderada en la predicci√≥n")
    else:
        print("‚ùå Baja confianza en la predicci√≥n")
    
    return clase, max_prob

# Ejemplo de interpretaci√≥n:
# interpretar_prediccion([valor1, valor2, valor3, ...])
"""
    return code


def create_interactive_knn_visualization(X_2d, y, model, feature1, feature2, class_names, show_confidence, animate_distances):
    """
    Crea una visualizaci√≥n interactiva de KNN usando JavaScript/HTML5 Canvas.

    Parameters:
    -----------
    X_2d : array
        Datos de entrenamiento en 2D
    y : array
        Etiquetas de clase
    model : KNeighborsClassifier
        Modelo KNN entrenado
    feature1, feature2 : str
        Nombres de las caracter√≠sticas
    class_names : list
        Nombres de las clases
    show_confidence : bool
        Mostrar niveles de confianza
    animate_distances : bool
        Mostrar distancias a los vecinos
    """

    try:
        # Normalizar los datos para la visualizaci√≥n
        x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1
        y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1

        # Convertir datos a formato JSON para JavaScript
        import json

        # Preparar datos de entrenamiento
        training_data = []
        unique_classes = np.unique(y)
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA726',
                  '#AB47BC', '#66BB6A', '#EF5350', '#42A5F5']

        for i, (point, label) in enumerate(zip(X_2d, y)):
            training_data.append({
                'x': float(point[0]),
                'y': float(point[1]),
                'class': int(label),
                'className': class_names[int(label)] if class_names else f"Clase {int(label)}",
                'color': colors[int(label) % len(colors)]
            })

        # Informaci√≥n de las clases
        class_info = []
        for i, class_val in enumerate(unique_classes):
            class_info.append({
                'id': int(class_val),
                'name': class_names[int(class_val)] if class_names else f"Clase {int(class_val)}",
                'color': colors[int(class_val) % len(colors)]
            })

        # Obtener puntos de prueba del estado de sesi√≥n
        test_points = st.session_state.get('test_points', [])

        # HTML y JavaScript para la visualizaci√≥n interactiva
        html_code = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <style>
            .knn-container {{
                max-width: 100%;
                margin: 0 auto;
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
            }}
            .canvas-container {{
                position: relative;
                border: 2px solid #e0e0e0;
                border-radius: 8px;
                margin: 20px 0;
                background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
                width: 100%;
                overflow: hidden;
            }}
            #knnCanvas {{
                display: block;
                cursor: crosshair;
                border-radius: 6px;
                width: 100%;
                height: auto;
                max-width: 100%;
            }}
            .controls {{
                display: flex;
                gap: 15px;
                margin-bottom: 15px;
                flex-wrap: wrap;
                align-items: center;
                justify-content: center;
            }}
            .control-group {{
                display: flex;
                flex-direction: column;
                gap: 5px;
                min-width: 120px;
            }}
            .control-group label {{
                font-weight: 600;
                font-size: 12px;
                color: #555;
                text-align: center;
            }}
            .control-group input, .control-group select {{
                padding: 5px 8px;
                border: 1px solid #ddd;
                border-radius: 4px;
                font-size: 14px;
            }}
            .legend {{
                display: flex;
                gap: 15px;
                margin-top: 15px;
                flex-wrap: wrap;
                justify-content: center;
            }}
            .legend-item {{
                display: flex;
                align-items: center;
                gap: 5px;
                font-size: 14px;
            }}
            .legend-color {{
                width: 16px;
                height: 16px;
                border-radius: 50%;
                border: 2px solid #333;
                flex-shrink: 0;
            }}
            .stats {{
                background: #f8f9fa;
                padding: 15px;
                border-radius: 8px;
                margin-top: 15px;
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
                gap: 10px;
            }}
            .stat-item {{
                text-align: center;
                padding: 10px;
                background: white;
                border-radius: 6px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }}
            .stat-value {{
                font-size: 24px;
                font-weight: bold;
                color: #2196F3;
            }}
            .stat-label {{
                font-size: 12px;
                color: #666;
                margin-top: 5px;
            }}
            .clear-btn {{
                background: #ff4444;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
                cursor: pointer;
                font-size: 14px;
                font-weight: 600;
                min-width: 140px;
            }}
            .clear-btn:hover {{
                background: #cc3333;
            }}
            .info-box {{
                background: #e3f2fd;
                border-left: 4px solid #2196F3;
                padding: 15px;
                margin: 15px 0;
                border-radius: 4px;
            }}
            
            /* Responsivo para m√≥viles */
            @media (max-width: 768px) {{
                .controls {{
                    gap: 10px;
                }}
                .control-group {{
                    min-width: 100px;
                }}
                .legend {{
                    gap: 10px;
                }}
                .legend-item {{
                    font-size: 12px;
                }}
                .stats {{
                    grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
                    gap: 8px;
                }}
                .stat-value {{
                    font-size: 20px;
                }}
                .clear-btn {{
                    min-width: 120px;
                    font-size: 12px;
                }}
            }}
        </style>
    </head>
    <body>
        <div class="knn-container">
            <div class="info-box">
                <strong>üéØ Visualizaci√≥n Interactiva KNN</strong><br>
                Haz click en cualquier parte del √°rea gris para agregar puntos de prueba y ver c√≥mo el algoritmo los clasifica.
            </div>
            
            <div class="controls">
                <div class="control-group">
                    <label>Valor K:</label>
                    <input type="range" id="kValue" min="1" max="15" value="{model.n_neighbors}" onchange="updateK(this.value)">
                    <span id="kDisplay">{model.n_neighbors}</span>
                </div>
                <div class="control-group">
                    <label>M√©trica:</label>
                    <select id="metric" onchange="updateMetric(this.value)">
                        <option value="euclidean" {'selected' if model.metric == 'euclidean' else ''}>Euclidean</option>
                        <option value="manhattan" {'selected' if model.metric == 'manhattan' else ''}>Manhattan</option>
                        <option value="minkowski" {'selected' if model.metric == 'minkowski' else ''}>Minkowski</option>
                    </select>
                </div>
                <div class="control-group">
                    <label>Pesos:</label>
                    <select id="weights" onchange="updateWeights(this.value)">
                        <option value="uniform" {'selected' if model.weights == 'uniform' else ''}>Uniforme</option>
                        <option value="distance" {'selected' if model.weights == 'distance' else ''}>Por distancia</option>
                    </select>
                </div>
                <div class="control-group">
                    <label>Mostrar confianza:</label>
                    <input type="checkbox" id="showConfidence" {'checked' if show_confidence else ''} onchange="updateShowConfidence(this.checked)">
                </div>
                <div class="control-group">
                    <label>Mostrar distancias:</label>
                    <input type="checkbox" id="showDistances" {'checked' if animate_distances else ''} onchange="updateShowDistances(this.checked)">
                </div>
                <button class="clear-btn" onclick="clearTestPoints()">üóëÔ∏è Limpiar Puntos</button>
            </div>
            
            <div class="canvas-container">
                <canvas id="knnCanvas"></canvas>
            </div>
            
            <div class="legend">
                <strong>Leyenda:</strong>
                {' '.join([f'<div class="legend-item"><div class="legend-color" style="background-color: {colors[i % len(colors)]}"></div><span>{class_info[i]["name"]}</span></div>' for i in range(len(class_info))])}
                <div class="legend-item"><div class="legend-color" style="background-color: #FFD700; transform: rotate(45deg);"></div><span>Puntos de Prueba</span></div>
            </div>
            
            <div class="stats" id="stats">
                <div class="stat-item">
                    <div class="stat-value" id="totalPoints">0</div>
                    <div class="stat-label">Puntos de Prueba</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value" id="avgConfidence">0%</div>
                    <div class="stat-label">Confianza Promedio</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value" id="currentK">{model.n_neighbors}</div>
                    <div class="stat-label">Valor K Actual</div>
                </div>
            </div>
        </div>

        <script>
            // Configuraci√≥n global
            const canvas = document.getElementById('knnCanvas');
            const ctx = canvas.getContext('2d');
            
            // Funci√≥n para redimensionar el canvas
            function resizeCanvas() {{
                const container = document.querySelector('.canvas-container');
                const containerWidth = container.clientWidth - 4; // Restar bordes
                const aspectRatio = 3/2; // Relaci√≥n de aspecto 3:2
                const canvasHeight = Math.max(400, containerWidth / aspectRatio);
                
                canvas.width = containerWidth;
                canvas.height = canvasHeight;
                canvas.style.width = containerWidth + 'px';
                canvas.style.height = canvasHeight + 'px';
                
                // Redibujar despu√©s de redimensionar
                if (typeof draw === 'function') {{
                    draw();
                }}
            }}
            
            // Datos del modelo
            const trainingData = {json.dumps(training_data)};
            const classInfo = {json.dumps(class_info)};
            const bounds = {{
                xMin: {x_min},
                xMax: {x_max},
                yMin: {y_min},
                yMax: {y_max}
            }};
            
            // Estado de la visualizaci√≥n
            let currentK = {model.n_neighbors};
            let currentMetric = "{model.metric}";
            let currentWeights = "{model.weights}";
            let showConfidence = {str(show_confidence).lower()};
            let showDistances = {str(animate_distances).lower()};
            let testPoints = [];
            
            // Funciones de conversi√≥n de coordenadas
            function dataToCanvas(x, y) {{
                const margin = 20;
                const canvasX = ((x - bounds.xMin) / (bounds.xMax - bounds.xMin)) * (canvas.width - 2 * margin) + margin;
                const canvasY = canvas.height - (((y - bounds.yMin) / (bounds.yMax - bounds.yMin)) * (canvas.height - 2 * margin) + margin);
                return {{x: canvasX, y: canvasY}};
            }}
            
            function canvasToData(canvasX, canvasY) {{
                const margin = 20;
                const x = ((canvasX - margin) / (canvas.width - 2 * margin)) * (bounds.xMax - bounds.xMin) + bounds.xMin;
                const y = bounds.yMax - (((canvasY - margin) / (canvas.height - 2 * margin)) * (bounds.yMax - bounds.yMin));
                return {{x: x, y: y}};
            }}
            
            // Funci√≥n de distancia
            function calculateDistance(p1, p2, metric) {{
                if (metric === 'euclidean') {{
                    return Math.sqrt(Math.pow(p1.x - p2.x, 2) + Math.pow(p1.y - p2.y, 2));
                }} else if (metric === 'manhattan') {{
                    return Math.abs(p1.x - p2.x) + Math.abs(p1.y - p2.y);
                }} else {{ // minkowski (p=2, equivalent to euclidean)
                    return Math.sqrt(Math.pow(p1.x - p2.x, 2) + Math.pow(p1.y - p2.y, 2));
                }}
            }}
            
            // Clasificaci√≥n KNN
            function classifyPoint(testPoint) {{
                const distances = trainingData.map(point => ({{
                    ...point,
                    distance: calculateDistance(testPoint, point, currentMetric)
                }}));
                
                distances.sort((a, b) => a.distance - b.distance);
                const neighbors = distances.slice(0, currentK);
                
                // Contar votos por clase
                const votes = {{}};
                const weights = {{}};
                
                neighbors.forEach(neighbor => {{
                    if (!votes[neighbor.class]) {{
                        votes[neighbor.class] = 0;
                        weights[neighbor.class] = 0;
                    }}
                    
                    if (currentWeights === 'distance') {{
                        const weight = neighbor.distance === 0 ? 1 : 1 / neighbor.distance;
                        weights[neighbor.class] += weight;
                    }} else {{
                        votes[neighbor.class] += 1;
                    }}
                }});
                
                // Encontrar la clase ganadora
                let winningClass = null;
                let maxScore = 0;
                
                if (currentWeights === 'distance') {{
                    for (const [cls, weight] of Object.entries(weights)) {{
                        if (weight > maxScore) {{
                            maxScore = weight;
                            winningClass = parseInt(cls);
                        }}
                    }}
                }} else {{
                    for (const [cls, count] of Object.entries(votes)) {{
                        if (count > maxScore) {{
                            maxScore = count;
                            winningClass = parseInt(cls);
                        }}
                    }}
                }}
                
                // Calcular confianza
                const totalVotes = currentWeights === 'distance' ? 
                    Object.values(weights).reduce((a, b) => a + b, 0) :
                    Object.values(votes).reduce((a, b) => a + b, 0);
                    
                const confidence = totalVotes > 0 ? (maxScore / totalVotes) : 0;
                
                return {{
                    predictedClass: winningClass,
                    confidence: confidence,
                    neighbors: neighbors,
                    className: classInfo.find(c => c.id === winningClass)?.name || `Clase ${{winningClass}}`
                }};
            }}
            
            // Dibujar la visualizaci√≥n
            function draw() {{
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                // Calcular tama√±o de puntos basado en el tama√±o del canvas
                const pointSize = Math.max(4, Math.min(8, canvas.width / 120));
                const testPointSize = Math.max(6, Math.min(12, canvas.width / 80));
                
                // Dibujar puntos de entrenamiento
                trainingData.forEach(point => {{
                    const pos = dataToCanvas(point.x, point.y);
                    ctx.fillStyle = point.color;
                    ctx.beginPath();
                    ctx.arc(pos.x, pos.y, pointSize, 0, 2 * Math.PI);
                    ctx.fill();
                    ctx.strokeStyle = '#333';
                    ctx.lineWidth = Math.max(1, pointSize / 3);
                    ctx.stroke();
                }});
                
                // Dibujar puntos de prueba y sus clasificaciones
                testPoints.forEach((testPoint, index) => {{
                    const pos = dataToCanvas(testPoint.x, testPoint.y);
                    const classification = classifyPoint(testPoint);
                    
                    // Dibujar l√≠neas a vecinos m√°s cercanos
                    if (showDistances && classification.neighbors) {{
                        ctx.strokeStyle = '#FF4444';
                        ctx.lineWidth = Math.max(1, canvas.width / 400);
                        ctx.setLineDash([5, 5]);
                        
                        classification.neighbors.forEach(neighbor => {{
                            const neighborPos = dataToCanvas(neighbor.x, neighbor.y);
                            ctx.beginPath();
                            ctx.moveTo(pos.x, pos.y);
                            ctx.lineTo(neighborPos.x, neighborPos.y);
                            ctx.stroke();
                        }});
                        ctx.setLineDash([]);
                    }}
                    
                    // Dibujar punto de prueba
                    const classColor = classInfo.find(c => c.id === classification.predictedClass)?.color || '#FFD700';
                    ctx.fillStyle = classColor;
                    ctx.beginPath();
                    ctx.arc(pos.x, pos.y, testPointSize, 0, 2 * Math.PI);
                    ctx.fill();
                    ctx.strokeStyle = '#333';
                    ctx.lineWidth = Math.max(2, testPointSize / 4);
                    ctx.stroke();
                    
                    // Dibujar estrella en el centro
                    ctx.fillStyle = '#FFD700';
                    ctx.beginPath();
                    const starSize = testPointSize * 0.6;
                    for (let i = 0; i < 5; i++) {{
                        const angle = (i * 2 * Math.PI) / 5 - Math.PI / 2;
                        const x = pos.x + Math.cos(angle) * starSize;
                        const y = pos.y + Math.sin(angle) * starSize;
                        if (i === 0) ctx.moveTo(x, y);
                        else ctx.lineTo(x, y);
                    }}
                    ctx.closePath();
                    ctx.fill();
                    
                    // Mostrar confianza si est√° habilitado
                    if (showConfidence) {{
                        const confidenceRadius = testPointSize + 8;
                        const confidenceAngle = classification.confidence * 2 * Math.PI;
                        
                        ctx.strokeStyle = '#4CAF50';
                        ctx.lineWidth = Math.max(2, canvas.width / 300);
                        ctx.beginPath();
                        ctx.arc(pos.x, pos.y, confidenceRadius, -Math.PI / 2, -Math.PI / 2 + confidenceAngle);
                        ctx.stroke();
                        
                        // Texto de confianza (solo si hay espacio)
                        if (canvas.width > 400) {{
                            ctx.fillStyle = '#333';
                            ctx.font = `${{Math.max(10, canvas.width / 60)}}px Arial`;
                            ctx.textAlign = 'center';
                            ctx.fillText(`${{Math.round(classification.confidence * 100)}}%`, pos.x, pos.y + confidenceRadius + 15);
                        }}
                    }}
                    
                    // Etiqueta de clase (solo si hay espacio)
                    if (canvas.width > 300) {{
                        ctx.fillStyle = '#333';
                        ctx.font = `bold ${{Math.max(10, canvas.width / 60)}}px Arial`;
                        ctx.textAlign = 'center';
                        ctx.fillText(classification.className, pos.x, pos.y - testPointSize - 8);
                    }}
                }});
                
                // Actualizar estad√≠sticas
                updateStats();
            }}
            
            // Actualizar estad√≠sticas
            function updateStats() {{
                document.getElementById('totalPoints').textContent = testPoints.length;
                document.getElementById('currentK').textContent = currentK;
                
                if (testPoints.length > 0) {{
                    const avgConf = testPoints.reduce((sum, point) => {{
                        const classification = classifyPoint(point);
                        return sum + classification.confidence;
                    }}, 0) / testPoints.length;
                    document.getElementById('avgConfidence').textContent = `${{Math.round(avgConf * 100)}}%`;
                }} else {{
                    document.getElementById('avgConfidence').textContent = '0%';
                }}
            }}
            
            // Event listeners
            canvas.addEventListener('click', function(event) {{
                const rect = canvas.getBoundingClientRect();
                const canvasX = event.clientX - rect.left;
                const canvasY = event.clientY - rect.top;
                
                // Verificar que el click est√© dentro del √°rea de datos (con m√°rgenes)
                const margin = 20;
                if (canvasX >= margin && canvasX <= canvas.width - margin && 
                    canvasY >= margin && canvasY <= canvas.height - margin) {{
                    const dataPoint = canvasToData(canvasX, canvasY);
                    testPoints.push(dataPoint);
                    draw();
                    
                    // Sincronizar con Streamlit
                    window.parent.postMessage({{
                        type: 'addTestPoint',
                        point: [dataPoint.x, dataPoint.y]
                    }}, '*');
                }}
            }});
            
            // Redimensionar cuando cambie el tama√±o de ventana
            window.addEventListener('resize', function() {{
                setTimeout(resizeCanvas, 100);
            }});
            
            // Funciones de control
            function updateK(value) {{
                currentK = parseInt(value);
                document.getElementById('kDisplay').textContent = value;
                draw();
            }}
            
            function updateMetric(value) {{
                currentMetric = value;
                draw();
            }}
            
            function updateWeights(value) {{
                currentWeights = value;
                draw();
            }}
            
            function updateShowConfidence(checked) {{
                showConfidence = checked;
                draw();
            }}
            
            function updateShowDistances(checked) {{
                showDistances = checked;
                draw();
            }}
            
            function clearTestPoints() {{
                testPoints = [];
                draw();
                window.parent.postMessage({{type: 'clearTestPoints'}}, '*');
            }}
            
            // Cargar puntos de prueba existentes
            const existingTestPoints = {json.dumps(test_points)};
            testPoints = existingTestPoints.map(point => ({{x: point[0], y: point[1]}}));
            
            // Inicializaci√≥n
            resizeCanvas();
            
            // Observer para detectar cambios en el tama√±o del contenedor
            if (window.ResizeObserver) {{
                const resizeObserver = new ResizeObserver(entries => {{
                    for (let entry of entries) {{
                        if (entry.target.querySelector('#knnCanvas')) {{
                            resizeCanvas();
                        }}
                    }}
                }});
                resizeObserver.observe(document.querySelector('.canvas-container'));
            }}
        </script>
    </body>
    </html>
        """

        # Mostrar la visualizaci√≥n usando st.components.v1.html con ancho completo
        components.html(html_code, height=800, scrolling=False)

        # CSS personalizado para forzar ancho completo del contenedor
        st.markdown("""
        <style>
        /* Forzar ancho completo para el contenedor de la visualizaci√≥n KNN */
        .stElementContainer.element-container.st-emotion-cache-1vr7d6u.eceldm40 {
            width: 100% !important;
        }
        
        /* Alternativa m√°s espec√≠fica si la anterior no funciona */
        div[data-testid="stVerticalBlock"] > div:has(iframe) {
            width: 100% !important;
        }
        
        /* Asegurar que el iframe tambi√©n use todo el ancho */
        iframe {
            width: 100% !important;
        }
        
        /* Forzar contenedores padre tambi√©n */
        .main .block-container {
            max-width: 100% !important;
            padding-left: 1rem !important;
            padding-right: 1rem !important;
        }
        </style>
        """, unsafe_allow_html=True)

        # JavaScript listener para sincronizar con Streamlit
        st.markdown("""
    <script>
    window.addEventListener('message', function(event) {
        if (event.data.type === 'addTestPoint') {
            // Aqu√≠ podr√≠amos enviar el punto de vuelta a Streamlit si fuera necesario
            console.log('New test point:', event.data.point);
        } else if (event.data.type === 'clearTestPoints') {
            console.log('Clearing test points');
        }
        });
        </script>
        """, unsafe_allow_html=True)

        # Informaci√≥n adicional debajo de la visualizaci√≥n
        if test_points:
            st.markdown("### üìä An√°lisis de Puntos de Prueba")

            # Crear tabla con resultados
            results_data = []
            for i, (tx, ty) in enumerate(test_points):
                test_point = np.array([[tx, ty]])
                prediction = model.predict(test_point)[0]
                probabilities = model.predict_proba(test_point)[0]

                predicted_class = class_names[int(
                    prediction)] if class_names else f"Clase {int(prediction)}"
                confidence = np.max(probabilities)

                # Encontrar vecinos m√°s cercanos
                distances, indices = model.kneighbors(test_point)

                results_data.append({
                    'Punto': i+1,
                    f'{feature1}': f"{tx:.3f}",
                    f'{feature2}': f"{ty:.3f}",
                    'Predicci√≥n': predicted_class,
                    'Confianza': f"{confidence:.1%}",
                    'Distancia Promedio': f"{np.mean(distances[0]):.3f}"
                })

            st.dataframe(pd.DataFrame(results_data), use_container_width=True)

            # Estad√≠sticas generales
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("Total de Puntos", len(test_points))

            with col2:
                avg_confidence = np.mean(
                    [np.max(model.predict_proba(np.array([[tx, ty]])))
                     for tx, ty in test_points]
                )
                st.metric("Confianza Promedio", f"{avg_confidence:.1%}")

            with col3:
                st.metric("Par√°metros",
                          f"K={model.n_neighbors}, {model.metric}")

        else:
            st.info("üí° **¬øC√≥mo usar la visualizaci√≥n?**\n\n" +
                    "1. **Haz click** en cualquier parte del √°rea gris para agregar puntos de prueba\n" +
                    "2. **Ajusta los controles** para cambiar el comportamiento del algoritmo\n" +
                    "3. **Observa las l√≠neas punteadas** que conectan cada punto con sus vecinos m√°s cercanos\n" +
                    "4. **Examina la confianza** mostrada como porcentaje y anillo alrededor de cada punto\n\n" +
                    "¬°Experimenta con diferentes valores de K y m√©tricas para entender c√≥mo afectan las predicciones!")

        # Explicaci√≥n educativa
        with st.expander("üìö Gu√≠a de la Visualizaci√≥n Interactiva"):
            st.markdown(f"""
        **üéØ Visualizaci√≥n Interactiva de K-Nearest Neighbors**
        
        Esta herramienta te permite experimentar directamente con el algoritmo KNN:
        
        #### üîß **Controles Disponibles:**
        - **Valor K (1-15)**: N√∫mero de vecinos m√°s cercanos a considerar
        - **M√©trica de Distancia**: Euclidean, Manhattan, o Minkowski
        - **Tipo de Pesos**: Uniforme (todos iguales) o por distancia (m√°s cercanos pesan m√°s)
        - **Mostrar Confianza**: Visualiza qu√© tan seguro est√° el modelo (anillo verde)
        - **Mostrar Distancias**: L√≠neas punteadas rojas conectando con vecinos
        
        #### üé® **Elementos Visuales:**
        - **Puntos de colores**: Datos de entrenamiento (cada color = una clase)
        - **Estrellas doradas**: Puntos de prueba que agregues
        - **L√≠neas punteadas**: Conexiones a los K vecinos m√°s cercanos
        - **Anillo verde**: Nivel de confianza de la predicci√≥n
        - **Porcentaje**: Confianza num√©rica de la clasificaci√≥n
        
        #### üí° **Consejos para Experimentar:**
        - Prueba diferentes valores de K en la misma ubicaci√≥n
        - Haz click cerca de las fronteras entre clases
        - Observa c√≥mo cambia la confianza en diferentes regiones
        - Compara las m√©tricas Euclidean vs Manhattan
        - Experimenta con pesos uniformes vs por distancia
        
        #### üéì **¬øQu√© Aprender?**
        - **K bajo**: M√°s sensible a ruido, fronteras m√°s irregulares
        - **K alto**: M√°s suave, pero puede perder detalles importantes
        - **Distancia Euclidean**: C√≠rculos de influencia
        - **Distancia Manhattan**: Cuadrados de influencia (movimiento tipo taxi)
        - **Pesos por distancia**: Vecinos m√°s cercanos tienen m√°s influencia
        
        **¬°La mejor forma de aprender es experimentando directamente con la visualizaci√≥n!**
        """)

    except Exception as e:
        st.error(f"Error en la visualizaci√≥n interactiva: {str(e)}")
        st.info("Fallback: Usando controles manuales")

        # Fallback a controles manuales simples
        col1, col2, col3 = st.columns(3)

        with col1:
            test_x = st.number_input(f"Valor {feature1}:",
                                     min_value=float(x_min),
                                     max_value=float(x_max),
                                     value=float((x_min + x_max) / 2),
                                     step=0.1)

        with col2:
            test_y = st.number_input(f"Valor {feature2}:",
                                     min_value=float(y_min),
                                     max_value=float(y_max),
                                     value=float((y_min + y_max) / 2),
                                     step=0.1)

        with col3:
            if st.button("‚ûï Agregar Punto", type="primary"):
                if 'test_points' not in st.session_state:
                    st.session_state.test_points = []
                st.session_state.test_points.append((test_x, test_y))
                st.rerun()


def create_animated_neighbors_plot(X_2d, y, test_point, model, feature1, feature2, class_names, colors):
    """
    Crea una visualizaci√≥n animada mostrando los vecinos m√°s cercanos.
    """
    try:
        import plotly.graph_objects as go

        # Encontrar vecinos
        distances, indices = model.kneighbors(test_point)

        # Crear figura
        fig = go.Figure()

        # Agregar todos los puntos de entrenamiento (transparentes)
        for i, class_val in enumerate(np.unique(y)):
            mask = y == class_val
            class_name = class_names[int(
                class_val)] if class_names else f"Clase {int(class_val)}"

            fig.add_trace(go.Scatter(
                x=X_2d[mask, 0],
                y=X_2d[mask, 1],
                mode='markers',
                marker=dict(
                    color=colors[i],
                    size=6,
                    opacity=0.3,
                    line=dict(color='black', width=0.5)
                ),
                name=f"{class_name} (entrenamiento)",
                showlegend=False
            ))

        # Agregar punto de prueba
        fig.add_trace(go.Scatter(
            x=[test_point[0, 0]],
            y=[test_point[0, 1]],
            mode='markers',
            marker=dict(
                color='red',
                size=15,
                symbol='star',
                line=dict(color='black', width=2)
            ),
            name='Punto de prueba'
        ))

        # Agregar vecinos m√°s cercanos destacados
        neighbor_points = X_2d[indices[0]]
        neighbor_classes = y[indices[0]]

        for i, (neighbor, neighbor_class, dist) in enumerate(zip(neighbor_points, neighbor_classes, distances[0])):
            class_name = class_names[int(
                neighbor_class)] if class_names else f"Clase {int(neighbor_class)}"

            # Punto vecino
            fig.add_trace(go.Scatter(
                x=[neighbor[0]],
                y=[neighbor[1]],
                mode='markers',
                marker=dict(
                    color=colors[int(neighbor_class)],
                    size=12,
                    line=dict(color='black', width=2)
                ),
                name=f'Vecino {i+1}: {class_name}',
                text=f"Distancia: {dist:.3f}",
                hovertemplate=f'Vecino {i+1}<br>Clase: {class_name}<br>Distancia: {dist:.3f}<extra></extra>'
            ))

            # L√≠nea de conexi√≥n
            fig.add_trace(go.Scatter(
                x=[test_point[0, 0], neighbor[0]],
                y=[test_point[0, 1], neighbor[1]],
                mode='lines',
                line=dict(
                    color='gray',
                    width=2,
                    dash='dash'
                ),
                showlegend=False,
                hoverinfo='skip'
            ))

        # Configurar layout
        fig.update_layout(
            title=f'Vecinos m√°s cercanos (K={model.n_neighbors})',
            xaxis_title=feature1,
            yaxis_title=feature2,
            hovermode='closest',
            height=400
        )

        st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"Error creando visualizaci√≥n animada: {str(e)}")


# ===== FUNCIONES PARA REDES NEURONALES =====

def safe_get_output_size(config):
    """
    Extrae el tama√±o de salida de forma segura para evitar errores de comparaci√≥n de arrays.
    """
    try:
        output_size = config['output_size']
        # Si es un array o lista, tomar el primer elemento
        if hasattr(output_size, '__len__') and not isinstance(output_size, (str, bytes)):
            return int(output_size[0]) if len(output_size) > 0 else 1
        # Si es un escalar
        return int(output_size)
    except:
        return 1


def create_neural_network_visualization(architecture, activation, output_activation, task_type):
    """
    Crea una visualizaci√≥n din√°mica de la arquitectura de red neuronal usando HTML5 Canvas.
    """
    try:
        # Colores para diferentes elementos
        colors = {
            'input': '#4ECDC4',
            'hidden': '#45B7D1',
            'output': '#FF6B6B',
            'connection': '#BDC3C7',
            'text': '#2C3E50'
        }

        html_code = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <style>
                .nn-container {{
                    max-width: 100%;
                    margin: 0 auto;
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
                }}
                .canvas-container {{
                    position: relative;
                    border: 2px solid #e0e0e0;
                    border-radius: 8px;
                    margin: 10px 0;
                    background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
                    width: 100%;
                    overflow: hidden;
                }}
                #nnCanvas {{
                    display: block;
                    width: 100%;
                    height: auto;
                    max-width: 100%;
                }}
                .info-box {{
                    background: #e3f2fd;
                    border-left: 4px solid #2196F3;
                    padding: 10px;
                    margin: 10px 0;
                    border-radius: 4px;
                    font-size: 14px;
                }}
                .layer-info {{
                    display: flex;
                    gap: 15px;
                    margin-top: 10px;
                    flex-wrap: wrap;
                    justify-content: center;
                    font-size: 12px;
                }}
                .layer-item {{
                    display: flex;
                    align-items: center;
                    gap: 5px;
                    padding: 5px 10px;
                    background: white;
                    border-radius: 15px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                }}
                .layer-color {{
                    width: 12px;
                    height: 12px;
                    border-radius: 50%;
                }}
            </style>
        </head>
        <body>
            <div class="nn-container">
                <div class="info-box">
                    <strong>üß† Arquitectura de Red Neuronal</strong><br>
                    Visualizaci√≥n din√°mica de la estructura de la red para {task_type.lower()}
                </div>
                
                <div class="canvas-container">
                    <canvas id="nnCanvas"></canvas>
                </div>
                
                <div class="layer-info">
                    <div class="layer-item">
                        <div class="layer-color" style="background-color: {colors['input']}"></div>
                        <span>Capa de Entrada</span>
                    </div>
                    <div class="layer-item">
                        <div class="layer-color" style="background-color: {colors['hidden']}"></div>
                        <span>Capas Ocultas ({activation.upper()})</span>
                    </div>
                    <div class="layer-item">
                        <div class="layer-color" style="background-color: {colors['output']}"></div>
                        <span>Capa de Salida ({output_activation.upper()})</span>
                    </div>
                </div>
            </div>

            <script>
                const canvas = document.getElementById('nnCanvas');
                const ctx = canvas.getContext('2d');
                
                // Arquitectura de la red
                const architecture = {architecture};
                const maxNeurons = Math.max(...architecture);
                
                // Funci√≥n para redimensionar el canvas
                function resizeCanvas() {{
                    const container = document.querySelector('.canvas-container');
                    const containerWidth = container.clientWidth - 4;
                    const aspectRatio = 2/1;
                    const canvasHeight = Math.max(300, containerWidth / aspectRatio);
                    
                    canvas.width = containerWidth;
                    canvas.height = canvasHeight;
                    canvas.style.width = containerWidth + 'px';
                    canvas.style.height = canvasHeight + 'px';
                    
                    drawNetwork();
                }}
                
                // Funci√≥n para dibujar la red neuronal
                function drawNetwork() {{
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    
                    const margin = 40;
                    const layerWidth = (canvas.width - 2 * margin) / (architecture.length - 1);
                    const maxRadius = Math.min(20, canvas.width / (architecture.length * 8));
                    
                    // Dibujar conexiones primero
                    ctx.strokeStyle = '{colors['connection']}';
                    ctx.lineWidth = 1;
                    ctx.globalAlpha = 0.3;
                    
                    for (let i = 0; i < architecture.length - 1; i++) {{
                        const currentLayerSize = architecture[i];
                        const nextLayerSize = architecture[i + 1];
                        
                        const currentX = margin + i * layerWidth;
                        const nextX = margin + (i + 1) * layerWidth;
                        
                        for (let j = 0; j < currentLayerSize; j++) {{
                            const currentY = getNodeY(j, currentLayerSize);
                            
                            for (let k = 0; k < nextLayerSize; k++) {{
                                const nextY = getNodeY(k, nextLayerSize);
                                
                                ctx.beginPath();
                                ctx.moveTo(currentX, currentY);
                                ctx.lineTo(nextX, nextY);
                                ctx.stroke();
                            }}
                        }}
                    }}
                    
                    ctx.globalAlpha = 1.0;
                    
                    // Dibujar nodos
                    architecture.forEach((layerSize, layerIndex) => {{
                        const x = margin + layerIndex * layerWidth;
                        const radius = Math.min(maxRadius, Math.max(8, (canvas.height - 2 * margin) / (maxNeurons * 3)));
                        
                        // Color seg√∫n tipo de capa
                        let color;
                        if (layerIndex === 0) {{
                            color = '{colors['input']}';
                        }} else if (layerIndex === architecture.length - 1) {{
                            color = '{colors['output']}';
                        }} else {{
                            color = '{colors['hidden']}';
                        }}
                        
                        // Dibujar nodos de la capa
                        for (let nodeIndex = 0; nodeIndex < layerSize; nodeIndex++) {{
                            const y = getNodeY(nodeIndex, layerSize);
                            
                            // Nodo
                            ctx.fillStyle = color;
                            ctx.beginPath();
                            ctx.arc(x, y, radius, 0, 2 * Math.PI);
                            ctx.fill();
                            
                            // Borde
                            ctx.strokeStyle = '#2C3E50';
                            ctx.lineWidth = 2;
                            ctx.stroke();
                        }}
                        
                        // Etiqueta de capa
                        ctx.fillStyle = '{colors['text']}';
                        ctx.font = `bold ${{Math.max(10, canvas.width / 50)}}px Arial`;
                        ctx.textAlign = 'center';
                        
                        let layerLabel;
                        if (layerIndex === 0) {{
                            layerLabel = `Entrada\\n(${{layerSize}})`;
                        }} else if (layerIndex === architecture.length - 1) {{
                            layerLabel = `Salida\\n(${{layerSize}})`;
                        }} else {{
                            layerLabel = `Oculta ${{layerIndex}}\\n(${{layerSize}})`;
                        }}
                        
                        // Dibujar texto en m√∫ltiples l√≠neas
                        const lines = layerLabel.split('\\n');
                        lines.forEach((line, lineIndex) => {{
                            ctx.fillText(line, x, canvas.height - 25 + lineIndex * 15);
                        }});
                    }});
                }}
                
                // Funci√≥n auxiliar para calcular posici√≥n Y de un nodo
                function getNodeY(nodeIndex, layerSize) {{
                    const margin = 40;
                    const availableHeight = canvas.height - 2 * margin - 60; // Espacio para etiquetas
                    
                    if (layerSize === 1) {{
                        return margin + availableHeight / 2;
                    }}
                    
                    const spacing = availableHeight / (layerSize + 1);
                    return margin + spacing * (nodeIndex + 1);
                }}
                
                // Inicializaci√≥n
                resizeCanvas();
                
                // Redimensionar cuando cambie el tama√±o de ventana
                window.addEventListener('resize', function() {{
                    setTimeout(resizeCanvas, 100);
                }});
                
                // Observer para detectar cambios en el contenedor
                if (window.ResizeObserver) {{
                    const resizeObserver = new ResizeObserver(entries => {{
                        for (let entry of entries) {{
                            if (entry.target.querySelector('#nnCanvas')) {{
                                resizeCanvas();
                            }}
                        }}
                    }});
                    resizeObserver.observe(document.querySelector('.canvas-container'));
                }}
            </script>
        </body>
        </html>
        """

        components.html(html_code, height=400, scrolling=False)

    except Exception as e:
        st.error(f"Error en la visualizaci√≥n de red neuronal: {str(e)}")


def calculate_network_parameters(architecture):
    """Calcula el n√∫mero total de par√°metros en la red."""
    total_params = 0
    for i in range(len(architecture) - 1):
        # Pesos: current_layer * next_layer + Sesgos: next_layer
        weights = architecture[i] * architecture[i + 1]
        biases = architecture[i + 1]
        total_params += weights + biases
    return total_params


def train_neural_network(df, target_col, config, learning_rate, epochs, validation_split,
                         early_stopping, patience, reduce_lr, lr_factor, progress_callback=None):
    """
    Entrena una red neuronal con la configuraci√≥n especificada.
    """
    try:
        # Importar TensorFlow/Keras
        import tensorflow as tf
        from tensorflow import keras
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler, LabelEncoder
        from sklearn.metrics import classification_report, confusion_matrix
        import numpy as np
        import time

        # Paso 1: Preparar datos (ya mostrado)
        X = df.drop(columns=[target_col])
        y = df[target_col]

        # Preprocesamiento
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42,
            stratify=y if config['task_type'] == 'Clasificaci√≥n' else None
        )

        # Paso 2: Construyendo la red neuronal
        if progress_callback:
            progress_callback(
                2, "Construyendo arquitectura de red neuronal con capas y neuronas...")
        time.sleep(0.8)  # Pausa para que se vea el paso

        # Procesar variable objetivo
        label_encoder = None
        if config['task_type'] == 'Clasificaci√≥n':
            label_encoder = LabelEncoder()
            y_train_encoded = label_encoder.fit_transform(y_train)
            y_test_encoded = label_encoder.transform(y_test)

            # Decisi√≥n de one-hot encoding basada en funci√≥n de activaci√≥n y n√∫mero de clases
            output_size = safe_get_output_size(config)
            if config['output_activation'] == 'softmax' or (output_size > 1 and config['output_activation'] != 'sigmoid'):
                # Para softmax multiclase o funciones no-est√°ndar multiclase
                y_train_encoded = keras.utils.to_categorical(y_train_encoded)
                y_test_encoded = keras.utils.to_categorical(y_test_encoded)
            # Para sigmoid (binaria o multiclase) mantener encoding simple
        else:
            y_train_encoded = y_train.values
            y_test_encoded = y_test.values

        # Construir modelo
        model = keras.Sequential()

        # Capa de entrada
        model.add(keras.layers.Dense(
            config['architecture'][1],
            activation=config['activation'],
            input_shape=(config['input_size'],)
        ))
        model.add(keras.layers.Dropout(config['dropout_rate']))

        # Capas ocultas
        for layer_size in config['architecture'][2:-1]:
            model.add(keras.layers.Dense(
                layer_size, activation=config['activation']))
            model.add(keras.layers.Dropout(config['dropout_rate']))

        # Capa de salida
        model.add(keras.layers.Dense(
            config['output_size'],
            activation=config['output_activation']
        ))

        # Paso 3: Compilando el modelo
        if progress_callback:
            progress_callback(
                3, "Compilando modelo con optimizadores y funciones de p√©rdida...")
        time.sleep(0.8)

        # Compilar modelo - Funci√≥n de p√©rdida inteligente seg√∫n activaci√≥n
        if config['task_type'] == 'Clasificaci√≥n':
            # Selecci√≥n inteligente de funci√≥n de p√©rdida
            output_size = safe_get_output_size(config)
            if config['output_activation'] == 'sigmoid':
                if output_size == 1:
                    loss = 'binary_crossentropy'  # Est√°ndar para binaria con sigmoid
                else:
                    # Sigmoid multiclase (multi-label)
                    loss = 'binary_crossentropy'
                metrics = ['accuracy']
            elif config['output_activation'] == 'softmax':
                if output_size == 1:
                    # Softmax con 1 neurona es problem√°tico, pero manejar el caso
                    loss = 'sparse_categorical_crossentropy'
                    metrics = ['accuracy']
                    st.warning(
                        "‚ö†Ô∏è Softmax con 1 neurona detectada. Puede causar problemas.")
                else:
                    loss = 'categorical_crossentropy'  # Est√°ndar para multiclase con softmax
                    metrics = ['accuracy']
            elif config['output_activation'] == 'linear':
                # Linear para clasificaci√≥n - usar sparse categorical
                loss = 'sparse_categorical_crossentropy'
                metrics = ['accuracy']
                st.warning(
                    "‚ö†Ô∏è Funci√≥n linear detectada en clasificaci√≥n. Rendimiento puede ser sub√≥ptimo.")
            elif config['output_activation'] == 'tanh':
                # Tanh para clasificaci√≥n - tratar como regresi√≥n pero con accuracy
                loss = 'mse'
                metrics = ['accuracy']
                st.warning(
                    "‚ö†Ô∏è Funci√≥n tanh detectada en clasificaci√≥n. Comportamiento no est√°ndar.")
            else:
                # Fallback
                loss = 'categorical_crossentropy' if output_size > 1 else 'binary_crossentropy'
                metrics = ['accuracy']
        else:
            # Para regresi√≥n
            if config['output_activation'] == 'linear':
                loss = 'mse'  # Est√°ndar para regresi√≥n
                metrics = ['mae']
            elif config['output_activation'] in ['sigmoid', 'tanh']:
                loss = 'mse'  # MSE tambi√©n funciona con activaciones acotadas
                metrics = ['mae']
                if config['output_activation'] == 'sigmoid':
                    st.info(
                        "‚ÑπÔ∏è Sigmoid limitar√° las salidas a [0,1]. Aseg√∫rate de que tus datos objetivo est√©n normalizados.")
                else:  # tanh
                    st.info(
                        "‚ÑπÔ∏è Tanh limitar√° las salidas a [-1,1]. Aseg√∫rate de que tus datos objetivo est√©n normalizados.")
            elif config['output_activation'] == 'softmax':
                loss = 'mse'
                metrics = ['mae']
                st.error(
                    "‚ö†Ô∏è Softmax en regresi√≥n: las salidas sumar√°n 1. Esto raramente es lo deseado.")
            else:
                loss = 'mse'
                metrics = ['mae']

        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
        if config['optimizer'] == 'sgd':
            optimizer = keras.optimizers.SGD(learning_rate=learning_rate)
        elif config['optimizer'] == 'rmsprop':
            optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)

        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

        # Callbacks
        callbacks = []

        if early_stopping:
            early_stop = keras.callbacks.EarlyStopping(
                monitor='val_loss', patience=patience, restore_best_weights=True
            )
            callbacks.append(early_stop)

        if reduce_lr:
            reduce_lr_callback = keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss', factor=lr_factor, patience=patience//2, min_lr=1e-7
            )
            callbacks.append(reduce_lr_callback)

        # Paso 4: Iniciando entrenamiento
        if progress_callback:
            progress_callback(
                4, f"Entrenando red neuronal ({epochs} √©pocas m√°ximo)... ¬°Puede tardar unos minutos!")
        time.sleep(1.0)  # Pausa m√°s larga antes del entrenamiento

        # Entrenar modelo
        history = model.fit(
            X_train, y_train_encoded,
            epochs=epochs,
            batch_size=config['batch_size'],
            validation_split=validation_split,
            callbacks=callbacks,
            verbose=0
        )

        return model, history, X_test, y_test_encoded, scaler, label_encoder

    except ImportError:
        st.error(
            "‚ùå TensorFlow no est√° instalado. Las redes neuronales requieren TensorFlow.")
        st.info("Instala TensorFlow con: `pip install tensorflow`")
        return None, None, None, None, None, None
    except Exception as e:
        st.error(f"Error durante el entrenamiento: {str(e)}")
        return None, None, None, None, None, None


def plot_training_history(history, task_type):
    """Grafica el historial de entrenamiento."""
    try:
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        import streamlit as st

        # Crear subplots
        if task_type == 'Clasificaci√≥n':
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=('P√©rdida durante el Entrenamiento',
                                'Precisi√≥n durante el Entrenamiento')
            )

            # P√©rdida
            fig.add_trace(
                go.Scatter(
                    y=history.history['loss'], name='Entrenamiento', line=dict(color='blue')),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(
                    y=history.history['val_loss'], name='Validaci√≥n', line=dict(color='red')),
                row=1, col=1
            )

            # Precisi√≥n
            fig.add_trace(
                go.Scatter(y=history.history['accuracy'], name='Entrenamiento', line=dict(
                    color='blue'), showlegend=False),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(y=history.history['val_accuracy'], name='Validaci√≥n', line=dict(
                    color='red'), showlegend=False),
                row=1, col=2
            )

            fig.update_yaxes(title_text="P√©rdida", row=1, col=1)
            fig.update_yaxes(title_text="Precisi√≥n", row=1, col=2)

        else:
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=(
                    'P√©rdida (MSE) durante el Entrenamiento', 'Error Absoluto Medio')
            )

            # MSE
            fig.add_trace(
                go.Scatter(
                    y=history.history['loss'], name='Entrenamiento', line=dict(color='blue')),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(
                    y=history.history['val_loss'], name='Validaci√≥n', line=dict(color='red')),
                row=1, col=1
            )

            # MAE
            fig.add_trace(
                go.Scatter(y=history.history['mae'], name='Entrenamiento', line=dict(
                    color='blue'), showlegend=False),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(y=history.history['val_mae'], name='Validaci√≥n', line=dict(
                    color='red'), showlegend=False),
                row=1, col=2
            )

            fig.update_yaxes(title_text="MSE", row=1, col=1)
            fig.update_yaxes(title_text="MAE", row=1, col=2)

        fig.update_xaxes(title_text="√âpoca")
        fig.update_layout(height=400, showlegend=True)

        st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"Error graficando historial: {str(e)}")


def show_neural_network_evaluation():
    """Muestra la evaluaci√≥n detallada del modelo de red neuronal."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "‚ö†Ô∏è Primero debes entrenar un modelo en la pesta√±a 'Entrenamiento'")
        return

    # Tips educativos sobre evaluaci√≥n
    st.info("""
    üéì **Evaluaci√≥n de Redes Neuronales:**
    - **Accuracy**: Porcentaje de predicciones correctas (para clasificaci√≥n)
    - **Matriz de Confusi√≥n**: Muestra qu√© clases se confunden entre s√≠
    - **MSE/MAE**: Errores promedio para regresi√≥n
    - **Datos de test**: Nunca vistos durante entrenamiento, miden la capacidad real
    """)

    try:
        import tensorflow as tf
        import numpy as np
        import pandas as pd
        from sklearn.metrics import classification_report, confusion_matrix, r2_score, mean_squared_error, mean_absolute_error
        import plotly.graph_objects as go
        import plotly.figure_factory as ff
        from plotly.subplots import make_subplots

        model = st.session_state.nn_model
        X_test, y_test = st.session_state.nn_test_data
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        st.header("üìä Evaluaci√≥n del Modelo")

        # Hacer predicciones
        y_pred = model.predict(X_test, verbose=0)

        # M√©tricas seg√∫n el tipo de tarea
        if config['task_type'] == 'Clasificaci√≥n':
            # Obtener el tama√±o de salida de forma segura
            output_size = safe_get_output_size(config)

            # Para clasificaci√≥n - detectar formato de y_test
            # One-hot encoded (multiclase)
            if len(y_test.shape) > 1 and y_test.shape[1] > 1:
                y_pred_classes = np.argmax(y_pred, axis=1)
                y_test_classes = np.argmax(y_test, axis=1)
            else:  # Binaria o multiclase sin one-hot
                if output_size == 1:  # Binaria con 1 neurona
                    y_pred_classes = (y_pred > 0.5).astype(int).flatten()
                    y_test_classes = y_test.flatten()
                else:  # Multiclase sin one-hot (sparse)
                    y_pred_classes = np.argmax(y_pred, axis=1)
                    y_test_classes = y_test.flatten()

            # Accuracy
            accuracy = np.mean(y_pred_classes == y_test_classes)

            # Mostrar m√©tricas principales con explicaciones
            st.markdown("### üéØ M√©tricas Principales")
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("üéØ Accuracy", f"{accuracy:.4f}", f"{accuracy*100:.2f}%",
                          help="Porcentaje de predicciones correctas en datos nunca vistos")

                # Interpretaci√≥n del accuracy
                if accuracy >= 0.9:
                    st.success("üåü **Excelente**: Tu red predice muy bien")
                elif accuracy >= 0.8:
                    st.success("‚úÖ **Muy Bueno**: Predicciones muy confiables")
                elif accuracy >= 0.7:
                    st.warning("‚ö†Ô∏è **Bueno**: Predicciones aceptables")
                elif accuracy >= 0.6:
                    st.warning("üü° **Regular**: Hay margen de mejora")
                else:
                    st.error("üî¥ **Bajo**: Considera ajustar el modelo")

            with col2:
                # Calcular confianza promedio
                # One-hot multiclase
                if len(y_test.shape) > 1 and y_test.shape[1] > 1:
                    confidence = np.mean(np.max(y_pred, axis=1))
                elif output_size == 1:  # Binaria
                    confidence = np.mean(np.maximum(
                        y_pred.flatten(), 1 - y_pred.flatten()))
                else:  # Multiclase sparse
                    confidence = np.mean(np.max(y_pred, axis=1))
                st.metric("üé≤ Confianza Promedio",
                          f"{confidence:.4f}", f"{confidence*100:.2f}%")

            with col3:
                # N√∫mero de predicciones correctas
                correct_preds = np.sum(y_pred_classes == y_test_classes)
                st.metric("‚úÖ Predicciones Correctas",
                          f"{correct_preds}/{len(y_test_classes)}")

            # Matriz de confusi√≥n
            st.subheader("üîç Matriz de Confusi√≥n")

            try:
                cm = confusion_matrix(y_test_classes, y_pred_classes)

                # Obtener nombres de clases
                if label_encoder and hasattr(label_encoder, 'classes_'):
                    class_names = list(label_encoder.classes_)
                else:
                    # Determinar clases basado en los datos √∫nicos
                    all_classes = sorted(
                        set(list(y_test_classes) + list(y_pred_classes)))
                    class_names = [f"Clase {i}" for i in all_classes]

                # Ajustar class_names al tama√±o de la matriz si es necesario
                if len(class_names) != cm.shape[0]:
                    class_names = [f"Clase {i}" for i in range(cm.shape[0])]

                # Crear heatmap de la matriz de confusi√≥n
                fig_cm = ff.create_annotated_heatmap(
                    z=cm,
                    x=class_names,
                    y=class_names,
                    annotation_text=cm,
                    colorscale='Blues',
                    showscale=True
                )

                fig_cm.update_layout(
                    title='Matriz de Confusi√≥n',
                    xaxis_title='Predicciones',
                    yaxis_title='Valores Reales',
                    height=500
                )

                st.plotly_chart(fig_cm, use_container_width=True)

            except Exception as cm_error:
                st.error(
                    f"‚ùå Error creando matriz de confusi√≥n: {str(cm_error)}")
                st.info(
                    "La matriz de confusi√≥n no pudo generarse. El modelo funciona correctamente pero hay un problema con la visualizaci√≥n.")

            # Reporte de clasificaci√≥n detallado
            st.subheader("üìã Reporte de Clasificaci√≥n")

            if label_encoder:
                target_names = label_encoder.classes_
            else:
                target_names = [f"Clase {i}" for i in range(
                    len(np.unique(y_test_classes)))]

            # Generar reporte
            report = classification_report(
                y_test_classes, y_pred_classes,
                target_names=target_names,
                output_dict=True
            )

            # Mostrar m√©tricas por clase
            metrics_data = []
            for class_name in target_names:
                if class_name in report:
                    metrics_data.append({
                        'Clase': class_name,
                        'Precisi√≥n': f"{report[class_name]['precision']:.4f}",
                        'Recall': f"{report[class_name]['recall']:.4f}",
                        'F1-Score': f"{report[class_name]['f1-score']:.4f}",
                        'Soporte': report[class_name]['support']
                    })

            st.dataframe(metrics_data, use_container_width=True)

            # M√©tricas macro y weighted
            st.subheader("üìä M√©tricas Agregadas")
            col1, col2 = st.columns(2)

            with col1:
                st.info(f"""
                **Macro Average:**
                - Precisi√≥n: {report['macro avg']['precision']:.4f}
                - Recall: {report['macro avg']['recall']:.4f}
                - F1-Score: {report['macro avg']['f1-score']:.4f}
                """)

            with col2:
                st.info(f"""
                **Weighted Average:**
                - Precisi√≥n: {report['weighted avg']['precision']:.4f}
                - Recall: {report['weighted avg']['recall']:.4f}
                - F1-Score: {report['weighted avg']['f1-score']:.4f}
                """)

        else:
            # Para regresi√≥n
            y_pred_flat = y_pred.flatten()
            y_test_flat = y_test.flatten()

            # M√©tricas de regresi√≥n
            mse = mean_squared_error(y_test_flat, y_pred_flat)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test_flat, y_pred_flat)
            r2 = r2_score(y_test_flat, y_pred_flat)

            # Mostrar m√©tricas principales
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("üìä R¬≤ Score", f"{r2:.4f}")

            with col2:
                st.metric("üìè MAE", f"{mae:.4f}")

            with col3:
                st.metric("üìê RMSE", f"{rmse:.4f}")

            with col4:
                st.metric("üéØ MSE", f"{mse:.4f}")

            # Gr√°ficos de evaluaci√≥n para regresi√≥n
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=('Predicciones vs Valores Reales',
                                'Distribuci√≥n de Residuos')
            )

            # Scatter plot de predicciones vs reales
            fig.add_trace(
                go.Scatter(
                    x=y_test_flat,
                    y=y_pred_flat,
                    mode='markers',
                    name='Predicciones',
                    marker=dict(size=8, opacity=0.6)
                ),
                row=1, col=1
            )

            # L√≠nea de referencia y = x
            min_val = min(y_test_flat.min(), y_pred_flat.min())
            max_val = max(y_test_flat.max(), y_pred_flat.max())

            fig.add_trace(
                go.Scatter(
                    x=[min_val, max_val],
                    y=[min_val, max_val],
                    mode='lines',
                    name='L√≠nea Ideal',
                    line=dict(color='red', dash='dash')
                ),
                row=1, col=1
            )

            # Histograma de residuos
            residuals = y_test_flat - y_pred_flat
            fig.add_trace(
                go.Histogram(
                    x=residuals,
                    name='Residuos',
                    nbinsx=30,
                    opacity=0.7
                ),
                row=1, col=2
            )

            fig.update_xaxes(title_text="Valores Reales", row=1, col=1)
            fig.update_yaxes(title_text="Predicciones", row=1, col=1)
            fig.update_xaxes(title_text="Residuos", row=1, col=2)
            fig.update_yaxes(title_text="Frecuencia", row=1, col=2)

            fig.update_layout(height=500, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)

        # Informaci√≥n del modelo
        st.subheader("üîß Informaci√≥n del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            st.info(f"""
            **Arquitectura:**
            - Capas: {len(config['architecture'])}
            - Neuronas por capa: {config['architecture']}
            - Funci√≥n de activaci√≥n: {config['activation']}
            - Activaci√≥n de salida: {config['output_activation']}
            """)

        with col2:
            total_params = calculate_network_parameters(config['architecture'])
            st.info(f"""
            **Par√°metros:**
            - Total de par√°metros: {total_params:,}
            - Optimizador: {config['optimizer']}
            - Dropout: {config['dropout_rate']}
            - Batch size: {config['batch_size']}
            """)

        # Bot√≥n para generar c√≥digo Python de evaluaci√≥n
        st.markdown("### üíª C√≥digo Python")
        if st.button("üìù Generar C√≥digo de Evaluaci√≥n", use_container_width=True):
            # Generar c√≥digo Python para evaluaci√≥n
            code = generate_neural_network_evaluation_code(
                config, st.session_state.nn_feature_names, st.session_state.nn_class_names
            )

            st.markdown("#### üêç C√≥digo Python para Evaluaci√≥n")
            st.code(code, language='python')

            # Bot√≥n para descargar el c√≥digo
            st.download_button(
                label="üíæ Descargar C√≥digo de Evaluaci√≥n",
                data=code,
                file_name=f"evaluacion_red_neuronal_{config['task_type'].lower()}.py",
                mime="text/plain"
            )

        # Navegaci√≥n
        st.markdown("---")
        st.markdown("### üß≠ Navegaci√≥n")
        col_nav1, col_nav2 = st.columns(2)
        with col_nav1:
            if st.button("üîô Volver a Entrenamiento", use_container_width=True):
                st.session_state.active_tab_nn = 2
                st.rerun()
        with col_nav2:
            if st.button("üéØ Ver Visualizaciones", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 4
                st.rerun()

    except Exception as e:
        st.error(f"Error en la evaluaci√≥n: {str(e)}")
        st.info(
            "Aseg√∫rate de que TensorFlow est√© instalado y el modelo est√© entrenado correctamente.")


def show_neural_network_visualizations():
    """Muestra visualizaciones avanzadas del modelo."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "‚ö†Ô∏è Primero debes entrenar un modelo en la pesta√±a 'Entrenamiento'")
        return

    # Tips educativos sobre visualizaciones
    st.info("""
    üéì **Visualizaciones de Redes Neuronales:**
    - **Historial de entrenamiento**: Muestra c√≥mo evoluciona el aprendizaje
    - **Pesos y sesgos**: Revelan qu√© ha aprendido cada neurona
    - **Superficie de decisi√≥n**: C√≥mo la red separa las clases (2D)
    - **An√°lisis de capas**: Activaciones y patrones internos
    """)

    try:
        import tensorflow as tf
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        import numpy as np
        from sklearn.preprocessing import StandardScaler

        model = st.session_state.nn_model
        history = st.session_state.nn_history
        config = st.session_state.nn_config

        # FORZAR inicializaci√≥n completa del modelo SIEMPRE (de forma transparente)
        try:
            # Obtener datos de test para inicializar el modelo
            X_test, _ = st.session_state.nn_test_data
            
            # Estrategia SILENCIOSA de inicializaci√≥n (sin importar el estado actual)
            # 1. SIEMPRE hacer predicciones para forzar construcci√≥n
            dummy_pred = model.predict(X_test[:1], verbose=0)
            
            # 2. Forzar construcci√≥n expl√≠cita usando el input shape real
            input_shape = (None, X_test.shape[1])
            
            # 3. Si el modelo no est√° construido, construirlo
            if not model.built:
                model.build(input_shape)
                
            # 4. FORZAR reconstrucci√≥n de todas las capas una por una
            for i, layer in enumerate(model.layers):
                if hasattr(layer, 'built'):
                    if not layer.built:
                        # Construir capa por capa
                        if i == 0:
                            # Primera capa usa input_shape original
                            layer.build(input_shape)
                        else:
                            # Capas subsecuentes usan la salida de la capa anterior
                            prev_layer_output_shape = model.layers[i-1].output_shape
                            layer.build(prev_layer_output_shape)
            
            # 5. Verificaci√≥n M√öLTIPLE con diferentes tama√±os de batch
            for batch_size in [1, 5, 10]:
                test_batch = X_test[:min(batch_size, len(X_test))]
                _ = model.predict(test_batch, verbose=0)
            
            # 6. Verificar que el modelo tenga input definido
            if model.input is None:
                # √öltima estrategia: recrear el modelo si es necesario
                model._set_inputs(X_test[:1])
            
        except Exception as init_error:
            # Proceso de reparaci√≥n de emergencia SILENCIOSO
            try:
                # Obtener la configuraci√≥n original del modelo
                original_config = st.session_state.nn_config
                
                # Recrear el modelo desde cero si es necesario
                import tensorflow as tf
                from tensorflow import keras
                
                # Crear nuevo modelo con la misma arquitectura
                new_model = keras.Sequential()
                
                # Agregar capas seg√∫n la configuraci√≥n original
                arch = original_config['architecture']
                
                # Primera capa con input_shape expl√≠cito
                new_model.add(keras.layers.Dense(
                    arch[1],
                    activation=original_config['activation'],
                    input_shape=(arch[0],)
                ))
                
                # Capas ocultas
                for layer_size in arch[2:-1]:
                    new_model.add(keras.layers.Dense(
                        layer_size,
                        activation=original_config['activation']
                    ))
                
                # Capa de salida
                new_model.add(keras.layers.Dense(
                    arch[-1],
                    activation=original_config['output_activation']
                ))
                
                # Copiar pesos del modelo original
                new_model.set_weights(model.get_weights())
                
                # Compilar el nuevo modelo
                new_model.compile(
                    optimizer=model.optimizer,
                    loss=model.loss,
                    metrics=model.metrics
                )
                
                # Reemplazar el modelo en session state
                st.session_state.nn_model = new_model
                model = new_model
                
                # Verificar que funciona
                test_pred = model.predict(X_test[:5], verbose=0)
                
            except Exception as emergency_error:
                # Si todo falla, mostrar error simplificado
                st.error("‚ùå No se pudo inicializar el modelo para visualizaciones.")
                st.info("üí° Intenta reentrenar el modelo desde cero.")
                return
            
            # Proceso de reparaci√≥n de emergencia
            try:
                # Obtener la configuraci√≥n original del modelo
                original_config = st.session_state.nn_config
                
                # Recrear el modelo desde cero si es necesario
                import tensorflow as tf
                from tensorflow import keras
                
                st.info("ÔøΩ Recreando modelo desde configuraci√≥n guardada...")
                
                # Crear nuevo modelo con la misma arquitectura
                new_model = keras.Sequential()
                
                # Agregar capas seg√∫n la configuraci√≥n original
                arch = original_config['architecture']
                
                # Primera capa con input_shape expl√≠cito
                new_model.add(keras.layers.Dense(
                    arch[1],
                    activation=original_config['activation'],
                    input_shape=(arch[0],)
                ))
                
                # Capas ocultas
                for layer_size in arch[2:-1]:
                    new_model.add(keras.layers.Dense(
                        layer_size,
                        activation=original_config['activation']
                    ))
                
                # Capa de salida
                new_model.add(keras.layers.Dense(
                    arch[-1],
                    activation=original_config['output_activation']
                ))
                
                # Copiar pesos del modelo original
                new_model.set_weights(model.get_weights())
                
                # Compilar el nuevo modelo
                new_model.compile(
                    optimizer=model.optimizer,
                    loss=model.loss,
                    metrics=model.metrics
                )
                
                # Reemplazar el modelo en session state
                st.session_state.nn_model = new_model
                model = new_model
                
                # Verificar que funciona
                test_pred = model.predict(X_test[:5], verbose=0)
                
                st.success("‚úÖ ¬°Modelo recreado y funcionando!")
                
            except Exception as emergency_error:
                st.error(f"‚ùå Fallo en reparaci√≥n de emergencia: {emergency_error}")
                st.info("üí° Como √∫ltimo recurso, intenta reentrenar el modelo desde cero.")

        st.header("üìà Visualizaciones Avanzadas")

        # Tabs para diferentes visualizaciones
        viz_tab1, viz_tab2, viz_tab3, viz_tab4 = st.tabs([
            "üìä Historial de Entrenamiento",
            "üß† Pesos y Sesgos",
            "üéØ Superficie de Decisi√≥n",
            "üìâ An√°lisis de Capas"
        ])

        with viz_tab1:
            st.subheader("üìä Historial de Entrenamiento Detallado")
            st.markdown("üìà **¬øC√≥mo aprendi√≥ tu red neuronal?**")

            # Explicaci√≥n sobre el historial
            with st.expander("üí° ¬øC√≥mo interpretar estas gr√°ficas?"):
                st.markdown("""
                **Gr√°fica de P√©rdida (Loss):**
                - **Bajando**: La red est√° aprendiendo ‚úÖ
                - **Estable**: Ha convergido üéØ
                - **Subiendo**: Posible sobreajuste ‚ö†Ô∏è
                - **Gap grande entre train/val**: Sobreajuste üö®
                
                **Gr√°fica de Accuracy (clasificaci√≥n) o MAE (regresi√≥n):**
                - **Subiendo**: Mejorando en las predicciones ‚úÖ
                - **Plateau**: Ha alcanzado su l√≠mite üìä
                - **Train > Val**: Normal, pero gap grande = sobreajuste ‚ö†Ô∏è
                """)

            plot_training_history(history, config['task_type'])

            # Informaci√≥n adicional del entrenamiento
            st.markdown("#### üìä Estad√≠sticas del Entrenamiento")
            col1, col2, col3 = st.columns(3)

            with col1:
                final_loss = history.history['loss'][-1]
                initial_loss = history.history['loss'][0]
                improvement = ((initial_loss - final_loss) /
                               initial_loss) * 100
                st.metric("üî¥ P√©rdida Final (Entrenamiento)", f"{final_loss:.6f}",
                          f"-{improvement:.1f}% desde inicio")

            with col2:
                if 'val_loss' in history.history:
                    final_val_loss = history.history['val_loss'][-1]
                    overfitting_gap = final_val_loss - final_loss
                    st.metric("üü° P√©rdida Final (Validaci√≥n)", f"{final_val_loss:.6f}",
                              f"Gap: {overfitting_gap:.6f}")

                    # Interpretaci√≥n del gap
                    if overfitting_gap < 0.01:
                        st.success("‚úÖ **Sin sobreajuste**: Gap muy peque√±o")
                    elif overfitting_gap < 0.05:
                        st.warning("‚ö†Ô∏è **Sobreajuste leve**: Gap aceptable")
                    else:
                        st.error("üö® **Sobreajuste**: Gap significativo")

            with col3:
                epochs_trained = len(history.history['loss'])
                st.metric("‚è±Ô∏è √âpocas Entrenadas", epochs_trained)

                # ¬øPar√≥ por early stopping?
                if 'nn_config' in st.session_state:
                    max_epochs = st.session_state.get('training_epochs', 100)
                    if epochs_trained < max_epochs:
                        st.caption(
                            "üõë **Early Stopping**: Par√≥ autom√°ticamente")
                    else:
                        st.caption("üîÑ **Complet√≥ todas las √©pocas**")

        with viz_tab2:
            st.subheader("üß† An√°lisis de Pesos y Sesgos")
            st.markdown("üîç **¬øQu√© ha aprendido cada neurona?**")

            # Explicaci√≥n sobre pesos
            with st.expander("üí° ¬øQu√© significan los pesos?"):
                st.markdown("""
                **Pesos (Weights):**
                - **Valores altos**: Conexiones importantes entre neuronas
                - **Valores cercanos a 0**: Conexiones d√©biles o irrelevantes
                - **Valores negativos**: Relaciones inversas
                - **Distribuci√≥n**: Indica si la red est√° bien inicializada
                
                **Sesgos (Biases):**
                - **Valores altos**: Neurona se activa f√°cilmente
                - **Valores bajos**: Neurona es m√°s selectiva
                - **Distribuci√≥n**: Debe ser razonable, no extrema
                """)

            # Obtener pesos de todas las capas
            layer_weights = []
            layer_biases = []

            for i, layer in enumerate(model.layers):
                if hasattr(layer, 'get_weights') and layer.get_weights():
                    weights = layer.get_weights()
                    if len(weights) >= 2:  # Pesos y sesgos
                        layer_weights.append(weights[0])
                        layer_biases.append(weights[1])

            if layer_weights:
                # Crear gr√°ficos para cada capa
                for i, (weights, biases) in enumerate(zip(layer_weights, layer_biases)):
                    st.markdown(f"#### üìä Capa {i+1}")

                    col1, col2 = st.columns(2)

                    with col1:
                        # Histograma de pesos
                        fig_weights = go.Figure()
                        fig_weights.add_trace(go.Histogram(
                            x=weights.flatten(),
                            nbinsx=50,
                            name=f'Pesos Capa {i+1}',
                            opacity=0.7
                        ))
                        fig_weights.update_layout(
                            title=f'Distribuci√≥n de Pesos - Capa {i+1}',
                            xaxis_title='Valor de Peso',
                            yaxis_title='Frecuencia',
                            height=300
                        )
                        st.plotly_chart(fig_weights, use_container_width=True)

                        # Estad√≠sticas de pesos
                        st.caption(f"üìä **Estad√≠sticas**: Media={np.mean(weights):.4f}, "
                                   f"Std={np.std(weights):.4f}, "
                                   f"Min={np.min(weights):.4f}, "
                                   f"Max={np.max(weights):.4f}")

                    with col2:
                        # Histograma de sesgos
                        fig_biases = go.Figure()
                        fig_biases.add_trace(go.Histogram(
                            x=biases.flatten(),
                            nbinsx=20,
                            name=f'Sesgos Capa {i+1}',
                            opacity=0.7,
                            marker_color='orange'
                        ))
                        fig_biases.update_layout(
                            title=f'Distribuci√≥n de Sesgos - Capa {i+1}',
                            xaxis_title='Valor de Sesgo',
                            yaxis_title='Frecuencia',
                            height=300
                        )
                        st.plotly_chart(fig_biases, use_container_width=True)

                        # Estad√≠sticas de sesgos
                        st.caption(f"üìä **Estad√≠sticas**: Media={np.mean(biases):.4f}, "
                                   f"Std={np.std(biases):.4f}, "
                                   f"Min={np.min(biases):.4f}, "
                                   f"Max={np.max(biases):.4f}")

                # An√°lisis general
                st.markdown("#### üîç An√°lisis General de la Red")
                all_weights = np.concatenate(
                    [w.flatten() for w in layer_weights])
                all_biases = np.concatenate(
                    [b.flatten() for b in layer_biases])

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üéØ Pesos Promedio",
                              f"{np.mean(all_weights):.6f}")
                with col2:
                    st.metric("üìä Desv. Std. Pesos",
                              f"{np.std(all_weights):.6f}")
                with col3:
                    dead_neurons = np.sum(np.abs(all_weights) < 1e-6)
                    st.metric("üíÄ Pesos ~0", f"{dead_neurons}")

                # Salud de la red
                if np.std(all_weights) < 0.01:
                    st.error(
                        "üö® **Problema**: Pesos muy peque√±os, la red puede no haber aprendido")
                elif np.std(all_weights) > 2:
                    st.warning(
                        "‚ö†Ô∏è **Atenci√≥n**: Pesos muy grandes, posible inestabilidad")
                else:
                    st.success("‚úÖ **Saludable**: Distribuci√≥n de pesos normal")
            else:
                st.warning("No se pudieron extraer los pesos del modelo")

        with viz_tab3:
            st.subheader("üéØ Superficie de Decisi√≥n")
            st.markdown(
                "üó∫Ô∏è **¬øC√≥mo divide tu red el espacio de caracter√≠sticas?**")

            # Solo mostrar si tenemos 2 caracter√≠sticas o menos
            if config['input_size'] <= 2:
                st.info(
                    "Generando superficie de decisi√≥n... (Puede tomar unos segundos)")
                # Aqu√≠ ir√≠a el c√≥digo para generar superficie de decisi√≥n
                # Es complejo, por ahora mostrar mensaje
                st.markdown("""
                **Superficie de Decisi√≥n 2D:**
                - Cada color representa una clase predicha
                - Los puntos son tus datos de entrenamiento
                - Las fronteras muestran c√≥mo la red separa las clases
                - Fronteras suaves = red bien generalizada
                - Fronteras muy complejas = posible sobreajuste
                """)
            else:
                st.warning(f"‚ö†Ô∏è **No disponible**: Tu dataset tiene {config['input_size']} caracter√≠sticas. "
                           "La superficie de decisi√≥n solo se puede visualizar con 2 caracter√≠sticas o menos.")

                st.markdown("""
                **Alternativas para datasets de alta dimensionalidad:**
                - Usar PCA para reducir a 2D
                - Seleccionar las 2 caracter√≠sticas m√°s importantes
                - Analizar pares de caracter√≠sticas individualmente
                """)

        with viz_tab4:
            st.subheader("üìâ An√°lisis de Capas")
            st.markdown("üî¨ **Activaciones y patrones internos de la red**")

            # Explicaci√≥n sobre activaciones
            with st.expander("üí° ¬øQu√© son las activaciones?"):
                st.markdown("""
                **Activaciones:**
                - **Valores que producen las neuronas** cuando procesan datos
                - **Primeras capas**: Detectan caracter√≠sticas b√°sicas
                - **Capas intermedias**: Combinan caracter√≠sticas en patrones
                - **√öltima capa**: Decisi√≥n final o predicci√≥n
                
                **Qu√© buscar:**
                - **Muchos ceros**: Neuronas "muertas" (problema)
                - **Valores extremos**: Saturaci√≥n (problema)
                - **Distribuci√≥n balanceada**: Red saludable ‚úÖ
                """)

            # Obtener algunas muestras para analizar activaciones
            X_test, y_test = st.session_state.nn_test_data
            sample_size = min(100, len(X_test))
            X_sample = X_test[:sample_size]

            try:
                # M√âTODO DIRECTO Y SIMPLE para an√°lisis de activaciones
                st.info("ÔøΩ Iniciando an√°lisis de activaciones...")
                
                # Como el modelo ya fue inicializado arriba, proceder directamente
                # Usar el input del modelo (deber√≠a estar disponible ya)
                model_input = model.input
                
                # Verificaci√≥n simple
                if model_input is None:
                    st.error("‚ùå El modelo no se pudo inicializar correctamente.")
                    st.info("üí° Intenta reentrenar el modelo desde cero.")
                    return
                
                # Obtener outputs de todas las capas excepto la √∫ltima
                if len(model.layers) <= 1:
                    st.warning("‚ö†Ô∏è El modelo tiene muy pocas capas para an√°lisis detallado")
                    return
                
                # Crear lista de outputs de capas
                layer_outputs = []
                for i, layer in enumerate(model.layers[:-1]):
                    layer_outputs.append(layer.output)
                
                # Crear modelo de activaciones de forma SIMPLE
                activation_model = tf.keras.Model(inputs=model_input, outputs=layer_outputs)
                
                # Obtener activaciones directamente
                st.info("ÔøΩ Calculando activaciones de las capas...")
                activations = activation_model.predict(X_sample, verbose=0)

                if not isinstance(activations, list):
                    activations = [activations]

                # Mostrar estad√≠sticas por capa
                for i, activation in enumerate(activations):
                    st.markdown(f"#### üìä Capa {i+1} - Activaciones")

                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("üî• Media", f"{np.mean(activation):.4f}")
                    with col2:
                        st.metric("üìä Desv. Std.", f"{np.std(activation):.4f}")
                    with col3:
                        dead_ratio = np.mean(activation == 0) * 100
                        st.metric("üíÄ % Neuronas Muertas", f"{dead_ratio:.1f}%")
                    with col4:
                        saturated_ratio = np.mean(activation >= 0.99) * 100
                        st.metric("üî¥ % Saturadas", f"{saturated_ratio:.1f}%")

                    # Interpretaci√≥n de la salud
                    if dead_ratio > 50:
                        st.error(
                            f"üö® **Problema en Capa {i+1}**: Muchas neuronas muertas")
                    elif dead_ratio > 20:
                        st.warning(
                            f"‚ö†Ô∏è **Atenci√≥n en Capa {i+1}**: Algunas neuronas muertas")
                    else:
                        st.success(
                            f"‚úÖ **Capa {i+1} Saludable**: Buena activaci√≥n")

            except Exception as e:
                st.error(f"‚ùå Error al analizar activaciones: {str(e)}")

                # Informaci√≥n de debug m√°s detallada
                st.markdown("**üîç Informaci√≥n de Debug:**")

                # Informaci√≥n del modelo
                try:
                    st.write(f"- **Tipo de modelo**: {type(model).__name__}")
                    st.write(f"- **N√∫mero de capas**: {len(model.layers)}")
                    st.write(f"- **Modelo construido**: {model.built}")

                    # Verificar si el modelo tiene input_spec
                    if hasattr(model, 'input_spec') and model.input_spec:
                        st.write(f"- **Input spec definido**: ‚úÖ")
                    else:
                        st.write(f"- **Input spec definido**: ‚ùå")

                    # Verificar layers
                    for i, layer in enumerate(model.layers):
                        layer_built = getattr(layer, 'built', False)
                        st.write(
                            f"- **Capa {i+1} ({layer.__class__.__name__})**: {'‚úÖ' if layer_built else '‚ùå'}")

                except Exception as debug_error:
                    st.write(f"- **Error en debug**: {debug_error}")

                st.info("""
                üí° **Posibles soluciones:**
                - El modelo necesita estar completamente construido antes del an√°lisis
                - Intenta hacer algunas predicciones primero para que el modelo se inicialice
                - Si el problema persiste, vuelve a entrenar el modelo
                - Este error puede ocurrir con modelos Sequential que no han definido su input shape correctamente
                """)

                # Bot√≥n para intentar "reparar" el modelo
                if st.button("üîß Intentar Reparar Modelo para An√°lisis", key="repair_model_viz"):
                    try:
                        st.info("Intentando construir el modelo completamente...")
                        # Hacer varias predicciones para asegurar que el modelo se construya
                        X_test, _ = st.session_state.nn_test_data

                        # Predicci√≥n con batch peque√±o
                        _ = model.predict(X_test[:1], verbose=0)

                        # Predicci√≥n con batch m√°s grande
                        batch_size = min(32, len(X_test))
                        _ = model.predict(X_test[:batch_size], verbose=0)

                        # Intentar construir expl√≠citamente
                        if hasattr(model, 'build') and not model.built:
                            # Obtener el input shape del primer batch
                            input_shape = X_test[:1].shape
                            model.build(input_shape)

                        st.success(
                            "‚úÖ Modelo reparado. Intenta el an√°lisis de activaciones nuevamente.")
                        st.rerun()

                    except Exception as repair_error:
                        st.error(
                            f"‚ùå No se pudo reparar el modelo: {repair_error}")
                        st.info("Considera reentrenar el modelo desde cero.")

        # Bot√≥n para generar c√≥digo de visualizaci√≥n
        st.markdown("### üíª C√≥digo Python")
        if st.button("üìù Generar C√≥digo de Visualizaci√≥n", use_container_width=True):
            code = generate_neural_network_visualization_code(config)

            st.markdown("#### üêç C√≥digo Python para Visualizaciones")
            st.code(code, language='python')

            st.download_button(
                label="üíæ Descargar C√≥digo de Visualizaci√≥n",
                data=code,
                file_name="visualizaciones_red_neuronal.py",
                mime="text/plain"
            )

        # Navegaci√≥n
        st.markdown("---")
        st.markdown("### üß≠ Navegaci√≥n")
        col_nav1, col_nav2 = st.columns(2)
        with col_nav1:
            if st.button("üîô Volver a Evaluaci√≥n", use_container_width=True):
                st.session_state.active_tab_nn = 3
                st.rerun()
        with col_nav2:
            if st.button("üîÆ Hacer Predicciones", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 5
                st.rerun()

    except Exception as e:
        st.error(f"‚ùå Error en las visualizaciones: {str(e)}")

        # Diagn√≥stico detallado del error
        error_type = type(e).__name__
        error_msg = str(e)

        st.markdown("### üîç Diagn√≥stico del Error")

        if "never been called" in error_msg or "no defined input" in error_msg:
            st.error("üö® **Problema de Inicializaci√≥n del Modelo**")
            st.markdown("""
            **Causa del problema:**
            - El modelo Sequential no ha sido completamente inicializado
            - Las capas no tienen sus formas de entrada definidas
            - Se necesita hacer al menos una predicci√≥n para construir el modelo
            """)

            # Bot√≥n de reparaci√≥n autom√°tica
            col1, col2 = st.columns(2)

            with col1:
                if st.button("üîß Reparar Modelo Autom√°ticamente", type="primary", key="auto_repair"):
                    try:
                        st.info("üîÑ Reparando modelo...")

                        # Obtener datos de test
                        if 'nn_test_data' in st.session_state:
                            X_test, y_test = st.session_state.nn_test_data

                            # Forzar construcci√≥n del modelo con m√∫ltiples estrategias
                            with st.spinner("Inicializando modelo..."):
                                # Estrategia 1: Predicci√≥n simple
                                _ = model.predict(X_test[:1], verbose=0)

                                # Estrategia 2: Predicci√≥n con batch m√°s grande
                                batch_size = min(10, len(X_test))
                                _ = model.predict(
                                    X_test[:batch_size], verbose=0)

                                # Estrategia 3: Compilar expl√≠citamente si es necesario
                                if not model.built:
                                    model.build(input_shape=(
                                        None, X_test.shape[1]))

                                # Estrategia 4: Verificar que todas las capas est√©n construidas
                                for layer in model.layers:
                                    if hasattr(layer, 'built') and not layer.built:
                                        layer.build(input_shape=(
                                            None, X_test.shape[1]))

                            # Verificar que el modelo est√© funcionando
                            test_pred = model.predict(X_test[:5], verbose=0)

                            st.success("‚úÖ ¬°Modelo reparado exitosamente!")
                            st.info(
                                "El modelo ahora est√° completamente inicializado. Puedes usar todas las visualizaciones.")

                            # Bot√≥n para recargar visualizaciones
                            if st.button("üîÑ Recargar Visualizaciones", type="primary"):
                                st.rerun()

                        else:
                            st.error(
                                "‚ùå No se encontraron datos de test para reparar el modelo")

                    except Exception as repair_error:
                        st.error(
                            f"‚ùå Error durante la reparaci√≥n: {repair_error}")
                        st.info("Intenta reentrenar el modelo desde cero.")

            with col2:
                st.markdown("**üí° Soluci√≥n manual:**")
                st.markdown("""
                1. Ve a la pesta√±a **'Entrenamiento'**
                2. Reentrena el modelo desde cero
                3. Regresa a esta pesta√±a
                4. Las visualizaciones deber√≠an funcionar
                """)

                if st.button("üîô Ir a Entrenamiento", key="go_training"):
                    st.session_state.active_tab_nn = 2
                    st.rerun()

        else:
            # Otros tipos de errores
            st.warning("‚ö†Ô∏è **Error Inesperado**")
            st.code(f"Tipo: {error_type}\nMensaje: {error_msg}")

            st.markdown("""
            **Posibles soluciones:**
            - Verifica que TensorFlow est√© instalado correctamente
            - Aseg√∫rate de que el modelo est√© entrenado
            - Intenta reentrenar el modelo
            - Reinicia la aplicaci√≥n si persiste el problema
            """)

        # Informaci√≥n t√©cnica adicional
        with st.expander("üî¨ Informaci√≥n T√©cnica Detallada"):
            try:
                st.write("**Estado del Modelo:**")
                st.write(f"- Tipo: {type(model).__name__}")
                st.write(
                    f"- Construido: {getattr(model, 'built', 'No disponible')}")
                st.write(
                    f"- N√∫mero de capas: {len(model.layers) if hasattr(model, 'layers') else 'No disponible'}")

                if hasattr(model, 'input'):
                    st.write(
                        f"- Input definido: {'‚úÖ' if model.input is not None else '‚ùå'}")

                if hasattr(model, 'layers'):
                    st.write("**Estado de las Capas:**")
                    for i, layer in enumerate(model.layers):
                        layer_built = getattr(layer, 'built', False)
                        st.write(
                            f"  - Capa {i+1} ({layer.__class__.__name__}): {'‚úÖ' if layer_built else '‚ùå'}")

            except Exception as debug_error:
                st.write(f"Error obteniendo informaci√≥n: {debug_error}")

        st.info("üí° **Tip**: Este error es com√∫n con modelos Sequential. La reparaci√≥n autom√°tica deber√≠a resolverlo.")


def show_neural_network_predictions():
    """Interfaz para hacer predicciones con el modelo entrenado."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "‚ö†Ô∏è Primero debes entrenar un modelo en la pesta√±a 'Entrenamiento'")
        return

    try:
        import numpy as np
        import pandas as pd
        import scipy.stats

        model = st.session_state.nn_model
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        if 'nn_df' not in st.session_state or 'nn_target_col' not in st.session_state:
            st.error("No hay datos disponibles para hacer predicciones.")
            return

        df = st.session_state.nn_df
        target_col = st.session_state.nn_target_col
        feature_cols = [col for col in df.columns if col != target_col]

        st.header("üéØ Hacer Predicciones")

        # Tabs para diferentes tipos de predicci√≥n
        pred_tab1, pred_tab2, pred_tab3 = st.tabs([
            "üîç Predicci√≥n Individual",
            "üìä Predicci√≥n por Lotes",
            "üé≤ Exploraci√≥n Interactiva"
        ])

        with pred_tab1:
            st.subheader("üîç Predicci√≥n Individual")
            st.markdown("Introduce los valores para cada caracter√≠stica:")

            # Crear inputs para cada caracter√≠stica
            input_values = {}

            # Organizar en columnas
            num_cols = min(3, len(feature_cols))
            cols = st.columns(num_cols)

            for i, feature in enumerate(feature_cols):
                col_idx = i % num_cols

                with cols[col_idx]:
                    # Obtener estad√≠sticas de la caracter√≠stica
                    min_val = float(df[feature].min())
                    max_val = float(df[feature].max())
                    mean_val = float(df[feature].mean())

                    input_values[feature] = st.number_input(
                        f"{feature}",
                        min_value=min_val,
                        max_value=max_val,
                        value=mean_val,
                        step=(max_val - min_val) / 100,
                        key=f"nn_pred_{feature}"
                    )

                    st.caption(
                        f"Min: {min_val:.2f}, Max: {max_val:.2f}, Media: {mean_val:.2f}")

            # Bot√≥n para hacer predicci√≥n
            if st.button("üöÄ Hacer Predicci√≥n", type="primary"):
                # Preparar datos para predicci√≥n
                input_array = np.array(
                    [[input_values[feature] for feature in feature_cols]])
                input_scaled = scaler.transform(input_array)

                # Hacer predicci√≥n
                prediction = model.predict(input_scaled, verbose=0)

                # Mostrar resultados
                st.success("‚úÖ Predicci√≥n completada")

                if config['task_type'] == 'Clasificaci√≥n':
                    output_size = safe_get_output_size(config)
                    if output_size > 2:  # Multiclase
                        predicted_class_idx = np.argmax(prediction[0])
                        confidence = prediction[0][predicted_class_idx]

                        if label_encoder:
                            predicted_class = label_encoder.inverse_transform(
                                [predicted_class_idx])[0]
                        else:
                            predicted_class = f"Clase {predicted_class_idx}"

                        # Mostrar resultado principal
                        col1, col2 = st.columns(2)

                        with col1:
                            st.metric("üéØ Clase Predicha", predicted_class)

                        with col2:
                            st.metric(
                                "üé≤ Confianza", f"{confidence:.4f}", f"{confidence*100:.2f}%")

                        # Mostrar probabilidades para todas las clases
                        st.subheader("üìä Probabilidades por Clase")

                        prob_data = []
                        for i, prob in enumerate(prediction[0]):
                            if label_encoder:
                                class_name = label_encoder.inverse_transform([i])[
                                    0]
                            else:
                                class_name = f"Clase {i}"

                            prob_data.append({
                                'Clase': class_name,
                                'Probabilidad': f"{prob:.4f}",
                                'Porcentaje': f"{prob*100:.2f}%"
                            })

                        st.dataframe(prob_data, use_container_width=True)

                        # Gr√°fico de barras de probabilidades
                        import plotly.graph_objects as go

                        class_names = [item['Clase'] for item in prob_data]
                        probabilities = [float(item['Probabilidad'])
                                         for item in prob_data]

                        fig = go.Figure(data=[
                            go.Bar(x=class_names, y=probabilities,
                                   marker_color=['red' if i == predicted_class_idx else 'lightblue'
                                                 for i in range(len(class_names))])
                        ])

                        fig.update_layout(
                            title="Distribuci√≥n de Probabilidades",
                            xaxis_title="Clases",
                            yaxis_title="Probabilidad",
                            height=400
                        )

                        st.plotly_chart(fig, use_container_width=True)

                    else:  # Binaria
                        probability = prediction[0][0]
                        predicted_class_idx = 1 if probability > 0.5 else 0

                        if label_encoder:
                            predicted_class = label_encoder.inverse_transform(
                                [predicted_class_idx])[0]
                        else:
                            predicted_class = f"Clase {predicted_class_idx}"

                        col1, col2, col3 = st.columns(3)

                        with col1:
                            st.metric("üéØ Clase Predicha", predicted_class)

                        with col2:
                            st.metric("üé≤ Probabilidad", f"{probability:.4f}")

                        with col3:
                            confidence = max(probability, 1 - probability)
                            st.metric(
                                "‚ú® Confianza", f"{confidence:.4f}", f"{confidence*100:.2f}%")

                else:  # Regresi√≥n
                    predicted_value = prediction[0][0]

                    st.metric("üéØ Valor Predicho", f"{predicted_value:.6f}")

                    # Informaci√≥n adicional para regresi√≥n
                    target_stats = df[target_col].describe()

                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.info(f"üìä **Estad√≠sticas del Target:**\n"
                                f"- Media: {target_stats['mean']:.4f}\n"
                                f"- Mediana: {target_stats['50%']:.4f}")

                    with col2:
                        st.info(f"üìè **Rango de Datos:**\n"
                                f"- M√≠nimo: {target_stats['min']:.4f}\n"
                                f"- M√°ximo: {target_stats['max']:.4f}")

                    with col3:
                        deviation_from_mean = abs(
                            predicted_value - target_stats['mean'])
                        st.info(f"üéØ **An√°lisis:**\n"
                                f"- Desviaci√≥n de la media: {deviation_from_mean:.4f}\n"
                                f"- Percentil aproximado: {scipy.stats.percentileofscore(df[target_col], predicted_value):.1f}%")

        with pred_tab2:
            st.subheader("üìä Predicci√≥n por Lotes")

            st.markdown(
                "Sube un archivo CSV con nuevos datos para hacer predicciones en lote:")

            uploaded_file = st.file_uploader(
                "Selecciona archivo CSV",
                type=['csv'],
                key="nn_batch_predictions"
            )

            if uploaded_file is not None:
                try:
                    # Cargar datos
                    new_df = pd.read_csv(uploaded_file)

                    st.success(
                        f"‚úÖ Archivo cargado: {new_df.shape[0]} filas, {new_df.shape[1]} columnas")

                    # Verificar que las columnas coincidan
                    missing_features = set(feature_cols) - set(new_df.columns)
                    extra_features = set(new_df.columns) - set(feature_cols)

                    if missing_features:
                        st.error(
                            f"‚ùå Faltan caracter√≠sticas: {', '.join(missing_features)}")
                    elif extra_features:
                        st.warning(
                            f"‚ö†Ô∏è Caracter√≠sticas adicionales (ser√°n ignoradas): {', '.join(extra_features)}")
                        # Seleccionar solo las caracter√≠sticas necesarias
                        new_df = new_df[feature_cols]

                    if not missing_features:
                        # Mostrar vista previa
                        st.dataframe(new_df.head(), use_container_width=True)

                        if st.button("üöÄ Generar Predicciones", type="primary"):
                            # Procesar datos
                            new_data_scaled = scaler.transform(new_df)

                            # Hacer predicciones
                            batch_predictions = model.predict(
                                new_data_scaled, verbose=0)

                            # Procesar resultados seg√∫n el tipo de tarea
                            if config['task_type'] == 'Clasificaci√≥n':
                                output_size = safe_get_output_size(config)
                                if output_size > 2:
                                    predicted_classes_idx = np.argmax(
                                        batch_predictions, axis=1)
                                    confidences = np.max(
                                        batch_predictions, axis=1)

                                    if label_encoder:
                                        predicted_classes = label_encoder.inverse_transform(
                                            predicted_classes_idx)
                                    else:
                                        predicted_classes = [
                                            f"Clase {idx}" for idx in predicted_classes_idx]

                                    results_df = new_df.copy()
                                    results_df['Predicci√≥n'] = predicted_classes
                                    results_df['Confianza'] = confidences

                                else:  # Binaria
                                    probabilities = batch_predictions.flatten()
                                    predicted_classes_idx = (
                                        probabilities > 0.5).astype(int)
                                    confidences = np.maximum(
                                        probabilities, 1 - probabilities)

                                    if label_encoder:
                                        predicted_classes = label_encoder.inverse_transform(
                                            predicted_classes_idx)
                                    else:
                                        predicted_classes = [
                                            f"Clase {idx}" for idx in predicted_classes_idx]

                                    results_df = new_df.copy()
                                    results_df['Predicci√≥n'] = predicted_classes
                                    results_df['Probabilidad'] = probabilities
                                    results_df['Confianza'] = confidences

                            else:  # Regresi√≥n
                                predicted_values = batch_predictions.flatten()

                                results_df = new_df.copy()
                                results_df['Predicci√≥n'] = predicted_values

                            # Mostrar resultados
                            st.success(
                                f"‚úÖ Predicciones generadas para {len(results_df)} muestras")
                            st.dataframe(results_df, use_container_width=True)

                            # Bot√≥n para descargar resultados
                            csv_results = results_df.to_csv(index=False)
                            st.download_button(
                                label="üì• Descargar Resultados",
                                data=csv_results,
                                file_name="predicciones_neural_network.csv",
                                mime="text/csv"
                            )

                except Exception as e:
                    st.error(f"Error procesando archivo: {str(e)}")

            else:
                # Mostrar formato esperado
                st.info("üìã **Formato esperado del archivo CSV:**")

                sample_data = df[feature_cols].head(3)
                st.dataframe(sample_data, use_container_width=True)

                st.markdown(
                    "El archivo debe contener las siguientes columnas:")
                st.code(", ".join(feature_cols))

        with pred_tab3:
            st.subheader("üé≤ Exploraci√≥n Interactiva")

            # Informaci√≥n educativa sobre la exploraci√≥n interactiva
            with st.expander("‚ÑπÔ∏è ¬øQu√© es la Exploraci√≥n Interactiva?", expanded=False):
                st.markdown("""
                **La exploraci√≥n interactiva** te permite entender c√≥mo el modelo neural toma decisiones:
                
                üîç **¬øPara qu√© sirve?**
                - Ver c√≥mo cada caracter√≠stica influye en las predicciones
                - Identificar patrones y comportamientos del modelo
                - Detectar posibles sesgos o comportamientos inesperados
                - Comprender la sensibilidad del modelo a cambios en los datos
                
                üìä **¬øC√≥mo interpretar los resultados?**
                - **L√≠neas ascendentes**: La caracter√≠stica tiene correlaci√≥n positiva
                - **L√≠neas descendentes**: La caracter√≠stica tiene correlaci√≥n negativa  
                - **L√≠neas planas**: La caracter√≠stica tiene poco impacto
                - **Cambios abruptos**: Puntos de decisi√≥n cr√≠ticos del modelo
                
                üí° **Consejos de uso:**
                - Prueba diferentes muestras base para ver patrones generales
                - Observa qu√© caracter√≠sticas causan mayores cambios
                - Busca comportamientos inesperados o poco realistas
                """)

            st.markdown(
                "üéØ **Explora c√≥mo cambian las predicciones al modificar diferentes caracter√≠sticas:**")

            # Seleccionar una muestra base
            st.markdown("**1. üìç Selecciona una muestra base:**")

            st.info("üí° **Tip:** La muestra base es tu punto de referencia. Todas las exploraciones mostrar√°n c√≥mo cambian las predicciones desde este punto inicial.")

            sample_idx = st.selectbox(
                "√çndice de muestra:",
                range(len(df)),
                format_func=lambda x: f"Muestra {x}",
                key="nn_interactive_sample"
            )

            base_sample = df.iloc[sample_idx][feature_cols].to_dict()

            # Mostrar valores base
            st.markdown("**2. üìã Valores base de la muestra:**")
            st.caption(
                "Estos son los valores de todas las caracter√≠sticas para la muestra seleccionada:")
            base_df = pd.DataFrame([base_sample])
            st.dataframe(base_df, use_container_width=True)

            # Hacer predicci√≥n base
            base_array = np.array([[base_sample[feature]
                                  for feature in feature_cols]])
            base_scaled = scaler.transform(base_array)
            base_prediction = model.predict(base_scaled, verbose=0)

            if config['task_type'] == 'Clasificaci√≥n':
                output_size = safe_get_output_size(config)
                if output_size > 2:
                    base_class_idx = np.argmax(base_prediction[0])
                    base_confidence = base_prediction[0][base_class_idx]

                    if label_encoder:
                        base_class = label_encoder.inverse_transform([base_class_idx])[
                            0]
                    else:
                        base_class = f"Clase {base_class_idx}"

                    st.info(
                        f"üéØ **Predicci√≥n Base:** {base_class} (Confianza: {base_confidence:.3f})")
                else:
                    base_prob = base_prediction[0][0]
                    base_class_idx = 1 if base_prob > 0.5 else 0

                    if label_encoder:
                        base_class = label_encoder.inverse_transform([base_class_idx])[
                            0]
                    else:
                        base_class = f"Clase {base_class_idx}"

                    st.info(
                        f"üéØ **Predicci√≥n Base:** {base_class} (Probabilidad: {base_prob:.3f})")
            else:
                base_value = base_prediction[0][0]
                st.info(f"üéØ **Predicci√≥n Base:** {base_value:.6f}")

            # Seleccionar caracter√≠stica para explorar
            st.markdown("**3. üîç Explora el efecto de una caracter√≠stica:**")

            st.info("üéØ **Objetivo:** Ver√°s c√≥mo cambia la predicci√≥n cuando modificas solo UNA caracter√≠stica, manteniendo todas las dem√°s constantes. Esto te ayuda a entender la importancia relativa de cada variable.")

            feature_to_explore = st.selectbox(
                "Caracter√≠stica a explorar:",
                feature_cols,
                key="nn_explore_feature",
                help="Selecciona la caracter√≠stica cuyo efecto quieres analizar en las predicciones"
            )

            # Crear rango de valores para la caracter√≠stica seleccionada
            min_val = float(df[feature_to_explore].min())
            max_val = float(df[feature_to_explore].max())

            # Generar valores para exploraci√≥n
            exploration_values = np.linspace(min_val, max_val, 50)
            exploration_predictions = []

            for val in exploration_values:
                # Crear muestra modificada
                modified_sample = base_sample.copy()
                modified_sample[feature_to_explore] = val

                # Hacer predicci√≥n
                modified_array = np.array(
                    [[modified_sample[feature] for feature in feature_cols]])
                modified_scaled = scaler.transform(modified_array)
                pred = model.predict(modified_scaled, verbose=0)

                if config['task_type'] == 'Clasificaci√≥n':
                    output_size = safe_get_output_size(config)
                    if output_size > 2:
                        pred_class_idx = np.argmax(pred[0])
                        confidence = pred[0][pred_class_idx]
                        exploration_predictions.append(
                            (pred_class_idx, confidence))
                    else:
                        prob = pred[0][0]
                        exploration_predictions.append(prob)
                else:
                    exploration_predictions.append(pred[0][0])

            # Crear visualizaci√≥n
            import plotly.graph_objects as go

            fig = go.Figure()

            if config['task_type'] == 'Clasificaci√≥n':
                output_size = safe_get_output_size(config)
                if output_size > 2:
                    # Multiclase: mostrar clase predicha y confianza
                    classes = [pred[0] for pred in exploration_predictions]
                    confidences = [pred[1] for pred in exploration_predictions]

                    fig.add_trace(go.Scatter(
                        x=exploration_values,
                        y=classes,
                        mode='lines+markers',
                        name='Clase Predicha',
                        yaxis='y1'
                    ))

                    fig.add_trace(go.Scatter(
                        x=exploration_values,
                        y=confidences,
                        mode='lines+markers',
                        name='Confianza',
                        yaxis='y2',
                        line=dict(color='red')
                    ))

                    fig.update_layout(
                        title=f'Efecto de {feature_to_explore} en la Predicci√≥n',
                        xaxis_title=feature_to_explore,
                        yaxis=dict(title='Clase Predicha', side='left'),
                        yaxis2=dict(title='Confianza',
                                    side='right', overlaying='y'),
                        height=500
                    )
                else:
                    # Binaria: mostrar probabilidad
                    fig.add_trace(go.Scatter(
                        x=exploration_values,
                        y=exploration_predictions,
                        mode='lines+markers',
                        name='Probabilidad'
                    ))

                    fig.add_hline(y=0.5, line_dash="dash", line_color="red",
                                  annotation_text="Umbral de decisi√≥n")

                    fig.update_layout(
                        title=f'Efecto de {feature_to_explore} en la Probabilidad',
                        xaxis_title=feature_to_explore,
                        yaxis_title='Probabilidad',
                        height=500
                    )
            else:
                # Regresi√≥n
                fig.add_trace(go.Scatter(
                    x=exploration_values,
                    y=exploration_predictions,
                    mode='lines+markers',
                    name='Predicci√≥n'
                ))

                fig.update_layout(
                    title=f'Efecto de {feature_to_explore} en la Predicci√≥n',
                    xaxis_title=feature_to_explore,
                    yaxis_title='Valor Predicho',
                    height=500
                )

            # Marcar el valor base
            base_val = base_sample[feature_to_explore]
            fig.add_vline(x=base_val, line_dash="dash", line_color="green",
                          annotation_text="Valor Base")

            st.plotly_chart(fig, use_container_width=True)

            # An√°lisis interpretativo
            st.markdown("**üìà An√°lisis de Resultados:**")

            # Calcular estad√≠sticas del efecto
            if config['task_type'] == 'Clasificaci√≥n':
                output_size = safe_get_output_size(config)
                if output_size <= 2:
                    pred_range = max(exploration_predictions) - \
                        min(exploration_predictions)
                    volatility = np.std(exploration_predictions)

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Rango de Probabilidades", f"{pred_range:.3f}",
                                  help="Diferencia entre la probabilidad m√°xima y m√≠nima observada")
                    with col2:
                        st.metric("Volatilidad", f"{volatility:.3f}",
                                  help="Qu√© tan variables son las predicciones (desviaci√≥n est√°ndar)")

                    if pred_range > 0.3:
                        st.success(
                            f"üéØ **Caracter√≠stica muy influyente:** '{feature_to_explore}' tiene un gran impacto en las predicciones")
                    elif pred_range > 0.1:
                        st.warning(
                            f"üìä **Caracter√≠stica moderadamente influyente:** '{feature_to_explore}' tiene un impacto moderado")
                    else:
                        st.info(
                            f"üìâ **Caracter√≠stica poco influyente:** '{feature_to_explore}' tiene poco impacto en las predicciones")
            else:
                pred_range = max(exploration_predictions) - \
                    min(exploration_predictions)
                pred_mean = np.mean(exploration_predictions)
                relative_impact = (pred_range / abs(pred_mean)
                                   ) * 100 if pred_mean != 0 else 0

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Rango de Predicciones", f"{pred_range:.6f}")
                with col2:
                    st.metric("Impacto Relativo", f"{relative_impact:.1f}%")

                if relative_impact > 20:
                    st.success(
                        f"üéØ **Caracter√≠stica muy influyente:** '{feature_to_explore}' causa cambios significativos")
                elif relative_impact > 5:
                    st.warning(
                        f"üìä **Caracter√≠stica moderadamente influyente:** '{feature_to_explore}' tiene impacto moderado")
                else:
                    st.info(
                        f"üìâ **Caracter√≠stica poco influyente:** '{feature_to_explore}' tiene poco impacto")

            # Consejos interpretativos
            with st.expander("üí° Consejos para Interpretar los Resultados", expanded=False):
                st.markdown(f"""
                **üîç Analizando '{feature_to_explore}':**
                
                ‚úÖ **Buenas se√±ales:**
                - Cambios graduales y suaves en las predicciones
                - Comportamiento consistente con el conocimiento del dominio
                - Relaciones monot√≥nicas (siempre creciente o decreciente)
                
                ‚ö†Ô∏è **Se√±ales de alerta:**
                - Cambios muy abruptos sin explicaci√≥n l√≥gica
                - Comportamientos contradictorios al conocimiento experto
                - Excesiva sensibilidad a peque√±os cambios
                
                **üéØ Pr√≥ximos pasos:**
                1. Prueba con diferentes muestras base para confirmar patrones
                2. Explora otras caracter√≠sticas para comparar importancias
                3. Si encuentras comportamientos extra√±os, considera reentrenar el modelo
                4. Documenta los insights para mejorar futuras versiones del modelo
                """)

    except Exception as e:
        st.error(f"Error en las predicciones: {str(e)}")
        st.info("Aseg√∫rate de que el modelo est√© entrenado correctamente.")


def show_neural_network_export():
    """Permite exportar el modelo entrenado."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "‚ö†Ô∏è Primero debes entrenar un modelo en la pesta√±a 'Entrenamiento'")
        return

    try:
        import pickle
        import json
        from datetime import datetime

        model = st.session_state.nn_model
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        st.header("üì¶ Exportar Modelo")

        # Informaci√≥n del modelo
        st.subheader("‚ÑπÔ∏è Informaci√≥n del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            st.info(f"""
            **Arquitectura:**
            - Tipo: {config['task_type']}
            - Capas: {len(config['architecture'])}
            - Neuronas: {config['architecture']}
            - Activaci√≥n: {config['activation']}
            - Optimizador: {config['optimizer']}
            """)

        with col2:
            total_params = calculate_network_parameters(config['architecture'])
            st.info(f"""
            **Par√°metros:**
            - Total: {total_params:,}
            - Dropout: {config['dropout_rate']}
            - Batch size: {config['batch_size']}
            - Fecha entrenamiento: {datetime.now().strftime('%Y-%m-%d %H:%M')}
            """)

        # Opciones de exportaci√≥n
        st.subheader("üìÅ Opciones de Exportaci√≥n")

        export_tab1, export_tab2, export_tab3, export_tab4 = st.tabs([
            "ü§ñ Modelo TensorFlow",
            "üìä Modelo Completo",
            "üìù C√≥digo Python",
            "üìã Metadatos"
        ])

        with export_tab1:
            st.markdown("**Exportar solo el modelo de TensorFlow:**")

            format_option = st.radio(
                "Formato:",
                ["SavedModel (.pb)", "HDF5 (.h5)",
                 "TensorFlow Lite (.tflite)"],
                key="nn_export_format"
            )

            if st.button("üíæ Exportar Modelo TensorFlow", type="primary"):
                try:
                    if format_option == "SavedModel (.pb)":
                        # Guardar como SavedModel
                        import tempfile
                        import zipfile
                        import io

                        with tempfile.TemporaryDirectory() as temp_dir:
                            model_path = f"{temp_dir}/neural_network_model"
                            model.save(model_path)

                            # Crear ZIP con el modelo
                            zip_buffer = io.BytesIO()
                            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                                import os
                                for root, dirs, files in os.walk(model_path):
                                    for file in files:
                                        file_path = os.path.join(root, file)
                                        arc_name = os.path.relpath(
                                            file_path, temp_dir)
                                        zip_file.write(file_path, arc_name)

                            zip_buffer.seek(0)

                            st.download_button(
                                label="üì• Descargar SavedModel",
                                data=zip_buffer.getvalue(),
                                file_name="neural_network_savedmodel.zip",
                                mime="application/zip"
                            )

                    elif format_option == "HDF5 (.h5)":
                        # Guardar como HDF5
                        import io
                        import tempfile

                        with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as tmp_file:
                            model.save(tmp_file.name)

                            with open(tmp_file.name, 'rb') as f:
                                model_data = f.read()

                            st.download_button(
                                label="üì• Descargar Modelo HDF5",
                                data=model_data,
                                file_name="neural_network_model.h5",
                                mime="application/octet-stream"
                            )

                    elif format_option == "TensorFlow Lite (.tflite)":
                        # Convertir a TensorFlow Lite
                        import tensorflow as tf

                        converter = tf.lite.TFLiteConverter.from_keras_model(
                            model)
                        tflite_model = converter.convert()

                        st.download_button(
                            label="üì• Descargar Modelo TFLite",
                            data=tflite_model,
                            file_name="neural_network_model.tflite",
                            mime="application/octet-stream"
                        )

                        st.success("‚úÖ Modelo convertido a TensorFlow Lite")
                        st.info(
                            "üí° TensorFlow Lite es ideal para aplicaciones m√≥viles y embebidas")

                except Exception as e:
                    st.error(f"Error exportando modelo: {str(e)}")

        with export_tab2:
            st.markdown("**Exportar modelo completo con preprocesadores:**")
            st.info("Incluye el modelo, scaler, label encoder y configuraci√≥n")

            if st.button("üíæ Exportar Modelo Completo", type="primary"):
                try:
                    # Crear diccionario con todos los componentes
                    complete_model = {
                        'model': model,
                        'scaler': scaler,
                        'label_encoder': label_encoder,
                        'config': config,
                        'feature_names': st.session_state.get('nn_feature_names', []),
                        'export_date': datetime.now().isoformat(),
                        'version': '1.0'
                    }

                    # Serializar con pickle
                    model_data = pickle.dumps(complete_model)

                    st.download_button(
                        label="üì• Descargar Modelo Completo",
                        data=model_data,
                        file_name="neural_network_complete.pkl",
                        mime="application/octet-stream"
                    )

                    st.success("‚úÖ Modelo completo exportado")
                    st.info(
                        "üí° Este archivo contiene todo lo necesario para hacer predicciones")

                except Exception as e:
                    st.error(f"Error exportando modelo completo: {str(e)}")

            # Mostrar c√≥digo de ejemplo para cargar
            st.markdown("**C√≥digo para cargar el modelo:**")

            load_code = """
import pickle
import numpy as np

# Cargar modelo completo
with open('neural_network_complete.pkl', 'rb') as f:
    loaded_model = pickle.load(f)

model = loaded_model['model']
scaler = loaded_model['scaler']
label_encoder = loaded_model['label_encoder']
config = loaded_model['config']

# Hacer predicci√≥n con nuevos datos
def predecir(nuevos_datos):
    # nuevos_datos debe ser una lista con valores para cada caracter√≠stica
    datos_escalados = scaler.transform([nuevos_datos])
    prediccion = model.predict(datos_escalados)
    
    if config['task_type'] == 'Clasificaci√≥n':
        output_size = safe_get_output_size(config)
        if output_size > 2:
            clase_idx = np.argmax(prediccion[0])
            if label_encoder:
                clase = label_encoder.inverse_transform([clase_idx])[0]
            else:
                clase = f"Clase {clase_idx}"
            confianza = prediccion[0][clase_idx]
            return clase, confianza
        else:
            probabilidad = prediccion[0][0]
            clase_idx = 1 if probabilidad > 0.5 else 0
            if label_encoder:
                clase = label_encoder.inverse_transform([clase_idx])[0]
            else:
                clase = f"Clase {clase_idx}"
            return clase, probabilidad
    else:
        return prediccion[0][0]

# Ejemplo de uso:
# resultado = predecir([valor1, valor2, valor3, ...])
# print(resultado)
"""

            st.code(load_code, language='python')

        with export_tab3:
            st.markdown("**Generar c√≥digo Python independiente:**")

            if st.button("üìù Generar C√≥digo", type="primary"):
                try:
                    # Obtener pesos del modelo
                    weights_data = []
                    for layer in model.layers:
                        if hasattr(layer, 'get_weights') and layer.get_weights():
                            weights_data.append(layer.get_weights())

                    # Generar c√≥digo
                    code = f"""
# C√≥digo generado autom√°ticamente para Red Neuronal
# Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder

class NeuralNetworkPredictor:
    def __init__(self):
        # Configuraci√≥n del modelo
        self.config = {json.dumps(config, indent=8)}
        
        # Inicializar preprocesadores
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder() if {bool(label_encoder)} else None
        
        # Configurar preprocesadores (reemplaza con tus datos de entrenamiento)
        # self.scaler.fit(X_train)  # X_train son tus datos de entrenamiento
        # if self.label_encoder:
        #     self.label_encoder.fit(y_train)  # y_train son tus etiquetas
        
    def activation_function(self, x, activation):
        \"\"\"Implementa funciones de activaci√≥n\"\"\"
        if activation == 'relu':
            return np.maximum(0, x)
        elif activation == 'sigmoid':
            return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
        elif activation == 'tanh':
            return np.tanh(x)
        elif activation == 'softmax':
            exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
            return exp_x / np.sum(exp_x, axis=1, keepdims=True)
        else:
            return x  # linear
    
    def predict(self, X):
        \"\"\"Hace predicciones con la red neuronal\"\"\"
        # Normalizar entrada
        X_scaled = self.scaler.transform(X)
        
        # Forward pass a trav√©s de las capas
        # NOTA: Debes implementar los pesos espec√≠ficos de tu modelo entrenado
        
        # Ejemplo de estructura (reemplaza con tus pesos reales):
        # layer_1 = self.activation_function(np.dot(X_scaled, weights_1) + bias_1, '{config['activation']}')
        # layer_2 = self.activation_function(np.dot(layer_1, weights_2) + bias_2, '{config['activation']}')
        # output = self.activation_function(np.dot(layer_2, weights_out) + bias_out, '{config['output_activation']}')
        
        # Placeholder para la implementaci√≥n
        print("‚ö†Ô∏è Implementa los pesos espec√≠ficos del modelo en este m√©todo")
        return np.zeros((X.shape[0], {config['output_size']}))
    
    def predict_class(self, X):
        \"\"\"Predicci√≥n para clasificaci√≥n\"\"\"
        predictions = self.predict(X)
        
        if self.config['task_type'] == 'Clasificaci√≥n':
            output_size = safe_get_output_size(self.config)
            if output_size > 2:
                class_indices = np.argmax(predictions, axis=1)
                if self.label_encoder:
                    return self.label_encoder.inverse_transform(class_indices)
                else:
                    return [f"Clase {{i}}" for i in class_indices]
            else:
                class_indices = (predictions > 0.5).astype(int).flatten()
                if self.label_encoder:
                    return self.label_encoder.inverse_transform(class_indices)
                else:
                    return [f"Clase {{i}}" for i in class_indices]
        else:
            return predictions.flatten()

# Uso del modelo:
# predictor = NeuralNetworkPredictor()
# 
# # Configura los preprocesadores con tus datos de entrenamiento
# # predictor.scaler.fit(X_train)
# # if predictor.label_encoder:
# #     predictor.label_encoder.fit(y_train)
# 
# # Hacer predicciones
# # nuevos_datos = [[valor1, valor2, valor3, ...]]
# # resultado = predictor.predict_class(nuevos_datos)
# # print(resultado)
"""

                    st.code(code, language='python')

                    # Bot√≥n para descargar el c√≥digo
                    st.download_button(
                        label="üì• Descargar C√≥digo",
                        data=code,
                        file_name="neural_network_predictor.py",
                        mime="text/plain"
                    )

                    st.warning(
                        "‚ö†Ô∏è El c√≥digo generado es una plantilla. Debes implementar los pesos espec√≠ficos del modelo entrenado.")

                except Exception as e:
                    st.error(f"Error generando c√≥digo: {str(e)}")

        with export_tab4:
            st.markdown("**Exportar metadatos del modelo:**")

            # Preparar metadatos
            if 'nn_history' in st.session_state:
                history = st.session_state.nn_history
                final_metrics = {
                    'final_loss': float(history.history['loss'][-1]),
                    'final_val_loss': float(history.history.get('val_loss', [0])[-1]) if 'val_loss' in history.history else None,
                    'epochs_trained': len(history.history['loss'])
                }

                if config['task_type'] == 'Clasificaci√≥n' and 'accuracy' in history.history:
                    final_metrics['final_accuracy'] = float(
                        history.history['accuracy'][-1])
                    if 'val_accuracy' in history.history:
                        final_metrics['final_val_accuracy'] = float(
                            history.history['val_accuracy'][-1])
            else:
                final_metrics = {}

            metadata = {
                'model_info': {
                    'type': 'Neural Network',
                    'task_type': config['task_type'],
                    'architecture': config['architecture'],
                    'total_parameters': calculate_network_parameters(config['architecture']),
                    'activation_function': config['activation'],
                    'output_activation': config['output_activation'],
                    'optimizer': config['optimizer'],
                    'dropout_rate': config['dropout_rate'],
                    'batch_size': config['batch_size']
                },
                'training_info': final_metrics,
                'data_info': {
                    'feature_names': st.session_state.get('nn_feature_names', []),
                    'target_column': st.session_state.get('nn_target_col', ''),
                    'num_features': config['input_size'],
                    'num_classes': config['output_size'] if config['task_type'] == 'Clasificaci√≥n' else 1
                },
                'export_info': {
                    'export_date': datetime.now().isoformat(),
                    'version': '1.0',
                    'framework': 'TensorFlow/Keras'
                }
            }

            # Mostrar metadatos
            st.json(metadata)

            # Bot√≥n para descargar metadatos
            metadata_json = json.dumps(metadata, indent=2)

            st.download_button(
                label="üì• Descargar Metadatos",
                data=metadata_json,
                file_name="neural_network_metadata.json",
                mime="application/json"
            )

        # Informaci√≥n adicional
        st.subheader("üí° Informaci√≥n Adicional")

        st.info("""
        **Recomendaciones para el uso del modelo:**
        
        1. **Modelo TensorFlow**: Ideal para integrar en aplicaciones que ya usan TensorFlow
        2. **Modelo Completo**: Incluye preprocesadores, perfecto para producci√≥n
        3. **C√≥digo Python**: Para entender la implementaci√≥n o crear versiones optimizadas
        4. **Metadatos**: Para documentaci√≥n y seguimiento del modelo
        
        **Consideraciones de versi√≥n:**
        - TensorFlow versi√≥n utilizada en entrenamiento
        - Compatibilidad con versiones futuras
        - Dependencias del entorno de producci√≥n
        """)

    except Exception as e:
        st.error(f"Error en la exportaci√≥n: {str(e)}")
        st.info("Aseg√∫rate de que el modelo est√© entrenado correctamente.")


def generate_neural_network_architecture_code(architecture, activation, output_activation,
                                              dropout_rate, optimizer, batch_size, task_type, feature_names):
    """Genera c√≥digo Python completo para la arquitectura de red neuronal."""

    feature_names_str = str(
        feature_names) if feature_names else "['feature_1', 'feature_2', ...]"

    # Determinar loss y metrics seg√∫n el tipo de tarea
    if task_type == "Clasificaci√≥n":
        if architecture[-1] == 1:  # Clasificaci√≥n binaria
            loss = "binary_crossentropy"
            metrics = "['accuracy']"
            output_processing = """
# Para clasificaci√≥n binaria
y_pred_classes = (y_pred > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred_classes)
print(f"Accuracy: {accuracy:.4f}")
"""
        else:  # Clasificaci√≥n multiclase
            if output_activation == "softmax":
                loss = "sparse_categorical_crossentropy"
            else:
                loss = "categorical_crossentropy"
            metrics = "['accuracy']"
            output_processing = """
# Para clasificaci√≥n multiclase
y_pred_classes = np.argmax(y_pred, axis=1)
accuracy = accuracy_score(y_test, y_pred_classes)
print(f"Accuracy: {accuracy:.4f}")
print("\\nReporte de clasificaci√≥n:")
print(classification_report(y_test, y_pred_classes))
"""
    else:  # Regresi√≥n
        loss = "mse"
        metrics = "['mae']"
        output_processing = """
# Para regresi√≥n
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.4f}")
print(f"MAE: {mae:.4f}")
print(f"R¬≤: {r2:.4f}")
"""

    # Generar c√≥digo de las capas
    layers_code = []
    for i, neurons in enumerate(architecture[1:-1], 1):
        if i == 1:  # Primera capa oculta
            layers_code.append(f"""
# Capa oculta {i}
model.add(Dense({neurons}, activation='{activation}', input_shape=({architecture[0]},)))
model.add(Dropout({dropout_rate}))""")
        else:
            layers_code.append(f"""
# Capa oculta {i}
model.add(Dense({neurons}, activation='{activation}'))
model.add(Dropout({dropout_rate}))""")

    layers_code_str = "".join(layers_code)

    code = f"""# C√≥digo completo para Red Neuronal - {task_type}
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam, SGD, RMSprop
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# 1. CARGAR Y PREPARAR LOS DATOS
# Reemplaza esta secci√≥n con tu m√©todo de carga de datos
# df = pd.read_csv('tu_archivo.csv')  # Cargar desde CSV

# Caracter√≠sticas y variable objetivo
feature_names = {feature_names_str}
# X = df[feature_names]  # Caracter√≠sticas
# y = df['target']  # Variable objetivo

# 2. PREPROCESAMIENTO
# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, 
    stratify=y if '{task_type}' == 'Clasificaci√≥n' else None
)

# Normalizar caracter√≠sticas
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Procesar variable objetivo
{"# Para clasificaci√≥n multiclase con softmax, usar sparse_categorical_crossentropy" if task_type == "Clasificaci√≥n" and architecture[-1] > 1 and output_activation == "softmax" else ""}
{"# Para clasificaci√≥n binaria, mantener y como est√°" if task_type == "Clasificaci√≥n" and architecture[-1] == 1 else ""}
{"# Para regresi√≥n, mantener y como est√°" if task_type == "Regresi√≥n" else ""}

# 3. CONSTRUIR EL MODELO
model = Sequential()
{layers_code_str}

# Capa de salida
model.add(Dense({architecture[-1]}, activation='{output_activation}'))

# 4. COMPILAR EL MODELO
# Seleccionar optimizador
if '{optimizer}' == 'adam':
    optimizer = Adam()
elif '{optimizer}' == 'sgd':
    optimizer = SGD()
elif '{optimizer}' == 'rmsprop':
    optimizer = RMSprop()

model.compile(
    optimizer=optimizer,
    loss='{loss}',
    metrics={metrics}
)

# 5. MOSTRAR RESUMEN DE LA ARQUITECTURA
print("=== ARQUITECTURA DE LA RED NEURONAL ===")
model.summary()

# Informaci√≥n detallada
total_params = model.count_params()
print(f"\\nTotal de par√°metros: {{total_params:,}}")
print(f"Arquitectura: {architecture}")
print(f"Funciones de activaci√≥n: {activation} (ocultas), {output_activation} (salida)")
print(f"Dropout: {dropout_rate}")
print(f"Optimizador: {optimizer}")
print(f"Batch size: {batch_size}")

# 6. ENTRENAR EL MODELO
print("\\n=== INICIANDO ENTRENAMIENTO ===")

# Callbacks opcionales
callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_loss', 
        patience=10, 
        restore_best_weights=True
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss', 
        factor=0.5, 
        patience=5, 
        min_lr=1e-7
    )
]

# Entrenar
history = model.fit(
    X_train_scaled, y_train,
    epochs=100,  # Ajusta seg√∫n necesites
    batch_size={batch_size},
    validation_split=0.2,
    callbacks=callbacks,
    verbose=1
)

# 7. EVALUAR EL MODELO
print("\\n=== EVALUACI√ìN DEL MODELO ===")

# Predicciones
y_pred = model.predict(X_test_scaled)
{output_processing}

# 8. VISUALIZAR HISTORIAL DE ENTRENAMIENTO
plt.figure(figsize=(12, 4))

# P√©rdida
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validaci√≥n')
plt.title('P√©rdida durante el entrenamiento')
plt.xlabel('√âpoca')
plt.ylabel('P√©rdida')
plt.legend()

# M√©trica principal
plt.subplot(1, 2, 2)
metric_key = list(history.history.keys())[1]  # Primera m√©trica despu√©s de loss
plt.plot(history.history[metric_key], label='Entrenamiento')
plt.plot(history.history[f'val_{{metric_key}}'], label='Validaci√≥n')
plt.title(f'{{metric_key.title()}} durante el entrenamiento')
plt.xlabel('√âpoca')
plt.ylabel(metric_key.title())
plt.legend()

plt.tight_layout()
plt.show()

# 9. FUNCI√ìN PARA NUEVAS PREDICCIONES
def predecir_nueva_muestra(nueva_muestra):
    \"\"\"
    Funci√≥n para hacer predicciones con nuevos datos.
    
    Par√°metros:
    nueva_muestra: lista con valores para cada caracter√≠stica
                  en el orden: {feature_names_str}
    
    Retorna:
    prediccion: resultado de la predicci√≥n
    \"\"\"
    # Convertir a array y normalizar
    nueva_muestra = np.array(nueva_muestra).reshape(1, -1)
    nueva_muestra_scaled = scaler.transform(nueva_muestra)
    
    # Predecir
    prediccion = model.predict(nueva_muestra_scaled)
    
    {"# Para clasificaci√≥n, convertir a clase" if task_type == "Clasificaci√≥n" else "# Para regresi√≥n, devolver valor directo"}
    {"if prediccion[0][0] > 0.5: return 'Clase 1' else return 'Clase 0'  # Binaria" if task_type == "Clasificaci√≥n" and architecture[-1] == 1 else ""}
    {"return np.argmax(prediccion[0])  # Multiclase" if task_type == "Clasificaci√≥n" and architecture[-1] > 1 else ""}
    {"return prediccion[0][0]  # Regresi√≥n" if task_type == "Regresi√≥n" else ""}

# Ejemplo de uso:
# nueva_muestra = [valor1, valor2, valor3, ...]  # Reemplaza con tus valores
# resultado = predecir_nueva_muestra(nueva_muestra)
# print(f"Predicci√≥n: {{resultado}}")

# 10. GUARDAR EL MODELO
print("\\n=== GUARDANDO MODELO ===")

# Guardar modelo completo
model.save('modelo_red_neuronal.h5')
print("Modelo guardado como 'modelo_red_neuronal.h5'")

# Guardar scaler por separado
import pickle
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
print("Scaler guardado como 'scaler.pkl'")

# C√≥digo para cargar el modelo guardado:
# modelo_cargado = keras.models.load_model('modelo_red_neuronal.h5')
# with open('scaler.pkl', 'rb') as f:
#     scaler_cargado = pickle.load(f)

print("\\n‚úÖ ¬°Entrenamiento completado!")
print("Tu red neuronal est√° lista para hacer predicciones.")
"""

    return code


def generate_neural_network_evaluation_code(config, feature_names, class_names=None):
    """Genera c√≥digo Python para evaluaci√≥n de red neuronal."""

    feature_names_str = str(
        feature_names) if feature_names else "['feature_1', 'feature_2', ...]"
    class_names_str = str(
        class_names) if class_names else "['Clase_0', 'Clase_1', ...]"

    if config['task_type'] == "Clasificaci√≥n":
        if config['output_size'] == 1:  # Clasificaci√≥n binaria
            evaluation_metrics = """
# Evaluaci√≥n para clasificaci√≥n binaria
y_pred_classes = (y_pred > 0.5).astype(int).flatten()
y_test_flat = y_test.flatten()

# M√©tricas principales
accuracy = accuracy_score(y_test_flat, y_pred_classes)
precision = precision_score(y_test_flat, y_pred_classes)
recall = recall_score(y_test_flat, y_pred_classes)
f1 = f1_score(y_test_flat, y_pred_classes)

print("=== M√âTRICAS DE CLASIFICACI√ìN BINARIA ===")
print(f"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")

# Matriz de confusi√≥n
cm = confusion_matrix(y_test_flat, y_pred_classes)
print("\\nMatriz de Confusi√≥n:")
print(cm)
"""
        else:  # Clasificaci√≥n multiclase
            evaluation_metrics = """
# Evaluaci√≥n para clasificaci√≥n multiclase
y_pred_classes = np.argmax(y_pred, axis=1)
if len(y_test.shape) > 1:
    y_test_classes = np.argmax(y_test, axis=1)
else:
    y_test_classes = y_test.flatten()

# M√©tricas principales
accuracy = accuracy_score(y_test_classes, y_pred_classes)

print("=== M√âTRICAS DE CLASIFICACI√ìN MULTICLASE ===")
print(f"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")

# Reporte detallado
class_names = """ + class_names_str + """
print("\\nReporte de Clasificaci√≥n:")
print(classification_report(y_test_classes, y_pred_classes, target_names=class_names))

# Matriz de confusi√≥n
cm = confusion_matrix(y_test_classes, y_pred_classes)
print("\\nMatriz de Confusi√≥n:")
print(cm)
"""
    else:  # Regresi√≥n
        evaluation_metrics = """
# Evaluaci√≥n para regresi√≥n
y_pred_flat = y_pred.flatten()
y_test_flat = y_test.flatten()

# M√©tricas principales
mse = mean_squared_error(y_test_flat, y_pred_flat)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test_flat, y_pred_flat)
r2 = r2_score(y_test_flat, y_pred_flat)

print("=== M√âTRICAS DE REGRESI√ìN ===")
print(f"MSE: {mse:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"MAE: {mae:.4f}")
print(f"R¬≤: {r2:.4f}")

# An√°lisis de residuos
residuos = y_test_flat - y_pred_flat
print(f"\\nAn√°lisis de Residuos:")
print(f"Media de residuos: {np.mean(residuos):.6f}")
print(f"Desviaci√≥n est√°ndar de residuos: {np.std(residuos):.4f}")
"""

    visualization_code = """
# Visualizaciones
plt.figure(figsize=(15, 10))

# Historial de entrenamiento
plt.subplot(2, 3, 1)
plt.plot(history.history['loss'], label='Entrenamiento')
if 'val_loss' in history.history:
    plt.plot(history.history['val_loss'], label='Validaci√≥n')
plt.title('P√©rdida durante el entrenamiento')
plt.xlabel('√âpoca')
plt.ylabel('P√©rdida')
plt.legend()

# M√©trica principal (accuracy o mae)
plt.subplot(2, 3, 2)
metric_key = list(history.history.keys())[1]  # Primera m√©trica despu√©s de loss
plt.plot(history.history[metric_key], label='Entrenamiento')
if f'val_{metric_key}' in history.history:
    plt.plot(history.history[f'val_{metric_key}'], label='Validaci√≥n')
plt.title(f'{metric_key.title()} durante el entrenamiento')
plt.xlabel('√âpoca')
plt.ylabel(metric_key.title())
plt.legend()
"""

    if config['task_type'] == "Clasificaci√≥n":
        specific_viz = """
# Matriz de confusi√≥n visualizada
plt.subplot(2, 3, 3)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Matriz de Confusi√≥n')
plt.xlabel('Predicciones')
plt.ylabel('Valores Reales')

# Distribuci√≥n de confianza
plt.subplot(2, 3, 4)
if """ + str(config['output_size']) + """ == 1:
    confidence = np.maximum(y_pred.flatten(), 1 - y_pred.flatten())
else:
    confidence = np.max(y_pred, axis=1)
plt.hist(confidence, bins=20, alpha=0.7)
plt.title('Distribuci√≥n de Confianza de Predicciones')
plt.xlabel('Confianza')
plt.ylabel('Frecuencia')
"""
    else:
        specific_viz = """
# Predicciones vs Valores Reales
plt.subplot(2, 3, 3)
plt.scatter(y_test_flat, y_pred_flat, alpha=0.6)
plt.plot([y_test_flat.min(), y_test_flat.max()], [y_test_flat.min(), y_test_flat.max()], 'r--', lw=2)
plt.xlabel('Valores Reales')
plt.ylabel('Predicciones')
plt.title('Predicciones vs Valores Reales')

# Distribuci√≥n de residuos
plt.subplot(2, 3, 4)
plt.hist(residuos, bins=20, alpha=0.7)
plt.title('Distribuci√≥n de Residuos')
plt.xlabel('Residuos')
plt.ylabel('Frecuencia')

# Q-Q plot de residuos
plt.subplot(2, 3, 5)
from scipy import stats
stats.probplot(residuos, dist="norm", plot=plt)
plt.title('Q-Q Plot de Residuos')
"""

    code = f"""# C√≥digo completo para Evaluaci√≥n de Red Neuronal - {config['task_type']}
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# 1. CARGAR MODELO Y DATOS
# Asumiendo que ya tienes:
# - model: tu modelo entrenado
# - X_test, y_test: datos de prueba
# - scaler: preprocessor para normalizar datos
# - history: historial de entrenamiento

print("=== EVALUACI√ìN DE RED NEURONAL ===")
print("Tipo de tarea: {config['task_type']}")
print("Arquitectura: {config['architecture']}")

# 2. HACER PREDICCIONES
print("\\nHaciendo predicciones...")
y_pred = model.predict(X_test, verbose=0)

# 3. CALCULAR M√âTRICAS
{evaluation_metrics}

# 4. VISUALIZACIONES
{visualization_code}
{specific_viz}

plt.tight_layout()
plt.show()

# 5. AN√ÅLISIS DETALLADO DEL MODELO
print("\\n=== INFORMACI√ìN DEL MODELO ===")
model.summary()

# Contar par√°metros
total_params = model.count_params()
trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
non_trainable_params = total_params - trainable_params

print(f"\\nPar√°metros totales: {{total_params:,}}")
print(f"Par√°metros entrenables: {{trainable_params:,}}")
print(f"Par√°metros no entrenables: {{non_trainable_params:,}}")

# 6. FUNCI√ìN PARA NUEVAS PREDICCIONES CON M√âTRICAS
def evaluar_nueva_muestra(nueva_muestra, valor_real=None):
    \"\"\"
    Eval√∫a una nueva muestra y opcionalmente compara con valor real.
    
    Par√°metros:
    nueva_muestra: lista con valores para cada caracter√≠stica
    valor_real: valor real para comparar (opcional)
    \"\"\"
    # Normalizar
    nueva_muestra = np.array(nueva_muestra).reshape(1, -1)
    nueva_muestra_scaled = scaler.transform(nueva_muestra)
    
    # Predecir
    prediccion = model.predict(nueva_muestra_scaled, verbose=0)
    
    print(f"\\n=== PREDICCI√ìN INDIVIDUAL ===")
    print(f"Entrada: {{nueva_muestra[0]}}")
    
    {"# Clasificaci√≥n" if config['task_type'] == "Clasificaci√≥n" else "# Regresi√≥n"}
    {"if prediccion[0][0] > 0.5:" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] == 1 else ""}
    {"    clase_pred = 1" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] == 1 else ""}
    {"    confianza = prediccion[0][0]" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] == 1 else ""}
    {"else:" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] == 1 else ""}
    {"    clase_pred = 0" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] == 1 else ""}
    {"    confianza = 1 - prediccion[0][0]" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] == 1 else ""}
    {"print(f'Clase predicha: {clase_pred}')" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] == 1 else ""}
    {"print(f'Confianza: {confianza:.4f} ({confianza*100:.2f}%)')" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] == 1 else ""}
    
    {"clase_pred = np.argmax(prediccion[0])" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] > 1 else ""}
    {"confianza = np.max(prediccion[0])" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] > 1 else ""}
    {"print(f'Clase predicha: {clase_pred}')" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] > 1 else ""}
    {"print(f'Confianza: {confianza:.4f} ({confianza*100:.2f}%)')" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] > 1 else ""}
    {"print(f'Probabilidades por clase: {prediccion[0]}')" if config['task_type'] == "Clasificaci√≥n" and config['output_size'] > 1 else ""}
    
    {"valor_pred = prediccion[0][0]" if config['task_type'] == "Regresi√≥n" else ""}
    {"print(f'Valor predicho: {valor_pred:.4f}')" if config['task_type'] == "Regresi√≥n" else ""}
    
    if valor_real is not None:
        {"error = abs(valor_real - clase_pred)" if config['task_type'] == "Clasificaci√≥n" else "error = abs(valor_real - valor_pred)"}
        print(f"Valor real: {{valor_real}}")
        print(f"Error: {{error:.4f}}")
    
    {"return clase_pred, confianza" if config['task_type'] == "Clasificaci√≥n" else "return valor_pred"}

# Ejemplo de uso:
# nueva_muestra = [valor1, valor2, valor3, ...]  # Reemplaza con tus valores
# resultado = evaluar_nueva_muestra(nueva_muestra)
# print(f"Resultado: {{resultado}}")

print("\\n‚úÖ Evaluaci√≥n completada!")
"""

    return code


def generate_neural_network_visualization_code(config):
    """Genera c√≥digo Python para visualizaciones de red neuronal."""

    code = f"""# C√≥digo completo para Visualizaciones de Red Neuronal
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras

# Configuraci√≥n de matplotlib
plt.style.use('default')
sns.set_palette("husl")

print("=== VISUALIZACIONES DE RED NEURONAL ===")
print("Tipo de tarea: {config['task_type']}")
print("Arquitectura: {config['architecture']}")

# 1. HISTORIAL DE ENTRENAMIENTO
def plot_training_history_detailed(history):
    \"\"\"Crea gr√°ficas detalladas del historial de entrenamiento.\"\"\"
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # P√©rdida
    axes[0, 0].plot(history.history['loss'], label='Entrenamiento', linewidth=2)
    if 'val_loss' in history.history:
        axes[0, 0].plot(history.history['val_loss'], label='Validaci√≥n', linewidth=2)
    axes[0, 0].set_title('P√©rdida durante el entrenamiento', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('√âpoca')
    axes[0, 0].set_ylabel('P√©rdida')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # M√©trica principal
    metric_key = list(history.history.keys())[1]  # Primera m√©trica despu√©s de loss
    axes[0, 1].plot(history.history[metric_key], label='Entrenamiento', linewidth=2)
    if f'val_{{metric_key}}' in history.history:
        axes[0, 1].plot(history.history[f'val_{{metric_key}}'], label='Validaci√≥n', linewidth=2)
    axes[0, 1].set_title(f'{{metric_key.title()}} durante el entrenamiento', fontsize=14, fontweight='bold')
    axes[0, 1].set_xlabel('√âpoca')
    axes[0, 1].set_ylabel(metric_key.title())
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # Learning rate (si disponible)
    if 'lr' in history.history:
        axes[1, 0].plot(history.history['lr'], color='red', linewidth=2)
        axes[1, 0].set_title('Learning Rate', fontsize=14, fontweight='bold')
        axes[1, 0].set_xlabel('√âpoca')
        axes[1, 0].set_ylabel('Learning Rate')
        axes[1, 0].set_yscale('log')
        axes[1, 0].grid(True, alpha=0.3)
    else:
        axes[1, 0].text(0.5, 0.5, 'Learning Rate\\nno disponible', 
                       ha='center', va='center', transform=axes[1, 0].transAxes)
    
    # Mejora por √©poca
    loss_improvement = np.diff(history.history['loss'])
    axes[1, 1].plot(loss_improvement, color='purple', linewidth=2)
    axes[1, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)
    axes[1, 1].set_title('Mejora por √âpoca (P√©rdida)', fontsize=14, fontweight='bold')
    axes[1, 1].set_xlabel('√âpoca')
    axes[1, 1].set_ylabel('Cambio en P√©rdida')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# 2. AN√ÅLISIS DE PESOS Y SESGOS
def analyze_weights_and_biases(model):
    \"\"\"Analiza la distribuci√≥n de pesos y sesgos en todas las capas.\"\"\"
    
    layer_weights = []
    layer_biases = []
    
    # Extraer pesos y sesgos
    for i, layer in enumerate(model.layers):
        if hasattr(layer, 'get_weights') and layer.get_weights():
            weights = layer.get_weights()
            if len(weights) >= 2:
                layer_weights.append(weights[0])
                layer_biases.append(weights[1])
    
    if not layer_weights:
        print("No se encontraron capas con pesos")
        return
    
    num_layers = len(layer_weights)
    fig, axes = plt.subplots(num_layers, 2, figsize=(12, 4*num_layers))
    
    if num_layers == 1:
        axes = axes.reshape(1, -1)
    
    for i, (weights, biases) in enumerate(zip(layer_weights, layer_biases)):
        # Histograma de pesos
        axes[i, 0].hist(weights.flatten(), bins=50, alpha=0.7, color='blue', edgecolor='black')
        axes[i, 0].set_title(f'Distribuci√≥n de Pesos - Capa {{i+1}}', fontweight='bold')
        axes[i, 0].set_xlabel('Valor de Peso')
        axes[i, 0].set_ylabel('Frecuencia')
        axes[i, 0].grid(True, alpha=0.3)
        
        # Estad√≠sticas de pesos
        mean_w = np.mean(weights)
        std_w = np.std(weights)
        axes[i, 0].axvline(mean_w, color='red', linestyle='--', label=f'Media: {{mean_w:.4f}}')
        axes[i, 0].axvline(mean_w + std_w, color='orange', linestyle=':', label=f'¬±1œÉ: {{std_w:.4f}}')
        axes[i, 0].axvline(mean_w - std_w, color='orange', linestyle=':')
        axes[i, 0].legend()
        
        # Histograma de sesgos
        axes[i, 1].hist(biases.flatten(), bins=20, alpha=0.7, color='orange', edgecolor='black')
        axes[i, 1].set_title(f'Distribuci√≥n de Sesgos - Capa {{i+1}}', fontweight='bold')
        axes[i, 1].set_xlabel('Valor de Sesgo')
        axes[i, 1].set_ylabel('Frecuencia')
        axes[i, 1].grid(True, alpha=0.3)
        
        # Estad√≠sticas de sesgos
        mean_b = np.mean(biases)
        std_b = np.std(biases)
        axes[i, 1].axvline(mean_b, color='red', linestyle='--', label=f'Media: {{mean_b:.4f}}')
        axes[i, 1].axvline(mean_b + std_b, color='blue', linestyle=':', label=f'¬±1œÉ: {{std_b:.4f}}')
        axes[i, 1].axvline(mean_b - std_b, color='blue', linestyle=':')
        axes[i, 1].legend()
    
    plt.tight_layout()
    plt.show()
    
    # Estad√≠sticas generales
    all_weights = np.concatenate([w.flatten() for w in layer_weights])
    all_biases = np.concatenate([b.flatten() for b in layer_biases])
    
    print("\\n=== ESTAD√çSTICAS GENERALES ===")
    print(f"N√∫mero total de pesos: {{len(all_weights):,}}")
    print(f"N√∫mero total de sesgos: {{len(all_biases):,}}")
    print(f"\\nPesos - Media: {{np.mean(all_weights):.6f}}, Std: {{np.std(all_weights):.6f}}")
    print(f"Pesos - Min: {{np.min(all_weights):.6f}}, Max: {{np.max(all_weights):.6f}}")
    print(f"\\nSesgos - Media: {{np.mean(all_biases):.6f}}, Std: {{np.std(all_biases):.6f}}")
    print(f"Sesgos - Min: {{np.min(all_biases):.6f}}, Max: {{np.max(all_biases):.6f}}")
    
    # Detecci√≥n de problemas
    dead_weights = np.sum(np.abs(all_weights) < 1e-6)
    if dead_weights > len(all_weights) * 0.1:
        print(f"\\n‚ö†Ô∏è ADVERTENCIA: {{dead_weights}} pesos muy cerca de cero ({{dead_weights/len(all_weights)*100:.1f}}%)")
    
    if np.std(all_weights) < 0.01:
        print("\\nüö® PROBLEMA: Pesos muy peque√±os, la red puede no haber aprendido correctamente")
    elif np.std(all_weights) > 2:
        print("\\n‚ö†Ô∏è ATENCI√ìN: Pesos muy grandes, posible inestabilidad")

# 3. AN√ÅLISIS DE ACTIVACIONES
def analyze_layer_activations(model, X_sample):
    \"\"\"Analiza las activaciones de cada capa con datos de muestra.\"\"\"
    
    # Crear modelo para extraer activaciones
    layer_outputs = [layer.output for layer in model.layers[:-1]]
    activation_model = tf.keras.Model(inputs=model.input, outputs=layer_outputs)
    
    # Obtener activaciones
    activations = activation_model.predict(X_sample, verbose=0)
    if not isinstance(activations, list):
        activations = [activations]
    
    # Analizar cada capa
    print("\\n=== AN√ÅLISIS DE ACTIVACIONES ===")
    for i, activation in enumerate(activations):
        print(f"\\nCapa {{i+1}}:")
        print(f"  Forma: {{activation.shape}}")
        print(f"  Media: {{np.mean(activation):.4f}}")
        print(f"  Desviaci√≥n est√°ndar: {{np.std(activation):.4f}}")
        print(f"  Min: {{np.min(activation):.4f}}, Max: {{np.max(activation):.4f}}")
        
        # Neuronas muertas (siempre 0)
        dead_neurons = np.mean(activation == 0, axis=0)
        dead_ratio = np.mean(dead_neurons > 0.95) * 100
        print(f"  Neuronas muertas: {{dead_ratio:.1f}}%")
        
        # Neuronas saturadas (siempre cerca del m√°ximo)
        if activation.max() > 0:
            saturated_neurons = np.mean(activation >= 0.99 * activation.max(), axis=0)
            saturated_ratio = np.mean(saturated_neurons > 0.95) * 100
            print(f"  Neuronas saturadas: {{saturated_ratio:.1f}}%")
        
        # Visualizar distribuci√≥n de activaciones
        plt.figure(figsize=(10, 4))
        
        plt.subplot(1, 2, 1)
        plt.hist(activation.flatten(), bins=50, alpha=0.7, edgecolor='black')
        plt.title(f'Distribuci√≥n de Activaciones - Capa {{i+1}}')
        plt.xlabel('Valor de Activaci√≥n')
        plt.ylabel('Frecuencia')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(1, 2, 2)
        plt.boxplot(activation.T)
        plt.title(f'Box Plot por Neurona - Capa {{i+1}}')
        plt.xlabel('Neurona')
        plt.ylabel('Activaci√≥n')
        plt.xticks(range(1, min(21, activation.shape[1]+1)))  # M√°ximo 20 neuronas
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

# 4. FUNCI√ìN PRINCIPAL DE VISUALIZACI√ìN
def visualize_neural_network_complete(model, history, X_sample=None):
    \"\"\"Ejecuta todas las visualizaciones de la red neuronal.\"\"\"
    
    print("Generando visualizaciones completas...")
    
    # 1. Historial de entrenamiento
    print("\\n1. Analizando historial de entrenamiento...")
    plot_training_history_detailed(history)
    
    # 2. Pesos y sesgos
    print("\\n2. Analizando pesos y sesgos...")
    analyze_weights_and_biases(model)
    
    # 3. Activaciones (si se proporcionan datos)
    if X_sample is not None:
        print("\\n3. Analizando activaciones...")
        analyze_layer_activations(model, X_sample)
    else:
        print("\\n3. An√°lisis de activaciones omitido (no se proporcionaron datos)")
    
    print("\\n‚úÖ Visualizaciones completadas!")

# EJEMPLO DE USO:
# Asumiendo que tienes:
# - model: tu modelo entrenado
# - history: historial de entrenamiento
# - X_test: datos de prueba para an√°lisis de activaciones

# Ejecutar todas las visualizaciones
# visualize_neural_network_complete(model, history, X_test[:100])

# O ejecutar individualmente:
# plot_training_history_detailed(history)
# analyze_weights_and_biases(model)
# analyze_layer_activations(model, X_test[:100])
"""

    return code


def generate_neural_network_complete_code(config, feature_names, class_names=None):
    """Genera c√≥digo Python completo para entrenar y usar la red neuronal."""
    # Esta funci√≥n se puede expandir para generar c√≥digo m√°s completo
    # incluyendo carga de datos, entrenamiento completo, etc.
    pass


if __name__ == "__main__":
    main()
