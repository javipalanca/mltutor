import streamlit as st
import streamlit.components.v1 as components
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from dataset.dataset_manager import load_data
from utils import create_info_box, get_image_download_link, show_code_with_download


def run_neural_networks_app():
    """Ejecuta la aplicaciÃ³n especÃ­fica de redes neuronales."""
    st.header("ğŸ§  Redes Neuronales")
    st.markdown(
        "Aprende sobre redes neuronales artificiales de forma visual e interactiva")

    # InformaciÃ³n sobre redes neuronales
    with st.expander("â„¹ï¸ Â¿QuÃ© son las Redes Neuronales?", expanded=False):
        st.markdown("""
        Las redes neuronales artificiales son modelos computacionales inspirados en el funcionamiento del cerebro humano.
        EstÃ¡n compuestas por nodos (neuronas) interconectados que procesan informaciÃ³n de manera paralela.

        **CaracterÃ­sticas principales:**
        - **Neuronas**: Unidades bÃ¡sicas que reciben entradas, las procesan y generan salidas
        - **Capas**: Organizan las neuronas en estructuras jerÃ¡rquicas (entrada, ocultas, salida)
        - **Pesos y Sesgos**: ParÃ¡metros que se ajustan durante el entrenamiento
        - **Funciones de ActivaciÃ³n**: Determinan la salida de cada neurona
        - **Backpropagation**: Algoritmo para entrenar la red ajustando pesos y sesgos

        **Ventajas:**
        - Pueden modelar relaciones no lineales complejas
        - Excelentes para reconocimiento de patrones
        - Adaptables a diferentes tipos de problemas
        - Capaces de aproximar cualquier funciÃ³n continua

        **Desventajas:**
        - Requieren grandes cantidades de datos
        - Pueden ser "cajas negras" (difÃ­ciles de interpretar)
        - Propensos al sobreajuste
        - Requieren mucho poder computacional
        """)

    # Sistema de pestaÃ±as
    tab_names = [
        "ğŸ“Š Datos",
        "ğŸ—ï¸ Arquitectura",
        "âš™ï¸ Entrenamiento",
        "ğŸ“ˆ EvaluaciÃ³n",
        "ğŸ¯ Visualizaciones",
        "ğŸ”® Predicciones",
        "ğŸ’¾ Exportar"
    ]

    # Inicializar estado de pestaÃ±as si no existe
    if 'active_tab_nn' not in st.session_state:
        st.session_state.active_tab_nn = 0

    # Crear pestaÃ±as visuales personalizadas
    cols = st.columns(len(tab_names))
    for i, (col, tab_name) in enumerate(zip(cols, tab_names)):
        with col:
            if st.button(
                tab_name,
                key=f"tab_nn_{i}",
                use_container_width=True,
                type="primary" if st.session_state.active_tab_nn == i else "secondary"
            ):
                st.session_state.active_tab_nn = i
                st.rerun()

    st.markdown("---")

    # PestaÃ±a de Datos
    if st.session_state.active_tab_nn == 0:
        st.header("ğŸ“Š SelecciÃ³n y PreparaciÃ³n de Datos")

        # Tips educativos sobre datos para redes neuronales
        st.info("""
        ğŸ“ **Tips para Redes Neuronales:**
        - Las redes neuronales funcionan mejor con **datos normalizados** (valores entre 0 y 1 o -1 y 1)
        - Necesitan **suficientes datos** para entrenar bien (mÃ­nimo 100 ejemplos por clase)
        - Son excelentes para **patrones complejos** y **relaciones no lineales**
        - Pueden funcionar tanto para **clasificaciÃ³n** como para **regresiÃ³n**
        """)

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset_nn' not in st.session_state:
            st.session_state.selected_dataset_nn = "ğŸŒ¸ Iris - ClasificaciÃ³n de flores"

        # Lista base de datasets predefinidos
        builtin_datasets = [
            "ğŸŒ¸ Iris - ClasificaciÃ³n de flores",
            "ğŸ· Vino - ClasificaciÃ³n de vinos",
            "ğŸ”¬ CÃ¡ncer - DiagnÃ³stico binario",
            "ğŸš¢ Titanic - Supervivencia",
            "ğŸ’° Propinas - PredicciÃ³n de propinas",
            "ğŸ  Viviendas California - Precios",
            "ğŸ§ PingÃ¼inos - ClasificaciÃ³n de especies"
        ]

        # AÃ±adir datasets CSV cargados si existen
        available_datasets = builtin_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado estÃ© en la lista disponible
        if st.session_state.selected_dataset_nn not in available_datasets:
            st.session_state.selected_dataset_nn = builtin_datasets[0]

        # Selector unificado con explicaciÃ³n
        with st.container():
            st.markdown("### ğŸ¯ SelecciÃ³n del Dataset")
            dataset_option = st.selectbox(
                "Elige tu dataset:",
                available_datasets,
                index=available_datasets.index(
                    st.session_state.selected_dataset_nn),
                key="unified_dataset_selector_nn",
                help="ğŸ’¡ Cada dataset presenta diferentes retos de aprendizaje para tu red neuronal"
            )

            # ExplicaciÃ³n sobre el dataset seleccionado
            if "Iris" in dataset_option:
                st.markdown(
                    "ğŸŒ¸ **Iris**: Perfecto para empezar. 3 clases de flores, 4 caracterÃ­sticas simples.")
            elif "Vino" in dataset_option:
                st.markdown(
                    "ğŸ· **Vino**: ClasificaciÃ³n multiclase con 13 caracterÃ­sticas quÃ­micas.")
            elif "CÃ¡ncer" in dataset_option:
                st.markdown(
                    "ğŸ”¬ **CÃ¡ncer**: Problema binario mÃ©dico con 30 caracterÃ­sticas.")
            elif "Titanic" in dataset_option:
                st.markdown(
                    "ğŸš¢ **Titanic**: PredicciÃ³n de supervivencia con datos categÃ³ricos y numÃ©ricos.")
            elif "Propinas" in dataset_option:
                st.markdown(
                    "ğŸ’° **Propinas**: RegresiÃ³n para predecir cantidad de propina.")
            elif "Viviendas" in dataset_option:
                st.markdown(
                    "ğŸ  **Viviendas**: RegresiÃ³n para predecir precios de casas.")
            elif "PingÃ¼inos" in dataset_option:
                st.markdown(
                    "ğŸ§ **PingÃ¼inos**: ClasificaciÃ³n de especies con datos biolÃ³gicos.")

        # Actualizar la variable de sesiÃ³n
        st.session_state.selected_dataset_nn = dataset_option

        # Separador despuÃ©s del selector
        st.markdown("---")

        # Mostrar informaciÃ³n del dataset seleccionado
        if 'selected_dataset_nn' in st.session_state:
            dataset_name = st.session_state.selected_dataset_nn
            st.success(f"âœ… Dataset seleccionado: **{dataset_name}**")

            # Cargar y mostrar datos
            try:
                # Cargar datos usando la funciÃ³n load_data comÃºn
                X, y, feature_names, class_names, dataset_info, task_type = load_data(
                    dataset_name)

                # Crear DataFrame
                df = pd.DataFrame(X, columns=feature_names)

                # Determinar el nombre de la columna objetivo
                if class_names is not None and len(class_names) > 0:
                    # Para clasificaciÃ³n, usar el nombre de la variable objetivo del dataset_info
                    target_col = 'target'  # Nombre por defecto
                    if hasattr(dataset_info, 'target_names'):
                        target_col = 'target'
                    df[target_col] = y
                else:
                    # Para regresiÃ³n
                    target_col = 'target'
                    df[target_col] = y

                # Almacenar informaciÃ³n del dataset
                st.session_state.nn_df = df
                st.session_state.nn_target_col = target_col
                st.session_state.nn_feature_names = feature_names
                st.session_state.nn_class_names = class_names
                st.session_state.nn_task_type = task_type
                st.session_state.nn_dataset_info = dataset_info

                # Mostrar informaciÃ³n bÃ¡sica con explicaciones
                st.markdown("### ğŸ“Š InformaciÃ³n del Dataset")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(
                        "ğŸ“ Filas", df.shape[0], help="NÃºmero total de ejemplos para entrenar")
                with col2:
                    st.metric(
                        "ğŸ“Š Columnas", df.shape[1], help="CaracterÃ­sticas + variable objetivo")
                with col3:
                    st.metric("ğŸ¯ Variable Objetivo", target_col,
                              help="Lo que la red va a predecir")
                with col4:
                    task_icon = "ğŸ·ï¸" if task_type == "ClasificaciÃ³n" else "ğŸ“ˆ"
                    st.metric(f"{task_icon} Tipo de Tarea",
                              task_type, help="ClasificaciÃ³n o RegresiÃ³n")

                # Mostrar muestra de datos con explicaciÃ³n
                st.markdown("### ğŸ‘€ Vista Previa de los Datos")
                st.markdown("ğŸ“‹ **Primeras 10 filas de tu dataset:**")
                st.dataframe(df.head(10), use_container_width=True)

                # Tip sobre los datos
                with st.expander("ğŸ’¡ Â¿QuÃ© significan estos datos?"):
                    st.markdown(f"""
                    - **Filas**: Cada fila es un ejemplo que la red usarÃ¡ para aprender
                    - **Columnas de caracterÃ­sticas**: Las variables que la red analiza para hacer predicciones
                    - **Variable objetivo ({target_col})**: Lo que queremos predecir
                    - **Preprocesamiento**: Los datos se normalizarÃ¡n automÃ¡ticamente para la red neuronal
                    """)

                # AnÃ¡lisis de la variable objetivo con explicaciones
                if task_type == "ClasificaciÃ³n":
                    st.markdown("### ğŸ¯ DistribuciÃ³n de Clases")
                    st.markdown("ğŸ“Š **Â¿CuÃ¡ntos ejemplos hay de cada clase?**")
                    class_counts = df[target_col].value_counts()

                    # Usar nombres de clases si estÃ¡n disponibles
                    if class_names is not None:
                        # Mapear valores numÃ©ricos a nombres de clases
                        class_labels = [class_names[int(idx)] if int(idx) < len(class_names) else f"Clase {idx}"
                                        for idx in class_counts.index]
                        fig = px.bar(x=class_labels, y=class_counts.values,
                                     labels={'x': target_col, 'y': 'Cantidad'},
                                     title=f"DistribuciÃ³n de {target_col}")
                    else:
                        fig = px.bar(x=class_counts.index, y=class_counts.values,
                                     labels={'x': target_col, 'y': 'Cantidad'},
                                     title=f"DistribuciÃ³n de {target_col}")

                    st.plotly_chart(fig, use_container_width=True)

                    # ExplicaciÃ³n sobre balance de clases
                    balance_ratio = class_counts.max() / class_counts.min()
                    if balance_ratio > 3:
                        st.warning(
                            f"âš ï¸ **Dataset desbalanceado**: La clase mÃ¡s frecuente tiene {balance_ratio:.1f}x mÃ¡s ejemplos que la menos frecuente")
                        st.info(
                            "ğŸ’¡ Las redes neuronales funcionan mejor con clases balanceadas. Considera tÃ©cnicas de balanceo si es necesario.")
                    else:
                        st.success(
                            "âœ… **Dataset bien balanceado**: Las clases tienen cantidad similar de ejemplos")

                else:
                    st.markdown("### ğŸ“Š DistribuciÃ³n de la Variable Objetivo")
                    st.markdown(
                        "ğŸ“ˆ **DistribuciÃ³n de los valores que queremos predecir:**")
                    fig = px.histogram(df, x=target_col, nbins=30,
                                       title=f"DistribuciÃ³n de {target_col}")
                    st.plotly_chart(fig, use_container_width=True)

                    # EstadÃ­sticas bÃ¡sicas para regresiÃ³n
                    with st.expander("ğŸ“Š EstadÃ­sticas de la Variable Objetivo"):
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric(
                                "ğŸ¯ Media", f"{df[target_col].mean():.2f}")
                        with col2:
                            st.metric("ğŸ“ Desv. EstÃ¡ndar",
                                      f"{df[target_col].std():.2f}")
                        with col3:
                            st.metric(
                                "ğŸ“‰ MÃ­nimo", f"{df[target_col].min():.2f}")
                        with col4:
                            st.metric(
                                "ğŸ“ˆ MÃ¡ximo", f"{df[target_col].max():.2f}")

                # InformaciÃ³n adicional del dataset
                if dataset_info and hasattr(dataset_info, 'DESCR'):
                    with st.expander("ğŸ“– DescripciÃ³n Detallada del Dataset"):
                        st.text(dataset_info.DESCR)

                # BotÃ³n para continuar con explicaciÃ³n
                st.markdown("---")
                st.markdown("### â¡ï¸ Siguiente Paso")
                st.markdown(
                    "Una vez que entiendas tus datos, es hora de **diseÃ±ar la arquitectura** de tu red neuronal.")
                if st.button("ğŸ—ï¸ Continuar a Arquitectura", type="primary", use_container_width=True):
                    st.session_state.active_tab_nn = 1
                    st.rerun()

            except Exception as e:
                st.error(f"Error cargando dataset: {str(e)}")
                st.info("Por favor, selecciona un dataset vÃ¡lido.")

        else:
            st.warning("âš ï¸ Por favor, selecciona un dataset para continuar.")

    # PestaÃ±a de Arquitectura
    elif st.session_state.active_tab_nn == 1:
        st.header("ğŸ—ï¸ DiseÃ±o de la Arquitectura de la Red")

        if 'nn_df' not in st.session_state or 'nn_task_type' not in st.session_state:
            st.warning(
                "âš ï¸ Primero debes seleccionar un dataset en la pestaÃ±a de Datos.")
            if st.button("ğŸ”™ Ir a Datos"):
                st.session_state.active_tab_nn = 0
                st.rerun()
            return

        # Tips educativos sobre arquitectura
        st.info("""
        ğŸ“ **Conceptos Clave de Arquitectura:**
        - **Capas ocultas**: MÃ¡s capas = mayor capacidad de aprender patrones complejos
        - **Neuronas por capa**: MÃ¡s neuronas = mayor capacidad, pero riesgo de sobreajuste
        - **Funciones de activaciÃ³n**: Determinan cÃ³mo las neuronas procesan la informaciÃ³n
        - **Arquitectura Ã³ptima**: Depende del problema y cantidad de datos
        """)

        st.markdown("### ğŸ›ï¸ ConfiguraciÃ³n de la Red Neuronal")

        # InformaciÃ³n bÃ¡sica del dataset
        df = st.session_state.nn_df
        target_col = st.session_state.nn_target_col
        task_type = st.session_state.nn_task_type

        # Preparar datos bÃ¡sicos para mostrar dimensiones
        X = df.drop(columns=[target_col])
        y = df[target_col]
        input_size = X.shape[1]

        if task_type == "ClasificaciÃ³n":
            num_classes = len(y.unique())
            if num_classes == 2:
                output_size = 1  # Para clasificaciÃ³n binaria
                st.info(
                    f"ğŸ“Š **Entrada**: {input_size} caracterÃ­sticas â†’ **Salida**: {output_size} neurona (clasificaciÃ³n binaria)")
            else:
                output_size = num_classes  # Para clasificaciÃ³n multiclase
                st.info(
                    f"ğŸ“Š **Entrada**: {input_size} caracterÃ­sticas â†’ **Salida**: {output_size} clases")
        else:
            output_size = 1
            st.info(
                f"ğŸ“Š **Entrada**: {input_size} caracterÃ­sticas â†’ **Salida**: {output_size} valor numÃ©rico")

        # Tips sobre dimensiones
        with st.expander("ğŸ’¡ Â¿CÃ³mo decidir el tamaÃ±o de la red?"):
            st.markdown(f"""
            **Reglas generales para tu dataset ({df.shape[0]} muestras, {input_size} caracterÃ­sticas):**
            
            ğŸ”¢ **Neuronas por capa oculta:**
            - PequeÃ±o: {input_size//2} - {input_size} neuronas
            - Mediano: {input_size} - {input_size*2} neuronas  
            - Grande: {input_size*2} - {input_size*4} neuronas
            
            ğŸ“š **NÃºmero de capas:**
            - 1-2 capas: Problemas simples, linealmente separables
            - 2-3 capas: Problemas moderadamente complejos (recomendado para empezar)
            - 4+ capas: Problemas muy complejos (requiere muchos datos)
            
            âš–ï¸ **Balance capacidad vs. datos:**
            - MÃ¡s parÃ¡metros que datos â†’ riesgo de sobreajuste
            - Tu dataset: {df.shape[0]} muestras, mantÃ©n parÃ¡metros < {df.shape[0]//10}
            """)

        # ConfiguraciÃ³n de arquitectura
        col1, col2 = st.columns([1, 1])

        with col1:
            st.markdown("#### âš™ï¸ ConfiguraciÃ³n de Capas")

            # NÃºmero de capas ocultas con explicaciÃ³n
            num_hidden_layers = st.slider(
                "NÃºmero de capas ocultas",
                min_value=1, max_value=5, value=2,
                help="ğŸ’¡ MÃ¡s capas = mayor capacidad de aprender patrones complejos, pero tambiÃ©n mayor riesgo de sobreajuste"
            )

            # Sugerencia basada en el nÃºmero de capas
            if num_hidden_layers == 1:
                st.caption(
                    "ğŸŸ¦ **1 capa**: Ideal para problemas linealmente separables")
            elif num_hidden_layers == 2:
                st.caption(
                    "ğŸŸ¨ **2 capas**: Recomendado para la mayorÃ­a de problemas")
            elif num_hidden_layers >= 3:
                st.caption(
                    "ğŸŸ¥ **3+ capas**: Solo para problemas muy complejos con muchos datos")

            # ConfiguraciÃ³n de cada capa oculta con explicaciones
            hidden_layers = []
            for i in range(num_hidden_layers):
                # Calcular sugerencia inteligente
                suggested_size = max(10, input_size // (i+1))
                if task_type == "ClasificaciÃ³n" and num_classes > 2:
                    suggested_size = max(suggested_size, num_classes * 2)

                neurons = st.slider(
                    f"Neuronas en capa oculta {i+1}",
                    min_value=1, max_value=256,
                    value=min(suggested_size, 64),  # Limitar valor por defecto
                    key=f"layer_{i}",
                    help=f"ğŸ’¡ Sugerencia para capa {i+1}: {suggested_size} neuronas"
                )
                hidden_layers.append(neurons)

            # FunciÃ³n de activaciÃ³n con explicaciones detalladas
            st.markdown("#### ğŸ§® FunciÃ³n de ActivaciÃ³n (Capas Ocultas)")
            activation = st.selectbox(
                "FunciÃ³n de activaciÃ³n",
                ["relu", "tanh", "sigmoid"],
                help="ğŸ’¡ ReLU es la mÃ¡s popular y efectiva para la mayorÃ­a de problemas"
            )

            # Explicaciones sobre funciones de activaciÃ³n
            if activation == "relu":
                st.success(
                    "âœ… **ReLU**: RÃ¡pida, evita el problema del gradiente que desaparece. Recomendada.")
            elif activation == "tanh":
                st.info(
                    "â„¹ï¸ **Tanh**: Salida entre -1 y 1. Buena para datos normalizados.")
            elif activation == "sigmoid":
                st.warning(
                    "âš ï¸ **Sigmoid**: Puede causar gradientes que desaparecen. Ãšsala solo si es necesario.")

            # FunciÃ³n de activaciÃ³n de salida - AHORA SELECCIONABLE
            st.markdown("#### ğŸ¯ FunciÃ³n de ActivaciÃ³n de Salida")

            # Opciones disponibles segÃºn el tipo de tarea
            if task_type == "ClasificaciÃ³n":
                output_options = ["sigmoid", "softmax", "linear", "tanh"]
                if output_size == 1:  # ClasificaciÃ³n binaria
                    recommended = "sigmoid"
                    default_index = 0
                else:  # ClasificaciÃ³n multiclase
                    recommended = "softmax"
                    default_index = 1
            else:
                output_options = ["linear", "sigmoid", "tanh", "softmax"]
                recommended = "linear"
                default_index = 0

            output_activation = st.selectbox(
                "FunciÃ³n de activaciÃ³n de salida",
                output_options,
                index=default_index,
                help=f"ğŸ’¡ FunciÃ³n recomendada para {task_type.lower()}: **{recommended}**"
            )

            # Validaciones y avisos
            show_warning = False
            warning_message = ""

            if task_type == "ClasificaciÃ³n":
                if output_size == 1:  # ClasificaciÃ³n binaria
                    if output_activation == "sigmoid":
                        st.success(
                            "âœ… Sigmoid es ideal para clasificaciÃ³n binaria")
                    elif output_activation == "softmax":
                        show_warning = True
                        warning_message = "âš ï¸ Softmax no es recomendada para clasificaciÃ³n binaria (1 neurona). Considera usar Sigmoid."
                    elif output_activation == "linear":
                        show_warning = True
                        warning_message = "âš ï¸ Linear puede causar problemas en clasificaciÃ³n. Considera usar Sigmoid."
                    elif output_activation == "tanh":
                        show_warning = True
                        warning_message = "âš ï¸ Tanh puede funcionar pero Sigmoid es mÃ¡s estÃ¡ndar para clasificaciÃ³n binaria."

                else:  # ClasificaciÃ³n multiclase
                    if output_activation == "softmax":
                        st.success(
                            "âœ… Softmax es ideal para clasificaciÃ³n multiclase")
                    elif output_activation == "sigmoid":
                        st.warning(
                            "âš ï¸ Sigmoid en multiclase requiere 'binary_crossentropy' por clase. Softmax es mÃ¡s estÃ¡ndar.")
                    elif output_activation == "linear":
                        show_warning = True
                        warning_message = "âš ï¸ Linear no es apropiada para clasificaciÃ³n. Usa Softmax."
                    elif output_activation == "tanh":
                        show_warning = True
                        warning_message = "âš ï¸ Tanh no es estÃ¡ndar para clasificaciÃ³n multiclase. Softmax es recomendada."

            else:  # RegresiÃ³n
                if output_activation == "linear":
                    st.success("âœ… Linear es ideal para regresiÃ³n")
                elif output_activation == "sigmoid":
                    st.warning(
                        "âš ï¸ Sigmoid limita la salida a [0,1]. Solo Ãºtil si tus valores objetivo estÃ¡n en este rango.")
                elif output_activation == "tanh":
                    st.warning(
                        "âš ï¸ Tanh limita la salida a [-1,1]. Solo Ãºtil si tus valores objetivo estÃ¡n en este rango.")
                elif output_activation == "softmax":
                    show_warning = True
                    warning_message = "âš ï¸ Softmax no es apropiada para regresiÃ³n. Las salidas suman 1. Usa Linear."

            # Mostrar advertencia crÃ­tica si es necesario
            if show_warning:
                st.error(warning_message)

        with col2:
            st.markdown("#### ğŸ¨ VisualizaciÃ³n de la Arquitectura")

            # Crear arquitectura completa
            architecture = [input_size] + hidden_layers + [output_size]

            # Guardar configuraciÃ³n en session state
            st.session_state.nn_architecture = {
                'layers': architecture,
                'activation': activation,
                'output_activation': output_activation,
                'input_size': input_size,
                'output_size': output_size,
                'task_type': task_type
            }

            # Visualizar la red neuronal dinÃ¡micamente
            create_neural_network_visualization(
                architecture, activation, output_activation, task_type)

        # ConfiguraciÃ³n adicional con explicaciones detalladas
        st.markdown("### âš™ï¸ ConfiguraciÃ³n Adicional")

        st.markdown("ğŸ“š **ParÃ¡metros importantes para el entrenamiento:**")

        col3, col4, col5 = st.columns(3)

        with col3:
            st.markdown("#### ğŸ›¡ï¸ RegularizaciÃ³n")
            dropout_rate = st.slider(
                "Tasa de Dropout",
                min_value=0.0, max_value=0.8, value=0.2, step=0.1,
                help="ğŸ’¡ Dropout previene sobreajuste eliminando aleatoriamente neuronas durante entrenamiento"
            )

            # ExplicaciÃ³n del dropout
            if dropout_rate == 0.0:
                st.caption("ğŸ”´ **Sin Dropout**: Mayor riesgo de sobreajuste")
            elif dropout_rate <= 0.2:
                st.caption("ğŸŸ¢ **Dropout Ligero**: Bueno para datasets grandes")
            elif dropout_rate <= 0.5:
                st.caption(
                    "ğŸŸ¡ **Dropout Moderado**: Recomendado para la mayorÃ­a de casos")
            else:
                st.caption(
                    "ğŸŸ  **Dropout Alto**: Solo para datasets muy pequeÃ±os")

        with col4:
            st.markdown("#### ğŸ“¦ Procesamiento")
            batch_size = st.selectbox(
                "TamaÃ±o de Batch",
                [16, 32, 64, 128, 256],
                index=2,  # 64 por defecto
                help="ğŸ’¡ NÃºmero de muestras procesadas antes de actualizar los pesos"
            )

            # Sugerencias segÃºn el tamaÃ±o del dataset
            dataset_size = df.shape[0]
            if batch_size >= dataset_size // 4:
                st.caption(
                    "ğŸ”´ **Batch Grande**: Puede ser lento pero mÃ¡s estable")
            elif batch_size >= 32:
                st.caption(
                    "ğŸŸ¢ **Batch Ã“ptimo**: Buen balance velocidad/estabilidad")
            else:
                st.caption("ğŸŸ¡ **Batch PequeÃ±o**: MÃ¡s rÃ¡pido pero mÃ¡s ruidoso")

        with col5:
            st.markdown("#### ğŸš€ OptimizaciÃ³n")
            optimizer = st.selectbox(
                "Optimizador",
                ["adam", "sgd", "rmsprop"],
                help="ğŸ’¡ Algoritmo para actualizar los pesos de la red"
            )

            # Explicaciones sobre optimizadores
            if optimizer == "adam":
                st.caption(
                    "ğŸŸ¢ **Adam**: Adaptativo, recomendado para la mayorÃ­a de casos")
            elif optimizer == "sgd":
                st.caption(
                    "ğŸŸ¡ **SGD**: ClÃ¡sico, requiere ajuste fino del learning rate")
            elif optimizer == "rmsprop":
                st.caption(
                    "ğŸŸ¦ **RMSprop**: Bueno para RNNs y problemas especÃ­ficos")

        # Tips sobre la configuraciÃ³n
        with st.expander("ğŸ’¡ Tips para optimizar tu configuraciÃ³n"):
            st.markdown(f"""
            **Para tu dataset especÃ­fico ({dataset_size} muestras):**
            
            ğŸ¯ **Batch Size recomendado:**
            - Dataset pequeÃ±o (<1000): 16-32
            - Dataset mediano (1000-10000): 32-64
            - Dataset grande (>10000): 64-128
            - Tu dataset: {dataset_size} muestras â†’ Recomendado: {32 if dataset_size < 1000 else 64 if dataset_size < 10000 else 128}
            
            ğŸ›¡ï¸ **Dropout recomendado:**
            - Pocos datos: 0.3-0.5 (mÃ¡s regularizaciÃ³n)
            - Muchos datos: 0.1-0.2 (menos regularizaciÃ³n)
            - Dataset balanceado: 0.2-0.3
            
            ğŸš€ **Optimizador:**
            - **Adam**: Mejor opciÃ³n general, se adapta automÃ¡ticamente
            - **SGD**: Ãšsalo solo si tienes experiencia ajustando learning rates
            - **RMSprop**: Alternativa a Adam, a veces funciona mejor en problemas especÃ­ficos
            """)

        # Guardar configuraciÃ³n completa
        st.session_state.nn_config = {
            'architecture': architecture,
            'activation': activation,
            'output_activation': output_activation,
            'dropout_rate': dropout_rate,
            'batch_size': batch_size,
            'optimizer': optimizer,
            'task_type': task_type,
            'input_size': input_size,
            'output_size': output_size
        }

        # Resumen de la configuraciÃ³n con anÃ¡lisis
        st.markdown("### ğŸ“‹ Resumen de la Arquitectura")

        total_params = calculate_network_parameters(architecture)

        col6, col7, col8 = st.columns(3)
        with col6:
            st.metric("ğŸ”¢ Total de ParÃ¡metros", f"{total_params:,}",
                      help="NÃºmero total de pesos y sesgos que la red aprenderÃ¡")
        with col7:
            st.metric("ğŸ“š Capas Totales", len(architecture),
                      help="Entrada + Ocultas + Salida")
        with col8:
            complexity_ratio = total_params / dataset_size if dataset_size > 0 else 0
            complexity_level = "Baja" if complexity_ratio < 0.1 else "Media" if complexity_ratio < 1 else "Alta"
            st.metric("âš–ï¸ Complejidad", complexity_level,
                      help=f"Ratio parÃ¡metros/datos: {complexity_ratio:.2f}")
        with col8:
            st.metric("ğŸ§  Tipo de Red", "PerceptrÃ³n Multicapa")

        # Mostrar detalles de cada capa
        st.markdown("#### ğŸ“Š Detalles por Capa")
        layer_details = []
        for i, (current, next_size) in enumerate(zip(architecture[:-1], architecture[1:])):
            if i == 0:
                layer_type = "Entrada"
                params = 0
            elif i == len(architecture) - 2:
                layer_type = "Salida"
                params = current * next_size + next_size
            else:
                layer_type = f"Oculta {i}"
                params = current * next_size + next_size

            layer_details.append({
                "Capa": layer_type,
                "Neuronas": current if i < len(architecture) - 1 else next_size,
                "ParÃ¡metros": params,
                "ActivaciÃ³n": "Entrada" if i == 0 else (output_activation if i == len(architecture) - 2 else activation)
            })

        st.dataframe(pd.DataFrame(layer_details), use_container_width=True)

        # AnÃ¡lisis de complejidad y recomendaciones
        st.markdown("#### ğŸ” AnÃ¡lisis de Complejidad")

        # AnÃ¡lisis del ratio parÃ¡metros/datos
        if complexity_ratio < 0.1:
            st.success(
                f"âœ… **Complejidad Ã“ptima**: Tu red tiene {total_params:,} parÃ¡metros para {dataset_size} muestras (ratio: {complexity_ratio:.3f}). Bajo riesgo de sobreajuste.")
        elif complexity_ratio < 1:
            st.warning(
                f"âš ï¸ **Complejidad Media**: Tu red tiene {total_params:,} parÃ¡metros para {dataset_size} muestras (ratio: {complexity_ratio:.3f}). Monitorea el sobreajuste.")
        else:
            st.error(
                f"ğŸš¨ **Complejidad Alta**: Tu red tiene {total_params:,} parÃ¡metros para {dataset_size} muestras (ratio: {complexity_ratio:.3f}). Alto riesgo de sobreajuste. Considera reducir el tamaÃ±o de la red.")

        # BotÃ³n para generar cÃ³digo Python
        st.markdown("### ğŸ’» CÃ³digo Python")
        if st.button("ğŸ“ Generar CÃ³digo de la Arquitectura", use_container_width=True):
            # Generar cÃ³digo Python para la arquitectura
            code = generate_neural_network_architecture_code(
                architecture, activation, output_activation, dropout_rate,
                optimizer, batch_size, task_type, st.session_state.nn_feature_names
            )

            st.markdown("#### ğŸ CÃ³digo Python Generado")
            st.code(code, language='python')

            # BotÃ³n para descargar el cÃ³digo
            st.download_button(
                label="ğŸ’¾ Descargar CÃ³digo Python",
                data=code,
                file_name=f"red_neuronal_arquitectura_{task_type.lower()}.py",
                mime="text/plain"
            )

        # Botones de navegaciÃ³n
        st.markdown("---")
        st.markdown("### ğŸ§­ NavegaciÃ³n")
        col_nav1, col_nav2 = st.columns(2)
        with col_nav1:
            if st.button("ğŸ”™ Volver a Datos", use_container_width=True):
                st.session_state.active_tab_nn = 0
                st.rerun()
        with col_nav2:
            st.markdown(
                "**Â¿Listo para entrenar?** Â¡Tu arquitectura estÃ¡ configurada!")
            if st.button("ğŸš€ Continuar a Entrenamiento", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 2
                st.rerun()

    # PestaÃ±a de Entrenamiento
    elif st.session_state.active_tab_nn == 2:
        st.header("âš™ï¸ Entrenamiento de la Red Neuronal")

        if 'nn_config' not in st.session_state:
            st.warning("âš ï¸ Primero debes configurar la arquitectura de la red.")
            if st.button("ğŸ”™ Ir a Arquitectura"):
                st.session_state.active_tab_nn = 1
                st.rerun()
            return

        # Tips educativos sobre entrenamiento
        st.info("""
        ğŸ“ **Conceptos Clave del Entrenamiento:**
        - **Learning Rate**: Controla quÃ© tan rÃ¡pido aprende la red (muy alto = inestable, muy bajo = lento)
        - **Ã‰pocas**: CuÃ¡ntas veces la red ve todos los datos (mÃ¡s Ã©pocas â‰  siempre mejor)
        - **ValidaciÃ³n**: Datos separados para monitorear si la red estÃ¡ generalizando bien
        - **Early Stopping**: Para evitar sobreajuste, para cuando la validaciÃ³n no mejora
        """)

        st.markdown("### ğŸ›ï¸ ParÃ¡metros de Entrenamiento")

        # InformaciÃ³n del dataset para sugerencias
        df = st.session_state.nn_df
        dataset_size = df.shape[0]

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("#### ğŸ“ˆ **Learning Rate**")
            learning_rate = st.selectbox(
                "Tasa de Aprendizaje",
                [0.001, 0.01, 0.1, 0.3],
                index=0,
                help="ğŸ’¡ 0.001 es seguro para empezar. Valores mÃ¡s altos pueden acelerar el entrenamiento pero causar inestabilidad"
            )

            # ExplicaciÃ³n del learning rate seleccionado
            if learning_rate == 0.001:
                st.caption("ğŸŸ¢ **Conservador**: Aprendizaje lento pero estable")
            elif learning_rate == 0.01:
                st.caption(
                    "ğŸŸ¡ **Moderado**: Buen balance velocidad/estabilidad")
            elif learning_rate == 0.1:
                st.caption("ğŸŸ  **Agresivo**: RÃ¡pido pero puede ser inestable")
            else:
                st.caption("ğŸ”´ **Muy Alto**: Solo para casos especiales")

        with col2:
            st.markdown("#### ğŸ”„ **Ã‰pocas**")
            # Sugerir Ã©pocas basado en tamaÃ±o del dataset
            suggested_epochs = min(200, max(50, dataset_size // 10))
            epochs = st.slider(
                "Ã‰pocas",
                min_value=10, max_value=500, value=min(100, suggested_epochs), step=10,
                help=f"ğŸ’¡ Sugerencia para tu dataset: ~{suggested_epochs} Ã©pocas"
            )

            # ExplicaciÃ³n sobre las Ã©pocas
            if epochs < 50:
                st.caption(
                    "ğŸŸ¡ **Pocas Ã©pocas**: Puede que no aprenda completamente")
            elif epochs <= 150:
                st.caption("ğŸŸ¢ **Ã‰pocas adecuadas**: Buen balance")
            else:
                st.caption("ğŸŸ  **Muchas Ã©pocas**: Monitorea el sobreajuste")

        with col3:
            st.markdown("#### ğŸ¯ **ValidaciÃ³n**")
            validation_split = st.slider(
                "% Datos de ValidaciÃ³n",
                min_value=10, max_value=40, value=20,
                help="ğŸ’¡ 20% es estÃ¡ndar. MÃ¡s datos = mejor validaciÃ³n, menos datos para entrenar"
            )

            # Calcular tamaÃ±os efectivos
            # 80% del total para entrenamiento
            train_size = int(
                dataset_size * (100 - validation_split) / 100 * 0.8)
            val_size = int(dataset_size * validation_split / 100)
            test_size = dataset_size - train_size - val_size

            st.caption(
                f"ğŸ“Š **DistribuciÃ³n**: Train={train_size}, Val={val_size}, Test={test_size}")

        # ConfiguraciÃ³n avanzada con explicaciones detalladas
        with st.expander("âš™ï¸ ConfiguraciÃ³n Avanzada - TÃ©cnicas para Mejorar el Entrenamiento", expanded=False):
            st.markdown("#### ğŸ›¡ï¸ TÃ©cnicas de RegularizaciÃ³n y OptimizaciÃ³n")

            col4, col5 = st.columns(2)

            with col4:
                st.markdown("##### ğŸ›‘ Early Stopping")
                early_stopping = st.checkbox(
                    "Activar Parada Temprana",
                    value=True,
                    help="ğŸ’¡ Recomendado: Evita sobreajuste parando cuando la validaciÃ³n no mejora"
                )

                if early_stopping:
                    st.success(
                        "âœ… **Early Stopping activado**: La red pararÃ¡ automÃ¡ticamente cuando deje de mejorar")
                    patience = st.slider(
                        "Paciencia (Ã©pocas)",
                        min_value=5, max_value=50, value=10,
                        help="Ã‰pocas a esperar sin mejora antes de parar. MÃ¡s paciencia = mÃ¡s oportunidades de mejorar"
                    )

                    if patience <= 5:
                        st.caption(
                            "ğŸ”´ **Impatiente**: Para rÃ¡pido, puede interrumpir mejoras tardÃ­as")
                    elif patience <= 15:
                        st.caption("ğŸŸ¢ **Balanceado**: Buen equilibrio")
                    else:
                        st.caption(
                            "ğŸŸ¡ **Paciente**: Da muchas oportunidades, pero puede sobreajustar")
                else:
                    st.warning(
                        "âš ï¸ **Sin Early Stopping**: La red entrenarÃ¡ todas las Ã©pocas. Riesgo de sobreajuste.")

            with col5:
                st.markdown("##### ğŸ“‰ Learning Rate Scheduler")
                reduce_lr = st.checkbox(
                    "Reducir Learning Rate AutomÃ¡ticamente",
                    value=True,
                    help="ğŸ’¡ Recomendado: Reduce la tasa de aprendizaje cuando no mejora"
                )

                if reduce_lr:
                    st.success(
                        "âœ… **Scheduler activado**: La tasa de aprendizaje se reducirÃ¡ automÃ¡ticamente")
                    lr_factor = st.slider(
                        "Factor de ReducciÃ³n",
                        min_value=0.1, max_value=0.9, value=0.5,
                        help="Factor por el que se multiplica la tasa. 0.5 = reduce a la mitad"
                    )

                    if lr_factor <= 0.3:
                        st.caption(
                            "ğŸ”´ **ReducciÃ³n agresiva**: Cambios dramÃ¡ticos")
                    elif lr_factor <= 0.7:
                        st.caption("ğŸŸ¢ **ReducciÃ³n moderada**: Recomendado")
                    else:
                        st.caption("ğŸŸ¡ **ReducciÃ³n suave**: Cambios graduales")
                else:
                    st.info(
                        "â„¹ï¸ **Learning rate fijo**: Se mantendrÃ¡ constante durante todo el entrenamiento")

            # ExplicaciÃ³n sobre las tÃ©cnicas
            st.markdown("---")
            st.markdown("#### ğŸ“š Â¿Por quÃ© usar estas tÃ©cnicas?")
            st.markdown("""
            - **Early Stopping**: Evita que la red memorice los datos (sobreajuste) parando cuando la performance en validaciÃ³n deja de mejorar
            - **Learning Rate Reduction**: Permite un ajuste fino hacia el final del entrenamiento cuando se estÃ¡ cerca del Ã³ptimo
            - **Combinadas**: Estas tÃ©cnicas trabajan juntas para lograr el mejor modelo posible automÃ¡ticamente
            """)

        # BotÃ³n de entrenamiento con explicaciÃ³n
        st.markdown("### ğŸš€ Iniciar Entrenamiento")
        st.markdown(
            "**Â¿Todo listo?** Tu red estÃ¡ configurada y lista para aprender de los datos.")

        if st.button("ğŸ§  Entrenar Red Neuronal", type="primary", use_container_width=True):
            with st.spinner("ğŸ§  Entrenando la red neuronal... Esto puede tomar unos minutos."):
                # Preparar datos
                df = st.session_state.nn_df
                target_col = st.session_state.nn_target_col
                task_type = st.session_state.nn_task_type

                try:
                    # Mostrar progreso del entrenamiento con pasos
                    progress_container = st.empty()

                    # Paso 1: Preparando datos
                    with progress_container.container():
                        st.info(
                            "ğŸ”„ **Paso 1/4**: Preparando y dividiendo los datos...")

                    # Llamar funciÃ³n de entrenamiento con callback de progreso
                    def update_progress(step, message):
                        with progress_container.container():
                            if step == 2:
                                st.info(f"ğŸ§  **Paso {step}/4**: {message}")
                            elif step == 3:
                                st.info(f"âš™ï¸ **Paso {step}/4**: {message}")
                            elif step == 4:
                                st.info(f"ğŸš€ **Paso {step}/4**: {message}")
                            else:
                                st.info(f"ğŸ”„ **Paso {step}/4**: {message}")

                    # Entrenar el modelo con callback de progreso
                    model, history, X_test, y_test, scaler, label_encoder = train_neural_network(
                        df, target_col, st.session_state.nn_config,
                        learning_rate, epochs, validation_split/100,
                        early_stopping, patience if early_stopping else None,
                        reduce_lr, lr_factor if reduce_lr else None,
                        progress_callback=update_progress
                    )

                    # Guardar resultados
                    st.session_state.nn_model = model
                    st.session_state.nn_history = history
                    st.session_state.nn_test_data = (X_test, y_test)
                    st.session_state.nn_scaler = scaler
                    st.session_state.nn_label_encoder = label_encoder
                    st.session_state.model_trained_nn = True

                    # Limpiar el progreso y mostrar finalizaciÃ³n
                    with progress_container.container():
                        st.success(
                            "âœ… **Â¡Entrenamiento completado!** Red neuronal lista para usar")

                    st.success("ğŸ‰ Â¡Red neuronal entrenada exitosamente!")

                    # Mostrar mÃ©tricas bÃ¡sicas con explicaciones
                    st.markdown("#### ğŸ“Š Resultados del Entrenamiento")
                    if task_type == "ClasificaciÃ³n":
                        test_loss, test_acc = model.evaluate(
                            X_test, y_test, verbose=0)
                        col_m1, col_m2 = st.columns(2)
                        with col_m1:
                            st.metric("ğŸ¯ PrecisiÃ³n en Test", f"{test_acc:.3f}",
                                      help="Porcentaje de predicciones correctas en datos nunca vistos")
                        with col_m2:
                            st.metric("ğŸ“‰ PÃ©rdida en Test", f"{test_loss:.3f}",
                                      help="QuÃ© tan 'equivocada' estÃ¡ la red en promedio")
                    else:
                        test_loss = model.evaluate(X_test, y_test, verbose=0)
                        st.metric("ğŸ“‰ Error en Test", f"{test_loss:.3f}")

                    # GrÃ¡fico de entrenamiento en tiempo real
                    st.markdown("### ğŸ“ˆ Progreso del Entrenamiento")
                    plot_training_history(history, task_type)

                except Exception as e:
                    # Limpiar el progreso en caso de error
                    with progress_container.container():
                        st.error("âŒ **Error durante el entrenamiento**")

                    st.error(f"âŒ Error durante el entrenamiento: {str(e)}")
                    st.info(
                        "Intenta ajustar los parÃ¡metros o verificar el dataset.")

        # Botones de navegaciÃ³n
        if st.session_state.get('model_trained_nn', False):
            col_nav1, col_nav2 = st.columns(2)
            with col_nav1:
                if st.button("ğŸ”™ Volver a Arquitectura", use_container_width=True):
                    st.session_state.active_tab_nn = 1
                    st.rerun()
            with col_nav2:
                if st.button("â¡ï¸ Ver EvaluaciÃ³n", type="primary", use_container_width=True):
                    st.session_state.active_tab_nn = 3
                    st.rerun()

    # PestaÃ±as restantes (EvaluaciÃ³n, Visualizaciones, Predicciones, Exportar)
    elif st.session_state.active_tab_nn == 3:
        st.header("ğŸ“ˆ EvaluaciÃ³n del Modelo")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("âš ï¸ Primero debes entrenar un modelo.")
            if st.button("ğŸ”™ Ir a Entrenamiento"):
                st.session_state.active_tab_nn = 2
                st.rerun()
        else:
            show_neural_network_evaluation()

    elif st.session_state.active_tab_nn == 4:
        st.header("ğŸ¯ Visualizaciones")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("âš ï¸ Primero debes entrenar un modelo.")
        else:
            show_neural_network_visualizations()

    elif st.session_state.active_tab_nn == 5:
        st.header("ğŸ”® Predicciones")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("âš ï¸ Primero debes entrenar un modelo.")
        else:
            show_neural_network_predictions()

    elif st.session_state.active_tab_nn == 6:
        st.header("ğŸ’¾ Exportar Modelo")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("âš ï¸ Primero debes entrenar un modelo.")
        else:
            show_neural_network_export()


# ===== FUNCIONES PARA REDES NEURONALES =====

def safe_get_output_size(config):
    """
    Extrae el tamaÃ±o de salida de forma segura para evitar errores de comparaciÃ³n de arrays.
    """
    try:
        output_size = config['output_size']
        # Si es un array o lista, tomar el primer elemento
        if hasattr(output_size, '__len__') and not isinstance(output_size, (str, bytes)):
            return int(output_size[0]) if len(output_size) > 0 else 1
        # Si es un escalar
        return int(output_size)
    except:
        return 1


def create_neural_network_visualization(architecture, activation, output_activation, task_type):
    """
    Crea una visualizaciÃ³n dinÃ¡mica de la arquitectura de red neuronal usando HTML5 Canvas.
    """
    try:
        # Colores para diferentes elementos
        colors = {
            'input': '#4ECDC4',
            'hidden': '#45B7D1',
            'output': '#FF6B6B',
            'connection': '#BDC3C7',
            'text': '#2C3E50'
        }

        html_code = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <style>
                .nn-container {{
                    max-width: 100%;
                    margin: 0 auto;
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
                }}
                .canvas-container {{
                    position: relative;
                    border: 2px solid #e0e0e0;
                    border-radius: 8px;
                    margin: 10px 0;
                    background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
                    width: 100%;
                    overflow: hidden;
                }}
                #nnCanvas {{
                    display: block;
                    width: 100%;
                    height: auto;
                    max-width: 100%;
                }}
                .info-box {{
                    background: #e3f2fd;
                    border-left: 4px solid #2196F3;
                    padding: 10px;
                    margin: 10px 0;
                    border-radius: 4px;
                    font-size: 14px;
                }}
                .layer-info {{
                    display: flex;
                    gap: 15px;
                    margin-top: 10px;
                    flex-wrap: wrap;
                    justify-content: center;
                    font-size: 12px;
                }}
                .layer-item {{
                    display: flex;
                    align-items: center;
                    gap: 5px;
                    padding: 5px 10px;
                    background: white;
                    border-radius: 15px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                }}
                .layer-color {{
                    width: 12px;
                    height: 12px;
                    border-radius: 50%;
                }}
            </style>
        </head>
        <body>
            <div class="nn-container">
                <div class="info-box">
                    <strong>ğŸ§  Arquitectura de Red Neuronal</strong><br>
                    VisualizaciÃ³n dinÃ¡mica de la estructura de la red para {task_type.lower()}
                </div>
                
                <div class="canvas-container">
                    <canvas id="nnCanvas"></canvas>
                </div>
                
                <div class="layer-info">
                    <div class="layer-item">
                        <div class="layer-color" style="background-color: {colors['input']}"></div>
                        <span>Capa de Entrada</span>
                    </div>
                    <div class="layer-item">
                        <div class="layer-color" style="background-color: {colors['hidden']}"></div>
                        <span>Capas Ocultas ({activation.upper()})</span>
                    </div>
                    <div class="layer-item">
                        <div class="layer-color" style="background-color: {colors['output']}"></div>
                        <span>Capa de Salida ({output_activation.upper()})</span>
                    </div>
                </div>
            </div>

            <script>
                const canvas = document.getElementById('nnCanvas');
                const ctx = canvas.getContext('2d');
                
                // Arquitectura de la red
                const architecture = {architecture};
                const maxNeurons = Math.max(...architecture);
                
                // FunciÃ³n para redimensionar el canvas
                function resizeCanvas() {{
                    const container = document.querySelector('.canvas-container');
                    const containerWidth = container.clientWidth - 4;
                    const aspectRatio = 2/1;
                    const canvasHeight = Math.max(300, containerWidth / aspectRatio);
                    
                    canvas.width = containerWidth;
                    canvas.height = canvasHeight;
                    canvas.style.width = containerWidth + 'px';
                    canvas.style.height = canvasHeight + 'px';
                    
                    drawNetwork();
                }}
                
                // FunciÃ³n para dibujar la red neuronal
                function drawNetwork() {{
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    
                    const margin = 40;
                    const layerWidth = (canvas.width - 2 * margin) / (architecture.length - 1);
                    const maxRadius = Math.min(20, canvas.width / (architecture.length * 8));
                    
                    // Dibujar conexiones primero
                    ctx.strokeStyle = '{colors['connection']}';
                    ctx.lineWidth = 1;
                    ctx.globalAlpha = 0.3;
                    
                    for (let i = 0; i < architecture.length - 1; i++) {{
                        const currentLayerSize = architecture[i];
                        const nextLayerSize = architecture[i + 1];
                        
                        const currentX = margin + i * layerWidth;
                        const nextX = margin + (i + 1) * layerWidth;
                        
                        for (let j = 0; j < currentLayerSize; j++) {{
                            const currentY = getNodeY(j, currentLayerSize);
                            
                            for (let k = 0; k < nextLayerSize; k++) {{
                                const nextY = getNodeY(k, nextLayerSize);
                                
                                ctx.beginPath();
                                ctx.moveTo(currentX, currentY);
                                ctx.lineTo(nextX, nextY);
                                ctx.stroke();
                            }}
                        }}
                    }}
                    
                    ctx.globalAlpha = 1.0;
                    
                    // Dibujar nodos
                    architecture.forEach((layerSize, layerIndex) => {{
                        const x = margin + layerIndex * layerWidth;
                        const radius = Math.min(maxRadius, Math.max(8, (canvas.height - 2 * margin) / (maxNeurons * 3)));
                        
                        // Color segÃºn tipo de capa
                        let color;
                        if (layerIndex === 0) {{
                            color = '{colors['input']}';
                        }} else if (layerIndex === architecture.length - 1) {{
                            color = '{colors['output']}';
                        }} else {{
                            color = '{colors['hidden']}';
                        }}
                        
                        // Dibujar nodos de la capa
                        for (let nodeIndex = 0; nodeIndex < layerSize; nodeIndex++) {{
                            const y = getNodeY(nodeIndex, layerSize);
                            
                            // Nodo
                            ctx.fillStyle = color;
                            ctx.beginPath();
                            ctx.arc(x, y, radius, 0, 2 * Math.PI);
                            ctx.fill();
                            
                            // Borde
                            ctx.strokeStyle = '#2C3E50';
                            ctx.lineWidth = 2;
                            ctx.stroke();
                        }}
                        
                        // Etiqueta de capa
                        ctx.fillStyle = '{colors['text']}';
                        ctx.font = `bold ${{Math.max(10, canvas.width / 50)}}px Arial`;
                        ctx.textAlign = 'center';
                        
                        let layerLabel;
                        if (layerIndex === 0) {{
                            layerLabel = `Entrada\\n(${{layerSize}})`;
                        }} else if (layerIndex === architecture.length - 1) {{
                            layerLabel = `Salida\\n(${{layerSize}})`;
                        }} else {{
                            layerLabel = `Oculta ${{layerIndex}}\\n(${{layerSize}})`;
                        }}
                        
                        // Dibujar texto en mÃºltiples lÃ­neas
                        const lines = layerLabel.split('\\n');
                        lines.forEach((line, lineIndex) => {{
                            ctx.fillText(line, x, canvas.height - 25 + lineIndex * 15);
                        }});
                    }});
                }}
                
                // FunciÃ³n auxiliar para calcular posiciÃ³n Y de un nodo
                function getNodeY(nodeIndex, layerSize) {{
                    const margin = 40;
                    const availableHeight = canvas.height - 2 * margin - 60; // Espacio para etiquetas
                    
                    if (layerSize === 1) {{
                        return margin + availableHeight / 2;
                    }}
                    
                    const spacing = availableHeight / (layerSize + 1);
                    return margin + spacing * (nodeIndex + 1);
                }}
                
                // InicializaciÃ³n
                resizeCanvas();
                
                // Redimensionar cuando cambie el tamaÃ±o de ventana
                window.addEventListener('resize', function() {{
                    setTimeout(resizeCanvas, 100);
                }});
                
                // Observer para detectar cambios en el contenedor
                if (window.ResizeObserver) {{
                    const resizeObserver = new ResizeObserver(entries => {{
                        for (let entry of entries) {{
                            if (entry.target.querySelector('#nnCanvas')) {{
                                resizeCanvas();
                            }}
                        }}
                    }});
                    resizeObserver.observe(document.querySelector('.canvas-container'));
                }}
            </script>
        </body>
        </html>
        """

        components.html(html_code, height=400, scrolling=False)

    except Exception as e:
        st.error(f"Error en la visualizaciÃ³n de red neuronal: {str(e)}")


def calculate_network_parameters(architecture):
    """Calcula el nÃºmero total de parÃ¡metros en la red."""
    total_params = 0
    for i in range(len(architecture) - 1):
        # Pesos: current_layer * next_layer + Sesgos: next_layer
        weights = architecture[i] * architecture[i + 1]
        biases = architecture[i + 1]
        total_params += weights + biases
    return total_params


def train_neural_network(df, target_col, config, learning_rate, epochs, validation_split,
                         early_stopping, patience, reduce_lr, lr_factor, progress_callback=None):
    """
    Entrena una red neuronal con la configuraciÃ³n especificada.
    """
    try:
        # Importar TensorFlow/Keras
        import tensorflow as tf
        from tensorflow import keras
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler, LabelEncoder
        from sklearn.metrics import classification_report, confusion_matrix
        import numpy as np
        import time

        # Paso 1: Preparar datos (ya mostrado)
        X = df.drop(columns=[target_col])
        y = df[target_col]

        # Preprocesamiento
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42,
            stratify=y if config['task_type'] == 'ClasificaciÃ³n' else None
        )

        # Paso 2: Construyendo la red neuronal
        if progress_callback:
            progress_callback(
                2, "Construyendo arquitectura de red neuronal con capas y neuronas...")
        time.sleep(0.8)  # Pausa para que se vea el paso

        # Procesar variable objetivo
        label_encoder = None
        if config['task_type'] == 'ClasificaciÃ³n':
            label_encoder = LabelEncoder()
            y_train_encoded = label_encoder.fit_transform(y_train)
            y_test_encoded = label_encoder.transform(y_test)

            # DecisiÃ³n de one-hot encoding basada en funciÃ³n de activaciÃ³n y nÃºmero de clases
            output_size = safe_get_output_size(config)
            if config['output_activation'] == 'softmax' or (output_size > 1 and config['output_activation'] != 'sigmoid'):
                # Para softmax multiclase o funciones no-estÃ¡ndar multiclase
                y_train_encoded = keras.utils.to_categorical(y_train_encoded)
                y_test_encoded = keras.utils.to_categorical(y_test_encoded)
            # Para sigmoid (binaria o multiclase) mantener encoding simple
        else:
            y_train_encoded = y_train.values
            y_test_encoded = y_test.values

        # Construir modelo con Input layer (mejores prÃ¡cticas)
        model = keras.Sequential()

        # Capa de entrada explÃ­cita (elimina warnings)
        model.add(keras.layers.Input(shape=(config['input_size'],)))

        # Primera capa densa (sin input_shape)
        model.add(keras.layers.Dense(
            config['architecture'][1],
            activation=config['activation']
        ))
        model.add(keras.layers.Dropout(config['dropout_rate']))

        # Capas ocultas
        for layer_size in config['architecture'][2:-1]:
            model.add(keras.layers.Dense(
                layer_size, activation=config['activation']))
            model.add(keras.layers.Dropout(config['dropout_rate']))

        # Capa de salida
        model.add(keras.layers.Dense(
            config['output_size'],
            activation=config['output_activation']
        ))

        # Paso 3: Compilando el modelo
        if progress_callback:
            progress_callback(
                3, "Compilando modelo con optimizadores y funciones de pÃ©rdida...")
        time.sleep(0.8)

        # Compilar modelo - FunciÃ³n de pÃ©rdida inteligente segÃºn activaciÃ³n
        if config['task_type'] == 'ClasificaciÃ³n':
            # SelecciÃ³n inteligente de funciÃ³n de pÃ©rdida
            output_size = safe_get_output_size(config)
            if config['output_activation'] == 'sigmoid':
                if output_size == 1:
                    loss = 'binary_crossentropy'  # EstÃ¡ndar para binaria con sigmoid
                else:
                    # Sigmoid multiclase (multi-label)
                    loss = 'binary_crossentropy'
                metrics = ['accuracy']
            elif config['output_activation'] == 'softmax':
                if output_size == 1:
                    # Softmax con 1 neurona es problemÃ¡tico, pero manejar el caso
                    loss = 'sparse_categorical_crossentropy'
                    metrics = ['accuracy']
                    st.warning(
                        "âš ï¸ Softmax con 1 neurona detectada. Puede causar problemas.")
                else:
                    loss = 'categorical_crossentropy'  # EstÃ¡ndar para multiclase con softmax
                    metrics = ['accuracy']
            elif config['output_activation'] == 'linear':
                # Linear para clasificaciÃ³n - usar sparse categorical
                loss = 'sparse_categorical_crossentropy'
                metrics = ['accuracy']
                st.warning(
                    "âš ï¸ FunciÃ³n linear detectada en clasificaciÃ³n. Rendimiento puede ser subÃ³ptimo.")
            elif config['output_activation'] == 'tanh':
                # Tanh para clasificaciÃ³n - tratar como regresiÃ³n pero con accuracy
                loss = 'mse'
                metrics = ['accuracy']
                st.warning(
                    "âš ï¸ FunciÃ³n tanh detectada en clasificaciÃ³n. Comportamiento no estÃ¡ndar.")
            else:
                # Fallback
                loss = 'categorical_crossentropy' if output_size > 1 else 'binary_crossentropy'
                metrics = ['accuracy']
        else:
            # Para regresiÃ³n
            if config['output_activation'] == 'linear':
                loss = 'mse'  # EstÃ¡ndar para regresiÃ³n
                metrics = ['mae']
            elif config['output_activation'] in ['sigmoid', 'tanh']:
                loss = 'mse'  # MSE tambiÃ©n funciona con activaciones acotadas
                metrics = ['mae']
                if config['output_activation'] == 'sigmoid':
                    st.info(
                        "â„¹ï¸ Sigmoid limitarÃ¡ las salidas a [0,1]. AsegÃºrate de que tus datos objetivo estÃ©n normalizados.")
                else:  # tanh
                    st.info(
                        "â„¹ï¸ Tanh limitarÃ¡ las salidas a [-1,1]. AsegÃºrate de que tus datos objetivo estÃ©n normalizados.")
            elif config['output_activation'] == 'softmax':
                loss = 'mse'
                metrics = ['mae']
                st.error(
                    "âš ï¸ Softmax en regresiÃ³n: las salidas sumarÃ¡n 1. Esto raramente es lo deseado.")
            else:
                loss = 'mse'
                metrics = ['mae']

        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
        if config['optimizer'] == 'sgd':
            optimizer = keras.optimizers.SGD(learning_rate=learning_rate)
        elif config['optimizer'] == 'rmsprop':
            optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)

        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

        # Callbacks
        callbacks = []

        if early_stopping:
            early_stop = keras.callbacks.EarlyStopping(
                monitor='val_loss', patience=patience, restore_best_weights=True
            )
            callbacks.append(early_stop)

        if reduce_lr:
            reduce_lr_callback = keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss', factor=lr_factor, patience=patience//2, min_lr=1e-7
            )
            callbacks.append(reduce_lr_callback)

        # Paso 4: Iniciando entrenamiento
        if progress_callback:
            progress_callback(
                4, f"Entrenando red neuronal ({epochs} Ã©pocas mÃ¡ximo)... Â¡Puede tardar unos minutos!")
        time.sleep(1.0)  # Pausa mÃ¡s larga antes del entrenamiento

        # Entrenar modelo
        history = model.fit(
            X_train, y_train_encoded,
            epochs=epochs,
            batch_size=config['batch_size'],
            validation_split=validation_split,
            callbacks=callbacks,
            verbose=0
        )

        # PASO 5: INICIALIZACIÃ“N COMPLETA DEL MODELO PARA VISUALIZACIONES
        if progress_callback:
            progress_callback(5, "Preparando modelo para visualizaciones...")

        # Forzar construcciÃ³n completa del modelo
        try:
            # Asegurar que el modelo estÃ© completamente construido
            sample_data = X_test[:1].astype(np.float32)
            _ = model.predict(sample_data, verbose=0)

            # Verificar que model.input estÃ© definido
            if model.input is None:
                # Forzar definiciÃ³n de input si es necesario
                model.build(input_shape=(None, config['input_size']))
                _ = model(sample_data)

            # Crear modelo de activaciones para anÃ¡lisis de capas
            if len(model.layers) > 2:  # Al menos Input + Hidden + Output
                intermediate_layers = []
                for i, layer in enumerate(model.layers):
                    # Excluir la primera capa (Input) y la Ãºltima (Output)
                    if i > 0 and i < len(model.layers) - 1:
                        if hasattr(layer, 'output') and layer.output is not None:
                            intermediate_layers.append(layer.output)

                if intermediate_layers:
                    import tensorflow as tf
                    activation_model = tf.keras.Model(
                        inputs=model.input,
                        outputs=intermediate_layers
                    )
                    # Verificar que funcione
                    _ = activation_model.predict(sample_data, verbose=0)

                    # Marcar que el modelo de activaciones estÃ¡ listo
                    model._activation_model_ready = activation_model

            # Marcar el modelo como completamente inicializado
            model._fully_initialized = True

        except Exception as init_error:
            # Si falla la inicializaciÃ³n, al menos el modelo base funciona
            if progress_callback:
                progress_callback(
                    5, f"Advertencia en inicializaciÃ³n: {str(init_error)}")
            model._fully_initialized = False

        return model, history, X_test, y_test_encoded, scaler, label_encoder

    except ImportError:
        st.error(
            "âŒ TensorFlow no estÃ¡ instalado. Las redes neuronales requieren TensorFlow.")
        st.info("Instala TensorFlow con: `pip install tensorflow`")
        return None, None, None, None, None, None
    except Exception as e:
        st.error(f"Error durante el entrenamiento: {str(e)}")
        return None, None, None, None, None, None


def plot_training_history(history, task_type):
    """Grafica el historial de entrenamiento."""
    try:
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        import streamlit as st

        # Crear subplots
        if task_type == 'ClasificaciÃ³n':
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=('PÃ©rdida durante el Entrenamiento',
                                'PrecisiÃ³n durante el Entrenamiento')
            )

            # PÃ©rdida
            fig.add_trace(
                go.Scatter(
                    y=history.history['loss'], name='Entrenamiento', line=dict(color='blue')),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(
                    y=history.history['val_loss'], name='ValidaciÃ³n', line=dict(color='red')),
                row=1, col=1
            )

            # PrecisiÃ³n
            fig.add_trace(
                go.Scatter(y=history.history['accuracy'], name='Entrenamiento', line=dict(
                    color='blue'), showlegend=False),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(y=history.history['val_accuracy'], name='ValidaciÃ³n', line=dict(
                    color='red'), showlegend=False),
                row=1, col=2
            )

            fig.update_yaxes(title_text="PÃ©rdida", row=1, col=1)
            fig.update_yaxes(title_text="PrecisiÃ³n", row=1, col=2)

        else:
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=(
                    'PÃ©rdida (MSE) durante el Entrenamiento', 'Error Absoluto Medio')
            )

            # MSE
            fig.add_trace(
                go.Scatter(
                    y=history.history['loss'], name='Entrenamiento', line=dict(color='blue')),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(
                    y=history.history['val_loss'], name='ValidaciÃ³n', line=dict(color='red')),
                row=1, col=1
            )

            # MAE
            fig.add_trace(
                go.Scatter(y=history.history['mae'], name='Entrenamiento', line=dict(
                    color='blue'), showlegend=False),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(y=history.history['val_mae'], name='ValidaciÃ³n', line=dict(
                    color='red'), showlegend=False),
                row=1, col=2
            )

            fig.update_yaxes(title_text="MSE", row=1, col=1)
            fig.update_yaxes(title_text="MAE", row=1, col=2)

        fig.update_xaxes(title_text="Ã‰poca")
        fig.update_layout(height=400, showlegend=True)

        st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"Error graficando historial: {str(e)}")


def show_neural_network_evaluation():
    """Muestra la evaluaciÃ³n detallada del modelo de red neuronal."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "âš ï¸ Primero debes entrenar un modelo en la pestaÃ±a 'Entrenamiento'")
        return

    # Tips educativos sobre evaluaciÃ³n
    st.info("""
    ğŸ“ **EvaluaciÃ³n de Redes Neuronales:**
    - **Accuracy**: Porcentaje de predicciones correctas (para clasificaciÃ³n)
    - **Matriz de ConfusiÃ³n**: Muestra quÃ© clases se confunden entre sÃ­
    - **MSE/MAE**: Errores promedio para regresiÃ³n
    - **Datos de test**: Nunca vistos durante entrenamiento, miden la capacidad real
    """)

    try:
        import tensorflow as tf
        import numpy as np
        import pandas as pd
        from sklearn.metrics import classification_report, confusion_matrix, r2_score, mean_squared_error, mean_absolute_error
        import plotly.graph_objects as go
        import plotly.figure_factory as ff
        from plotly.subplots import make_subplots

        model = st.session_state.nn_model
        X_test, y_test = st.session_state.nn_test_data
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        st.header("ğŸ“Š EvaluaciÃ³n del Modelo")

        # Hacer predicciones
        y_pred = model.predict(X_test, verbose=0)

        # MÃ©tricas segÃºn el tipo de tarea
        if config['task_type'] == 'ClasificaciÃ³n':
            # Obtener el tamaÃ±o de salida de forma segura
            output_size = safe_get_output_size(config)

            # Para clasificaciÃ³n - detectar formato de y_test
            # One-hot encoded (multiclase)
            if len(y_test.shape) > 1 and y_test.shape[1] > 1:
                y_pred_classes = np.argmax(y_pred, axis=1)
                y_test_classes = np.argmax(y_test, axis=1)
            else:  # Binaria o multiclase sin one-hot
                if output_size == 1:  # Binaria con 1 neurona
                    y_pred_classes = (y_pred > 0.5).astype(int).flatten()
                    y_test_classes = y_test.flatten()
                else:  # Multiclase sin one-hot (sparse)
                    y_pred_classes = np.argmax(y_pred, axis=1)
                    y_test_classes = y_test.flatten()

            # Accuracy
            accuracy = np.mean(y_pred_classes == y_test_classes)

            # Mostrar mÃ©tricas principales con explicaciones
            st.markdown("### ğŸ¯ MÃ©tricas Principales")
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("ğŸ¯ Accuracy", f"{accuracy:.4f}", f"{accuracy*100:.2f}%",
                          help="Porcentaje de predicciones correctas en datos nunca vistos")

                # InterpretaciÃ³n del accuracy
                if accuracy >= 0.9:
                    st.success("ğŸŒŸ **Excelente**: Tu red predice muy bien")
                elif accuracy >= 0.8:
                    st.success("âœ… **Muy Bueno**: Predicciones muy confiables")
                elif accuracy >= 0.7:
                    st.warning("âš ï¸ **Bueno**: Predicciones aceptables")
                elif accuracy >= 0.6:
                    st.warning("ğŸŸ¡ **Regular**: Hay margen de mejora")
                else:
                    st.error("ğŸ”´ **Bajo**: Considera ajustar el modelo")

            with col2:
                # Calcular confianza promedio
                # One-hot multiclase
                if len(y_test.shape) > 1 and y_test.shape[1] > 1:
                    confidence = np.mean(np.max(y_pred, axis=1))
                elif output_size == 1:  # Binaria
                    confidence = np.mean(np.maximum(
                        y_pred.flatten(), 1 - y_pred.flatten()))
                else:  # Multiclase sparse
                    confidence = np.mean(np.max(y_pred, axis=1))
                st.metric("ğŸ² Confianza Promedio",
                          f"{confidence:.4f}", f"{confidence*100:.2f}%")

            with col3:
                # NÃºmero de predicciones correctas
                correct_preds = np.sum(y_pred_classes == y_test_classes)
                st.metric("âœ… Predicciones Correctas",
                          f"{correct_preds}/{len(y_test_classes)}")

            # Matriz de confusiÃ³n
            st.subheader("ğŸ” Matriz de ConfusiÃ³n")

            try:
                cm = confusion_matrix(y_test_classes, y_pred_classes)

                # Obtener nombres de clases
                if label_encoder and hasattr(label_encoder, 'classes_'):
                    class_names = list(label_encoder.classes_)
                else:
                    # Determinar clases basado en los datos Ãºnicos
                    all_classes = sorted(
                        set(list(y_test_classes) + list(y_pred_classes)))
                    class_names = [f"Clase {i}" for i in all_classes]

                # Ajustar class_names al tamaÃ±o de la matriz si es necesario
                if len(class_names) != cm.shape[0]:
                    class_names = [f"Clase {i}" for i in range(cm.shape[0])]

                # Crear heatmap de la matriz de confusiÃ³n
                fig_cm = ff.create_annotated_heatmap(
                    z=cm,
                    x=class_names,
                    y=class_names,
                    annotation_text=cm,
                    colorscale='Blues',
                    showscale=True
                )

                fig_cm.update_layout(
                    title='Matriz de ConfusiÃ³n',
                    xaxis_title='Predicciones',
                    yaxis_title='Valores Reales',
                    height=500
                )

                st.plotly_chart(fig_cm, use_container_width=True)

            except Exception as cm_error:
                st.error(
                    f"âŒ Error creando matriz de confusiÃ³n: {str(cm_error)}")
                st.info(
                    "La matriz de confusiÃ³n no pudo generarse. El modelo funciona correctamente pero hay un problema con la visualizaciÃ³n.")

            # Reporte de clasificaciÃ³n detallado
            st.subheader("ğŸ“‹ Reporte de ClasificaciÃ³n")

            if label_encoder:
                target_names = label_encoder.classes_
            else:
                target_names = [f"Clase {i}" for i in range(
                    len(np.unique(y_test_classes)))]

            # Generar reporte
            report = classification_report(
                y_test_classes, y_pred_classes,
                target_names=target_names,
                output_dict=True
            )

            # Mostrar mÃ©tricas por clase
            metrics_data = []
            for class_name in target_names:
                if class_name in report:
                    metrics_data.append({
                        'Clase': class_name,
                        'PrecisiÃ³n': f"{report[class_name]['precision']:.4f}",
                        'Recall': f"{report[class_name]['recall']:.4f}",
                        'F1-Score': f"{report[class_name]['f1-score']:.4f}",
                        'Soporte': report[class_name]['support']
                    })

            st.dataframe(metrics_data, use_container_width=True)

            # MÃ©tricas macro y weighted
            st.subheader("ğŸ“Š MÃ©tricas Agregadas")
            col1, col2 = st.columns(2)

            with col1:
                st.info(f"""
                **Macro Average:**
                - PrecisiÃ³n: {report['macro avg']['precision']:.4f}
                - Recall: {report['macro avg']['recall']:.4f}
                - F1-Score: {report['macro avg']['f1-score']:.4f}
                """)

            with col2:
                st.info(f"""
                **Weighted Average:**
                - PrecisiÃ³n: {report['weighted avg']['precision']:.4f}
                - Recall: {report['weighted avg']['recall']:.4f}
                - F1-Score: {report['weighted avg']['f1-score']:.4f}
                """)

        else:
            # Para regresiÃ³n
            y_pred_flat = y_pred.flatten()
            y_test_flat = y_test.flatten()

            # MÃ©tricas de regresiÃ³n
            mse = mean_squared_error(y_test_flat, y_pred_flat)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test_flat, y_pred_flat)
            r2 = r2_score(y_test_flat, y_pred_flat)

            # Mostrar mÃ©tricas principales
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("ğŸ“Š RÂ² Score", f"{r2:.4f}")

            with col2:
                st.metric("ğŸ“ MAE", f"{mae:.4f}")

            with col3:
                st.metric("ğŸ“ RMSE", f"{rmse:.4f}")

            with col4:
                st.metric("ğŸ¯ MSE", f"{mse:.4f}")

            # GrÃ¡ficos de evaluaciÃ³n para regresiÃ³n
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=('Predicciones vs Valores Reales',
                                'DistribuciÃ³n de Residuos')
            )

            # Scatter plot de predicciones vs reales
            fig.add_trace(
                go.Scatter(
                    x=y_test_flat,
                    y=y_pred_flat,
                    mode='markers',
                    name='Predicciones',
                    marker=dict(size=8, opacity=0.6)
                ),
                row=1, col=1
            )

            # LÃ­nea de referencia y = x
            min_val = min(y_test_flat.min(), y_pred_flat.min())
            max_val = max(y_test_flat.max(), y_pred_flat.max())

            fig.add_trace(
                go.Scatter(
                    x=[min_val, max_val],
                    y=[min_val, max_val],
                    mode='lines',
                    name='LÃ­nea Ideal',
                    line=dict(color='red', dash='dash')
                ),
                row=1, col=1
            )

            # Histograma de residuos
            residuals = y_test_flat - y_pred_flat
            fig.add_trace(
                go.Histogram(
                    x=residuals,
                    name='Residuos',
                    nbinsx=30,
                    opacity=0.7
                ),
                row=1, col=2
            )

            fig.update_xaxes(title_text="Valores Reales", row=1, col=1)
            fig.update_yaxes(title_text="Predicciones", row=1, col=1)
            fig.update_xaxes(title_text="Residuos", row=1, col=2)
            fig.update_yaxes(title_text="Frecuencia", row=1, col=2)

            fig.update_layout(height=500, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)

        # InformaciÃ³n del modelo
        st.subheader("ğŸ”§ InformaciÃ³n del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            st.info(f"""
            **Arquitectura:**
            - Capas: {len(config['architecture'])}
            - Neuronas por capa: {config['architecture']}
            - FunciÃ³n de activaciÃ³n: {config['activation']}
            - ActivaciÃ³n de salida: {config['output_activation']}
            """)

        with col2:
            total_params = calculate_network_parameters(config['architecture'])
            st.info(f"""
            **ParÃ¡metros:**
            - Total de parÃ¡metros: {total_params:,}
            - Optimizador: {config['optimizer']}
            - Dropout: {config['dropout_rate']}
            - Batch size: {config['batch_size']}
            """)

        # BotÃ³n para generar cÃ³digo Python de evaluaciÃ³n
        st.markdown("### ğŸ’» CÃ³digo Python")
        if st.button("ğŸ“ Generar CÃ³digo de EvaluaciÃ³n", use_container_width=True):
            # Generar cÃ³digo Python para evaluaciÃ³n
            code = generate_neural_network_evaluation_code(
                config, st.session_state.nn_feature_names, st.session_state.nn_class_names
            )

            st.markdown("#### ğŸ CÃ³digo Python para EvaluaciÃ³n")
            st.code(code, language='python')

            # BotÃ³n para descargar el cÃ³digo
            st.download_button(
                label="ğŸ’¾ Descargar CÃ³digo de EvaluaciÃ³n",
                data=code,
                file_name=f"evaluacion_red_neuronal_{config['task_type'].lower()}.py",
                mime="text/plain"
            )

        # NavegaciÃ³n
        st.markdown("---")
        st.markdown("### ğŸ§­ NavegaciÃ³n")
        col_nav1, col_nav2 = st.columns(2)
        with col_nav1:
            if st.button("ğŸ”™ Volver a Entrenamiento", use_container_width=True):
                st.session_state.active_tab_nn = 2
                st.rerun()
        with col_nav2:
            if st.button("ğŸ¯ Ver Visualizaciones", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 4
                st.rerun()

    except Exception as e:
        st.error(f"Error en la evaluaciÃ³n: {str(e)}")
        st.info(
            "AsegÃºrate de que TensorFlow estÃ© instalado y el modelo estÃ© entrenado correctamente.")


def show_neural_network_visualizations():
    """Muestra visualizaciones avanzadas del modelo."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "âš ï¸ Primero debes entrenar un modelo en la pestaÃ±a 'Entrenamiento'")
        return

    # Tips educativos sobre visualizaciones
    st.info("""
    ğŸ“ **Visualizaciones de Redes Neuronales:**
    - **Historial de entrenamiento**: Muestra cÃ³mo evoluciona el aprendizaje
    - **Pesos y sesgos**: Revelan quÃ© ha aprendido cada neurona
    - **Superficie de decisiÃ³n**: CÃ³mo la red separa las clases (2D)
    - **AnÃ¡lisis de capas**: Activaciones y patrones internos
    
    ğŸ”§ **ReparaciÃ³n AutomÃ¡tica**: Esta funciÃ³n incluye inicializaciÃ³n automÃ¡tica del modelo para prevenir errores comunes.
    """)

    try:
        import tensorflow as tf
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        import numpy as np
        import matplotlib.pyplot as plt
        from sklearn.preprocessing import StandardScaler

        model = st.session_state.nn_model
        history = st.session_state.nn_history
        config = st.session_state.nn_config

        # SOLUCIÃ“N DEFINITIVA PARA EL ERROR DE TENSORFLOW
        st.info("ğŸ”„ Inicializando modelo para visualizaciones...")

        # Obtener datos de test
        X_test, _ = st.session_state.nn_test_data

        # ESTRATEGIA DEFINITIVA: FORZAR CONSTRUCCIÃ“N COMPLETA
        try:
            # Preparar datos de muestra
            sample_data = X_test[:1].astype(np.float32)

            # PASO 1: Forzar la construcciÃ³n del modelo de forma agresiva
            st.info("ğŸ—ï¸ Forzando construcciÃ³n del modelo...")

            # DIAGNÃ“STICO INICIAL
            st.info(
                f"Estado inicial: built={getattr(model, 'built', False)}, input={'definido' if hasattr(model, 'input') and model.input is not None else 'None'}")

            # ESTRATEGIA ESPECÃFICA PARA EL PROBLEMA DETECTADO
            # Cuando model.built=True pero model.input=None
            construction_success = False

            for attempt in range(3):
                try:
                    st.info(f"Intento {attempt + 1}/3 de construcciÃ³n...")

                    # ESTRATEGIA 1: Forzar predicciÃ³n simple
                    _ = model.predict(sample_data, verbose=0)

                    # ESTRATEGIA 2: Si input sigue siendo None, forzar build con input_shape
                    if not hasattr(model, 'input') or model.input is None:
                        st.info("ğŸ”§ Aplicando fix especÃ­fico para input=None...")
                        # Reconstruir completamente el modelo
                        model.build(input_shape=(None, X_test.shape[1]))

                        # Forzar que el modelo "vea" datos reales
                        _ = model(sample_data)  # Llamada directa

                    # ESTRATEGIA 3: Si aÃºn no funciona, usar _set_inputs (mÃ©todo interno)
                    if not hasattr(model, 'input') or model.input is None:
                        st.info("ğŸ”§ Aplicando fix avanzado...")
                        # MÃ©todo interno de TensorFlow para forzar input
                        try:
                            model._set_inputs(sample_data)
                        except:
                            # Si falla, intentar con fit en modo dummy usando la funciÃ³n de pÃ©rdida CORRECTA
                            try:
                                # Determinar la funciÃ³n de pÃ©rdida correcta segÃºn la arquitectura
                                output_size = model.layers[-1].units if hasattr(
                                    model.layers[-1], 'units') else 1

                                if output_size == 1:
                                    # ClasificaciÃ³n binaria o regresiÃ³n
                                    if hasattr(model.layers[-1], 'activation') and 'sigmoid' in str(model.layers[-1].activation):
                                        loss_func = 'binary_crossentropy'
                                    else:
                                        loss_func = 'mse'  # RegresiÃ³n
                                else:
                                    # ClasificaciÃ³n multiclase
                                    loss_func = 'sparse_categorical_crossentropy'

                                st.info(
                                    f"ğŸ”§ Usando {loss_func} para reparaciÃ³n...")
                                model.compile(optimizer='adam', loss=loss_func)

                                # Crear dummy target con el tamaÃ±o correcto
                                if loss_func == 'sparse_categorical_crossentropy':
                                    dummy_target = np.zeros(
                                        (1,), dtype=np.int32)  # Clase 0
                                elif loss_func == 'binary_crossentropy':
                                    dummy_target = np.zeros(
                                        (1, 1), dtype=np.float32)  # Probabilidad 0
                                else:  # MSE
                                    dummy_target = np.zeros(
                                        (1, output_size), dtype=np.float32)

                                model.fit(sample_data, dummy_target,
                                          epochs=1, verbose=0)
                            except Exception as fit_error:
                                st.warning(
                                    f"Fix avanzado fallÃ³: {str(fit_error)}")
                                pass

                    # VERIFICACIÃ“N CRÃTICA
                    if hasattr(model, 'input') and model.input is not None:
                        st.success(
                            f"âœ… ConstrucciÃ³n exitosa en intento {attempt + 1}")
                        construction_success = True
                        break
                    else:
                        st.warning(
                            f"âš ï¸ Intento {attempt + 1} fallÃ³: input sigue siendo None")

                except Exception as build_error:
                    st.warning(
                        f"âš ï¸ Intento {attempt + 1} fallÃ³: {str(build_error)}")
                    if attempt == 2:  # Ãšltimo intento
                        # Ãšltimo recurso: recrear el modelo completamente
                        st.info("ğŸ”¥ ÃšLTIMO RECURSO: Intentando recrear modelo...")
                        try:
                            # Obtener pesos del modelo actual
                            weights = model.get_weights()

                            # Recrear arquitectura desde config
                            config = st.session_state.nn_config

                            import tensorflow as tf
                            new_model = tf.keras.Sequential()
                            new_model.add(tf.keras.layers.Input(
                                shape=(config['input_size'],)))

                            # Recrear capas densas (excluyendo Input y Dropout)
                            layer_idx = 0
                            for i, layer in enumerate(model.layers):
                                if hasattr(layer, 'units'):  # Es una capa Dense
                                    if layer_idx == 0:  # Primera capa densa
                                        new_model.add(tf.keras.layers.Dense(
                                            layer.units,
                                            activation=layer.activation.__name__
                                        ))
                                    else:  # Capas siguientes
                                        new_model.add(tf.keras.layers.Dense(
                                            layer.units,
                                            activation=layer.activation.__name__
                                        ))
                                    layer_idx += 1
                                elif hasattr(layer, 'rate'):  # Es Dropout
                                    new_model.add(
                                        tf.keras.layers.Dropout(layer.rate))

                            # Compilar nuevo modelo con la configuraciÃ³n CORRECTA
                            if config['task_type'] == 'ClasificaciÃ³n':
                                if config.get('output_size', 1) == 1:
                                    loss_func = 'binary_crossentropy'
                                else:
                                    loss_func = 'sparse_categorical_crossentropy'
                            else:
                                loss_func = 'mse'

                            new_model.compile(optimizer='adam', loss=loss_func)

                            # Forzar construcciÃ³n
                            _ = new_model.predict(sample_data, verbose=0)

                            # Copiar pesos si es posible
                            try:
                                new_model.set_weights(weights)
                                st.info("âœ… Pesos copiados exitosamente")
                            except:
                                st.warning(
                                    "âš ï¸ No se pudieron copiar los pesos")

                            # Reemplazar modelo en session_state
                            st.session_state.nn_model = new_model
                            model = new_model

                            if model.input is not None:
                                st.success("ğŸ‰ Modelo recreado exitosamente!")
                                construction_success = True
                                break

                        except Exception as recreate_error:
                            st.error(
                                f"âŒ RecreaciÃ³n fallÃ³: {str(recreate_error)}")

                            # ÃšLTIMO ÃšLTIMO RECURSO: Modelo completamente nuevo SIN copiar pesos
                            st.info(
                                "ğŸš¨ ÃšLTIMO RECURSO EXTREMO: Modelo completamente nuevo...")
                            try:
                                config = st.session_state.nn_config

                                # Crear modelo minimalista garantizado que SIEMPRE funciona
                                minimal_model = tf.keras.Sequential([
                                    tf.keras.layers.Input(
                                        shape=(config['input_size'],)),
                                    tf.keras.layers.Dense(
                                        32, activation='relu'),
                                    tf.keras.layers.Dense(
                                        config['output_size'], activation=config['output_activation'])
                                ])

                                # Compilar con configuraciÃ³n correcta
                                if config['task_type'] == 'ClasificaciÃ³n':
                                    loss_func = 'sparse_categorical_crossentropy' if config[
                                        'output_size'] > 1 else 'binary_crossentropy'
                                else:
                                    loss_func = 'mse'

                                minimal_model.compile(
                                    optimizer='adam', loss=loss_func, metrics=['accuracy'])

                                # Forzar construcciÃ³n INMEDIATA
                                dummy_input = np.zeros(
                                    (1, config['input_size']), dtype=np.float32)
                                _ = minimal_model.predict(
                                    dummy_input, verbose=0)

                                # VERIFICAR que funcione
                                if minimal_model.input is not None:
                                    st.warning(
                                        "âš ï¸ Modelo minimal creado (PERDISTE los pesos entrenados)")
                                    st.info(
                                        "ğŸ’¡ Este modelo te permitirÃ¡ ver las visualizaciones, pero necesitarÃ¡s reentrenar")
                                    st.session_state.nn_model = minimal_model
                                    model = minimal_model
                                    construction_success = True
                                    break
                                else:
                                    st.error(
                                        "ğŸš¨ IMPOSIBLE: Incluso el modelo minimal fallÃ³")

                            except Exception as minimal_error:
                                st.error(
                                    f"âŒ Modelo minimal fallÃ³: {str(minimal_error)}")
                                st.error(
                                    "ğŸš¨ ERROR CRÃTICO: TensorFlow no funciona correctamente en este entorno")
                                pass

            if not construction_success:
                raise Exception(
                    "Fallo total en construcciÃ³n despuÃ©s de todos los intentos")

            # PASO 2: VerificaciÃ³n EXHAUSTIVA que el modelo funcione
            # No solo verificar model.input, sino que REALMENTE funcione
            test_prediction = model.predict(sample_data, verbose=0)

            # Verificar que las capas estÃ¡n construidas
            layers_built = all(getattr(layer, 'built', True)
                               for layer in model.layers)

            if model.input is not None and layers_built and test_prediction is not None:
                st.success("âœ… Modelo completamente construido y funcional")

                # PASO 3: Crear modelo de activaciones CON VERIFICACIÃ“N ROBUSTA
                if len(model.layers) > 2:  # Al menos Input + Hidden + Output
                    try:
                        # Identificar capas vÃ¡lidas para activaciones (excluir Input y Output)
                        intermediate_layers = []
                        for i, layer in enumerate(model.layers):
                            # Excluir la primera capa (Input) y la Ãºltima (Output)
                            if i > 0 and i < len(model.layers) - 1:
                                if hasattr(layer, 'output') and layer.output is not None:
                                    intermediate_layers.append(layer.output)

                        if intermediate_layers:
                            # Crear modelo de activaciones
                            activation_model = tf.keras.Model(
                                inputs=model.input,
                                outputs=intermediate_layers
                            )

                            # VERIFICAR que el modelo de activaciones funcione
                            test_activations = activation_model.predict(
                                sample_data, verbose=0)

                            # Guardar solo si funciona
                            st.session_state.activation_model = activation_model
                            st.success(
                                f"âœ… Modelo de activaciones creado ({len(intermediate_layers)} capas)")
                        else:
                            st.warning(
                                "âš ï¸ No hay capas intermedias vÃ¡lidas para anÃ¡lisis")
                            st.session_state.activation_model = None
                    except Exception as activation_error:
                        st.warning("âš ï¸ Error creando modelo de activaciones")
                        st.caption(f"Detalle: {str(activation_error)}")
                        st.session_state.activation_model = None
                else:
                    st.info("â„¹ï¸ Red muy simple, anÃ¡lisis de capas limitado")
                    st.session_state.activation_model = None

            else:
                # Si llegamos aquÃ­, hay un problema fundamental
                error_details = []
                if model.input is None:
                    error_details.append("model.input es None")
                if not layers_built:
                    error_details.append("capas no construidas")
                if test_prediction is None:
                    error_details.append("predicciÃ³n fallÃ³")

                raise Exception(
                    f"Modelo no funcional: {', '.join(error_details)}")

        except Exception as error:
            st.error("âŒ FALLO CRÃTICO: El modelo no se puede inicializar")
            st.markdown("### ğŸš¨ DiagnÃ³stico del Error")
            st.code(f"Error: {str(error)}")

            # DiagnÃ³stico tÃ©cnico detallado
            st.markdown("### ğŸ”¬ Estado TÃ©cnico del Modelo")
            try:
                st.write(f"- **Tipo de modelo**: {type(model).__name__}")
                st.write(
                    f"- **Modelo construido**: {getattr(model, 'built', 'Desconocido')}")
                st.write(
                    f"- **Input definido**: {model.input is not None if hasattr(model, 'input') else 'No disponible'}")
                st.write(
                    f"- **NÃºmero de capas**: {len(model.layers) if hasattr(model, 'layers') else 'Desconocido'}")

                if hasattr(model, 'layers'):
                    st.write("- **Estado de capas**:")
                    for i, layer in enumerate(model.layers):
                        built_status = getattr(layer, 'built', 'Desconocido')
                        st.write(
                            f"  - Capa {i+1} ({layer.__class__.__name__}): {built_status}")

            except Exception as diag_error:
                st.write(f"Error en diagnÃ³stico: {diag_error}")

            st.markdown("### ğŸ’¡ SoluciÃ³n Obligatoria")
            st.error(
                "**El modelo estÃ¡ corrupto o mal construido. DEBES reentrenarlo desde cero.**")
            st.markdown("""
            **Pasos para solucionarlo:**
            1. Ve a la pestaÃ±a **'Entrenamiento'**
            2. Reentrena el modelo completamente
            3. NO uses modelos guardados previamente
            4. Regresa a esta pestaÃ±a despuÃ©s del entrenamiento
            """)

            if st.button("ğŸ”™ Ir a Reentrenar Modelo", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 2
                st.rerun()

            return

        # CREAR PESTAÃ‘AS DE VISUALIZACIÃ“N UNA VEZ QUE EL MODELO ESTÃ REPARADO
        viz_tab1, viz_tab2, viz_tab3, viz_tab4 = st.tabs([
            "ğŸ“Š Historial de Entrenamiento",
            "ğŸ§  Pesos y Sesgos",
            "ğŸ¯ Superficie de DecisiÃ³n",
            "ğŸ“‰ AnÃ¡lisis de Capas"
        ])

        with viz_tab1:
            st.subheader("ğŸ“Š Historial de Entrenamiento Detallado")
            st.markdown("ğŸ“ˆ **Â¿CÃ³mo aprendiÃ³ tu red neuronal?**")

            # ExplicaciÃ³n sobre el historial
            with st.expander("ğŸ’¡ Â¿CÃ³mo interpretar estas grÃ¡ficas?"):
                st.markdown("""
                **GrÃ¡fica de PÃ©rdida (Loss):**
                - **Bajando**: La red estÃ¡ aprendiendo âœ…
                - **Estable**: Ha convergido ğŸ¯
                - **Subiendo**: Posible sobreajuste âš ï¸
                - **Gap grande entre train/val**: Sobreajuste ğŸš¨
                
                **GrÃ¡fica de Accuracy (clasificaciÃ³n) o MAE (regresiÃ³n):**
                - **Subiendo**: Mejorando en las predicciones âœ…
                - **Plateau**: Ha alcanzado su lÃ­mite ğŸ“Š
                - **Train > Val**: Normal, pero gap grande = sobreajuste âš ï¸
                """)

            plot_training_history(history, config['task_type'])

            # InformaciÃ³n adicional del entrenamiento
            st.markdown("#### ğŸ“Š EstadÃ­sticas del Entrenamiento")
            col1, col2, col3 = st.columns(3)

            with col1:
                final_loss = history.history['loss'][-1]
                initial_loss = history.history['loss'][0]
                improvement = ((initial_loss - final_loss) /
                               initial_loss) * 100
                st.metric("ğŸ”´ PÃ©rdida Final (Entrenamiento)", f"{final_loss:.6f}",
                          f"-{improvement:.1f}% desde inicio")

            with col2:
                if 'val_loss' in history.history:
                    final_val_loss = history.history['val_loss'][-1]
                    overfitting_gap = final_val_loss - final_loss
                    st.metric("ğŸŸ¡ PÃ©rdida Final (ValidaciÃ³n)", f"{final_val_loss:.6f}",
                              f"Gap: {overfitting_gap:.6f}")

                    # InterpretaciÃ³n del gap
                    if overfitting_gap < 0.01:
                        st.success("âœ… **Sin sobreajuste**: Gap muy pequeÃ±o")
                    elif overfitting_gap < 0.05:
                        st.warning("âš ï¸ **Sobreajuste leve**: Gap aceptable")
                    else:
                        st.error("ğŸš¨ **Sobreajuste**: Gap significativo")

            with col3:
                epochs_trained = len(history.history['loss'])
                st.metric("â±ï¸ Ã‰pocas Entrenadas", epochs_trained)

                # Â¿ParÃ³ por early stopping?
                if 'nn_config' in st.session_state:
                    max_epochs = st.session_state.get('training_epochs', 100)
                    if epochs_trained < max_epochs:
                        st.caption(
                            "ğŸ›‘ **Early Stopping**: ParÃ³ automÃ¡ticamente")
                    else:
                        st.caption("ğŸ”„ **CompletÃ³ todas las Ã©pocas**")

        with viz_tab2:
            st.subheader("ğŸ§  AnÃ¡lisis de Pesos y Sesgos")
            st.markdown("ğŸ” **Â¿QuÃ© ha aprendido cada neurona?**")

            # ExplicaciÃ³n sobre pesos
            with st.expander("ğŸ’¡ Â¿QuÃ© significan los pesos?"):
                st.markdown("""
                **Pesos (Weights):**
                - **Valores altos**: Conexiones importantes entre neuronas
                - **Valores cercanos a 0**: Conexiones dÃ©biles o irrelevantes
                - **Valores negativos**: Relaciones inversas
                - **DistribuciÃ³n**: Indica si la red estÃ¡ bien inicializada
                
                **Sesgos (Biases):**
                - **Valores altos**: Neurona se activa fÃ¡cilmente
                - **Valores bajos**: Neurona es mÃ¡s selectiva
                - **DistribuciÃ³n**: Debe ser razonable, no extrema
                """)

            # Obtener pesos de todas las capas
            layer_weights = []
            layer_biases = []

            for i, layer in enumerate(model.layers):
                if hasattr(layer, 'get_weights') and layer.get_weights():
                    weights = layer.get_weights()
                    if len(weights) >= 2:  # Pesos y sesgos
                        layer_weights.append(weights[0])
                        layer_biases.append(weights[1])

            if layer_weights:
                # Crear grÃ¡ficos para cada capa
                for i, (weights, biases) in enumerate(zip(layer_weights, layer_biases)):
                    st.markdown(f"#### ğŸ“Š Capa {i+1}")

                    col1, col2 = st.columns(2)

                    with col1:
                        # Histograma de pesos
                        fig_weights = go.Figure()
                        fig_weights.add_trace(go.Histogram(
                            x=weights.flatten(),
                            nbinsx=50,
                            name=f'Pesos Capa {i+1}',
                            opacity=0.7
                        ))
                        fig_weights.update_layout(
                            title=f'DistribuciÃ³n de Pesos - Capa {i+1}',
                            xaxis_title='Valor de Peso',
                            yaxis_title='Frecuencia',
                            height=300
                        )
                        st.plotly_chart(fig_weights, use_container_width=True)

                        # EstadÃ­sticas de pesos
                        st.caption(f"ğŸ“Š **EstadÃ­sticas**: Media={np.mean(weights):.4f}, "
                                   f"Std={np.std(weights):.4f}, "
                                   f"Min={np.min(weights):.4f}, "
                                   f"Max={np.max(weights):.4f}")

                    with col2:
                        # Histograma de sesgos
                        fig_biases = go.Figure()
                        fig_biases.add_trace(go.Histogram(
                            x=biases.flatten(),
                            nbinsx=20,
                            name=f'Sesgos Capa {i+1}',
                            opacity=0.7,
                            marker_color='orange'
                        ))
                        fig_biases.update_layout(
                            title=f'DistribuciÃ³n de Sesgos - Capa {i+1}',
                            xaxis_title='Valor de Sesgo',
                            yaxis_title='Frecuencia',
                            height=300
                        )
                        st.plotly_chart(fig_biases, use_container_width=True)

                        # EstadÃ­sticas de sesgos
                        st.caption(f"ğŸ“Š **EstadÃ­sticas**: Media={np.mean(biases):.4f}, "
                                   f"Std={np.std(biases):.4f}, "
                                   f"Min={np.min(biases):.4f}, "
                                   f"Max={np.max(biases):.4f}")

                # AnÃ¡lisis general
                st.markdown("#### ğŸ” AnÃ¡lisis General de la Red")
                all_weights = np.concatenate(
                    [w.flatten() for w in layer_weights])
                all_biases = np.concatenate(
                    [b.flatten() for b in layer_biases])

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸ¯ Pesos Promedio",
                              f"{np.mean(all_weights):.6f}")
                with col2:
                    st.metric("ğŸ“Š Desv. Std. Pesos",
                              f"{np.std(all_weights):.6f}")
                with col3:
                    dead_neurons = np.sum(np.abs(all_weights) < 1e-6)
                    st.metric("ğŸ’€ Pesos ~0", f"{dead_neurons}")

                # Salud de la red
                if np.std(all_weights) < 0.01:
                    st.error(
                        "ğŸš¨ **Problema**: Pesos muy pequeÃ±os, la red puede no haber aprendido")
                elif np.std(all_weights) > 2:
                    st.warning(
                        "âš ï¸ **AtenciÃ³n**: Pesos muy grandes, posible inestabilidad")
                else:
                    st.success("âœ… **Saludable**: DistribuciÃ³n de pesos normal")
            else:
                st.warning("No se pudieron extraer los pesos del modelo")

        with viz_tab3:
            st.subheader("ğŸ¯ Superficie de DecisiÃ³n")
            st.markdown(
                "ğŸ—ºï¸ **Â¿CÃ³mo divide tu red el espacio de caracterÃ­sticas?**")

            # Verificar si es clasificaciÃ³n para mostrar superficie de decisiÃ³n
            if config.get('task_type', 'ClasificaciÃ³n') == 'ClasificaciÃ³n':
                # Si hay mÃ¡s de 2 caracterÃ­sticas, permitir seleccionar 2
                if config['input_size'] > 2:
                    st.info(
                        "ğŸ’¡ Tu dataset tiene mÃ¡s de 2 caracterÃ­sticas. Selecciona 2 para visualizar la superficie de decisiÃ³n.")

                    # Obtener nombres de caracterÃ­sticas
                    if 'nn_feature_names' in st.session_state:
                        feature_names = st.session_state.nn_feature_names
                    else:
                        feature_names = [
                            f'CaracterÃ­stica {i+1}' for i in range(config['input_size'])]

                    st.markdown("### SelecciÃ³n de CaracterÃ­sticas")
                    col1, col2 = st.columns(2)

                    with col1:
                        feature1 = st.selectbox(
                            "Primera caracterÃ­stica:",
                            feature_names,
                            index=0,
                            key="viz_feature1_nn"
                        )

                    with col2:
                        feature2 = st.selectbox(
                            "Segunda caracterÃ­stica:",
                            feature_names,
                            index=min(1, len(feature_names) - 1),
                            key="viz_feature2_nn"
                        )

                    if feature1 != feature2:
                        # Obtener datos de test para la visualizaciÃ³n
                        X_test, y_test = st.session_state.nn_test_data

                        # Obtener Ã­ndices de las caracterÃ­sticas seleccionadas
                        feature_idx = [feature_names.index(
                            feature1), feature_names.index(feature2)]

                        # Extraer las caracterÃ­sticas seleccionadas
                        X_2d = X_test[:, feature_idx]

                        # Generar superficie de decisiÃ³n
                        try:
                            st.info("ğŸ¨ Generando superficie de decisiÃ³n...")

                            # Crear malla de puntos para la superficie
                            h = 0.02  # tamaÃ±o del paso en la malla
                            x_min, x_max = X_2d[:, 0].min(
                            ) - 0.5, X_2d[:, 0].max() + 0.5
                            y_min, y_max = X_2d[:, 1].min(
                            ) - 0.5, X_2d[:, 1].max() + 0.5
                            xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                                                 np.arange(y_min, y_max, h))

                            # Para hacer predicciones en la malla, necesitamos crear puntos completos
                            # con valores promedio para las caracterÃ­sticas no seleccionadas
                            X_full_test = X_test.copy()
                            mesh_points = []

                            for i in range(xx.ravel().shape[0]):
                                # Usar valores promedio
                                point = np.mean(X_full_test, axis=0)
                                # Primera caracterÃ­stica seleccionada
                                point[feature_idx[0]] = xx.ravel()[i]
                                # Segunda caracterÃ­stica seleccionada
                                point[feature_idx[1]] = yy.ravel()[i]
                                mesh_points.append(point)

                            mesh_points = np.array(mesh_points)

                            # Hacer predicciones en la malla
                            Z = model.predict(mesh_points, verbose=0)

                            # Si es clasificaciÃ³n multiclase, tomar la clase con mayor probabilidad
                            if len(Z.shape) > 1 and Z.shape[1] > 1:
                                Z = np.argmax(Z, axis=1)
                            else:
                                # Para clasificaciÃ³n binaria
                                Z = (Z > 0.5).astype(int).ravel()

                            Z = Z.reshape(xx.shape)

                            # Crear la visualizaciÃ³n
                            fig, ax = plt.subplots(figsize=(10, 8))

                            # Dibujar la superficie de decisiÃ³n
                            contourf = ax.contourf(
                                xx, yy, Z, levels=50, alpha=0.8, cmap='RdYlBu')

                            # AÃ±adir los puntos de datos reales
                            if 'nn_class_names' in st.session_state and st.session_state.nn_class_names:
                                class_names = st.session_state.nn_class_names
                                # Mapear y_test a Ã­ndices de clase si es necesario
                                if hasattr(y_test, 'shape') and len(y_test.shape) > 1:
                                    y_plot = np.argmax(y_test, axis=1)
                                else:
                                    y_plot = y_test

                                # Crear scatter plot por clase
                                unique_classes = np.unique(y_plot)
                                colors = plt.cm.Set1(
                                    np.linspace(0, 1, len(unique_classes)))

                                for i, class_idx in enumerate(unique_classes):
                                    mask = y_plot == class_idx
                                    class_name = class_names[class_idx] if class_idx < len(
                                        class_names) else f'Clase {class_idx}'
                                    ax.scatter(X_2d[mask, 0], X_2d[mask, 1],
                                               c=[colors[i]], label=class_name,
                                               edgecolors='black', s=50, alpha=0.9)
                            else:
                                ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y_test,
                                           cmap='RdYlBu', edgecolors='black', s=50, alpha=0.9)

                            # Configurar etiquetas y tÃ­tulo
                            ax.set_xlabel(feature1, fontsize=12)
                            ax.set_ylabel(feature2, fontsize=12)
                            ax.set_title(
                                f'Superficie de DecisiÃ³n de Red Neuronal\n{feature1} vs {feature2}', fontsize=14)
                            ax.grid(True, alpha=0.3)

                            # AÃ±adir leyenda si hay nombres de clase
                            if 'nn_class_names' in st.session_state and st.session_state.nn_class_names:
                                ax.legend(bbox_to_anchor=(
                                    1.05, 1), loc='upper left')

                            # AÃ±adir colorbar para la superficie
                            plt.colorbar(contourf, ax=ax,
                                         label='PredicciÃ³n de Clase')

                            plt.tight_layout()
                            st.pyplot(fig)

                            # InformaciÃ³n adicional
                            st.success(
                                "âœ… Superficie de decisiÃ³n generada exitosamente")
                            st.info(f"""
                            ğŸ” **InformaciÃ³n de la visualizaciÃ³n:**
                            - **CaracterÃ­sticas mostradas:** {feature1} vs {feature2}
                            - **Otras caracterÃ­sticas:** Se mantienen en sus valores promedio
                            - **Colores de fondo:** Regiones de decisiÃ³n de la red neuronal
                            - **Puntos:** Datos reales de prueba
                            - **Fronteras:** LÃ­mites donde la red cambia de decisiÃ³n
                            """)

                            # InterpretaciÃ³n de la superficie
                            with st.expander("ğŸ’¡ Â¿CÃ³mo interpretar la superficie de decisiÃ³n?"):
                                st.markdown("""
                                **Colores de fondo:**
                                - Cada color representa una clase diferente que predice la red
                                - Las transiciones suaves indican fronteras de decisiÃ³n graduales
                                - Las transiciones bruscas indican fronteras mÃ¡s definidas
                                
                                **Puntos de datos:**
                                - Muestran dÃ³nde estÃ¡n ubicados los datos reales en este espacio 2D
                                - Puntos del mismo color deberÃ­an estar en regiones del mismo color de fondo
                                - Puntos en la regiÃ³n "incorrecta" indican errores de clasificaciÃ³n
                                
                                **Complejidad de las fronteras:**
                                - Fronteras muy complejas pueden indicar sobreajuste
                                - Fronteras muy simples pueden indicar subajuste
                                - Lo ideal son fronteras que capturen el patrÃ³n sin ser excesivamente complejas
                                """)

                        except Exception as e:
                            st.error(
                                f"âŒ Error al generar la superficie de decisiÃ³n: {str(e)}")
                            st.info(
                                "ğŸ’¡ Intenta con diferentes caracterÃ­sticas o verifica que el modelo estÃ© correctamente entrenado.")

                    else:
                        st.warning(
                            "âš ï¸ Por favor selecciona dos caracterÃ­sticas diferentes.")

                else:
                    # Dataset con 2 o menos caracterÃ­sticas - mostrar directamente
                    st.info("ğŸ¨ Generando superficie de decisiÃ³n...")
                    st.markdown("""
                    **Superficie de DecisiÃ³n 2D:**
                    - Cada color representa una clase predicha
                    - Los puntos son tus datos de entrenamiento
                    - Las fronteras muestran cÃ³mo la red separa las clases
                    - Fronteras suaves = red bien generalizada
                    - Fronteras muy complejas = posible sobreajuste
                    """)

                    # AquÃ­ se podrÃ­a implementar la visualizaciÃ³n directa para datasets 2D
                    st.info(
                        "ğŸ’¡ ImplementaciÃ³n completa para datasets 2D prÃ³ximamente.")

            else:
                # Para tareas de regresiÃ³n
                st.info("ğŸ”ï¸ **Superficie de PredicciÃ³n para RegresiÃ³n**")
                st.markdown("""
                Para tareas de regresiÃ³n, se puede visualizar una superficie de predicciÃ³n que muestra 
                cÃ³mo varÃ­an las predicciones numÃ©ricas en el espacio de caracterÃ­sticas.
                """)

                if config['input_size'] > 2:
                    st.markdown(
                        "ğŸ’¡ Selecciona 2 caracterÃ­sticas para visualizar la superficie de predicciÃ³n.")
                    # AquÃ­ se podrÃ­a implementar similar lÃ³gica para regresiÃ³n
                    st.info(
                        "ğŸš§ ImplementaciÃ³n de superficie de predicciÃ³n para regresiÃ³n prÃ³ximamente.")
                else:
                    st.info(
                        "ğŸš§ ImplementaciÃ³n de superficie de predicciÃ³n prÃ³ximamente.")

        with viz_tab4:
            st.subheader("ğŸ“‰ AnÃ¡lisis de Capas")
            st.markdown("ğŸ”¬ **Activaciones y patrones internos de la red**")

            # ExplicaciÃ³n sobre activaciones
            with st.expander("ğŸ’¡ Â¿QuÃ© son las activaciones?"):
                st.markdown("""
                **Activaciones:**
                - **Valores que producen las neuronas** cuando procesan datos
                - **Primeras capas**: Detectan caracterÃ­sticas bÃ¡sicas
                - **Capas intermedias**: Combinan caracterÃ­sticas en patrones
                - **Ãšltima capa**: DecisiÃ³n final o predicciÃ³n
                
                **QuÃ© buscar:**
                - **Muchos ceros**: Neuronas "muertas" (problema)
                - **Valores extremos**: SaturaciÃ³n (problema)
                - **DistribuciÃ³n balanceada**: Red saludable âœ…
                """)

            # USAR EL MODELO DE ACTIVACIONES PRE-CREADO EN LA INICIALIZACIÃ“N
            try:
                # Obtener datos de test
                X_test, y_test = st.session_state.nn_test_data
                sample_size = min(100, len(X_test))
                X_sample = X_test[:sample_size]

                # Verificar que el modelo tiene suficientes capas
                if len(model.layers) <= 1:
                    st.warning(
                        "âš ï¸ El modelo tiene muy pocas capas para anÃ¡lisis detallado")
                    return

                # VERIFICAR SI HAY MODELO DE ACTIVACIONES PRE-CREADO
                activation_model = None

                # MÃ©todo 1: Modelo creado durante el entrenamiento
                if hasattr(model, '_activation_model_ready'):
                    activation_model = model._activation_model_ready
                    st.success(
                        "âœ… Usando modelo de activaciones preparado durante el entrenamiento")

                # MÃ©todo 2: Modelo guardado en session_state
                elif 'activation_model' in st.session_state and st.session_state.activation_model is not None:
                    activation_model = st.session_state.activation_model
                    st.success(
                        "âœ… Usando modelo de activaciones de session_state")

                # MÃ©todo 3: Crear on-demand si no existe
                else:
                    st.info("ğŸ”§ Creando modelo de activaciones...")
                    try:
                        import tensorflow as tf
                        intermediate_layers = []
                        for i, layer in enumerate(model.layers):
                            # Excluir la primera capa (Input) y la Ãºltima (Output)
                            if i > 0 and i < len(model.layers) - 1:
                                if hasattr(layer, 'output') and layer.output is not None:
                                    intermediate_layers.append(layer.output)

                        if intermediate_layers:
                            activation_model = tf.keras.Model(
                                inputs=model.input,
                                outputs=intermediate_layers
                            )
                            # Verificar que funcione
                            _ = activation_model.predict(
                                X_sample[:1], verbose=0)
                            st.session_state.activation_model = activation_model
                            st.success(
                                "âœ… Modelo de activaciones creado exitosamente")
                        else:
                            st.warning(
                                "âš ï¸ No hay capas intermedias vÃ¡lidas para anÃ¡lisis")
                            return
                    except Exception as create_error:
                        st.error(
                            f"âŒ Error creando modelo de activaciones: {str(create_error)}")
                        st.info(
                            "ğŸ’¡ El modelo necesita ser reentrenado para anÃ¡lisis de capas")
                        return

                # Si llegamos aquÃ­, tenemos un modelo de activaciones vÃ¡lido
                if activation_model is None:
                    st.error("âŒ No se pudo obtener modelo de activaciones")
                    return

                # Obtener activaciones usando el modelo pre-creado
                activations = activation_model.predict(X_sample, verbose=0)

                if not isinstance(activations, list):
                    activations = [activations]

                st.success(
                    f"âœ… AnÃ¡lisis de {len(activations)} capas completado exitosamente")

                # Mostrar estadÃ­sticas por capa
                for i, activation in enumerate(activations):
                    st.markdown(f"#### ğŸ“Š Capa {i+1} - Activaciones")

                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ğŸ”¥ Media", f"{np.mean(activation):.4f}")
                    with col2:
                        st.metric("ğŸ“Š Desv. Std.", f"{np.std(activation):.4f}")
                    with col3:
                        dead_ratio = np.mean(activation == 0) * 100
                        st.metric("ğŸ’€ % Neuronas Muertas", f"{dead_ratio:.1f}%")
                    with col4:
                        saturated_ratio = np.mean(activation >= 0.99) * 100
                        st.metric("ğŸ”´ % Saturadas", f"{saturated_ratio:.1f}%")

                    # InterpretaciÃ³n de la salud
                    if dead_ratio > 50:
                        st.error(
                            f"ğŸš¨ **Problema en Capa {i+1}**: Muchas neuronas muertas")
                    elif dead_ratio > 20:
                        st.warning(
                            f"âš ï¸ **AtenciÃ³n en Capa {i+1}**: Algunas neuronas muertas")
                    else:
                        st.success(
                            f"âœ… **Capa {i+1} Saludable**: Buena activaciÃ³n")

            except Exception as e:
                error_msg = str(e)
                if "never been called" in error_msg or "no defined input" in error_msg:
                    st.error(
                        "ğŸš¨ **Error de InicializaciÃ³n del Modelo Sequential**")
                    st.markdown("""
                    **Â¿QuÃ© significa este error?**
                    - El modelo Sequential de TensorFlow no ha sido completamente inicializado
                    - Las capas no conocen el tamaÃ±o de sus entradas
                    - Se necesita hacer al menos una predicciÃ³n para construir el modelo
                    
                    **SoluciÃ³n AutomÃ¡tica:**
                    La funciÃ³n incluye reparaciÃ³n automÃ¡tica que deberÃ­a resolver esto.
                    Si persiste, usa el botÃ³n de 'Reparar Modelo' en la secciÃ³n de errores abajo.
                    """)
                    st.info(
                        "ğŸ’¡ **Tip:** Este error es comÃºn con modelos Sequential reciÃ©n cargados y tiene soluciÃ³n automÃ¡tica.")
                else:
                    st.error(f"âŒ Error inesperado en el anÃ¡lisis: {str(e)}")
                    st.info(
                        "ğŸ”§ Esto puede indicar un problema con la arquitectura del modelo.")

                st.markdown(f"**Error tÃ©cnico:** {error_msg}")

        # BotÃ³n para generar cÃ³digo de visualizaciÃ³n
        st.markdown("### ğŸ’» CÃ³digo Python")
        if st.button("ğŸ“ Generar CÃ³digo de VisualizaciÃ³n", use_container_width=True):
            code = generate_neural_network_visualization_code(config)
            st.markdown("#### ğŸ CÃ³digo Python para Visualizaciones")
            st.code(code, language='python')

            st.download_button(
                label="ğŸ’¾ Descargar CÃ³digo de VisualizaciÃ³n",
                data=code,
                file_name="visualizaciones_red_neuronal.py",
                mime="text/plain"
            )

        # NavegaciÃ³n
        st.markdown("---")
        st.markdown("### ğŸ§­ NavegaciÃ³n")
        col_nav1, col_nav2 = st.columns(2)
        with col_nav1:
            if st.button("ğŸ”™ Volver a EvaluaciÃ³n", use_container_width=True):
                st.session_state.active_tab_nn = 3
                st.rerun()
        with col_nav2:
            if st.button("ğŸ”® Hacer Predicciones", type="primary", use_container_width=True):
                st.session_state.active_tab_nn = 5
                st.rerun()

    except Exception as e:
        st.error(f"âŒ Error en las visualizaciones: {str(e)}")

        # DiagnÃ³stico detallado del error
        error_type = type(e).__name__
        error_msg = str(e)

        st.markdown("### ğŸ” DiagnÃ³stico del Error")

        if "never been called" in error_msg or "no defined input" in error_msg:
            st.error("ğŸš¨ **Problema de InicializaciÃ³n del Modelo**")
            st.markdown("""
            **Causa del problema:**
            - El modelo Sequential no ha sido completamente inicializado
            - Las capas no tienen sus formas de entrada definidas
            - Se necesita hacer al menos una predicciÃ³n para construir el modelo
            """)

            # BotÃ³n de reparaciÃ³n automÃ¡tica
            col1, col2 = st.columns(2)

            with col1:
                if st.button("ğŸ”§ Reparar Modelo AutomÃ¡ticamente", type="primary", key="auto_repair"):
                    try:
                        st.info("ğŸ”„ Iniciando reparaciÃ³n exhaustiva del modelo...")

                        # Obtener datos de test
                        if 'nn_test_data' in st.session_state:
                            X_test, y_test = st.session_state.nn_test_data

                            # Forzar construcciÃ³n del modelo con mÃºltiples estrategias MEJORADAS
                            with st.spinner("Aplicando estrategias de reparaciÃ³n..."):
                                progress_bar = st.progress(0)

                                # Estrategia 1: PredicciÃ³n simple
                                progress_bar.progress(20)
                                _ = model.predict(X_test[:1], verbose=0)

                                # Estrategia 2: Llamada directa al modelo
                                progress_bar.progress(40)
                                _ = model(X_test[:1])

                                # Estrategia 3: PredicciÃ³n con batch mÃ¡s grande
                                progress_bar.progress(60)
                                batch_size = min(10, len(X_test))
                                _ = model.predict(
                                    X_test[:batch_size], verbose=0)

                                # Estrategia 4: Compilar explÃ­citamente si es necesario
                                progress_bar.progress(80)
                                if not model.built:
                                    model.build(input_shape=(
                                        None, X_test.shape[1]))

                                # Estrategia 5: Verificar input tensor
                                if model.input is None:
                                    model._set_inputs(X_test[:1])

                                # Estrategia 6: Forzar todas las capas
                                for i, layer in enumerate(model.layers):
                                    if hasattr(layer, 'built') and not layer.built:
                                        if i == 0:
                                            layer.build(input_shape=(
                                                None, X_test.shape[1]))
                                        else:
                                            prev_output = model.layers[i -
                                                                       1].output_shape
                                            layer.build(prev_output)

                                progress_bar.progress(100)

                            # VerificaciÃ³n EXHAUSTIVA que el modelo estÃ© funcionando
                            st.info("âœ… Verificando reparaciÃ³n...")

                            # Test mÃºltiples operaciones
                            test_pred = model.predict(X_test[:5], verbose=0)
                            _ = model.get_weights()

                            # Test crÃ­tico: modelo de activaciones
                            if len(model.layers) > 1:
                                layer_outputs = [
                                    layer.output for layer in model.layers[:-1]]
                                test_activation_model = tf.keras.Model(
                                    inputs=model.input, outputs=layer_outputs)
                                _ = test_activation_model.predict(
                                    X_test[:1], verbose=0)

                            st.success("ğŸ‰ Â¡Modelo reparado exitosamente!")
                            st.info(
                                "âœ… El modelo estÃ¡ completamente inicializado y listo para todas las visualizaciones.")

                            # BotÃ³n para recargar visualizaciones
                            if st.button("ğŸ”„ Recargar Visualizaciones", type="primary"):
                                st.rerun()

                        else:
                            st.error(
                                "âŒ No se encontraron datos de test para reparar el modelo")

                    except Exception as repair_error:
                        st.error(
                            f"âŒ Error durante la reparaciÃ³n: {repair_error}")

                        # DiagnÃ³stico especÃ­fico del error
                        if "never been called" in str(repair_error):
                            st.warning(
                                "ğŸ”§ **Error persistente de inicializaciÃ³n**")
                            st.markdown("""
                            **Estrategias adicionales:**
                            1. Reinicia la aplicaciÃ³n completamente
                            2. Reentrena el modelo desde cero  
                            3. Verifica que TensorFlow estÃ© actualizado
                            4. Prueba con un dataset mÃ¡s pequeÃ±o
                            """)
                        else:
                            st.info("ğŸ’¡ Intenta reentrenar el modelo desde cero.")

            with col2:
                st.markdown("**ğŸ’¡ SoluciÃ³n manual:**")
                st.markdown("""
                1. Ve a la pestaÃ±a **'Entrenamiento'**
                2. Reentrena el modelo desde cero
                3. Regresa a esta pestaÃ±a
                4. Las visualizaciones deberÃ­an funcionar
                """)

                if st.button("ğŸ”™ Ir a Entrenamiento", key="go_training"):
                    st.session_state.active_tab_nn = 2
                    st.rerun()

        else:
            # Otros tipos de errores
            st.warning("âš ï¸ **Error Inesperado**")
            st.code(f"Tipo: {error_type}\nMensaje: {error_msg}")

            st.markdown("""
            **Posibles soluciones:**
            - Verifica que TensorFlow estÃ© instalado correctamente
            - AsegÃºrate de que el modelo estÃ© entrenado
            - Intenta reentrenar el modelo
            - Reinicia la aplicaciÃ³n si persiste el problema
            """)

        # InformaciÃ³n tÃ©cnica adicional
        with st.expander("ğŸ”¬ InformaciÃ³n TÃ©cnica Detallada"):
            try:
                st.write("**Estado del Modelo:**")
                st.write(f"- Tipo: {type(model).__name__}")
                st.write(
                    f"- Construido: {getattr(model, 'built', 'No disponible')}")
                st.write(
                    f"- NÃºmero de capas: {len(model.layers) if hasattr(model, 'layers') else 'No disponible'}")

                if hasattr(model, 'input'):
                    st.write(
                        f"- Input definido: {'âœ…' if model.input is not None else 'âŒ'}")

                if hasattr(model, 'layers'):
                    st.write("**Estado de las Capas:**")
                    for i, layer in enumerate(model.layers):
                        layer_built = getattr(layer, 'built', False)
                        st.write(
                            f"  - Capa {i+1} ({layer.__class__.__name__}): {'âœ…' if layer_built else 'âŒ'}")

            except Exception as debug_error:
                st.write(f"Error obteniendo informaciÃ³n: {debug_error}")

        st.info("ğŸ’¡ **Tip**: Este error es comÃºn con modelos Sequential. La reparaciÃ³n automÃ¡tica deberÃ­a resolverlo.")


def show_neural_network_predictions():
    """Interfaz para hacer predicciones con el modelo entrenado."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "âš ï¸ Primero debes entrenar un modelo en la pestaÃ±a 'Entrenamiento'")
        return

    try:
        import numpy as np
        import pandas as pd
        import scipy.stats

        model = st.session_state.nn_model
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        if 'nn_df' not in st.session_state or 'nn_target_col' not in st.session_state:
            st.error("No hay datos disponibles para hacer predicciones.")
            return

        df = st.session_state.nn_df
        target_col = st.session_state.nn_target_col
        feature_cols = [col for col in df.columns if col != target_col]

        st.header("ğŸ¯ Hacer Predicciones")

        # Tabs para diferentes tipos de predicciÃ³n
        pred_tab1, pred_tab2, pred_tab3 = st.tabs([
            "ğŸ” PredicciÃ³n Individual",
            "ğŸ“Š PredicciÃ³n por Lotes",
            "ğŸ² ExploraciÃ³n Interactiva"
        ])

        with pred_tab1:
            st.subheader("ğŸ” PredicciÃ³n Individual")
            st.markdown("Introduce los valores para cada caracterÃ­stica:")

            # Crear inputs para cada caracterÃ­stica
            input_values = {}

            # Organizar en columnas
            num_cols = min(3, len(feature_cols))
            cols = st.columns(num_cols)

            for i, feature in enumerate(feature_cols):
                col_idx = i % num_cols

                with cols[col_idx]:
                    # Obtener estadÃ­sticas de la caracterÃ­stica
                    min_val = float(df[feature].min())
                    max_val = float(df[feature].max())
                    mean_val = float(df[feature].mean())

                    input_values[feature] = st.number_input(
                        f"{feature}",
                        min_value=min_val,
                        max_value=max_val,
                        value=mean_val,
                        step=(max_val - min_val) / 100,
                        key=f"nn_pred_{feature}"
                    )

                    st.caption(
                        f"Min: {min_val:.2f}, Max: {max_val:.2f}, Media: {mean_val:.2f}")

            # BotÃ³n para hacer predicciÃ³n
            if st.button("ğŸš€ Hacer PredicciÃ³n", type="primary"):
                # Preparar datos para predicciÃ³n
                input_array = np.array(
                    [[input_values[feature] for feature in feature_cols]])
                input_scaled = scaler.transform(input_array)

                # Hacer predicciÃ³n
                prediction = model.predict(input_scaled, verbose=0)

                # Mostrar resultados
                st.success("âœ… PredicciÃ³n completada")

                if config['task_type'] == 'ClasificaciÃ³n':
                    output_size = safe_get_output_size(config)
                    if output_size > 2:  # Multiclase
                        predicted_class_idx = np.argmax(prediction[0])
                        confidence = prediction[0][predicted_class_idx]

                        if label_encoder:
                            predicted_class = label_encoder.inverse_transform(
                                [predicted_class_idx])[0]
                        else:
                            predicted_class = f"Clase {predicted_class_idx}"

                        # Mostrar resultado principal
                        col1, col2 = st.columns(2)

                        with col1:
                            st.metric("ğŸ¯ Clase Predicha", predicted_class)

                        with col2:
                            st.metric(
                                "ğŸ² Confianza", f"{confidence:.4f}", f"{confidence*100:.2f}%")

                        # Mostrar probabilidades para todas las clases
                        st.subheader("ğŸ“Š Probabilidades por Clase")

                        prob_data = []
                        for i, prob in enumerate(prediction[0]):
                            if label_encoder:
                                class_name = label_encoder.inverse_transform([i])[
                                    0]
                            else:
                                class_name = f"Clase {i}"

                            prob_data.append({
                                'Clase': class_name,
                                'Probabilidad': f"{prob:.4f}",
                                'Porcentaje': f"{prob*100:.2f}%"
                            })

                        st.dataframe(prob_data, use_container_width=True)

                        # GrÃ¡fico de barras de probabilidades
                        import plotly.graph_objects as go

                        class_names = [item['Clase'] for item in prob_data]
                        probabilities = [float(item['Probabilidad'])
                                         for item in prob_data]

                        fig = go.Figure(data=[
                            go.Bar(x=class_names, y=probabilities,
                                   marker_color=['red' if i == predicted_class_idx else 'lightblue'
                                                 for i in range(len(class_names))])
                        ])

                        fig.update_layout(
                            title="DistribuciÃ³n de Probabilidades",
                            xaxis_title="Clases",
                            yaxis_title="Probabilidad",
                            height=400
                        )

                        st.plotly_chart(fig, use_container_width=True)

                    else:  # Binaria
                        probability = prediction[0][0]
                        predicted_class_idx = 1 if probability > 0.5 else 0

                        if label_encoder:
                            predicted_class = label_encoder.inverse_transform(
                                [predicted_class_idx])[0]
                        else:
                            predicted_class = f"Clase {predicted_class_idx}"

                        col1, col2, col3 = st.columns(3)

                        with col1:
                            st.metric("ğŸ¯ Clase Predicha", predicted_class)

                        with col2:
                            st.metric("ğŸ² Probabilidad", f"{probability:.4f}")

                        with col3:
                            confidence = max(probability, 1 - probability)
                            st.metric(
                                "âœ¨ Confianza", f"{confidence:.4f}", f"{confidence*100:.2f}%")

                else:  # RegresiÃ³n
                    predicted_value = prediction[0][0]

                    st.metric("ğŸ¯ Valor Predicho", f"{predicted_value:.6f}")

                    # InformaciÃ³n adicional para regresiÃ³n
                    target_stats = df[target_col].describe()

                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.info(f"ğŸ“Š **EstadÃ­sticas del Target:**\n"
                                f"- Media: {target_stats['mean']:.4f}\n"
                                f"- Mediana: {target_stats['50%']:.4f}")

                    with col2:
                        st.info(f"ğŸ“ **Rango de Datos:**\n"
                                f"- MÃ­nimo: {target_stats['min']:.4f}\n"
                                f"- MÃ¡ximo: {target_stats['max']:.4f}")

                    with col3:
                        deviation_from_mean = abs(
                            predicted_value - target_stats['mean'])
                        st.info(f"ğŸ¯ **AnÃ¡lisis:**\n"
                                f"- DesviaciÃ³n de la media: {deviation_from_mean:.4f}\n"
                                f"- Percentil aproximado: {scipy.stats.percentileofscore(df[target_col], predicted_value):.1f}%")

        with pred_tab2:
            st.subheader("ğŸ“Š PredicciÃ³n por Lotes")

            st.markdown(
                "Sube un archivo CSV con nuevos datos para hacer predicciones en lote:")

            uploaded_file = st.file_uploader(
                "Selecciona archivo CSV",
                type=['csv'],
                key="nn_batch_predictions"
            )

            if uploaded_file is not None:
                try:
                    # Cargar datos
                    new_df = pd.read_csv(uploaded_file)

                    st.success(
                        f"âœ… Archivo cargado: {new_df.shape[0]} filas, {new_df.shape[1]} columnas")

                    # Verificar que las columnas coincidan
                    missing_features = set(feature_cols) - set(new_df.columns)
                    extra_features = set(new_df.columns) - set(feature_cols)

                    if missing_features:
                        st.error(
                            f"âŒ Faltan caracterÃ­sticas: {', '.join(missing_features)}")
                    elif extra_features:
                        st.warning(
                            f"âš ï¸ CaracterÃ­sticas adicionales (serÃ¡n ignoradas): {', '.join(extra_features)}")
                        # Seleccionar solo las caracterÃ­sticas necesarias
                        new_df = new_df[feature_cols]

                    if not missing_features:
                        # Mostrar vista previa
                        st.dataframe(new_df.head(), use_container_width=True)

                        if st.button("ğŸš€ Generar Predicciones", type="primary"):
                            # Procesar datos
                            new_data_scaled = scaler.transform(new_df)

                            # Hacer predicciones
                            batch_predictions = model.predict(
                                new_data_scaled, verbose=0)

                            # Procesar resultados segÃºn el tipo de tarea
                            if config['task_type'] == 'ClasificaciÃ³n':
                                output_size = safe_get_output_size(config)
                                if output_size > 2:
                                    predicted_classes_idx = np.argmax(
                                        batch_predictions, axis=1)
                                    confidences = np.max(
                                        batch_predictions, axis=1)

                                    if label_encoder:
                                        predicted_classes = label_encoder.inverse_transform(
                                            predicted_classes_idx)
                                    else:
                                        predicted_classes = [
                                            f"Clase {idx}" for idx in predicted_classes_idx]

                                    results_df = new_df.copy()
                                    results_df['PredicciÃ³n'] = predicted_classes
                                    results_df['Confianza'] = confidences

                                else:  # Binaria
                                    probabilities = batch_predictions.flatten()
                                    predicted_classes_idx = (
                                        probabilities > 0.5).astype(int)
                                    confidences = np.maximum(
                                        probabilities, 1 - probabilities)

                                    if label_encoder:
                                        predicted_classes = label_encoder.inverse_transform(
                                            predicted_classes_idx)
                                    else:
                                        predicted_classes = [
                                            f"Clase {idx}" for idx in predicted_classes_idx]

                                    results_df = new_df.copy()
                                    results_df['PredicciÃ³n'] = predicted_classes
                                    results_df['Probabilidad'] = probabilities
                                    results_df['Confianza'] = confidences

                            else:  # RegresiÃ³n
                                predicted_values = batch_predictions.flatten()

                                results_df = new_df.copy()
                                results_df['PredicciÃ³n'] = predicted_values

                            # Mostrar resultados
                            st.success(
                                f"âœ… Predicciones generadas para {len(results_df)} muestras")
                            st.dataframe(results_df, use_container_width=True)

                            # BotÃ³n para descargar resultados
                            csv_results = results_df.to_csv(index=False)
                            st.download_button(
                                label="ğŸ“¥ Descargar Resultados",
                                data=csv_results,
                                file_name="predicciones_neural_network.csv",
                                mime="text/csv"
                            )

                except Exception as e:
                    st.error(f"Error procesando archivo: {str(e)}")

            else:
                # Mostrar formato esperado
                st.info("ğŸ“‹ **Formato esperado del archivo CSV:**")

                sample_data = df[feature_cols].head(3)
                st.dataframe(sample_data, use_container_width=True)

                st.markdown(
                    "El archivo debe contener las siguientes columnas:")
                st.code(", ".join(feature_cols))

        with pred_tab3:
            st.subheader("ğŸ² ExploraciÃ³n Interactiva")

            # InformaciÃ³n educativa sobre la exploraciÃ³n interactiva
            with st.expander("â„¹ï¸ Â¿QuÃ© es la ExploraciÃ³n Interactiva?", expanded=False):
                st.markdown("""
                **La exploraciÃ³n interactiva** te permite entender cÃ³mo el modelo neural toma decisiones:
                
                ğŸ” **Â¿Para quÃ© sirve?**
                - Ver cÃ³mo cada caracterÃ­stica influye en las predicciones
                - Identificar patrones y comportamientos del modelo
                - Detectar posibles sesgos o comportamientos inesperados
                - Comprender la sensibilidad del modelo a cambios en los datos
                
                ğŸ“Š **Â¿CÃ³mo interpretar los resultados?**
                - **LÃ­neas ascendentes**: La caracterÃ­stica tiene correlaciÃ³n positiva
                - **LÃ­neas descendentes**: La caracterÃ­stica tiene correlaciÃ³n negativa  
                - **LÃ­neas planas**: La caracterÃ­stica tiene poco impacto
                - **Cambios abruptos**: Puntos de decisiÃ³n crÃ­ticos del modelo
                
                ğŸ’¡ **Consejos de uso:**
                - Prueba diferentes muestras base para ver patrones generales
                - Observa quÃ© caracterÃ­sticas causan mayores cambios
                - Busca comportamientos inesperados o poco realistas
                """)

            st.markdown(
                "ğŸ¯ **Explora cÃ³mo cambian las predicciones al modificar diferentes caracterÃ­sticas:**")

            # Seleccionar una muestra base
            st.markdown("**1. ğŸ“ Selecciona una muestra base:**")

            st.info("ğŸ’¡ **Tip:** La muestra base es tu punto de referencia. Todas las exploraciones mostrarÃ¡n cÃ³mo cambian las predicciones desde este punto inicial.")

            sample_idx = st.selectbox(
                "Ãndice de muestra:",
                range(len(df)),
                format_func=lambda x: f"Muestra {x}",
                key="nn_interactive_sample"
            )

            base_sample = df.iloc[sample_idx][feature_cols].to_dict()

            # Mostrar valores base
            st.markdown("**2. ğŸ“‹ Valores base de la muestra:**")
            st.caption(
                "Estos son los valores de todas las caracterÃ­sticas para la muestra seleccionada:")
            base_df = pd.DataFrame([base_sample])
            st.dataframe(base_df, use_container_width=True)

            # Hacer predicciÃ³n base
            base_array = np.array([[base_sample[feature]
                                  for feature in feature_cols]])
            base_scaled = scaler.transform(base_array)
            base_prediction = model.predict(base_scaled, verbose=0)

            if config['task_type'] == 'ClasificaciÃ³n':
                output_size = safe_get_output_size(config)
                if output_size > 2:
                    base_class_idx = np.argmax(base_prediction[0])
                    base_confidence = base_prediction[0][base_class_idx]

                    if label_encoder:
                        base_class = label_encoder.inverse_transform([base_class_idx])[
                            0]
                    else:
                        base_class = f"Clase {base_class_idx}"

                    st.info(
                        f"ğŸ¯ **PredicciÃ³n Base:** {base_class} (Confianza: {base_confidence:.3f})")
                else:
                    base_prob = base_prediction[0][0]
                    base_class_idx = 1 if base_prob > 0.5 else 0

                    if label_encoder:
                        base_class = label_encoder.inverse_transform([base_class_idx])[
                            0]
                    else:
                        base_class = f"Clase {base_class_idx}"

                    st.info(
                        f"ğŸ¯ **PredicciÃ³n Base:** {base_class} (Probabilidad: {base_prob:.3f})")
            else:
                base_value = base_prediction[0][0]
                st.info(f"ğŸ¯ **PredicciÃ³n Base:** {base_value:.6f}")

            # Seleccionar caracterÃ­stica para explorar
            st.markdown("**3. ğŸ” Explora el efecto de una caracterÃ­stica:**")

            st.info("ğŸ¯ **Objetivo:** VerÃ¡s cÃ³mo cambia la predicciÃ³n cuando modificas solo UNA caracterÃ­stica, manteniendo todas las demÃ¡s constantes. Esto te ayuda a entender la importancia relativa de cada variable.")

            feature_to_explore = st.selectbox(
                "CaracterÃ­stica a explorar:",
                feature_cols,
                key="nn_explore_feature",
                help="Selecciona la caracterÃ­stica cuyo efecto quieres analizar en las predicciones"
            )

            # Crear rango de valores para la caracterÃ­stica seleccionada
            min_val = float(df[feature_to_explore].min())
            max_val = float(df[feature_to_explore].max())

            # Generar valores para exploraciÃ³n
            exploration_values = np.linspace(min_val, max_val, 50)
            exploration_predictions = []

            for val in exploration_values:
                # Crear muestra modificada
                modified_sample = base_sample.copy()
                modified_sample[feature_to_explore] = val

                # Hacer predicciÃ³n
                modified_array = np.array(
                    [[modified_sample[feature] for feature in feature_cols]])
                modified_scaled = scaler.transform(modified_array)
                pred = model.predict(modified_scaled, verbose=0)

                if config['task_type'] == 'ClasificaciÃ³n':
                    output_size = safe_get_output_size(config)
                    if output_size > 2:
                        pred_class_idx = np.argmax(pred[0])
                        confidence = pred[0][pred_class_idx]
                        exploration_predictions.append(
                            (pred_class_idx, confidence))
                    else:
                        prob = pred[0][0]
                        exploration_predictions.append(prob)
                else:
                    exploration_predictions.append(pred[0][0])

            # Crear visualizaciÃ³n
            import plotly.graph_objects as go

            fig = go.Figure()

            if config['task_type'] == 'ClasificaciÃ³n':
                output_size = safe_get_output_size(config)
                if output_size > 2:
                    # Multiclase: mostrar clase predicha y confianza
                    classes = [pred[0] for pred in exploration_predictions]
                    confidences = [pred[1] for pred in exploration_predictions]

                    fig.add_trace(go.Scatter(
                        x=exploration_values,
                        y=classes,
                        mode='lines+markers',
                        name='Clase Predicha',
                        yaxis='y1'
                    ))

                    fig.add_trace(go.Scatter(
                        x=exploration_values,
                        y=confidences,
                        mode='lines+markers',
                        name='Confianza',
                        yaxis='y2',
                        line=dict(color='red')
                    ))

                    fig.update_layout(
                        title=f'Efecto de {feature_to_explore} en la PredicciÃ³n',
                        xaxis_title=feature_to_explore,
                        yaxis=dict(title='Clase Predicha', side='left'),
                        yaxis2=dict(title='Confianza',
                                    side='right', overlaying='y'),
                        height=500
                    )
                else:
                    # Binaria: mostrar probabilidad
                    fig.add_trace(go.Scatter(
                        x=exploration_values,
                        y=exploration_predictions,
                        mode='lines+markers',
                        name='Probabilidad'
                    ))

                    fig.add_hline(y=0.5, line_dash="dash", line_color="red",
                                  annotation_text="Umbral de decisiÃ³n")

                    fig.update_layout(
                        title=f'Efecto de {feature_to_explore} en la Probabilidad',
                        xaxis_title=feature_to_explore,
                        yaxis_title='Probabilidad',
                        height=500
                    )
            else:
                # RegresiÃ³n
                fig.add_trace(go.Scatter(
                    x=exploration_values,
                    y=exploration_predictions,
                    mode='lines+markers',
                    name='PredicciÃ³n'
                ))

                fig.update_layout(
                    title=f'Efecto de {feature_to_explore} en la PredicciÃ³n',
                    xaxis_title=feature_to_explore,
                    yaxis_title='Valor Predicho',
                    height=500
                )

            # Marcar el valor base
            base_val = base_sample[feature_to_explore]
            fig.add_vline(x=base_val, line_dash="dash", line_color="green",
                          annotation_text="Valor Base")

            st.plotly_chart(fig, use_container_width=True)

            # AnÃ¡lisis interpretativo
            st.markdown("**ğŸ“ˆ AnÃ¡lisis de Resultados:**")

            # Calcular estadÃ­sticas del efecto
            if config['task_type'] == 'ClasificaciÃ³n':
                output_size = safe_get_output_size(config)
                if output_size <= 2:
                    pred_range = max(exploration_predictions) - \
                        min(exploration_predictions)
                    volatility = np.std(exploration_predictions)

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Rango de Probabilidades", f"{pred_range:.3f}",
                                  help="Diferencia entre la probabilidad mÃ¡xima y mÃ­nima observada")
                    with col2:
                        st.metric("Volatilidad", f"{volatility:.3f}",
                                  help="QuÃ© tan variables son las predicciones (desviaciÃ³n estÃ¡ndar)")

                    if pred_range > 0.3:
                        st.success(
                            f"ğŸ¯ **CaracterÃ­stica muy influyente:** '{feature_to_explore}' tiene un gran impacto en las predicciones")
                    elif pred_range > 0.1:
                        st.warning(
                            f"ğŸ“Š **CaracterÃ­stica moderadamente influyente:** '{feature_to_explore}' tiene un impacto moderado")
                    else:
                        st.info(
                            f"ğŸ“‰ **CaracterÃ­stica poco influyente:** '{feature_to_explore}' tiene poco impacto en las predicciones")
            else:
                pred_range = max(exploration_predictions) - \
                    min(exploration_predictions)
                pred_mean = np.mean(exploration_predictions)
                relative_impact = (pred_range / abs(pred_mean)
                                   ) * 100 if pred_mean != 0 else 0

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Rango de Predicciones", f"{pred_range:.6f}")
                with col2:
                    st.metric("Impacto Relativo", f"{relative_impact:.1f}%")

                if relative_impact > 20:
                    st.success(
                        f"ğŸ¯ **CaracterÃ­stica muy influyente:** '{feature_to_explore}' causa cambios significativos")
                elif relative_impact > 5:
                    st.warning(
                        f"ğŸ“Š **CaracterÃ­stica moderadamente influyente:** '{feature_to_explore}' tiene impacto moderado")
                else:
                    st.info(
                        f"ğŸ“‰ **CaracterÃ­stica poco influyente:** '{feature_to_explore}' tiene poco impacto")

            # Consejos interpretativos
            with st.expander("ğŸ’¡ Consejos para Interpretar los Resultados", expanded=False):
                st.markdown(f"""
                **ğŸ” Analizando '{feature_to_explore}':**
                
                âœ… **Buenas seÃ±ales:**
                - Cambios graduales y suaves en las predicciones
                - Comportamiento consistente con el conocimiento del dominio
                - Relaciones monotÃ³nicas (siempre creciente o decreciente)
                
                âš ï¸ **SeÃ±ales de alerta:**
                - Cambios muy abruptos sin explicaciÃ³n lÃ³gica
                - Comportamientos contradictorios al conocimiento experto
                - Excesiva sensibilidad a pequeÃ±os cambios
                
                **ğŸ¯ PrÃ³ximos pasos:**
                1. Prueba con diferentes muestras base para confirmar patrones
                2. Explora otras caracterÃ­sticas para comparar importancias
                3. Si encuentras comportamientos extraÃ±os, considera reentrenar el modelo
                4. Documenta los insights para mejorar futuras versiones del modelo
                """)

    except Exception as e:
        st.error(f"Error en las predicciones: {str(e)}")
        st.info("AsegÃºrate de que el modelo estÃ© entrenado correctamente.")


def show_neural_network_export():
    """Permite exportar el modelo entrenado."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "âš ï¸ Primero debes entrenar un modelo en la pestaÃ±a 'Entrenamiento'")
        return

    try:
        import pickle
        import json
        from datetime import datetime

        model = st.session_state.nn_model
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        st.header("ğŸ“¦ Exportar Modelo")

        # InformaciÃ³n del modelo
        st.subheader("â„¹ï¸ InformaciÃ³n del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            st.info(f"""
            **Arquitectura:**
            - Tipo: {config['task_type']}
            - Capas: {len(config['architecture'])}
            - Neuronas: {config['architecture']}
            - ActivaciÃ³n: {config['activation']}
            - Optimizador: {config['optimizer']}
            """)

        with col2:
            total_params = calculate_network_parameters(config['architecture'])
            st.info(f"""
            **ParÃ¡metros:**
            - Total: {total_params:,}
            - Dropout: {config['dropout_rate']}
            - Batch size: {config['batch_size']}
            - Fecha entrenamiento: {datetime.now().strftime('%Y-%m-%d %H:%M')}
            """)

        # Opciones de exportaciÃ³n
        st.subheader("ğŸ“ Opciones de ExportaciÃ³n")

        export_tab1, export_tab2, export_tab3, export_tab4 = st.tabs([
            "ğŸ¤– Modelo TensorFlow",
            "ğŸ“Š Modelo Completo",
            "ğŸ“ CÃ³digo Python",
            "ğŸ“‹ Metadatos"
        ])

        with export_tab1:
            st.markdown("**Exportar solo el modelo de TensorFlow:**")

            format_option = st.radio(
                "Formato:",
                ["SavedModel (.pb)", "HDF5 (.h5)",
                 "TensorFlow Lite (.tflite)"],
                key="nn_export_format"
            )

            if st.button("ğŸ’¾ Exportar Modelo TensorFlow", type="primary"):
                try:
                    if format_option == "SavedModel (.pb)":
                        # Guardar como SavedModel
                        import tempfile
                        import zipfile
                        import io

                        with tempfile.TemporaryDirectory() as temp_dir:
                            model_path = f"{temp_dir}/neural_network_model"
                            model.save(model_path)

                            # Crear ZIP con el modelo
                            zip_buffer = io.BytesIO()
                            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                                import os
                                for root, dirs, files in os.walk(model_path):
                                    for file in files:
                                        file_path = os.path.join(root, file)
                                        arc_name = os.path.relpath(
                                            file_path, temp_dir)
                                        zip_file.write(file_path, arc_name)

                            zip_buffer.seek(0)

                            st.download_button(
                                label="ğŸ“¥ Descargar SavedModel",
                                data=zip_buffer.getvalue(),
                                file_name="neural_network_savedmodel.zip",
                                mime="application/zip"
                            )

                    elif format_option == "HDF5 (.h5)":
                        # Guardar como HDF5
                        import io
                        import tempfile

                        with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as tmp_file:
                            model.save(tmp_file.name)

                            with open(tmp_file.name, 'rb') as f:
                                model_data = f.read()

                            st.download_button(
                                label="ğŸ“¥ Descargar Modelo HDF5",
                                data=model_data,
                                file_name="neural_network_model.h5",
                                mime="application/octet-stream"
                            )

                    elif format_option == "TensorFlow Lite (.tflite)":
                        # Convertir a TensorFlow Lite
                        import tensorflow as tf

                        converter = tf.lite.TFLiteConverter.from_keras_model(
                            model)
                        tflite_model = converter.convert()

                        st.download_button(
                            label="ğŸ“¥ Descargar Modelo TFLite",
                            data=tflite_model,
                            file_name="neural_network_model.tflite",
                            mime="application/octet-stream"
                        )

                        st.success("âœ… Modelo convertido a TensorFlow Lite")
                        st.info(
                            "ğŸ’¡ TensorFlow Lite es ideal para aplicaciones mÃ³viles y embebidas")

                except Exception as e:
                    st.error(f"Error exportando modelo: {str(e)}")

        with export_tab2:
            st.markdown("**Exportar modelo completo con preprocesadores:**")
            st.info("Incluye el modelo, scaler, label encoder y configuraciÃ³n")

            if st.button("ğŸ’¾ Exportar Modelo Completo", type="primary"):
                try:
                    # Crear diccionario con todos los componentes
                    complete_model = {
                        'model': model,
                        'scaler': scaler,
                        'label_encoder': label_encoder,
                        'config': config,
                        'feature_names': st.session_state.get('nn_feature_names', []),
                        'export_date': datetime.now().isoformat(),
                        'version': '1.0'
                    }

                    # Serializar con pickle
                    model_data = pickle.dumps(complete_model)

                    st.download_button(
                        label="ğŸ“¥ Descargar Modelo Completo",
                        data=model_data,
                        file_name="neural_network_complete.pkl",
                        mime="application/octet-stream"
                    )

                    st.success("âœ… Modelo completo exportado")
                    st.info(
                        "ğŸ’¡ Este archivo contiene todo lo necesario para hacer predicciones")

                except Exception as e:
                    st.error(f"Error exportando modelo completo: {str(e)}")

            # Mostrar cÃ³digo de ejemplo para cargar
            st.markdown("**CÃ³digo para cargar el modelo:**")

            load_code = LOAD_NN

            st.code(load_code, language='python')

        with export_tab3:
            st.markdown("**Generar cÃ³digo Python independiente:**")

            if st.button("ğŸ“ Generar CÃ³digo", type="primary"):
                try:
                    # Obtener pesos del modelo
                    weights_data = []
                    for layer in model.layers:
                        if hasattr(layer, 'get_weights') and layer.get_weights():
                            weights_data.append(layer.get_weights())

                    # Generar cÃ³digo
                    code = generate_neural_network_code(config, label_encoder)

                    st.code(code, language='python')

                    # BotÃ³n para descargar el cÃ³digo
                    st.download_button(
                        label="ğŸ“¥ Descargar CÃ³digo",
                        data=code,
                        file_name="neural_network_predictor.py",
                        mime="text/plain"
                    )

                    st.warning(
                        "âš ï¸ El cÃ³digo generado es una plantilla. Debes implementar los pesos especÃ­ficos del modelo entrenado.")

                except Exception as e:
                    st.error(f"Error generando cÃ³digo: {str(e)}")

        with export_tab4:
            st.markdown("**Exportar metadatos del modelo:**")

            # Preparar metadatos
            if 'nn_history' in st.session_state:
                history = st.session_state.nn_history
                final_metrics = {
                    'final_loss': float(history.history['loss'][-1]),
                    'final_val_loss': float(history.history.get('val_loss', [0])[-1]) if 'val_loss' in history.history else None,
                    'epochs_trained': len(history.history['loss'])
                }

                if config['task_type'] == 'ClasificaciÃ³n' and 'accuracy' in history.history:
                    final_metrics['final_accuracy'] = float(
                        history.history['accuracy'][-1])
                    if 'val_accuracy' in history.history:
                        final_metrics['final_val_accuracy'] = float(
                            history.history['val_accuracy'][-1])
            else:
                final_metrics = {}

            metadata = {
                'model_info': {
                    'type': 'Neural Network',
                    'task_type': config['task_type'],
                    'architecture': config['architecture'],
                    'total_parameters': calculate_network_parameters(config['architecture']),
                    'activation_function': config['activation'],
                    'output_activation': config['output_activation'],
                    'optimizer': config['optimizer'],
                    'dropout_rate': config['dropout_rate'],
                    'batch_size': config['batch_size']
                },
                'training_info': final_metrics,
                'data_info': {
                    'feature_names': st.session_state.get('nn_feature_names', []),
                    'target_column': st.session_state.get('nn_target_col', ''),
                    'num_features': config['input_size'],
                    'num_classes': config['output_size'] if config['task_type'] == 'ClasificaciÃ³n' else 1
                },
                'export_info': {
                    'export_date': datetime.now().isoformat(),
                    'version': '1.0',
                    'framework': 'TensorFlow/Keras'
                }
            }

            # Mostrar metadatos
            st.json(metadata)

            # BotÃ³n para descargar metadatos
            metadata_json = json.dumps(metadata, indent=2)

            st.download_button(
                label="ğŸ“¥ Descargar Metadatos",
                data=metadata_json,
                file_name="neural_network_metadata.json",
                mime="application/json"
            )

        # InformaciÃ³n adicional
        st.subheader("ğŸ’¡ InformaciÃ³n Adicional")

        st.info("""
        **Recomendaciones para el uso del modelo:**
        
        1. **Modelo TensorFlow**: Ideal para integrar en aplicaciones que ya usan TensorFlow
        2. **Modelo Completo**: Incluye preprocesadores, perfecto para producciÃ³n
        3. **CÃ³digo Python**: Para entender la implementaciÃ³n o crear versiones optimizadas
        4. **Metadatos**: Para documentaciÃ³n y seguimiento del modelo
        
        **Consideraciones de versiÃ³n:**
        - TensorFlow versiÃ³n utilizada en entrenamiento
        - Compatibilidad con versiones futuras
        - Dependencias del entorno de producciÃ³n
        """)

    except Exception as e:
        st.error(f"Error en la exportaciÃ³n: {str(e)}")
        st.info("AsegÃºrate de que el modelo estÃ© entrenado correctamente.")
