import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from dataset.dataset_manager import load_data
from dataset.dataset_tab import run_select_dataset, show_dataset_info, run_explore_dataset_tab
from utils import create_info_box, get_image_download_link, show_code_with_download
from algorithms.code_examples import generate_neural_network_architecture_code, generate_neural_network_evaluation_code
from algorithms.model_training import train_neural_network
from algorithms.model_evaluation import show_detailed_evaluation
from viz.nn import (
    evaluate_nn,
    show_neural_network_evaluation,
    create_neural_network_visualization,
    calculate_network_parameters,
)
from apps.navbar import navbar


def run_neural_networks_app():
    """Ejecuta la aplicaciÃ³n especÃ­fica de redes neuronales."""
    st.header("ğŸ§  Redes Neuronales")
    st.markdown(
        "Aprende sobre redes neuronales artificiales de forma visual e interactiva")

    # InformaciÃ³n sobre redes neuronales
    with st.expander("â„¹ï¸ Â¿QuÃ© son las Redes Neuronales?", expanded=False):
        st.markdown("""
        Las redes neuronales artificiales son modelos computacionales inspirados en el funcionamiento del cerebro humano.
        EstÃ¡n compuestas por nodos (neuronas) interconectados que procesan informaciÃ³n de manera paralela.

        **CaracterÃ­sticas principales:**
        - **Neuronas**: Unidades bÃ¡sicas que reciben entradas, las procesan y generan salidas
        - **Capas**: Organizan las neuronas en estructuras jerÃ¡rquicas (entrada, ocultas, salida)
        - **Pesos y Sesgos**: ParÃ¡metros que se ajustan durante el entrenamiento
        - **Funciones de ActivaciÃ³n**: Determinan la salida de cada neurona
        - **Backpropagation**: Algoritmo para entrenar la red ajustando pesos y sesgos

        **Ventajas:**
        - Pueden modelar relaciones no lineales complejas
        - Excelentes para reconocimiento de patrones
        - Adaptables a diferentes tipos de problemas
        - Capaces de aproximar cualquier funciÃ³n continua

        **Desventajas:**
        - Requieren grandes cantidades de datos
        - Pueden ser "cajas negras" (difÃ­ciles de interpretar)
        - Propensos al sobreajuste
        - Requieren mucho poder computacional
        """)

    # Sistema de pestaÃ±as
    tab_names = [
        "ğŸ“Š Datos",
        "ğŸ—ï¸ Arquitectura",
        "âš™ï¸ Entrenamiento",
        "ğŸ“ˆ EvaluaciÃ³n",
        "ğŸ¯ VisualizaciÃ³n",
        "ğŸ”® Predicciones",
        "ğŸ’¾ Exportar"
    ]

    # Inicializar estado de pestaÃ±as si no existe
    if 'active_tab_nn' not in st.session_state:
        st.session_state.active_tab_nn = 0

    # Crear pestaÃ±as visuales personalizadas
    cols = st.columns(len(tab_names))
    for i, (col, tab_name) in enumerate(zip(cols, tab_names)):
        with col:
            if st.button(
                tab_name,
                key=f"tab_nn_{i}",
                use_container_width=True,
                type="primary" if st.session_state.active_tab_nn == i else "secondary"
            ):
                st.session_state.active_tab_nn = i
                st.rerun()

    st.markdown("---")

    ###########################################
    #     PestaÃ±a de Datos                    #
    ###########################################
    tips = """
        ğŸ“ **Tips para Redes Neuronales:**
        - Las redes neuronales funcionan mejor con **datos normalizados** (valores entre 0 y 1 o -1 y 1)
        - Necesitan **suficientes datos** para entrenar bien (mÃ­nimo 100 ejemplos por clase)
        - Son excelentes para **patrones complejos** y **relaciones no lineales**
        - Pueden funcionar tanto para **clasificaciÃ³n** como para **regresiÃ³n**
        """
    if st.session_state.active_tab_nn == 0:
        st.header("ğŸ“Š SelecciÃ³n y PreparaciÃ³n de Datos")
        st.info(tips)
        run_select_dataset()
        run_explore_dataset_tab()

        # Botones de navegaciÃ³n
        navbar("active_tab_nn", None, "Continuar a Arquitectura")
    else:
        # Para otras pestaÃ±as, mostrar quÃ© dataset estÃ¡ seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset'):
            st.info(
                f"ğŸ“Š **Dataset actual:** {st.session_state.selected_dataset}")
            st.markdown("---")

    ###########################################
    #     PestaÃ±a de Arquitectura             #
    ###########################################
    if st.session_state.active_tab_nn == 1:
        st.header("ğŸ—ï¸ DiseÃ±o de la Arquitectura de la Red")
        st.markdown("### ğŸ›ï¸ ConfiguraciÃ³n de la Red Neuronal")

        try:
            # Cargar datos usando la funciÃ³n load_data comÃºn
            dataset_name = st.session_state.selected_dataset
            X, y, feature_names, class_names, dataset_info, task_type = load_data(
                dataset_name)

            # Crear DataFrame
            df = X  # pd.DataFrame(X, columns=feature_names)

            df = df.reset_index(drop=True)
            y = y.reset_index(drop=True)
            # Determinar el nombre de la columna objetivo
            if task_type == "ClasificaciÃ³n":
                # Para clasificaciÃ³n, usar el nombre de la variable objetivo del dataset_info
                target_col = 'target'  # Nombre por defecto
                if hasattr(dataset_info, 'target_names'):
                    target_col = 'target'
                df[target_col] = y
            else:
                # Para regresiÃ³n
                target_col = 'target'
                df[target_col] = y

            # Almacenar informaciÃ³n del dataset
            st.session_state.nn_df = df
            st.session_state.nn_target_col = target_col
            st.session_state.nn_feature_names = feature_names
            st.session_state.nn_class_names = class_names
            st.session_state.nn_task_type = task_type
            st.session_state.nn_dataset_info = dataset_info

        except Exception as e:
            st.error(f"Error al cargar el dataset: {e}")

        # Preparar datos bÃ¡sicos para mostrar dimensiones
        X = df.drop(columns=[target_col])
        y = df[target_col]
        input_size = X.shape[1]

        if task_type == "ClasificaciÃ³n":
            num_classes = len(y.unique())
            if num_classes == 2:
                output_size = 1  # Para clasificaciÃ³n binaria
                st.info(
                    f"ğŸ“Š **Entrada**: {input_size} caracterÃ­sticas â†’ **Salida**: {output_size} neurona (clasificaciÃ³n binaria)")
            else:
                output_size = num_classes  # Para clasificaciÃ³n multiclase
                st.info(
                    f"ğŸ“Š **Entrada**: {input_size} caracterÃ­sticas â†’ **Salida**: {output_size} clases")
        else:
            output_size = 1
            st.info(
                f"ğŸ“Š **Entrada**: {input_size} caracterÃ­sticas â†’ **Salida**: {output_size} valor numÃ©rico")

        # Tips sobre dimensiones
        with st.expander("ğŸ’¡ Â¿CÃ³mo decidir el tamaÃ±o de la red?"):
            st.markdown(f"""
            **Reglas generales para tu dataset ({df.shape[0]} muestras, {input_size} caracterÃ­sticas):**
            
            ğŸ”¢ **Neuronas por capa oculta:**
            - PequeÃ±o: {input_size//2} - {input_size} neuronas
            - Mediano: {input_size} - {input_size*2} neuronas  
            - Grande: {input_size*2} - {input_size*4} neuronas
            
            ğŸ“š **NÃºmero de capas:**
            - 1-2 capas: Problemas simples, linealmente separables
            - 2-3 capas: Problemas moderadamente complejos (recomendado para empezar)
            - 4+ capas: Problemas muy complejos (requiere muchos datos)
            
            âš–ï¸ **Balance capacidad vs. datos:**
            - MÃ¡s parÃ¡metros que datos â†’ riesgo de sobreajuste
            - Tu dataset: {df.shape[0]} muestras, mantÃ©n parÃ¡metros < {df.shape[0]//10}
            """)

        # ConfiguraciÃ³n de arquitectura
        col1, col2 = st.columns([1, 1])

        with col1:
            st.markdown("#### âš™ï¸ ConfiguraciÃ³n de Capas")

            # NÃºmero de capas ocultas con explicaciÃ³n
            num_hidden_layers = st.slider(
                "NÃºmero de capas ocultas",
                min_value=1, max_value=5, value=2,
                help="ğŸ’¡ MÃ¡s capas = mayor capacidad de aprender patrones complejos, pero tambiÃ©n mayor riesgo de sobreajuste"
            )

            # Sugerencia basada en el nÃºmero de capas
            if num_hidden_layers == 1:
                st.caption(
                    "ğŸŸ¦ **1 capa**: Ideal para problemas linealmente separables")
            elif num_hidden_layers == 2:
                st.caption(
                    "ğŸŸ¨ **2 capas**: Recomendado para la mayorÃ­a de problemas")
            elif num_hidden_layers >= 3:
                st.caption(
                    "ğŸŸ¥ **3+ capas**: Solo para problemas muy complejos con muchos datos")

            # ConfiguraciÃ³n de cada capa oculta con explicaciones
            hidden_layers = []
            for i in range(num_hidden_layers):
                # Calcular sugerencia inteligente
                suggested_size = max(10, input_size // (i+1))
                if task_type == "ClasificaciÃ³n" and num_classes > 2:
                    suggested_size = max(suggested_size, num_classes * 2)

                neurons = st.slider(
                    f"Neuronas en capa oculta {i+1}",
                    min_value=1, max_value=256,
                    value=min(suggested_size, 64),  # Limitar valor por defecto
                    key=f"layer_{i}",
                    help=f"ğŸ’¡ Sugerencia para capa {i+1}: {suggested_size} neuronas"
                )
                hidden_layers.append(neurons)

            # FunciÃ³n de activaciÃ³n con explicaciones detalladas
            st.markdown("#### ğŸ§® FunciÃ³n de ActivaciÃ³n (Capas Ocultas)")
            activation = st.selectbox(
                "FunciÃ³n de activaciÃ³n",
                ["relu", "tanh", "sigmoid"],
                help="ğŸ’¡ ReLU es la mÃ¡s popular y efectiva para la mayorÃ­a de problemas"
            )

            # Explicaciones sobre funciones de activaciÃ³n
            if activation == "relu":
                st.success(
                    "âœ… **ReLU**: RÃ¡pida, evita el problema del gradiente que desaparece. Recomendada.")
            elif activation == "tanh":
                st.info(
                    "â„¹ï¸ **Tanh**: Salida entre -1 y 1. Buena para datos normalizados.")
            elif activation == "sigmoid":
                st.warning(
                    "âš ï¸ **Sigmoid**: Puede causar gradientes que desaparecen. Ãšsala solo si es necesario.")

            # FunciÃ³n de activaciÃ³n de salida - AHORA SELECCIONABLE
            st.markdown("#### ğŸ¯ FunciÃ³n de ActivaciÃ³n de Salida")

            # Opciones disponibles segÃºn el tipo de tarea
            if task_type == "ClasificaciÃ³n":
                output_options = ["sigmoid", "softmax", "linear", "tanh"]
                if output_size == 1:  # ClasificaciÃ³n binaria
                    recommended = "sigmoid"
                    default_index = 0
                else:  # ClasificaciÃ³n multiclase
                    recommended = "softmax"
                    default_index = 1
            else:
                output_options = ["linear", "sigmoid", "tanh", "softmax"]
                recommended = "linear"
                default_index = 0

            output_activation = st.selectbox(
                "FunciÃ³n de activaciÃ³n de salida",
                output_options,
                index=default_index,
                help=f"ğŸ’¡ FunciÃ³n recomendada para {task_type.lower()}: **{recommended}**"
            )

            # Validaciones y avisos
            show_warning = False
            warning_message = ""

            if task_type == "ClasificaciÃ³n":
                if output_size == 1:  # ClasificaciÃ³n binaria
                    if output_activation == "sigmoid":
                        st.success(
                            "âœ… Sigmoid es ideal para clasificaciÃ³n binaria")
                    elif output_activation == "softmax":
                        show_warning = True
                        warning_message = "âš ï¸ Softmax no es recomendada para clasificaciÃ³n binaria (1 neurona). Considera usar Sigmoid."
                    elif output_activation == "linear":
                        show_warning = True
                        warning_message = "âš ï¸ Linear puede causar problemas en clasificaciÃ³n. Considera usar Sigmoid."
                    elif output_activation == "tanh":
                        show_warning = True
                        warning_message = "âš ï¸ Tanh puede funcionar pero Sigmoid es mÃ¡s estÃ¡ndar para clasificaciÃ³n binaria."

                else:  # ClasificaciÃ³n multiclase
                    if output_activation == "softmax":
                        st.success(
                            "âœ… Softmax es ideal para clasificaciÃ³n multiclase")
                    elif output_activation == "sigmoid":
                        st.warning(
                            "âš ï¸ Sigmoid en multiclase requiere 'binary_crossentropy' por clase. Softmax es mÃ¡s estÃ¡ndar.")
                    elif output_activation == "linear":
                        show_warning = True
                        warning_message = "âš ï¸ Linear no es apropiada para clasificaciÃ³n. Usa Softmax."
                    elif output_activation == "tanh":
                        show_warning = True
                        warning_message = "âš ï¸ Tanh no es estÃ¡ndar para clasificaciÃ³n multiclase. Softmax es recomendada."

            else:  # RegresiÃ³n
                if output_activation == "linear":
                    st.success("âœ… Linear es ideal para regresiÃ³n")
                elif output_activation == "sigmoid":
                    st.warning(
                        "âš ï¸ Sigmoid limita la salida a [0,1]. Solo Ãºtil si tus valores objetivo estÃ¡n en este rango.")
                elif output_activation == "tanh":
                    st.warning(
                        "âš ï¸ Tanh limita la salida a [-1,1]. Solo Ãºtil si tus valores objetivo estÃ¡n en este rango.")
                elif output_activation == "softmax":
                    show_warning = True
                    warning_message = "âš ï¸ Softmax no es apropiada para regresiÃ³n. Las salidas suman 1. Usa Linear."

            # Mostrar advertencia crÃ­tica si es necesario
            if show_warning:
                st.error(warning_message)

        with col2:
            st.markdown("#### ğŸ¨ VisualizaciÃ³n de la Arquitectura")

            # Crear arquitectura completa
            architecture = [input_size] + hidden_layers + [output_size]

            # Guardar configuraciÃ³n en session state
            st.session_state.nn_architecture = {
                'layers': architecture,
                'activation': activation,
                'output_activation': output_activation,
                'input_size': input_size,
                'output_size': output_size,
                'task_type': task_type
            }

            # Visualizar la red neuronal dinÃ¡micamente
            create_neural_network_visualization(
                architecture, activation, output_activation, task_type)

        # ConfiguraciÃ³n adicional con explicaciones detalladas
        st.markdown("### âš™ï¸ ConfiguraciÃ³n Adicional")

        st.markdown("ğŸ“š **ParÃ¡metros importantes para el entrenamiento:**")

        col3, col4, col5 = st.columns(3)

        with col3:
            st.markdown("#### ğŸ›¡ï¸ RegularizaciÃ³n")
            dropout_rate = st.slider(
                "Tasa de Dropout",
                min_value=0.0, max_value=0.8, value=0.2, step=0.1,
                help="ğŸ’¡ Dropout previene sobreajuste eliminando aleatoriamente neuronas durante entrenamiento"
            )

            # ExplicaciÃ³n del dropout
            if dropout_rate == 0.0:
                st.caption("ğŸ”´ **Sin Dropout**: Mayor riesgo de sobreajuste")
            elif dropout_rate <= 0.2:
                st.caption("ğŸŸ¢ **Dropout Ligero**: Bueno para datasets grandes")
            elif dropout_rate <= 0.5:
                st.caption(
                    "ğŸŸ¡ **Dropout Moderado**: Recomendado para la mayorÃ­a de casos")
            else:
                st.caption(
                    "ğŸŸ  **Dropout Alto**: Solo para datasets muy pequeÃ±os")

        with col4:
            st.markdown("#### ğŸ“¦ Procesamiento")
            batch_size = st.selectbox(
                "TamaÃ±o de Batch",
                [16, 32, 64, 128, 256],
                index=2,  # 64 por defecto
                help="ğŸ’¡ NÃºmero de muestras procesadas antes de actualizar los pesos"
            )

            # Sugerencias segÃºn el tamaÃ±o del dataset
            dataset_size = df.shape[0]
            if batch_size >= dataset_size // 4:
                st.caption(
                    "ğŸ”´ **Batch Grande**: Puede ser lento pero mÃ¡s estable")
            elif batch_size >= 32:
                st.caption(
                    "ğŸŸ¢ **Batch Ã“ptimo**: Buen balance velocidad/estabilidad")
            else:
                st.caption("ğŸŸ¡ **Batch PequeÃ±o**: MÃ¡s rÃ¡pido pero mÃ¡s ruidoso")

        with col5:
            st.markdown("#### ğŸš€ OptimizaciÃ³n")
            optimizer = st.selectbox(
                "Optimizador",
                ["adam", "sgd", "rmsprop"],
                help="ğŸ’¡ Algoritmo para actualizar los pesos de la red"
            )

            # Explicaciones sobre optimizadores
            if optimizer == "adam":
                st.caption(
                    "ğŸŸ¢ **Adam**: Adaptativo, recomendado para la mayorÃ­a de casos")
            elif optimizer == "sgd":
                st.caption(
                    "ğŸŸ¡ **SGD**: ClÃ¡sico, requiere ajuste fino del learning rate")
            elif optimizer == "rmsprop":
                st.caption(
                    "ğŸŸ¦ **RMSprop**: Bueno para RNNs y problemas especÃ­ficos")

        # Tips sobre la configuraciÃ³n
        with st.expander("ğŸ’¡ Tips para optimizar tu configuraciÃ³n"):
            st.markdown(f"""
            **Para tu dataset especÃ­fico ({dataset_size} muestras):**
            
            ğŸ¯ **Batch Size recomendado:**
            - Dataset pequeÃ±o (<1000): 16-32
            - Dataset mediano (1000-10000): 32-64
            - Dataset grande (>10000): 64-128
            - Tu dataset: {dataset_size} muestras â†’ Recomendado: {32 if dataset_size < 1000 else 64 if dataset_size < 10000 else 128}
            
            ğŸ›¡ï¸ **Dropout recomendado:**
            - Pocos datos: 0.3-0.5 (mÃ¡s regularizaciÃ³n)
            - Muchos datos: 0.1-0.2 (menos regularizaciÃ³n)
            - Dataset balanceado: 0.2-0.3
            
            ğŸš€ **Optimizador:**
            - **Adam**: Mejor opciÃ³n general, se adapta automÃ¡ticamente
            - **SGD**: Ãšsalo solo si tienes experiencia ajustando learning rates
            - **RMSprop**: Alternativa a Adam, a veces funciona mejor en problemas especÃ­ficos
            """)

        # Guardar configuraciÃ³n completa
        st.session_state.nn_config = {
            'architecture': architecture,
            'activation': activation,
            'output_activation': output_activation,
            'dropout_rate': dropout_rate,
            'batch_size': batch_size,
            'optimizer': optimizer,
            'task_type': task_type,
            'input_size': input_size,
            'output_size': output_size
        }

        # Resumen de la configuraciÃ³n con anÃ¡lisis
        st.markdown("### ğŸ“‹ Resumen de la Arquitectura")

        total_params = calculate_network_parameters(architecture)

        col6, col7, col8 = st.columns(3)
        with col6:
            st.metric("ğŸ”¢ Total de ParÃ¡metros", f"{total_params:,}",
                      help="NÃºmero total de pesos y sesgos que la red aprenderÃ¡")
        with col7:
            st.metric("ğŸ“š Capas Totales", len(architecture),
                      help="Entrada + Ocultas + Salida")
        with col8:
            complexity_ratio = total_params / dataset_size if dataset_size > 0 else 0
            complexity_level = "Baja" if complexity_ratio < 0.1 else "Media" if complexity_ratio < 1 else "Alta"
            st.metric("âš–ï¸ Complejidad", complexity_level,
                      help=f"Ratio parÃ¡metros/datos: {complexity_ratio:.2f}")
        with col8:
            st.metric("ğŸ§  Tipo de Red", "PerceptrÃ³n Multicapa")

        # Mostrar detalles de cada capa
        st.markdown("#### ğŸ“Š Detalles por Capa")
        layer_details = []
        for i, (current, next_size) in enumerate(zip(architecture[:-1], architecture[1:])):
            if i == 0:
                layer_type = "Entrada"
                params = 0
            elif i == len(architecture) - 2:
                layer_type = "Salida"
                params = current * next_size + next_size
            else:
                layer_type = f"Oculta {i}"
                params = current * next_size + next_size

            layer_details.append({
                "Capa": layer_type,
                "Neuronas": current if i < len(architecture) - 1 else next_size,
                "ParÃ¡metros": params,
                "ActivaciÃ³n": "Entrada" if i == 0 else (output_activation if i == len(architecture) - 2 else activation)
            })

        st.dataframe(pd.DataFrame(layer_details), use_container_width=True)

        # AnÃ¡lisis de complejidad y recomendaciones
        st.markdown("#### ğŸ” AnÃ¡lisis de Complejidad")

        # AnÃ¡lisis del ratio parÃ¡metros/datos
        if complexity_ratio < 0.1:
            st.success(
                f"âœ… **Complejidad Ã“ptima**: Tu red tiene {total_params:,} parÃ¡metros para {dataset_size} muestras (ratio: {complexity_ratio:.3f}). Bajo riesgo de sobreajuste.")
        elif complexity_ratio < 1:
            st.warning(
                f"âš ï¸ **Complejidad Media**: Tu red tiene {total_params:,} parÃ¡metros para {dataset_size} muestras (ratio: {complexity_ratio:.3f}). Monitorea el sobreajuste.")
        else:
            st.error(
                f"ğŸš¨ **Complejidad Alta**: Tu red tiene {total_params:,} parÃ¡metros para {dataset_size} muestras (ratio: {complexity_ratio:.3f}). Alto riesgo de sobreajuste. Considera reducir el tamaÃ±o de la red.")

        # BotÃ³n para generar cÃ³digo Python
        st.markdown("### ğŸ’» CÃ³digo Python")
        if st.button("ğŸ“ Generar CÃ³digo de la Arquitectura", use_container_width=True):
            # Generar cÃ³digo Python para la arquitectura
            code = generate_neural_network_architecture_code(
                architecture, activation, output_activation, dropout_rate,
                optimizer, batch_size, task_type, st.session_state.nn_feature_names
            )

            st.markdown("#### ğŸ CÃ³digo Python Generado")
            st.code(code, language='python')

            # BotÃ³n para descargar el cÃ³digo
            st.download_button(
                label="ğŸ’¾ Descargar CÃ³digo Python",
                data=code,
                file_name=f"red_neuronal_arquitectura_{task_type.lower()}.py",
                mime="text/plain"
            )

        # Botones de navegaciÃ³n
        navbar("active_tab_nn", "Volver a Datos", "Continuar a Entrenamiento",
               next_note="**Â¿Listo para entrenar?** Â¡Tu arquitectura estÃ¡ configurada!")

    ###########################################
    #     PestaÃ±a de Entrenamiento            #
    ###########################################
    elif st.session_state.active_tab_nn == 2:
        st.header("âš™ï¸ Entrenamiento de la Red Neuronal")

        if 'nn_config' not in st.session_state:
            st.warning("âš ï¸ Primero debes configurar la arquitectura de la red.")
            if st.button("ğŸ”™ Ir a Arquitectura"):
                st.session_state.active_tab_nn = 1
                st.rerun()
            return

        # Tips educativos sobre entrenamiento
        st.info("""
        ğŸ“ **Conceptos Clave del Entrenamiento:**
        - **Learning Rate**: Controla quÃ© tan rÃ¡pido aprende la red (muy alto = inestable, muy bajo = lento)
        - **Ã‰pocas**: CuÃ¡ntas veces la red ve todos los datos (mÃ¡s Ã©pocas â‰  siempre mejor)
        - **ValidaciÃ³n**: Datos separados para monitorear si la red estÃ¡ generalizando bien
        - **Early Stopping**: Para evitar sobreajuste, para cuando la validaciÃ³n no mejora
        """)

        st.markdown("### ğŸ›ï¸ ParÃ¡metros de Entrenamiento")

        # InformaciÃ³n del dataset para sugerencias
        df = st.session_state.nn_df
        dataset_size = df.shape[0]

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("#### ğŸ“ˆ **Learning Rate**")
            learning_rate = st.selectbox(
                "Tasa de Aprendizaje",
                [0.001, 0.01, 0.1, 0.3],
                index=0,
                help="ğŸ’¡ 0.001 es seguro para empezar. Valores mÃ¡s altos pueden acelerar el entrenamiento pero causar inestabilidad"
            )

            # ExplicaciÃ³n del learning rate seleccionado
            if learning_rate == 0.001:
                st.caption("ğŸŸ¢ **Conservador**: Aprendizaje lento pero estable")
            elif learning_rate == 0.01:
                st.caption(
                    "ğŸŸ¡ **Moderado**: Buen balance velocidad/estabilidad")
            elif learning_rate == 0.1:
                st.caption("ğŸŸ  **Agresivo**: RÃ¡pido pero puede ser inestable")
            else:
                st.caption("ğŸ”´ **Muy Alto**: Solo para casos especiales")

        with col2:
            st.markdown("#### ğŸ”„ **Ã‰pocas**")
            # Sugerir Ã©pocas basado en tamaÃ±o del dataset
            suggested_epochs = min(200, max(50, dataset_size // 10))
            epochs = st.slider(
                "Ã‰pocas",
                min_value=10, max_value=500, value=min(100, suggested_epochs), step=10,
                help=f"ğŸ’¡ Sugerencia para tu dataset: ~{suggested_epochs} Ã©pocas"
            )

            # ExplicaciÃ³n sobre las Ã©pocas
            if epochs < 50:
                st.caption(
                    "ğŸŸ¡ **Pocas Ã©pocas**: Puede que no aprenda completamente")
            elif epochs <= 150:
                st.caption("ğŸŸ¢ **Ã‰pocas adecuadas**: Buen balance")
            else:
                st.caption("ğŸŸ  **Muchas Ã©pocas**: Monitorea el sobreajuste")

        with col3:
            st.markdown("#### ğŸ¯ **ValidaciÃ³n**")
            validation_split = st.slider(
                "% Datos de ValidaciÃ³n",
                min_value=10, max_value=40, value=20,
                help="ğŸ’¡ 20% es estÃ¡ndar. MÃ¡s datos = mejor validaciÃ³n, menos datos para entrenar"
            )

            # Calcular tamaÃ±os efectivos
            # 80% del total para entrenamiento
            train_size = int(
                dataset_size * (100 - validation_split) / 100 * 0.8)
            val_size = int(dataset_size * validation_split / 100)
            test_size = dataset_size - train_size - val_size

            st.caption(
                f"ğŸ“Š **DistribuciÃ³n**: Train={train_size}, Val={val_size}, Test={test_size}")

        # ConfiguraciÃ³n avanzada con explicaciones detalladas
        with st.expander("âš™ï¸ ConfiguraciÃ³n Avanzada - TÃ©cnicas para Mejorar el Entrenamiento", expanded=False):
            st.markdown("#### ğŸ›¡ï¸ TÃ©cnicas de RegularizaciÃ³n y OptimizaciÃ³n")

            col4, col5 = st.columns(2)

            with col4:
                st.markdown("##### ğŸ›‘ Early Stopping")
                early_stopping = st.checkbox(
                    "Activar Parada Temprana",
                    value=True,
                    help="ğŸ’¡ Recomendado: Evita sobreajuste parando cuando la validaciÃ³n no mejora"
                )

                if early_stopping:
                    st.success(
                        "âœ… **Early Stopping activado**: La red pararÃ¡ automÃ¡ticamente cuando deje de mejorar")
                    patience = st.slider(
                        "Paciencia (Ã©pocas)",
                        min_value=5, max_value=50, value=10,
                        help="Ã‰pocas a esperar sin mejora antes de parar. MÃ¡s paciencia = mÃ¡s oportunidades de mejorar"
                    )

                    if patience <= 5:
                        st.caption(
                            "ğŸ”´ **Impatiente**: Para rÃ¡pido, puede interrumpir mejoras tardÃ­as")
                    elif patience <= 15:
                        st.caption("ğŸŸ¢ **Balanceado**: Buen equilibrio")
                    else:
                        st.caption(
                            "ğŸŸ¡ **Paciente**: Da muchas oportunidades, pero puede sobreajustar")
                else:
                    st.warning(
                        "âš ï¸ **Sin Early Stopping**: La red entrenarÃ¡ todas las Ã©pocas. Riesgo de sobreajuste.")

            with col5:
                st.markdown("##### ğŸ“‰ Learning Rate Scheduler")
                reduce_lr = st.checkbox(
                    "Reducir Learning Rate AutomÃ¡ticamente",
                    value=True,
                    help="ğŸ’¡ Recomendado: Reduce la tasa de aprendizaje cuando no mejora"
                )

                if reduce_lr:
                    st.success(
                        "âœ… **Scheduler activado**: La tasa de aprendizaje se reducirÃ¡ automÃ¡ticamente")
                    lr_factor = st.slider(
                        "Factor de ReducciÃ³n",
                        min_value=0.1, max_value=0.9, value=0.5,
                        help="Factor por el que se multiplica la tasa. 0.5 = reduce a la mitad"
                    )

                    if lr_factor <= 0.3:
                        st.caption(
                            "ğŸ”´ **ReducciÃ³n agresiva**: Cambios dramÃ¡ticos")
                    elif lr_factor <= 0.7:
                        st.caption("ğŸŸ¢ **ReducciÃ³n moderada**: Recomendado")
                    else:
                        st.caption("ğŸŸ¡ **ReducciÃ³n suave**: Cambios graduales")
                else:
                    st.info(
                        "â„¹ï¸ **Learning rate fijo**: Se mantendrÃ¡ constante durante todo el entrenamiento")

            # ExplicaciÃ³n sobre las tÃ©cnicas
            st.markdown("---")
            st.markdown("#### ğŸ“š Â¿Por quÃ© usar estas tÃ©cnicas?")
            st.markdown("""
            - **Early Stopping**: Evita que la red memorice los datos (sobreajuste) parando cuando la performance en validaciÃ³n deja de mejorar
            - **Learning Rate Reduction**: Permite un ajuste fino hacia el final del entrenamiento cuando se estÃ¡ cerca del Ã³ptimo
            - **Combinadas**: Estas tÃ©cnicas trabajan juntas para lograr el mejor modelo posible automÃ¡ticamente
            """)

        # BotÃ³n de entrenamiento con explicaciÃ³n
        st.markdown("### ğŸš€ Iniciar Entrenamiento")
        st.markdown(
            "**Â¿Todo listo?** Tu red estÃ¡ configurada y lista para aprender de los datos.")

        if st.button("ğŸ§  Entrenar Red Neuronal", type="primary", use_container_width=True):
            with st.spinner("ğŸ§  Entrenando la red neuronal... Esto puede tomar unos minutos."):
                # Preparar datos
                df = st.session_state.nn_df
                target_col = st.session_state.nn_target_col
                task_type = st.session_state.nn_task_type

                try:
                    # Mostrar progreso del entrenamiento con pasos
                    progress_container = st.empty()

                    # Paso 1: Preparando datos
                    with progress_container.container():
                        st.info(
                            "ğŸ”„ **Paso 1/4**: Preparando y dividiendo los datos...")

                    # Llamar funciÃ³n de entrenamiento con callback de progreso
                    def update_progress(step, message):
                        with progress_container.container():
                            if step == 2:
                                st.info(f"ğŸ§  **Paso {step}/4**: {message}")
                            elif step == 3:
                                st.info(f"âš™ï¸ **Paso {step}/4**: {message}")
                            elif step == 4:
                                st.info(f"ğŸš€ **Paso {step}/4**: {message}")
                            else:
                                st.info(f"ğŸ”„ **Paso {step}/4**: {message}")

                    # Entrenar el modelo con callback de progreso
                    model, history, X_test, y_test, scaler, label_encoder = train_neural_network(
                        df, target_col, st.session_state.nn_config,
                        learning_rate, epochs, validation_split/100,
                        early_stopping, patience if early_stopping else None,
                        reduce_lr, lr_factor if reduce_lr else None,
                        progress_callback=update_progress
                    )

                    # Guardar resultados
                    st.session_state.nn_model = model
                    st.session_state.nn_history = history
                    st.session_state.nn_test_data = (X_test, y_test)
                    st.session_state.nn_scaler = scaler
                    st.session_state.nn_label_encoder = label_encoder
                    st.session_state.model_trained_nn = True

                    # Limpiar el progreso y mostrar finalizaciÃ³n
                    with progress_container.container():
                        if model is not None:
                            st.success(
                                "âœ… **Â¡Entrenamiento completado!** Red neuronal lista para usar")

                    if model is not None:
                        st.success("ğŸ‰ Â¡Red neuronal entrenada exitosamente!")

                except Exception as e:
                    # Limpiar el progreso en caso de error
                    with progress_container.container():
                        st.error("âŒ **Error durante el entrenamiento**")

                    st.error(f"âŒ Error durante el entrenamiento: {str(e)}")
                    st.info(
                        "Intenta ajustar los parÃ¡metros o verificar el dataset.")

        # Botones de navegaciÃ³n
        if st.session_state.get('model_trained_nn', False):
            navbar("active_tab_nn", "Volver a Arquitectura", "Ver EvaluaciÃ³n")
        else:
            navbar("active_tab_nn", "Volver a Arquitectura", None)

    ###########################################
    #     PestaÃ±a de EvaluaciÃ³n.              #
    ###########################################
    elif st.session_state.active_tab_nn == 3:
        st.header("ğŸ“ˆ EvaluaciÃ³n del Modelo")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("âš ï¸ Primero debes entrenar un modelo.")
            if st.button("ğŸ”™ Ir a Entrenamiento"):
                st.session_state.active_tab_nn = 2
                st.rerun()
        else:
            model = st.session_state.nn_model
            X_test = st.session_state.nn_test_data[0]
            y_test = st.session_state.nn_test_data[1]
            class_names = st.session_state.nn_class_names
            task_type = st.session_state.nn_config.get(
                'task_type', 'ClasificaciÃ³n')
            y_pred = model.predict(X_test, verbose=0)
            if task_type == "ClasificaciÃ³n":
                y_pred = np.asarray(y_pred).argmax(axis=1)
            else:
                y_pred = y_pred.ravel()
            # y_pred = np.eye(len(class_names))[y_pred]

            st.session_state.nn_y_pred = y_pred

            evaluate_nn(model, X_test, y_test, task_type)
            if task_type == "ClasificaciÃ³n":
                y_test = np.asarray(y_test).argmax(axis=1)
            show_detailed_evaluation(y_test, y_pred, class_names, task_type)

            navbar("active_tab_nn", "Volver a Entrenamiento", "Ver VisualizaciÃ³n")

    ###########################################
    #     PestaÃ±a de VisualizaciÃ³n            #
    ###########################################
    elif st.session_state.active_tab_nn == 4:
        st.header("ğŸ¯ Visualizaciones")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("âš ï¸ Primero debes entrenar un modelo.")
        else:
            show_neural_network_visualizations()

    ###########################################
    #     PestaÃ±a de Predicciones             #
    ###########################################
    elif st.session_state.active_tab_nn == 5:
        st.header("ğŸ”® Predicciones")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("âš ï¸ Primero debes entrenar un modelo.")
        else:
            show_neural_network_predictions()

    ###########################################
    #     PestaÃ±a de Exportar.                #
    ###########################################
    elif st.session_state.active_tab_nn == 6:
        st.header("ğŸ’¾ Exportar Modelo")
        if not st.session_state.get('model_trained_nn', False):
            st.warning("âš ï¸ Primero debes entrenar un modelo.")
        else:
            show_neural_network_export()


# ===== FUNCIONES PARA REDES NEURONALES =====


def show_neural_network_export():
    """Permite exportar el modelo entrenado."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "âš ï¸ Primero debes entrenar un modelo en la pestaÃ±a 'Entrenamiento'")
        return

    try:
        import pickle
        import json
        from datetime import datetime

        model = st.session_state.nn_model
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        st.header("ğŸ“¦ Exportar Modelo")

        # InformaciÃ³n del modelo
        st.subheader("â„¹ï¸ InformaciÃ³n del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            st.info(f"""
            **Arquitectura:**
            - Tipo: {config['task_type']}
            - Capas: {len(config['architecture'])}
            - Neuronas: {config['architecture']}
            - ActivaciÃ³n: {config['activation']}
            - Optimizador: {config['optimizer']}
            """)

        with col2:
            total_params = calculate_network_parameters(config['architecture'])
            st.info(f"""
            **ParÃ¡metros:**
            - Total: {total_params:,}
            - Dropout: {config['dropout_rate']}
            - Batch size: {config['batch_size']}
            - Fecha entrenamiento: {datetime.now().strftime('%Y-%m-%d %H:%M')}
            """)

        # Opciones de exportaciÃ³n
        st.subheader("ğŸ“ Opciones de ExportaciÃ³n")

        export_tab1, export_tab2, export_tab3, export_tab4 = st.tabs([
            "ğŸ¤– Modelo TensorFlow",
            "ğŸ“Š Modelo Completo",
            "ğŸ“ CÃ³digo Python",
            "ğŸ“‹ Metadatos"
        ])

        with export_tab1:
            st.markdown("**Exportar solo el modelo de TensorFlow:**")

            format_option = st.radio(
                "Formato:",
                ["SavedModel (.pb)", "HDF5 (.h5)",
                 "TensorFlow Lite (.tflite)"],
                key="nn_export_format"
            )

            if st.button("ğŸ’¾ Exportar Modelo TensorFlow", type="primary"):
                try:
                    if format_option == "SavedModel (.pb)":
                        # Guardar como SavedModel
                        import tempfile
                        import zipfile
                        import io

                        with tempfile.TemporaryDirectory() as temp_dir:
                            model_path = f"{temp_dir}/neural_network_model"
                            model.save(model_path)

                            # Crear ZIP con el modelo
                            zip_buffer = io.BytesIO()
                            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                                import os
                                for root, dirs, files in os.walk(model_path):
                                    for file in files:
                                        file_path = os.path.join(root, file)
                                        arc_name = os.path.relpath(
                                            file_path, temp_dir)
                                        zip_file.write(file_path, arc_name)

                            zip_buffer.seek(0)

                            st.download_button(
                                label="ğŸ“¥ Descargar SavedModel",
                                data=zip_buffer.getvalue(),
                                file_name="neural_network_savedmodel.zip",
                                mime="application/zip"
                            )

                    elif format_option == "HDF5 (.h5)":
                        # Guardar como HDF5
                        import io
                        import tempfile

                        with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as tmp_file:
                            model.save(tmp_file.name)

                            with open(tmp_file.name, 'rb') as f:
                                model_data = f.read()

                            st.download_button(
                                label="ğŸ“¥ Descargar Modelo HDF5",
                                data=model_data,
                                file_name="neural_network_model.h5",
                                mime="application/octet-stream"
                            )

                    elif format_option == "TensorFlow Lite (.tflite)":
                        # Convertir a TensorFlow Lite
                        import tensorflow as tf

                        converter = tf.lite.TFLiteConverter.from_keras_model(
                            model)
                        tflite_model = converter.convert()

                        st.download_button(
                            label="ğŸ“¥ Descargar Modelo TFLite",
                            data=tflite_model,
                            file_name="neural_network_model.tflite",
                            mime="application/octet-stream"
                        )

                        st.success("âœ… Modelo convertido a TensorFlow Lite")
                        st.info(
                            "ğŸ’¡ TensorFlow Lite es ideal para aplicaciones mÃ³viles y embebidas")

                except Exception as e:
                    st.error(f"Error exportando modelo: {str(e)}")

        with export_tab2:
            st.markdown("**Exportar modelo completo con preprocesadores:**")
            st.info("Incluye el modelo, scaler, label encoder y configuraciÃ³n")

            if st.button("ğŸ’¾ Exportar Modelo Completo", type="primary"):
                try:
                    # Crear diccionario con todos los componentes
                    complete_model = {
                        'model': model,
                        'scaler': scaler,
                        'label_encoder': label_encoder,
                        'config': config,
                        'feature_names': st.session_state.get('nn_feature_names', []),
                        'export_date': datetime.now().isoformat(),
                        'version': '1.0'
                    }

                    # Serializar con pickle
                    model_data = pickle.dumps(complete_model)

                    st.download_button(
                        label="ğŸ“¥ Descargar Modelo Completo",
                        data=model_data,
                        file_name="neural_network_complete.pkl",
                        mime="application/octet-stream"
                    )

                    st.success("âœ… Modelo completo exportado")
                    st.info(
                        "ğŸ’¡ Este archivo contiene todo lo necesario para hacer predicciones")

                except Exception as e:
                    st.error(f"Error exportando modelo completo: {str(e)}")

            # Mostrar cÃ³digo de ejemplo para cargar
            st.markdown("**CÃ³digo para cargar el modelo:**")

            load_code = LOAD_NN

            st.code(load_code, language='python')

        with export_tab3:
            st.markdown("**Generar cÃ³digo Python independiente:**")

            if st.button("ğŸ“ Generar CÃ³digo", type="primary"):
                try:
                    # Obtener pesos del modelo
                    weights_data = []
                    for layer in model.layers:
                        if hasattr(layer, 'get_weights') and layer.get_weights():
                            weights_data.append(layer.get_weights())

                    # Generar cÃ³digo
                    code = generate_neural_network_code(config, label_encoder)

                    st.code(code, language='python')

                    # BotÃ³n para descargar el cÃ³digo
                    st.download_button(
                        label="ğŸ“¥ Descargar CÃ³digo",
                        data=code,
                        file_name="neural_network_predictor.py",
                        mime="text/plain"
                    )

                    st.warning(
                        "âš ï¸ El cÃ³digo generado es una plantilla. Debes implementar los pesos especÃ­ficos del modelo entrenado.")

                except Exception as e:
                    st.error(f"Error generando cÃ³digo: {str(e)}")

        with export_tab4:
            st.markdown("**Exportar metadatos del modelo:**")

            # Preparar metadatos
            if 'nn_history' in st.session_state:
                history = st.session_state.nn_history
                final_metrics = {
                    'final_loss': float(history.history['loss'][-1]),
                    'final_val_loss': float(history.history.get('val_loss', [0])[-1]) if 'val_loss' in history.history else None,
                    'epochs_trained': len(history.history['loss'])
                }

                if config['task_type'] == 'ClasificaciÃ³n' and 'accuracy' in history.history:
                    final_metrics['final_accuracy'] = float(
                        history.history['accuracy'][-1])
                    if 'val_accuracy' in history.history:
                        final_metrics['final_val_accuracy'] = float(
                            history.history['val_accuracy'][-1])
            else:
                final_metrics = {}

            metadata = {
                'model_info': {
                    'type': 'Neural Network',
                    'task_type': config['task_type'],
                    'architecture': config['architecture'],
                    'total_parameters': calculate_network_parameters(config['architecture']),
                    'activation_function': config['activation'],
                    'output_activation': config['output_activation'],
                    'optimizer': config['optimizer'],
                    'dropout_rate': config['dropout_rate'],
                    'batch_size': config['batch_size']
                },
                'training_info': final_metrics,
                'data_info': {
                    'feature_names': st.session_state.get('nn_feature_names', []),
                    'target_column': st.session_state.get('nn_target_col', ''),
                    'num_features': config['input_size'],
                    'num_classes': config['output_size'] if config['task_type'] == 'ClasificaciÃ³n' else 1
                },
                'export_info': {
                    'export_date': datetime.now().isoformat(),
                    'version': '1.0',
                    'framework': 'TensorFlow/Keras'
                }
            }

            # Mostrar metadatos
            st.json(metadata)

            # BotÃ³n para descargar metadatos
            metadata_json = json.dumps(metadata, indent=2)

            st.download_button(
                label="ğŸ“¥ Descargar Metadatos",
                data=metadata_json,
                file_name="neural_network_metadata.json",
                mime="application/json"
            )

        # InformaciÃ³n adicional
        st.subheader("ğŸ’¡ InformaciÃ³n Adicional")

        st.info("""
        **Recomendaciones para el uso del modelo:**
        
        1. **Modelo TensorFlow**: Ideal para integrar en aplicaciones que ya usan TensorFlow
        2. **Modelo Completo**: Incluye preprocesadores, perfecto para producciÃ³n
        3. **CÃ³digo Python**: Para entender la implementaciÃ³n o crear versiones optimizadas
        4. **Metadatos**: Para documentaciÃ³n y seguimiento del modelo
        
        **Consideraciones de versiÃ³n:**
        - TensorFlow versiÃ³n utilizada en entrenamiento
        - Compatibilidad con versiones futuras
        - Dependencias del entorno de producciÃ³n
        """)

    except Exception as e:
        st.error(f"Error en la exportaciÃ³n: {str(e)}")
        st.info("AsegÃºrate de que el modelo estÃ© entrenado correctamente.")
