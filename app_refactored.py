#!/usr/bin/env python3
"""
MLTutor: Plataforma educativa para el aprendizaje de Machine Learning.

Esta es la versi√≥n refactorizada de la aplicaci√≥n MLTutor, que separa la p√°gina de inicio
de los algoritmos espec√≠ficos para una mejor experiencia de usuario.
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import base64
import io

# Importar m√≥dulos refactorizados
from dataset_manager import load_data, preprocess_data, create_dataset_selector, load_dataset_from_file
from model_training import train_decision_tree, predict_sample, train_linear_model
from model_evaluation import evaluate_classification_model, evaluate_regression_model, show_detailed_evaluation
from decision_boundary import plot_decision_boundary
from sklearn.model_selection import train_test_split
from ui import (
    setup_page, init_session_state, show_welcome_page,
    display_feature_importance, display_model_export_options, create_prediction_interface
)
from tree_visualizer import (
    render_tree_visualization,
    create_tree_visualization, get_tree_text
)
from utils import (
    get_image_download_link, generate_model_code, export_model_pickle, export_model_onnx,
    create_info_box, format_number, show_code_with_download
)


def main():
    """Funci√≥n principal que ejecuta la aplicaci√≥n MLTutor."""
    # Configuraci√≥n de la p√°gina
    setup_page()

    # Inicializar estado de la sesi√≥n
    init_session_state()

    # Configurar navegaci√≥n principal con botones en lugar de radio
    st.sidebar.markdown("### Navegaci√≥n:")

    # Estilo para los botones de navegaci√≥n
    button_style = """
    <style>
    div.stButton > button {
        width: 100%;
        text-align: left;
        padding: 10px;
        margin-bottom: 5px;
        border-radius: 5px;
        font-weight: normal;
    }
    div.stButton > button:hover {
        background-color: #E3F2FD;
        border-color: #90CAF9;
    }
    </style>
    """
    st.sidebar.markdown(button_style, unsafe_allow_html=True)

    # Crear los botones de navegaci√≥n
    if st.sidebar.button("üè† Inicio",
                         key="nav_home",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üè† Inicio" else "primary"):
        st.session_state.navigation = "üè† Inicio"
        st.rerun()

    if st.sidebar.button("üå≤ √Årboles de Decisi√≥n",
                         key="nav_trees",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üå≤ √Årboles de Decisi√≥n" else "primary"):
        st.session_state.navigation = "üå≤ √Årboles de Decisi√≥n"
        st.rerun()

    if st.sidebar.button("üìä Regresi√≥n",
                         key="nav_linear",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üìä Regresi√≥n" else "primary"):
        st.session_state.navigation = "üìä Regresi√≥n"
        st.rerun()

    if st.sidebar.button("üîç K-Nearest Neighbors (pr√≥ximamente)",
                         key="nav_knn",
                         use_container_width=True,
                         disabled=True):
        st.session_state.navigation = "üîç K-Nearest Neighbors (pr√≥ximamente)"
        st.rerun()

    if st.sidebar.button("üß† Redes Neuronales (pr√≥ximamente)",
                         key="nav_nn",
                         use_container_width=True,
                         disabled=True):
        st.session_state.navigation = "üß† Redes Neuronales (pr√≥ximamente)"
        st.rerun()

    # Separador
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üîß Herramientas:")

    if st.sidebar.button("üìÅ Cargar CSV Personalizado",
                         key="nav_csv",
                         use_container_width=True):
        st.session_state.navigation = "üìÅ Cargar CSV Personalizado"
        st.rerun()

    # P√°gina de inicio
    if st.session_state.navigation == "üè† Inicio":
        show_welcome_page()
        return

    # P√°ginas de algoritmos
    if st.session_state.navigation == "üå≤ √Årboles de Decisi√≥n":
        run_decision_trees_app()
    elif st.session_state.navigation == "üìä Regresi√≥n":
        run_linear_regression_app()
    elif st.session_state.navigation == "üìÅ Cargar CSV Personalizado":
        run_csv_loader_app()
    elif st.session_state.navigation in ["üîç K-Nearest Neighbors (pr√≥ximamente)",
                                         "üß† Redes Neuronales (pr√≥ximamente)"]:
        algorithm_name = st.session_state.navigation.split(" ")[1]
        st.header(f"{algorithm_name} (pr√≥ximamente)")
        st.info(
            f"La funcionalidad de {algorithm_name} estar√° disponible pr√≥ximamente. Por ahora, puedes explorar los √Årboles de Decisi√≥n.")

        # Mostrar una imagen ilustrativa seg√∫n el algoritmo
        if "Regresi√≥n Log√≠stica" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_logistic_001.png",
                     caption="Ilustraci√≥n de Regresi√≥n Log√≠stica")
        elif "K-Nearest Neighbors" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_classification_001.png",
                     caption="Ilustraci√≥n de K-Nearest Neighbors")
        elif "Redes Neuronales" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_mlp_001.png",
                     caption="Ilustraci√≥n de Redes Neuronales")


def run_decision_trees_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de √°rboles de decisi√≥n."""
    st.header("üå≤ √Årboles de Decisi√≥n")
    st.markdown("Aprende sobre los √°rboles de decisi√≥n de forma interactiva")

    # Informaci√≥n sobre √°rboles de decisi√≥n
    with st.expander("‚ÑπÔ∏è ¬øQu√© son los √Årboles de Decisi√≥n?", expanded=False):
        st.markdown("""
        Los √°rboles de decisi√≥n son algoritmos de aprendizaje supervisado que se pueden usar tanto para tareas de clasificaci√≥n como de regresi√≥n.

        **Caracter√≠sticas principales:**
        - Funcionan dividiendo el conjunto de datos en subconjuntos m√°s peque√±os bas√°ndose en condiciones sobre las caracter√≠sticas
        - Son f√°ciles de interpretar y visualizar
        - Pueden manejar tanto datos num√©ricos como categ√≥ricos
        - No requieren escalado de datos

        **Limitaciones:**
        - Pueden sobreajustarse f√°cilmente (esto se puede controlar con par√°metros como max_depth)
        - Pueden ser inestables (peque√±os cambios en los datos pueden generar √°rboles muy diferentes)
        - No son tan precisos como algoritmos m√°s complejos para algunas tareas

        Experimenta con diferentes configuraciones para ver c√≥mo afectan al rendimiento del modelo.
        """)

    # Variables para almacenar datos
    dataset_loaded = False
    X, y, feature_names, class_names, dataset_info, task_type = None, None, None, None, None, None

    # Inicializar el estado de la pesta√±a activa si no existe
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = 0

    # Crear pesta√±as para organizar la informaci√≥n
    tab_options = [
        "üìä Datos",
        "üèãÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üå≤ Visualizaci√≥n",
        "üîç Caracter√≠sticas",
        "üîÆ Predicciones",
        "üíæ Exportar Modelo"
    ]

    # Crear contenedor para los botones de las pesta√±as
    tab_cols = st.columns(len(tab_options))

    # Estilo CSS para los botones de pesta√±as
    st.markdown("""
    <style>
    div.tab-button > button {
        border-radius: 4px 4px 0 0;
        padding: 10px;
        width: 100%;
        white-space: nowrap;
        background-color: #F0F2F6;
        border-bottom: 2px solid #E0E0E0;
    }
    div.tab-button-active > button {
        background-color: #E3F2FD;
        border-bottom: 2px solid #1E88E5;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

    # Crear botones para las pesta√±as
    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_{i}"
        button_style = "tab-button-active" if st.session_state.active_tab == i else "tab-button"

        with col:
            st.markdown(f"<div class='{button_style}'>",
                        unsafe_allow_html=True)
            if st.button(tab_name, key=button_key, use_container_width=True):
                st.session_state.active_tab = i
                st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    # Separador visual
    st.markdown("---")

    # SELECTOR UNIFICADO DE DATASET (solo mostrar en pesta√±as que lo necesiten)
    if st.session_state.active_tab in [0, 1]:  # Exploraci√≥n y Entrenamiento
        st.markdown("### üìä Selecci√≥n de Dataset")

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset' not in st.session_state:
            st.session_state.selected_dataset = "üå∏ Iris - Clasificaci√≥n de flores"

        # Lista base de datasets predefinidos
        builtin_datasets = [
            "üå∏ Iris - Clasificaci√≥n de flores",
            "üç∑ Vino - Clasificaci√≥n de vinos",
            "üî¨ C√°ncer - Diagn√≥stico binario",
            "üö¢ Titanic - Supervivencia",
            "üí∞ Propinas - Predicci√≥n de propinas",
            "üè† Viviendas California - Precios",
            "üêß Ping√ºinos - Clasificaci√≥n de especies"
        ]

        # A√±adir datasets CSV cargados si existen
        available_datasets = builtin_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado est√© en la lista disponible
        if st.session_state.selected_dataset not in available_datasets:
            st.session_state.selected_dataset = builtin_datasets[0]

        # Selector unificado
        dataset_option = st.selectbox(
            "Dataset:",
            available_datasets,
            index=available_datasets.index(st.session_state.selected_dataset),
            key="unified_dataset_selector",
            help="El dataset seleccionado se mantendr√° entre las pesta√±as de Exploraci√≥n y Entrenamiento"
        )

        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset = dataset_option

        # Separador despu√©s del selector
        st.markdown("---")
    else:
        # Para otras pesta√±as, mostrar qu√© dataset est√° seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset'):
            st.info(
                f"üìä **Dataset actual:** {st.session_state.selected_dataset}")
            st.markdown("---")

    # Pesta√±a de Datos
    if st.session_state.active_tab == 0:
        st.header("Exploraci√≥n de Datos")

        try:
            # Cargar datos para exploraci√≥n
            X, y, feature_names, class_names, dataset_info, task_type = load_data(
                st.session_state.selected_dataset)

            # Convertir a DataFrames para facilitar el manejo
            # FIXED: No sobrescribir las columnas si X ya es DataFrame para evitar NaN
            if isinstance(X, pd.DataFrame):
                X_df = X.copy()  # Usar las columnas originales
                # Crear mapeo de nombres para mostrar
                column_mapping = {}
                if len(feature_names) == len(X_df.columns):
                    column_mapping = dict(zip(X_df.columns, feature_names))
            else:
                X_df = pd.DataFrame(X, columns=feature_names)
                column_mapping = {}

            y_df = pd.Series(y, name="target")

            # Mapear nombres de clases si est√°n disponibles
            if task_type == "Clasificaci√≥n" and class_names is not None:
                y_df = y_df.map(
                    {i: name for i, name in enumerate(class_names)})

            df = pd.concat([X_df, y_df], axis=1)

            # Renombrar columnas para mostrar nombres amigables si existe el mapeo
            if column_mapping:
                df_display = df.rename(columns=column_mapping)
            else:
                df_display = df

            # Mostrar informaci√≥n del dataset
            st.markdown("### Informaci√≥n del Dataset")
            st.markdown(create_info_box(dataset_info), unsafe_allow_html=True)

            # Mostrar las primeras filas de los datos
            st.markdown("### Vista previa de datos")
            st.dataframe(df_display.head(10))

            # Estad√≠sticas descriptivas
            st.markdown("### Estad√≠sticas Descriptivas")
            st.dataframe(df_display.describe())

            # Distribuci√≥n de clases o valores objetivo
            st.markdown("### Distribuci√≥n del Objetivo")

            fig, ax = plt.subplots(figsize=(10, 6))

            if task_type == "Clasificaci√≥n":
                # Gr√°fico de barras para clasificaci√≥n
                value_counts = y_df.value_counts().sort_index()
                sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
                ax.set_title("Distribuci√≥n de Clases")
                ax.set_xlabel("Clase")
                ax.set_ylabel("Cantidad")

                # Rotar etiquetas si son muchas
                if len(value_counts) > 3:
                    plt.xticks(rotation=45, ha='right')
            else:
                # Histograma para regresi√≥n
                # Convertir a num√©rico en caso de que sean strings
                y_numeric = pd.to_numeric(y_df, errors='coerce')
                # Usar matplotlib directamente para evitar problemas de tipo
                ax.hist(y_numeric.dropna(), bins=30,
                        alpha=0.7, edgecolor='black')
                ax.set_title("Distribuci√≥n de Valores Objetivo")
                ax.set_xlabel("Valor")
                ax.set_ylabel("Frecuencia")

            # Mostrar la figura con tama√±o reducido pero expandible
            col1, col2, col3 = st.columns([1, 3, 1])
            with col2:
                st.pyplot(fig, use_container_width=True)

            # An√°lisis de correlaci√≥n
            st.markdown("### Matriz de Correlaci√≥n")

            # Matriz de correlaci√≥n
            corr = X_df.corr()

            # Generar m√°scara para el tri√°ngulo superior
            mask = np.triu(np.ones_like(corr, dtype=bool))

            # Generar mapa de calor
            fig_corr, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
                        square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
            ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

            # Mostrar la figura con tama√±o reducido pero expandible
            col1, col2, col3 = st.columns([1, 3, 1])
            with col2:
                st.pyplot(fig_corr, use_container_width=True)

            # Matriz de dispersi√≥n (Scatterplot Matrix)
            st.markdown("### Matriz de Dispersi√≥n (Pairplot)")

            # Opciones de visualizaci√≥n
            st.markdown("#### Opciones de visualizaci√≥n")
            col1, col2 = st.columns(2)

            with col1:
                # Seleccionar tipo de gr√°fico para la diagonal
                diag_kind = st.radio(
                    "Tipo de gr√°fico en la diagonal:",
                    ["Histograma", "KDE (Estimaci√≥n de Densidad)"],
                    index=1,
                    horizontal=True
                )
                diag_kind = "hist" if diag_kind == "Histograma" else "kde"

            with col2:
                # Seleccionar n√∫mero m√°ximo de caracter√≠sticas
                max_features_selected = st.slider(
                    "N√∫mero m√°ximo de caracter√≠sticas:",
                    min_value=2,
                    max_value=min(6, len(X_df.columns)),
                    value=min(4, len(X_df.columns)),
                    help="Un n√∫mero mayor de caracter√≠sticas puede hacer que el gr√°fico sea m√°s dif√≠cil de interpretar."
                )

            # Permitir al usuario seleccionar las caracter√≠sticas espec√≠ficas
            st.markdown("#### Selecciona las caracter√≠sticas para visualizar")

            # Limitar a max_features_selected
            # Usar nombres amigables si est√°n disponibles, sino usar originales
            if column_mapping:
                available_features = list(
                    column_mapping.values())  # Nombres amigables
                display_to_original = {
                    v: k for k, v in column_mapping.items()}  # Mapeo inverso
            else:
                available_features = X_df.columns.tolist()
                display_to_original = {}

            # Usar multiselect para seleccionar caracter√≠sticas
            selected_features = st.multiselect(
                "Caracter√≠sticas a incluir en la matriz de dispersi√≥n:",
                available_features,
                default=available_features[:max_features_selected],
                max_selections=max_features_selected,
                help=f"Selecciona hasta {max_features_selected} caracter√≠sticas para incluir en la visualizaci√≥n."
            )

            # Si no se seleccion√≥ ninguna caracter√≠stica, usar las primeras por defecto
            if not selected_features:
                selected_features = available_features[:max_features_selected]
                st.info(
                    f"No se seleccionaron caracter√≠sticas. Usando las primeras {max_features_selected} por defecto.")

            # Convertir nombres amigables a nombres originales si es necesario
            if column_mapping:
                original_features = [display_to_original[feat]
                                     for feat in selected_features]
            else:
                original_features = selected_features

            # Crear el dataframe para la visualizaci√≥n
            plot_df = X_df[original_features].copy()
            # Renombrar a nombres amigables para visualizaci√≥n
            if column_mapping:
                plot_df = plot_df.rename(columns=column_mapping)
            # A√±adir la variable objetivo para colorear
            plot_df['target'] = y_df

            # Generar el pairplot
            with st.spinner("Generando matriz de dispersi√≥n..."):
                pair_plot = sns.pairplot(
                    plot_df,
                    hue='target',
                    diag_kind=diag_kind,
                    plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
                    diag_kws={'alpha': 0.5},
                    height=2.0  # Reducir altura para que sea m√°s compacto
                )
                pair_plot.fig.suptitle(
                    "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=14)

                # Mostrar la figura con tama√±o reducido pero expandible
                col1, col2, col3 = st.columns([1, 3, 1])
                with col2:
                    st.pyplot(pair_plot.fig, use_container_width=True)

                # Enlace para descargar
                st.markdown(
                    get_image_download_link(
                        pair_plot.fig, "matriz_dispersion", "üì• Descargar matriz de dispersi√≥n"),
                    unsafe_allow_html=True
                )

            # Generar c√≥digo para este an√°lisis
            code = """
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar tus datos (reemplaza esto con tu m√©todo de carga)
# df = pd.read_csv('tu_archivo.csv')

# Separar caracter√≠sticas y objetivo
X = df.iloc[:, :-1]  # Todas las columnas excepto la √∫ltima
y = df.iloc[:, -1]   # √öltima columna como objetivo

# Estad√≠sticas descriptivas
print(df.describe())

# Distribuci√≥n del objetivo
fig, ax = plt.subplots(figsize=(10, 6))

# Para clasificaci√≥n:
if len(np.unique(y)) <= 10:  # Si hay pocas clases √∫nicas
    value_counts = y.value_counts().sort_index()
    sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
    ax.set_title("Distribuci√≥n de Clases")
    ax.set_xlabel("Clase")
    ax.set_ylabel("Cantidad")
else:  # Para regresi√≥n
    sns.histplot(y, kde=True, ax=ax)
    ax.set_title("Distribuci√≥n de Valores Objetivo")
    ax.set_xlabel("Valor")
    ax.set_ylabel("Frecuencia")

plt.tight_layout()
plt.show()

# Matriz de correlaci√≥n
corr = X.corr()
# M√°scara para tri√°ngulo superior
mask = np.triu(np.ones_like(corr, dtype=bool))

fig, ax = plt.subplots(figsize=(12, 10))
sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
           square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

plt.tight_layout()
plt.show()

# Matriz de dispersi√≥n (Scatterplot Matrix)
# Seleccionar caracter√≠sticas espec√≠ficas para visualizar
# Reemplaza con tus caracter√≠sticas de inter√©s
selected_features = ['feature1', 'feature2', 'feature3']
max_features = min(6, len(selected_features))

# Crear el dataframe para la visualizaci√≥n
plot_df = X[selected_features].copy()
plot_df['target'] = y  # A√±adir la variable objetivo para colorear

# Generar el pairplot
pair_plot = sns.pairplot(
    plot_df,
    hue='target',
    diag_kind='kde',  # Opciones: 'hist' para histograma o 'kde' para densidad
    plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
    diag_kws={'alpha': 0.5},
    height=2.5
)
pair_plot.fig.suptitle(
    "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=16)
plt.tight_layout()
plt.show()
"""

            show_code_with_download(
                code, "C√≥digo para an√°lisis exploratorio", "analisis_exploratorio.py")

        except Exception as e:
            st.error(f"Error al cargar el dataset: {str(e)}")
            st.info(
                "Por favor, selecciona un dataset v√°lido para continuar con la exploraci√≥n.")

    # Pesta√±a de Entrenamiento
    elif st.session_state.active_tab == 1:
        st.header("Configuraci√≥n del Modelo")

        # Inicializar session state variables
        if 'dataset_option' not in st.session_state:
            st.session_state.dataset_option = st.session_state.selected_dataset
        if 'tree_type' not in st.session_state:
            st.session_state.tree_type = "Clasificaci√≥n"
        if 'is_trained' not in st.session_state:
            st.session_state.is_trained = False

        # Cargar datos para la vista previa si cambia el dataset o si no se ha cargado
        if st.session_state.selected_dataset != st.session_state.dataset_option or not dataset_loaded:
            try:
                X, y, feature_names, class_names, dataset_info, task_type = load_data(
                    st.session_state.selected_dataset)

                st.session_state.dataset_option = st.session_state.selected_dataset
                dataset_loaded = True

                # Mostrar informaci√≥n del dataset
                st.markdown("### Informaci√≥n del Dataset")
                st.markdown(create_info_box(dataset_info),
                            unsafe_allow_html=True)

                # Usar el tipo de tarea detectado por la funci√≥n load_data
                st.markdown("### Tipo de √Årbol de Decisi√≥n")

                # Usar botones en lugar de radio para seleccionar el tipo de √°rbol
                tipo_col1, tipo_col2 = st.columns(2)

                with tipo_col1:
                    is_classification = True
                    if "tree_type" in st.session_state:
                        is_classification = st.session_state.tree_type == "Clasificaci√≥n"

                    if st.button("üè∑Ô∏è Clasificaci√≥n",
                                 key="btn_classification",
                                 type="primary" if is_classification else "secondary",
                                 use_container_width=True,
                                 help="Para predecir categor√≠as o clases"):
                        tree_type = "Clasificaci√≥n"
                        st.session_state.tree_type = tree_type
                        st.rerun()

                with tipo_col2:
                    is_regression = False
                    if "tree_type" in st.session_state:
                        is_regression = st.session_state.tree_type == "Regresi√≥n"

                    if st.button("üìà Regresi√≥n",
                                 key="btn_regression",
                                 type="primary" if is_regression else "secondary",
                                 use_container_width=True,
                                 help="Para predecir valores num√©ricos continuos"):
                        tree_type = "Regresi√≥n"
                        st.session_state.tree_type = tree_type
                        st.rerun()

                # Obtener el valor actual del tipo de √°rbol
                tree_type = st.session_state.get('tree_type', task_type)

                # Si no hay tree_type definido, usar el detectado
                if 'tree_type' not in st.session_state:
                    st.session_state.tree_type = task_type

                # Mostrar advertencia si la selecci√≥n no coincide con el tipo de tarea detectado
                if tree_type != task_type:
                    st.warning(
                        f"Este dataset parece ser m√°s adecuado para {task_type}. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")

            except Exception as e:
                st.error(f"Error al cargar el dataset: {str(e)}")
                dataset_loaded = False

        # Par√°metros del modelo
        st.markdown("### Par√°metros del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            criterion = st.selectbox(
                "Criterio de Divisi√≥n:",
                ["gini", "entropy"] if st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" else [
                    "squared_error", "friedman_mse", "absolute_error"],
                index=0,
                help="Medida de la calidad de una divisi√≥n. Gini o Entropy para clasificaci√≥n, MSE para regresi√≥n."
            )

            max_depth = st.slider(
                "Profundidad M√°xima:",
                min_value=1,
                max_value=10,
                value=3,
                help="La profundidad m√°xima del √°rbol. A mayor profundidad, m√°s complejo el modelo."
            )

        with col2:
            min_samples_split = st.slider(
                "Muestras M√≠nimas para Divisi√≥n:",
                min_value=2,
                max_value=10,
                value=2,
                help="N√∫mero m√≠nimo de muestras para dividir un nodo."
            )

            test_size = st.slider(
                "Tama√±o del Conjunto de Prueba:",
                min_value=0.1,
                max_value=0.5,
                value=0.3,
                step=0.05,
                help="Proporci√≥n de datos que se usar√° para evaluar el modelo."
            )

        # Guardar par√°metros en el estado de la sesi√≥n
        st.session_state.criterion = criterion
        st.session_state.max_depth = max_depth
        st.session_state.min_samples_split = min_samples_split
        st.session_state.test_size = test_size

        # Bot√≥n para entrenar el modelo
        train_button = st.button("Entrenar Modelo", type="primary")

        if train_button:
            with st.spinner("Entrenando modelo..."):
                try:
                    # Cargar y preprocesar datos
                    X, y, feature_names, class_names, dataset_info, task_type = load_data(
                        st.session_state.selected_dataset)
                    X_train, X_test, y_train, y_test = preprocess_data(
                        X, y, test_size=test_size)

                    # Entrenar el modelo
                    model_results = train_decision_tree(
                        X_train, y_train,
                        criterion=criterion,
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        tree_type=tree_type
                    )

                    # Extraer el modelo del diccionario de resultados
                    tree_model = model_results["model"]

                    # Guardar en el estado de la sesi√≥n
                    st.session_state.tree_model = tree_model
                    st.session_state.X_train = X_train
                    st.session_state.X_test = X_test
                    st.session_state.y_train = y_train
                    st.session_state.y_test = y_test
                    st.session_state.feature_names = feature_names
                    st.session_state.class_names = class_names
                    st.session_state.dataset_info = dataset_info
                    st.session_state.is_trained = True

                    # Evaluar el modelo
                    if tree_type == "Clasificaci√≥n":
                        # Obtener predicciones del modelo
                        y_pred = tree_model.predict(X_test)
                        st.session_state.test_results = evaluate_classification_model(
                            y_test, y_pred, class_names
                        )
                    else:
                        # Obtener predicciones del modelo
                        y_pred = tree_model.predict(X_test)
                        st.session_state.test_results = evaluate_regression_model(
                            y_test, y_pred
                        )

                    st.success(
                        "¬°Modelo entrenado con √©xito! Ahora puedes explorar las otras pesta√±as.")

                    # Sugerir ir a la pesta√±a de visualizaci√≥n
                    st.info(
                        "üëâ Ve a la pesta√±a 'üå≤ Visualizaci√≥n' para ver el √°rbol generado.")

                except Exception as e:
                    st.error(f"Error al entrenar el modelo: {str(e)}")

    # Pesta√±a de Evaluaci√≥n
    elif st.session_state.active_tab == 2:
        st.header("Evaluaci√≥n del Modelo")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Obtener predicciones del modelo
            y_pred = st.session_state.tree_model.predict(
                st.session_state.X_test)

            # Mostrar evaluaci√≥n detallada del modelo
            show_detailed_evaluation(
                st.session_state.y_test,
                y_pred,
                st.session_state.class_names if st.session_state.get(
                    'tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" else None,
                st.session_state.get('tree_type', 'Clasificaci√≥n')
            )

            # Decisi√≥n boundary si es clasificaci√≥n y tiene 2 caracter√≠sticas
            if st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" and st.session_state.X_train.shape[1] <= 2:
                st.markdown("### Frontera de Decisi√≥n")

                if st.session_state.X_train.shape[1] == 1:
                    # Caso especial: solo una caracter√≠stica - agregar una segunda artificial
                    if hasattr(st.session_state.X_train, 'values'):
                        # DataFrame
                        X_values = st.session_state.X_train.values
                    else:
                        # numpy array
                        X_values = st.session_state.X_train
                    X_plot = np.column_stack(
                        [X_values, np.zeros_like(X_values)])
                    feature_idx = [0]
                    feature_names_plot = [
                        st.session_state.feature_names[0], "Caracter√≠stica artificial"]
                else:
                    # Dos caracter√≠sticas - dejar seleccionar cu√°les usar
                    st.markdown(
                        "Selecciona las caracter√≠sticas para visualizar la frontera de decisi√≥n:")
                    col1, col2 = st.columns(2)

                    with col1:
                        feature1 = st.selectbox(
                            "Primera caracter√≠stica:",
                            st.session_state.feature_names,
                            index=0
                        )

                    with col2:
                        feature2 = st.selectbox(
                            "Segunda caracter√≠stica:",
                            st.session_state.feature_names,
                            index=min(
                                1, len(st.session_state.feature_names) - 1)
                        )

                    feature_idx = [st.session_state.feature_names.index(feature1),
                                   st.session_state.feature_names.index(feature2)]

                    # Manejar DataFrame vs numpy array
                    if hasattr(st.session_state.X_train, 'iloc'):
                        # DataFrame
                        X_plot = st.session_state.X_train.iloc[:,
                                                               feature_idx].values
                    else:
                        # numpy array
                        X_plot = st.session_state.X_train[:, feature_idx]
                    feature_names_plot = [feature1, feature2]

                # Generar y mostrar el plot en tama√±o reducido
                try:
                    fig, ax = plot_decision_boundary(
                        st.session_state.tree_model,
                        X_plot,
                        st.session_state.y_train,
                        feature_names=feature_names_plot,
                        class_names=st.session_state.class_names
                    )

                    # Mostrar en columnas para reducir el tama√±o al 75%
                    col1, col2, col3 = st.columns([1, 3, 1])
                    with col2:
                        # Mostrar la figura directamente
                        plt.tight_layout()
                        st.pyplot(fig, clear_figure=True,
                                  use_container_width=True)

                    # Enlace para descargar
                    st.markdown(
                        get_image_download_link(
                            fig, "frontera_decision", "üì• Descargar visualizaci√≥n de la frontera"),
                        unsafe_allow_html=True
                    )
                except Exception as e:
                    st.error(
                        f"Error al mostrar la visualizaci√≥n de frontera de decisi√≥n: {str(e)}")
                    st.info(
                        "La frontera de decisi√≥n requiere exactamente 2 caracter√≠sticas para visualizarse.")

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_boundary = """
import numpy as np
import matplotlib.pyplot as plt
from sklearn.inspection import DecisionBoundaryDisplay

def plot_decision_boundary(model, X, y, feature_names=None, class_names=None):
    \"\"\"
    Visualiza la frontera de decisi√≥n para un modelo con 2 caracter√≠sticas.

    Parameters:
    -----------
    model : Modelo de scikit-learn
        Modelo entrenado con m√©todo predict
    X : array-like
        Datos de caracter√≠sticas (solo se usan las primeras 2 columnas)
    y : array-like
        Etiquetas de clase
    feature_names : list, opcional
        Nombres de las caracter√≠sticas
    class_names : list, opcional
        Nombres de las clases

    Returns:
    --------
    fig : Figura de matplotlib
    \"\"\"
    # Asegurar que solo usamos 2 caracter√≠sticas
    X_plot = X[:, :2] if X.shape[1] > 2 else X

    # Crear figura
    fig, ax = plt.subplots(figsize=(8, 6))

    # Crear objeto de visualizaci√≥n de frontera
    disp = DecisionBoundaryDisplay.from_estimator(
        model,
        X_plot,
        alpha=0.5,
        ax=ax,
        response_method="predict"
    )

    # Colorear los puntos seg√∫n su clase
    scatter = ax.scatter(
        X_plot[:, 0],
        X_plot[:, 1],
        c=y,
        edgecolor="k",
        s=50
    )

    # Configurar etiquetas
    if feature_names and len(feature_names) >= 2:
        ax.set_xlabel(feature_names[0])
        ax.set_ylabel(feature_names[1])
    else:
        ax.set_xlabel("Caracter√≠stica 1")
        ax.set_ylabel("Caracter√≠stica 2")

    # Configurar leyenda
    if class_names:
        legend_labels = class_names
    else:
        legend_labels = [f"Clase {i}" for i in range(len(np.unique(y)))]

    legend = ax.legend(
        handles=scatter.legend_elements()[0],
        labels=legend_labels,
        title="Clases"
    )

    ax.add_artist(legend)
    ax.set_title("Frontera de Decisi√≥n")

    return fig

# Para usar:
# fig = plot_decision_boundary(model, X, y, feature_names, class_names)
# plt.show()
"""

                show_code_with_download(
                    code_boundary, "C√≥digo para generar la frontera de decisi√≥n",
                    "frontera_decision.py"
                )

    # Pesta√±a de Visualizaci√≥n
    elif st.session_state.active_tab == 3:
        st.header("Visualizaci√≥n del √Årbol")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Configuraci√≥n de la visualizaci√≥n
            st.markdown("### Tipo de visualizaci√≥n")

            # Usar botones para seleccionar el tipo de visualizaci√≥n
            if "viz_type" not in st.session_state:
                st.session_state.viz_type = "Est√°ndar"

            # Determinar si mostrar la opci√≥n de frontera de decisi√≥n
            show_boundary = (st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n"
                             and len(st.session_state.get('feature_names', [])) >= 2)

            if show_boundary:
                viz_col1, viz_col2, viz_col3 = st.columns(3)
            else:
                viz_col1, viz_col2 = st.columns(2)
                viz_col3 = None

            with viz_col1:
                if st.button("üìä Est√°ndar",
                             key="viz_standard",
                             type="primary" if st.session_state.viz_type == "Est√°ndar" else "secondary",
                             use_container_width=True):
                    st.session_state.viz_type = "Est√°ndar"
                    st.rerun()

            with viz_col2:
                if st.button("üìù Texto",
                             key="viz_text",
                             type="primary" if st.session_state.viz_type == "Texto" else "secondary",
                             use_container_width=True):
                    st.session_state.viz_type = "Texto"
                    st.rerun()

            if show_boundary and viz_col3:
                with viz_col3:
                    if st.button("üåà Frontera",
                                 key="viz_boundary",
                                 type="primary" if st.session_state.viz_type == "Frontera" else "secondary",
                                 use_container_width=True):
                        st.session_state.viz_type = "Frontera"
                        st.rerun()

            viz_type = st.session_state.viz_type

            # Opciones de tama√±o para la visualizaci√≥n
            col1, col2 = st.columns(2)

            with col1:
                fig_width = st.slider("Ancho de figura:", 8, 20, 14)

            with col2:
                fig_height = st.slider("Alto de figura:", 6, 15, 10)

            # Mostrar la visualizaci√≥n seg√∫n el tipo seleccionado
            if viz_type == "Est√°ndar":
                # Visualizaci√≥n est√°ndar de scikit-learn
                fig, ax = plt.subplots(figsize=(fig_width, fig_height))
                from sklearn.tree import plot_tree

                plot_tree(
                    st.session_state.tree_model,
                    feature_names=st.session_state.feature_names,
                    class_names=st.session_state.class_names if st.session_state.tree_type == "Clasificaci√≥n" else None,
                    filled=True,
                    rounded=True,
                    ax=ax,
                    proportion=True,
                    impurity=True
                )

                # Mostrar con tama√±o reducido pero expandible
                col1, col2, col3 = st.columns([1, 4, 1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Enlace para descargar
                st.markdown(
                    get_image_download_link(
                        fig, "arbol_decision", "üì• Descargar visualizaci√≥n del √°rbol"),
                    unsafe_allow_html=True
                )

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_tree = """
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# Suponiendo que ya tienes un modelo entrenado (tree_model)
# y los nombres de las caracter√≠sticas (feature_names) y clases (class_names)

fig, ax = plt.subplots(figsize=(14, 10))

plot_tree(
    tree_model,
    feature_names=feature_names,
    class_names=class_names,  # Solo para clasificaci√≥n
    filled=True,
    rounded=True,
    ax=ax,
    proportion=True,
    impurity=True
)

plt.tight_layout()
plt.show()

# Para guardar a un archivo:
# plt.savefig('arbol_decision.png', dpi=300, bbox_inches='tight')
"""

                show_code_with_download(
                    code_tree, "C√≥digo para visualizar el √°rbol", "visualizar_arbol.py")

            elif viz_type == "Texto":
                # Obtener representaci√≥n de texto
                tree_text = get_tree_text(
                    st.session_state.tree_model,
                    st.session_state.feature_names,
                )

                # Mostrar en un √°rea de texto
                st.text(tree_text)

                # Bot√≥n para descargar
                text_bytes = tree_text.encode()
                b64 = base64.b64encode(text_bytes).decode()
                href = f'<a href="data:text/plain;base64,{b64}" download="arbol_texto.txt">üì• Descargar texto del √°rbol</a>'
                st.markdown(href, unsafe_allow_html=True)

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_text = """
from sklearn.tree import export_text

def get_tree_text(model, feature_names, show_class_name=True):
    \"\"\"
    Obtiene una representaci√≥n de texto de un √°rbol de decisi√≥n.

    Parameters:
    -----------
    model : DecisionTreeClassifier o DecisionTreeRegressor
        Modelo de √°rbol entrenado
    feature_names : list
        Nombres de las caracter√≠sticas
    show_class_name : bool
        Si es True, muestra los nombres de las clases (para clasificaci√≥n)

    Returns:
    --------
    str
        Representaci√≥n de texto del √°rbol
    \"\"\"
    return export_text(
        model,
        feature_names=feature_names,
        show_weights=True
    )

# Ejemplo de uso:
tree_text = get_tree_text(tree_model, feature_names)
print(tree_text)

# Para guardar a un archivo:
# with open('arbol_texto.txt', 'w') as f:
#     f.write(tree_text)
"""

                show_code_with_download(
                    code_text, "C√≥digo para obtener el texto del √°rbol", "texto_arbol.py")

            elif viz_type == "Frontera":
                # Visualizaci√≥n de frontera de decisi√≥n
                st.markdown("### Visualizaci√≥n de Frontera de Decisi√≥n")

                st.info("""
                **C√≥mo interpretar esta visualizaci√≥n:**
                - Las √°reas coloreadas muestran las regiones de decisi√≥n para cada clase
                - Los puntos representan las muestras de entrenamiento
                - Las l√≠neas entre colores son las fronteras de decisi√≥n
                - Solo se muestran las primeras dos caracter√≠sticas para crear la visualizaci√≥n 2D
                """)

                # Selecci√≥n de caracter√≠sticas para la visualizaci√≥n
                if len(st.session_state.feature_names) > 2:
                    cols = st.columns(2)
                    with cols[0]:
                        feature1 = st.selectbox(
                            "Primera caracter√≠stica:",
                            st.session_state.feature_names,
                            index=0,
                            key="feature1_boundary_viz"
                        )
                    with cols[1]:
                        feature2 = st.selectbox(
                            "Segunda caracter√≠stica:",
                            st.session_state.feature_names,
                            index=1,
                            key="feature2_boundary_viz"
                        )

                    # Obtener √≠ndices de las caracter√≠sticas seleccionadas
                    feature_names_list = list(st.session_state.feature_names)
                    f1_idx = feature_names_list.index(feature1)
                    f2_idx = feature_names_list.index(feature2)

                    # Crear array con solo las dos caracter√≠sticas seleccionadas
                    # Verificar si X_train es DataFrame o numpy array
                    if hasattr(st.session_state.X_train, 'iloc'):
                        # Es un DataFrame, usar iloc para indexaci√≥n posicional
                        X_boundary = st.session_state.X_train.iloc[:, [
                            f1_idx, f2_idx]].values
                    else:
                        # Es un numpy array, usar indexaci√≥n normal
                        X_boundary = st.session_state.X_train[:, [
                            f1_idx, f2_idx]]
                    feature_names_boundary = [feature1, feature2]
                else:
                    # Si solo hay dos caracter√≠sticas, usarlas directamente
                    if hasattr(st.session_state.X_train, 'values'):
                        # Es un DataFrame, convertir a numpy array
                        X_boundary = st.session_state.X_train.values
                    else:
                        # Es un numpy array
                        X_boundary = st.session_state.X_train
                    feature_names_boundary = st.session_state.feature_names

                # Crear figura y dibujar frontera de decisi√≥n
                try:
                    fig, ax = plt.subplots(figsize=(fig_width, fig_height))
                    plot_decision_boundary(
                        st.session_state.tree_model,
                        X_boundary,
                        st.session_state.y_train,
                        ax=ax,
                        feature_names=feature_names_boundary,
                        class_names=st.session_state.class_names,
                        show_code=False
                    )

                    # Mostrar la figura
                    col1, col2, col3 = st.columns([1, 4, 1])
                    with col2:
                        st.pyplot(fig, use_container_width=True)

                    # Enlace para descargar
                    st.markdown(
                        get_image_download_link(
                            fig, "frontera_decision", "üì• Descargar visualizaci√≥n de frontera"),
                        unsafe_allow_html=True
                    )

                    # Explicaci√≥n adicional
                    st.markdown("""
                    **Nota:** Esta visualizaci√≥n muestra c√≥mo el √°rbol de decisi√≥n divide el espacio de caracter√≠sticas
                    en regiones de decisi√≥n. Cada color representa una clase diferente. 
                    
                    Para crear esta visualizaci√≥n 2D, se entrena un nuevo √°rbol utilizando solo las dos caracter√≠sticas 
                    seleccionadas, por lo que puede diferir ligeramente del modelo completo que utiliza todas las caracter√≠sticas.
                    """)

                    # Advertencia sobre dimensionalidad
                    if len(st.session_state.feature_names) > 2:
                        st.warning("""
                        ‚ö†Ô∏è Esta visualizaci√≥n solo muestra 2 caracter√≠sticas seleccionadas. El modelo real utiliza todas 
                        las caracter√≠sticas para hacer predicciones. Las fronteras pueden variar si se seleccionan 
                        diferentes pares de caracter√≠sticas.
                        """)

                    # Mostrar c√≥digo para generar esta visualizaci√≥n
                    code_boundary = f"""
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from decision_boundary import plot_decision_boundary

# Datos de entrenamiento (solo las primeras 2 caracter√≠sticas)
X_2d = X_train[:, [0, 1]]  # Usar las caracter√≠sticas seleccionadas
y_train = y_train

# Crear figura
fig, ax = plt.subplots(figsize=({fig_width}, {fig_height}))

# Visualizar frontera de decisi√≥n
plot_decision_boundary(
    tree_model,
    X_2d,
    y_train,
    ax=ax,
    feature_names={feature_names_boundary},
    class_names={st.session_state.class_names if st.session_state.class_names else None}
)

plt.tight_layout()
plt.show()

# Para guardar a un archivo:
# plt.savefig('frontera_decision.png', dpi=300, bbox_inches='tight')
"""

                    show_code_with_download(
                        code_boundary, "C√≥digo para generar la frontera de decisi√≥n", "frontera_decision.py")

                except Exception as e:
                    st.error(
                        f"Error al mostrar la visualizaci√≥n de frontera de decisi√≥n: {str(e)}")
                    st.info("""
                    La frontera de decisi√≥n requiere:
                    - Un modelo de clasificaci√≥n entrenado
                    - Exactamente 2 caracter√≠sticas para visualizar
                    - Datos de entrenamiento v√°lidos
                    """)
                    st.exception(
                        e)  # Mostrar detalles del error para debugging

    # Pesta√±a de Caracter√≠sticas
    elif st.session_state.active_tab == 4:
        st.header("Importancia de Caracter√≠sticas")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Mostrar importancia de caracter√≠sticas
            display_feature_importance(
                st.session_state.tree_model,
                st.session_state.feature_names
            )

    # Pesta√±a de Predicciones
    elif st.session_state.active_tab == 5:
        st.header("Predicciones con Nuevos Datos")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Interfaz para hacer predicciones
            create_prediction_interface(
                st.session_state.tree_model,
                st.session_state.feature_names,
                st.session_state.class_names,
                st.session_state.get('tree_type', 'Clasificaci√≥n'),
                # Pasar datos de entrenamiento para rangos din√°micos
                st.session_state.get('X_train', None),
                # Pasar nombre del dataset para metadata
                st.session_state.get('selected_dataset', 'Titanic')
            )

    # Pesta√±a de Exportar Modelo
    elif st.session_state.active_tab == 6:
        st.header("Exportar Modelo")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Opciones para exportar el modelo
            display_model_export_options(
                st.session_state.tree_model,
                st.session_state.feature_names,
                st.session_state.class_names,
                st.session_state.get('tree_type', 'Clasificaci√≥n'),
                st.session_state.get('max_depth', 3),
                st.session_state.get('min_samples_split', 2),
                st.session_state.get('criterion', 'gini')
            )


def run_linear_regression_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de regresi√≥n (lineal y log√≠stica)."""
    st.header("üìä Regresi√≥n")
    st.markdown(
        "Aprende sobre regresi√≥n lineal y log√≠stica de forma interactiva")

    # Informaci√≥n sobre regresi√≥n
    with st.expander("‚ÑπÔ∏è ¬øQu√© es la Regresi√≥n?", expanded=False):
        st.markdown("""
        La regresi√≥n es un conjunto de algoritmos de aprendizaje supervisado utilizados para predecir valores num√©ricos continuos (regresi√≥n lineal) o clasificar elementos en categor√≠as (regresi√≥n log√≠stica).

        **Caracter√≠sticas principales:**
        - **Regresi√≥n Lineal**: Establece una relaci√≥n lineal entre las variables independientes (caracter√≠sticas) y la variable dependiente (objetivo)
        - **Regresi√≥n Log√≠stica**: Utiliza la funci√≥n log√≠stica para modelar la probabilidad de pertenencia a una clase
        - Ambos tipos minimizan funciones de costo espec√≠ficas para encontrar los mejores par√°metros
        - Son interpretables: los coeficientes indican la importancia y direcci√≥n del efecto de cada caracter√≠stica
        - No requieren escalado de datos, aunque puede mejorar la convergencia

        **Tipos de regresi√≥n:**
        - **Regresi√≥n Lineal Simple**: Una sola caracter√≠stica predictora
        - **Regresi√≥n Lineal M√∫ltiple**: M√∫ltiples caracter√≠sticas predictoras
        - **Regresi√≥n Log√≠stica**: Para problemas de clasificaci√≥n binaria o multiclase

        **Limitaciones:**
        - Asume una relaci√≥n lineal entre variables (regresi√≥n lineal)
        - Sensible a valores at√≠picos (outliers)
        - Puede sufrir de multicolinealidad cuando las caracter√≠sticas est√°n correlacionadas
        """)

    # Variables para almacenar datos
    dataset_loaded = False
    X, y, feature_names, class_names, dataset_info, task_type = None, None, None, None, None, None

    # Inicializar el estado de la pesta√±a activa si no existe
    if 'active_tab_lr' not in st.session_state:
        st.session_state.active_tab_lr = 0

    # Crear pesta√±as para organizar la informaci√≥n
    tab_options = [
        "üìä Datos",
        "üèãÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üìâ Visualizaci√≥n",
        "üîç Coeficientes",
        "üîÆ Predicciones",
        "üíæ Exportar Modelo"
    ]

    # Crear contenedor para los botones de las pesta√±as
    tab_cols = st.columns(len(tab_options))

    # Crear botones para las pesta√±as
    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_lr_{i}"
        button_style = "tab-button-active" if st.session_state.active_tab_lr == i else "tab-button"

        with col:
            st.markdown(f"<div class='{button_style}'>",
                        unsafe_allow_html=True)
            if st.button(tab_name, key=button_key, use_container_width=True):
                st.session_state.active_tab_lr = i
                st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    # Separador visual
    st.markdown("---")

    # SELECTOR UNIFICADO DE DATASET (solo mostrar en pesta√±as que lo necesiten)
    if st.session_state.active_tab_lr in [0, 1]:  # Exploraci√≥n y Entrenamiento
        st.markdown("### üìä Selecci√≥n de Dataset")

        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset_lr' not in st.session_state:
            st.session_state.selected_dataset_lr = "üí∞ Propinas - Predicci√≥n de propinas"

        # Lista de datasets adecuados para regresi√≥n
        regression_datasets = [
            "üí∞ Propinas - Predicci√≥n de propinas",
            "üè† Viviendas California - Precios",
            "üå∏ Iris - Clasificaci√≥n de flores",  # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üç∑ Vino - Clasificaci√≥n de vinos",   # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üî¨ C√°ncer - Diagn√≥stico binario",   # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üö¢ Titanic - Supervivencia",        # Tambi√©n √∫til para regresi√≥n log√≠stica
            # Tambi√©n √∫til para regresi√≥n log√≠stica
            "üêß Ping√ºinos - Clasificaci√≥n de especies"
        ]

        # A√±adir datasets CSV cargados si existen
        available_datasets = regression_datasets.copy()
        if 'csv_datasets' in st.session_state:
            available_datasets.extend(st.session_state.csv_datasets.keys())

        # Asegurar que el dataset seleccionado est√© en la lista disponible
        if st.session_state.selected_dataset_lr not in available_datasets:
            st.session_state.selected_dataset_lr = regression_datasets[0]

        # Selector unificado
        dataset_option = st.selectbox(
            "Dataset:",
            available_datasets,
            index=available_datasets.index(
                st.session_state.selected_dataset_lr),
            key="unified_dataset_selector_lr",
            help="El dataset seleccionado se mantendr√° entre las pesta√±as de Exploraci√≥n y Entrenamiento"
        )

        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset_lr = dataset_option

        # Separador despu√©s del selector
        st.markdown("---")
    else:
        # Para otras pesta√±as, mostrar qu√© dataset est√° seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset_lr'):
            st.info(
                f"üìä **Dataset actual:** {st.session_state.selected_dataset_lr}")
            st.markdown("---")

    # Pesta√±a de Datos
    if st.session_state.active_tab_lr == 0:
        st.header("Exploraci√≥n de Datos")

        try:
            # Cargar datos para exploraci√≥n
            X, y, feature_names, class_names, dataset_info, task_type = load_data(
                st.session_state.selected_dataset_lr)

            # Convertir a DataFrames para facilitar el manejo
            if isinstance(X, pd.DataFrame):
                X_df = X.copy()
                column_mapping = {}
                if len(feature_names) == len(X_df.columns):
                    column_mapping = dict(zip(X_df.columns, feature_names))
            else:
                X_df = pd.DataFrame(X, columns=feature_names)
                column_mapping = {}

            y_df = pd.Series(y, name="target")

            # Para regresi√≥n log√≠stica, mapear nombres de clases si est√°n disponibles
            if task_type == "Clasificaci√≥n" and class_names is not None:
                y_df = y_df.map(
                    {i: name for i, name in enumerate(class_names)})

            df = pd.concat([X_df, y_df], axis=1)

            # Renombrar columnas para mostrar nombres amigables si existe el mapeo
            if column_mapping:
                df_display = df.rename(columns=column_mapping)
            else:
                df_display = df

            # Mostrar informaci√≥n del dataset
            st.markdown("### Informaci√≥n del Dataset")
            st.markdown(create_info_box(dataset_info), unsafe_allow_html=True)

            # Mostrar las primeras filas de los datos
            st.markdown("### Vista previa de datos")
            st.dataframe(df_display.head(10))

            # Estad√≠sticas descriptivas
            st.markdown("### Estad√≠sticas Descriptivas")
            st.dataframe(df_display.describe())

            # Distribuci√≥n de clases o valores objetivo
            st.markdown("### Distribuci√≥n del Objetivo")

            fig, ax = plt.subplots(figsize=(10, 6))

            if task_type == "Clasificaci√≥n":
                # Gr√°fico de barras para clasificaci√≥n (regresi√≥n log√≠stica)
                value_counts = y_df.value_counts().sort_index()
                try:
                    import seaborn as sns
                    sns.barplot(x=value_counts.index,
                                y=value_counts.values, ax=ax)
                except ImportError:
                    # Fallback to matplotlib if seaborn is not available
                    ax.bar(value_counts.index, value_counts.values)
                ax.set_title("Distribuci√≥n de Clases")
                ax.set_xlabel("Clase")
                ax.set_ylabel("Cantidad")

                # Rotar etiquetas si son muchas
                if len(value_counts) > 3:
                    plt.xticks(rotation=45, ha='right')
            else:
                # Histograma para regresi√≥n
                # Convertir a num√©rico en caso de que sean strings
                y_numeric = pd.to_numeric(y_df, errors='coerce')
                # Usar matplotlib directamente para evitar problemas de tipo
                ax.hist(y_numeric.dropna(), bins=30,
                        alpha=0.7, edgecolor='black')
                ax.set_title("Distribuci√≥n de Valores Objetivo")
                ax.set_xlabel("Valor")
                ax.set_ylabel("Frecuencia")

            # Mostrar la figura
            col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
            with col2:
                st.pyplot(fig, use_container_width=True)

            # An√°lisis de correlaci√≥n
            st.markdown("### Matriz de Correlaci√≥n")

            # Matriz de correlaci√≥n
            corr = X_df.corr()

            # Generar m√°scara para el tri√°ngulo superior
            mask = np.triu(np.ones_like(corr, dtype=bool))

            # Generar mapa de calor
            fig_corr, ax = plt.subplots(figsize=(10, 8))
            try:
                import seaborn as sns
                sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
                            square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
            except ImportError:
                # Fallback to matplotlib if seaborn is not available
                im = ax.imshow(corr.where(~mask),
                               cmap="coolwarm", aspect="auto")
                ax.set_xticks(range(len(corr.columns)))
                ax.set_yticks(range(len(corr.columns)))
                ax.set_xticklabels(corr.columns, rotation=45, ha='right')
                ax.set_yticklabels(corr.columns)
                # Add text annotations
                for i in range(len(corr.columns)):
                    for j in range(len(corr.columns)):
                        if not mask[i, j]:
                            text = ax.text(j, i, f'{corr.iloc[i, j]:.2f}',
                                           ha="center", va="center", color="black")
            ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

            # Mostrar la figura
            col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
            with col2:
                st.pyplot(fig_corr, use_container_width=True)

            # Matriz de dispersi√≥n (Scatterplot Matrix)
            st.markdown("### Matriz de Dispersi√≥n (Pairplot)")

            # Opciones de visualizaci√≥n
            st.markdown("#### Opciones de visualizaci√≥n")
            col1, col2 = st.columns(2)

            with col1:
                # Seleccionar tipo de gr√°fico para la diagonal
                diag_kind = st.radio(
                    "Tipo de gr√°fico en la diagonal:",
                    ["Histograma", "KDE (Estimaci√≥n de Densidad)"],
                    index=1,
                    horizontal=True
                )
                diag_kind = "hist" if diag_kind == "Histograma" else "kde"

            with col2:
                # Seleccionar n√∫mero m√°ximo de caracter√≠sticas
                max_features_selected = st.slider(
                    "N√∫mero m√°ximo de caracter√≠sticas:",
                    min_value=2,
                    max_value=min(6, len(X_df.columns)),
                    value=min(4, len(X_df.columns)),
                    help="Un n√∫mero mayor de caracter√≠sticas puede hacer que el gr√°fico sea m√°s dif√≠cil de interpretar."
                )

            # Permitir al usuario seleccionar las caracter√≠sticas espec√≠ficas
            st.markdown("#### Selecciona las caracter√≠sticas para visualizar")

            # Usar nombres amigables si est√°n disponibles
            if column_mapping:
                available_features = list(column_mapping.values())
                display_to_original = {v: k for k, v in column_mapping.items()}
            else:
                available_features = X_df.columns.tolist()
                display_to_original = {}

            # Usar multiselect para seleccionar caracter√≠sticas
            selected_features = st.multiselect(
                "Caracter√≠sticas a incluir en la matriz de dispersi√≥n:",
                available_features,
                default=available_features[:max_features_selected],
                max_selections=max_features_selected,
                help=f"Selecciona hasta {max_features_selected} caracter√≠sticas para incluir en la visualizaci√≥n."
            )

            # Si no se seleccion√≥ ninguna caracter√≠stica, usar las primeras por defecto
            if not selected_features:
                selected_features = available_features[:max_features_selected]
                st.info(
                    f"No se seleccionaron caracter√≠sticas. Usando las primeras {max_features_selected} por defecto.")

            # Convertir nombres amigables a nombres originales si es necesario
            if column_mapping:
                original_features = [display_to_original[feat]
                                     for feat in selected_features]
            else:
                original_features = selected_features

            # Crear el dataframe para la visualizaci√≥n
            plot_df = X_df[original_features].copy()
            # Renombrar a nombres amigables para visualizaci√≥n
            if column_mapping:
                plot_df = plot_df.rename(columns=column_mapping)
            # A√±adir la variable objetivo para colorear
            plot_df['target'] = y_df

            # Generar el pairplot
            with st.spinner("Generando matriz de dispersi√≥n..."):
                try:
                    import seaborn as sns
                    pair_plot = sns.pairplot(
                        plot_df,
                        hue='target' if task_type == "Clasificaci√≥n" else None,
                        diag_kind=diag_kind,
                        plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
                        diag_kws={'alpha': 0.5},
                        height=2.0
                    )
                    pair_plot.fig.suptitle(
                        "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=14)

                    # Mostrar la figura
                    col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                    with col2:
                        st.pyplot(pair_plot.fig, use_container_width=True)

                    # Enlace para descargar
                    st.markdown(
                        get_image_download_link(
                            pair_plot.fig, "matriz_dispersion_lr", "üì• Descargar matriz de dispersi√≥n"),
                        unsafe_allow_html=True
                    )
                except ImportError:
                    st.error(
                        "Seaborn no est√° disponible. Por favor, instala seaborn para usar la matriz de dispersi√≥n.")
                    st.info(
                        "Puedes instalar seaborn ejecutando: pip install seaborn")

        except Exception as e:
            st.error(f"Error al cargar el dataset: {str(e)}")
            st.info(
                "Por favor, selecciona un dataset v√°lido para continuar con la exploraci√≥n.")

    # Pesta√±a de Entrenamiento
    elif st.session_state.active_tab_lr == 1:
        st.header("Configuraci√≥n del Modelo")

        # Inicializar session state variables
        if 'dataset_option_lr' not in st.session_state:
            st.session_state.dataset_option_lr = st.session_state.selected_dataset_lr
        if 'model_type_lr' not in st.session_state:
            st.session_state.model_type_lr = "Linear"
        if 'is_trained_lr' not in st.session_state:
            st.session_state.is_trained_lr = False

        # Cargar datos para la vista previa si cambia el dataset o si no se ha cargado
        if st.session_state.selected_dataset_lr != st.session_state.dataset_option_lr or not dataset_loaded:
            try:
                X, y, feature_names, class_names, dataset_info, task_type = load_data(
                    st.session_state.selected_dataset_lr)

                st.session_state.dataset_option_lr = st.session_state.selected_dataset_lr
                dataset_loaded = True

                # Mostrar informaci√≥n del dataset
                st.markdown("### Informaci√≥n del Dataset")
                st.markdown(create_info_box(dataset_info),
                            unsafe_allow_html=True)

                # Determinar el tipo de modelo seg√∫n el task_type detectado
                st.markdown("### Tipo de Modelo Lineal")

                # Usar botones para seleccionar el tipo de modelo
                tipo_col1, tipo_col2 = st.columns(2)

                with tipo_col1:
                    is_linear = True
                    if "model_type_lr" in st.session_state:
                        is_linear = st.session_state.model_type_lr == "Linear"

                    if st.button("üìà Regresi√≥n Lineal",
                                 key="btn_linear",
                                 type="primary" if is_linear else "secondary",
                                 use_container_width=True,
                                 help="Para predecir valores num√©ricos continuos"):
                        model_type = "Linear"
                        st.session_state.model_type_lr = model_type
                        st.rerun()

                with tipo_col2:
                    is_logistic = False
                    if "model_type_lr" in st.session_state:
                        is_logistic = st.session_state.model_type_lr == "Logistic"

                    if st.button("üè∑Ô∏è Regresi√≥n Log√≠stica",
                                 key="btn_logistic",
                                 type="primary" if is_logistic else "secondary",
                                 use_container_width=True,
                                 help="Para predecir categor√≠as o clases"):
                        model_type = "Logistic"
                        st.session_state.model_type_lr = model_type
                        st.rerun()

                # Obtener el valor actual del tipo de modelo
                model_type = st.session_state.get('model_type_lr', "Linear")

                # Mostrar sugerencia basada en el tipo de tarea detectado
                if task_type == "Clasificaci√≥n" and model_type == "Linear":
                    st.warning(
                        "Este dataset parece ser m√°s adecuado para Regresi√≥n Log√≠stica. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")
                elif task_type == "Regresi√≥n" and model_type == "Logistic":
                    st.warning(
                        "Este dataset parece ser m√°s adecuado para Regresi√≥n Lineal. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")

            except Exception as e:
                st.error(f"Error al cargar el dataset: {str(e)}")
                dataset_loaded = False

        # Par√°metros del modelo
        st.markdown("### Par√°metros del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            # Para regresi√≥n log√≠stica, mostrar par√°metro max_iter
            if st.session_state.get('model_type_lr', 'Linear') == "Logistic":
                max_iter = st.slider(
                    "M√°ximo de Iteraciones:",
                    min_value=100,
                    max_value=2000,
                    value=1000,
                    step=100,
                    help="N√∫mero m√°ximo de iteraciones para el optimizador de regresi√≥n log√≠stica."
                )
            else:
                st.info(
                    "La regresi√≥n lineal no requiere configuraci√≥n adicional de iteraciones.")

        with col2:
            # Configuraciones adicionales pueden ir aqu√≠ en el futuro
            st.empty()

        if st.button("üöÄ Entrenar Modelo", key="train_lr_button", type="primary"):
            if dataset_loaded and X is not None and y is not None:
                with st.spinner("Entrenando modelo..."):
                    try:
                        # Entrenar el modelo
                        if model_type == "Logistic":
                            result = train_linear_model(
                                X, y,
                                model_type=model_type,
                                max_iter=max_iter,
                                test_size=0.2,
                                random_state=42
                            )
                        else:
                            result = train_linear_model(
                                X, y,
                                model_type=model_type,
                                test_size=0.2,
                                random_state=42
                            )

                        # Extraer el modelo y m√©tricas del resultado
                        model = result["model"]
                        metrics = result["test_results"]

                        # Guardar en session state
                        st.session_state.model_lr = model
                        st.session_state.metrics_lr = metrics
                        st.session_state.X_train_lr = result["X_train"]
                        st.session_state.X_test_lr = result["X_test"]
                        st.session_state.y_train_lr = result["y_train"]
                        st.session_state.y_test_lr = result["y_test"]
                        st.session_state.feature_names_lr = feature_names
                        st.session_state.class_names_lr = class_names
                        st.session_state.task_type_lr = task_type
                        st.session_state.model_trained_lr = True

                        st.success("¬°Modelo entrenado exitosamente!")

                    except Exception as e:
                        st.error(f"Error al entrenar el modelo: {str(e)}")
            else:
                st.error("Por favor, carga un dataset v√°lido primero.")

    # Pesta√±a de Evaluaci√≥n
    elif st.session_state.active_tab_lr == 2:
        st.header("Evaluaci√≥n del Modelo")

        if st.session_state.get('model_trained_lr', False):
            metrics = st.session_state.get('metrics_lr', {})
            model_type = st.session_state.get('model_type_lr', 'Linear')

            # Informaci√≥n sobre las m√©tricas
            with st.expander("‚ÑπÔ∏è ¬øQu√© significan estas m√©tricas?", expanded=False):
                if model_type == "Linear":
                    st.markdown("""
                    **M√©tricas de Regresi√≥n Lineal:**
                    
                    **R¬≤ Score (Coeficiente de Determinaci√≥n):**
                    - Mide qu√© tan bien el modelo explica la variabilidad de los datos
                    - Rango: 0 a 1 (valores negativos indican un modelo muy malo)
                    - **Interpretaci√≥n:**
                      - R¬≤ = 1.0: El modelo explica perfectamente toda la variabilidad
                      - R¬≤ = 0.8: El modelo explica el 80% de la variabilidad (muy bueno)
                      - R¬≤ = 0.5: El modelo explica el 50% de la variabilidad (moderado)
                      - R¬≤ = 0.0: El modelo no explica nada de la variabilidad
                    
                    **MAE (Error Absoluto Medio):**
                    - Promedio de las diferencias absolutas entre valores reales y predichos
                    - Se expresa en las mismas unidades que la variable objetivo
                    - **Interpretaci√≥n:** Valores m√°s bajos = mejor modelo
                    
                    **RMSE (Ra√≠z del Error Cuadr√°tico Medio):**
                    - Similar al MAE pero penaliza m√°s los errores grandes
                    - Se expresa en las mismas unidades que la variable objetivo
                    - **Interpretaci√≥n:** Valores m√°s bajos = mejor modelo
                    """)
                else:
                    st.markdown("""
                    **M√©tricas de Regresi√≥n Log√≠stica:**
                    
                    **Accuracy (Exactitud):**
                    - Porcentaje de predicciones correctas del total
                    - Rango: 0 a 1 (0% a 100%)
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor modelo
                    
                    **Precision (Precisi√≥n):**
                    - De todas las predicciones positivas, cu√°ntas fueron correctas
                    - Importante cuando los falsos positivos son costosos
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor modelo
                    
                    **Recall (Sensibilidad):**
                    - De todos los casos positivos reales, cu√°ntos detect√≥ el modelo
                    - Importante cuando los falsos negativos son costosos
                    - **Interpretaci√≥n:** Valores m√°s altos = mejor modelo
                    """)

            st.markdown("### üìä Resultados de Evaluaci√≥n")

            if model_type == "Linear":
                col1, col2, col3 = st.columns(3)
                with col1:
                    r2_value = metrics.get('r2', 0)
                    st.metric("R¬≤ Score", f"{r2_value:.4f}")
                    # Indicador de calidad
                    if r2_value >= 0.8:
                        st.success("üéØ Excelente ajuste")
                    elif r2_value >= 0.6:
                        st.info("üëç Buen ajuste")
                    elif r2_value >= 0.4:
                        st.warning("‚ö†Ô∏è Ajuste moderado")
                    else:
                        st.error("‚ùå Ajuste pobre")

                with col2:
                    mae_value = metrics.get('mae', 0)
                    st.metric("MAE", f"{mae_value:.4f}")

                with col3:
                    rmse_value = metrics.get('rmse', 0)
                    st.metric("RMSE", f"{rmse_value:.4f}")

            else:
                col1, col2, col3 = st.columns(3)
                with col1:
                    acc_value = metrics.get('accuracy', 0)
                    st.metric("Accuracy", f"{acc_value:.4f}")
                    # Indicador de calidad
                    if acc_value >= 0.9:
                        st.success("üéØ Excelente")
                    elif acc_value >= 0.8:
                        st.info("üëç Muy bueno")
                    elif acc_value >= 0.7:
                        st.warning("‚ö†Ô∏è Bueno")
                    else:
                        st.error("‚ùå Necesita mejora")

                with col2:
                    st.metric(
                        "Precision", f"{metrics.get('precision', 0):.4f}")

                with col3:
                    st.metric("Recall", f"{metrics.get('recall', 0):.4f}")

            # Mostrar interpretaci√≥n contextual
            st.markdown("### üéØ Interpretaci√≥n de Resultados")

            if model_type == "Linear":
                r2_value = metrics.get('r2', 0)
                mae_value = metrics.get('mae', 0)
                rmse_value = metrics.get('rmse', 0)

                interpretation = f"""
                **Resumen del Modelo:**
                - Tu modelo de regresi√≥n lineal explica **{r2_value*100:.1f}%** de la variabilidad en los datos
                - En promedio, las predicciones se desv√≠an **{mae_value:.2f} unidades** del valor real (MAE)
                - La ra√≠z del error cuadr√°tico medio es **{rmse_value:.2f} unidades** (RMSE)
                """

                if rmse_value > mae_value * 1.5:
                    interpretation += "\n- ‚ö†Ô∏è El RMSE es significativamente mayor que el MAE, lo que indica la presencia de algunos errores grandes"

                st.info(interpretation)

            else:
                acc_value = metrics.get('accuracy', 0)
                prec_value = metrics.get('precision', 0)
                rec_value = metrics.get('recall', 0)

                interpretation = f"""
                **Resumen del Modelo:**
                - Tu modelo clasifica correctamente **{acc_value*100:.1f}%** de los casos
                - De las predicciones positivas, **{prec_value*100:.1f}%** son correctas (Precisi√≥n)
                - Detecta **{rec_value*100:.1f}%** de todos los casos positivos reales (Recall)
                """

                st.info(interpretation)

        else:
            st.info("Entrena un modelo primero para ver las m√©tricas de evaluaci√≥n.")

    # Pesta√±a de Visualizaci√≥n
    elif st.session_state.active_tab_lr == 3:
        st.header("Visualizaciones")

        if st.session_state.get('model_trained_lr', False):
            model_type = st.session_state.get('model_type_lr', 'Linear')
            X_test = st.session_state.get('X_test_lr')
            y_test = st.session_state.get('y_test_lr')
            X_train = st.session_state.get('X_train_lr')
            y_train = st.session_state.get('y_train_lr')
            model = st.session_state.get('model_lr')

            # Informaci√≥n sobre las visualizaciones
            with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar estas visualizaciones?", expanded=False):
                if model_type == "Linear":
                    st.markdown("""
                    **Gr√°fico de Predicciones vs Valores Reales:**
                    - Cada punto representa una predicci√≥n del modelo
                    - La l√≠nea roja diagonal representa predicciones perfectas
                    - **Interpretaci√≥n:**
                      - Puntos cerca de la l√≠nea roja = buenas predicciones
                      - Puntos dispersos = predicciones menos precisas
                      - Patrones sistem√°ticos fuera de la l√≠nea pueden indicar problemas del modelo
                    
                    **Gr√°fico de Residuos:**
                    - Muestra la diferencia entre valores reales y predicciones
                    - **Interpretaci√≥n:**
                      - Residuos cerca de cero = buenas predicciones
                      - Patrones en los residuos pueden indicar que el modelo lineal no es adecuado
                      - Distribuci√≥n aleatoria alrededor de cero es ideal
                    """)
                else:
                    st.markdown("""
                    **Matriz de Confusi√≥n:**
                    - Muestra predicciones correctas e incorrectas por clase
                    - **Interpretaci√≥n:**
                      - Diagonal principal = predicciones correctas
                      - Fuera de la diagonal = errores del modelo
                      - Colores m√°s intensos = mayor cantidad de casos
                    
                    **Curva ROC (si es binaria):**
                    - Muestra el rendimiento del clasificador en diferentes umbrales
                    - **Interpretaci√≥n:**
                      - L√≠nea m√°s cerca de la esquina superior izquierda = mejor modelo
                      - √Årea bajo la curva (AUC) cercana a 1 = excelente modelo
                    """)

            if model_type == "Linear" and X_test is not None and y_test is not None and model is not None:
                y_pred = model.predict(X_test)

                # Crear visualizaciones con mejor tama√±o
                st.markdown("### üìä Gr√°fico de Predicciones vs Valores Reales")

                fig, ax = plt.subplots(figsize=(12, 8))

                # Scatter plot con mejor estilo
                ax.scatter(y_test, y_pred, alpha=0.6, s=50,
                           edgecolors='black', linewidth=0.5)

                # L√≠nea de predicci√≥n perfecta
                min_val = min(y_test.min(), y_pred.min())
                max_val = max(y_test.max(), y_pred.max())
                ax.plot([min_val, max_val], [min_val, max_val],
                        'r--', lw=2, label='Predicci√≥n Perfecta')

                # Personalizaci√≥n del gr√°fico
                ax.set_xlabel('Valores Reales', fontsize=12)
                ax.set_ylabel('Predicciones', fontsize=12)
                ax.set_title('Predicciones vs Valores Reales',
                             fontsize=14, fontweight='bold')
                ax.legend()
                ax.grid(True, alpha=0.3)

                # A√±adir estad√≠sticas al gr√°fico
                r2_value = st.session_state.get('metrics_lr', {}).get('r2', 0)
                ax.text(0.05, 0.95, f'R¬≤ = {r2_value:.4f}',
                        transform=ax.transAxes, fontsize=12,
                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Gr√°fico de residuos
                st.markdown("### üìà An√°lisis de Residuos")

                # Informaci√≥n explicativa sobre los residuos
                with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar el an√°lisis de residuos?", expanded=False):
                    st.markdown("""
                    **¬øQu√© son los residuos?**
                    Los residuos son las diferencias entre los valores reales y las predicciones del modelo:
                    `Residuo = Valor Real - Predicci√≥n`
                    
                    **Gr√°fico de Residuos vs Predicciones:**
                    - **Ideal:** Los puntos deben estar distribuidos aleatoriamente alrededor de la l√≠nea y=0
                    - **Problema:** Si ves patrones (curvas, abanicos), puede indicar:
                      - El modelo no captura relaciones no lineales
                      - Heterocedasticidad (varianza no constante)
                      - Variables importantes omitidas
                    
                    **Histograma de Residuos:**
                    - **Ideal:** Distribuci√≥n normal (campana) centrada en 0
                    - **Problema:** Si la distribuci√≥n est√° sesgada o tiene m√∫ltiples picos:
                      - Puede indicar que el modelo no es apropiado
                      - Sugiere la presencia de outliers o datos problem√°ticos
                    
                    **L√≠nea roja punteada:** Marca el residuo = 0 (predicci√≥n perfecta)
                    **Media de residuos:** Deber√≠a estar cerca de 0 para un modelo bien calibrado
                    """)

                residuals = y_test - y_pred

                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

                # Residuos vs Predicciones
                ax1.scatter(y_pred, residuals, alpha=0.6, s=50,
                            edgecolors='black', linewidth=0.5)
                ax1.axhline(y=0, color='r', linestyle='--',
                            lw=2, label='Residuo = 0')
                ax1.set_xlabel('Predicciones', fontsize=12)
                ax1.set_ylabel('Residuos (Real - Predicci√≥n)', fontsize=12)
                ax1.set_title('Residuos vs Predicciones',
                              fontsize=14, fontweight='bold')
                ax1.legend()
                ax1.grid(True, alpha=0.3)

                # A√±adir estad√≠sticas al gr√°fico
                residual_std = residuals.std()
                ax1.text(0.05, 0.95, f'Desv. Est√°ndar: {residual_std:.3f}',
                         transform=ax1.transAxes, fontsize=10,
                         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))

                # Histograma de residuos
                ax2.hist(residuals, bins=20, alpha=0.7,
                         edgecolor='black', color='skyblue')
                ax2.axvline(residuals.mean(), color='red', linestyle='--',
                            lw=2, label=f'Media: {residuals.mean():.3f}')
                ax2.axvline(0, color='green', linestyle='-',
                            lw=2, alpha=0.7, label='Ideal (0)')
                ax2.set_xlabel('Residuos', fontsize=12)
                ax2.set_ylabel('Frecuencia', fontsize=12)
                ax2.set_title('Distribuci√≥n de Residuos',
                              fontsize=14, fontweight='bold')
                ax2.legend()
                ax2.grid(True, alpha=0.3)

                plt.tight_layout()

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Interpretaci√≥n autom√°tica de los residuos
                st.markdown("### üîç Interpretaci√≥n de los Residuos")

                mean_residual = abs(residuals.mean())
                std_residual = residuals.std()

                interpretation = []

                if mean_residual < 0.1 * std_residual:
                    interpretation.append(
                        "‚úÖ **Media de residuos cercana a 0:** El modelo est√° bien calibrado")
                else:
                    interpretation.append(
                        "‚ö†Ô∏è **Media de residuos alejada de 0:** El modelo puede tener sesgo sistem√°tico")

                # Calcular R¬≤ de los residuos para detectar patrones
                from scipy import stats
                if len(residuals) > 10:
                    slope, _, r_value, _, _ = stats.linregress(
                        y_pred, residuals)
                    if abs(r_value) < 0.1:
                        interpretation.append(
                            "‚úÖ **Sin correlaci√≥n entre residuos y predicciones:** Buen ajuste lineal")
                    else:
                        interpretation.append(
                            "‚ö†Ô∏è **Correlaci√≥n detectada en residuos:** Puede haber relaciones no lineales")

                # Test de normalidad simplificado (basado en asimetr√≠a)
                skewness = abs(stats.skew(residuals))
                if skewness < 1:
                    interpretation.append(
                        "‚úÖ **Distribuci√≥n de residuos aproximadamente normal**")
                else:
                    interpretation.append(
                        "‚ö†Ô∏è **Distribuci√≥n de residuos sesgada:** Revisar outliers o transformaciones")

                for item in interpretation:
                    st.markdown(f"- {item}")

                if mean_residual >= 0.1 * std_residual or abs(r_value) >= 0.1 or skewness >= 1:
                    st.info(
                        "üí° **Sugerencias de mejora:** Considera probar transformaciones de variables, a√±adir caracter√≠sticas polin√≥micas, o usar modelos no lineales.")

            elif model_type == "Logistic" and X_test is not None and y_test is not None and model is not None:
                from sklearn.metrics import confusion_matrix, classification_report

                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)

                # Matriz de Confusi√≥n
                st.markdown("### üìä Matriz de Confusi√≥n")

                cm = confusion_matrix(y_test, y_pred)

                fig, ax = plt.subplots(figsize=(10, 8))

                # Crear mapa de calor
                try:
                    import seaborn as sns
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                                ax=ax, cbar_kws={'shrink': 0.8})
                except ImportError:
                    # Fallback to matplotlib if seaborn is not available
                    im = ax.imshow(cm, cmap='Blues', aspect='auto')
                    # Add text annotations
                    for i in range(cm.shape[0]):
                        for j in range(cm.shape[1]):
                            text = ax.text(j, i, f'{cm[i, j]}',
                                           ha="center", va="center", color="white" if cm[i, j] > cm.max()/2 else "black")
                    ax.set_xticks(range(cm.shape[1]))
                    ax.set_yticks(range(cm.shape[0]))
                ax.set_title('Matriz de Confusi√≥n',
                             fontsize=14, fontweight='bold')
                ax.set_xlabel('Predicciones', fontsize=12)
                ax.set_ylabel('Valores Reales', fontsize=12)

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Curva ROC para clasificaci√≥n binaria
                if len(np.unique(y_test)) == 2:
                    from sklearn.metrics import roc_curve, auc

                    st.markdown("### üìà Curva ROC")

                    # Calcular curva ROC
                    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])
                    roc_auc = auc(fpr, tpr)

                    fig, ax = plt.subplots(figsize=(10, 8))

                    ax.plot(fpr, tpr, color='darkorange', lw=2,
                            label=f'Curva ROC (AUC = {roc_auc:.3f})')
                    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',
                            label='Clasificador Aleatorio')

                    ax.set_xlim([0.0, 1.0])
                    ax.set_ylim([0.0, 1.05])
                    ax.set_xlabel('Tasa de Falsos Positivos', fontsize=12)
                    ax.set_ylabel('Tasa de Verdaderos Positivos', fontsize=12)
                    ax.set_title(
                        'Curva ROC (Receiver Operating Characteristic)', fontsize=14, fontweight='bold')
                    ax.legend(loc="lower right")
                    ax.grid(True, alpha=0.3)

                    # Mostrar con 80% del ancho
                    col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                    with col2:
                        st.pyplot(fig, use_container_width=True)

        else:
            st.info("Entrena un modelo primero para ver las visualizaciones.")

    # Pesta√±a de Coeficientes
    elif st.session_state.active_tab_lr == 4:
        st.header("Coeficientes del Modelo")

        if st.session_state.get('model_trained_lr', False):
            model = st.session_state.get('model_lr')
            feature_names = st.session_state.get('feature_names_lr', [])
            model_type = st.session_state.get('model_type_lr', 'Linear')

            # Informaci√≥n sobre los coeficientes
            with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar los coeficientes?", expanded=False):
                if model_type == "Linear":
                    st.markdown("""
                    **Coeficientes en Regresi√≥n Lineal:**
                    
                    - **Valor del coeficiente:** Indica cu√°nto cambia la variable objetivo por cada unidad de cambio en la caracter√≠stica
                    - **Signo del coeficiente:**
                      - **Positivo (+):** A mayor valor de la caracter√≠stica, mayor valor de la predicci√≥n
                      - **Negativo (-):** A mayor valor de la caracter√≠stica, menor valor de la predicci√≥n
                    - **Magnitud del coeficiente:** Indica la importancia/influencia de la caracter√≠stica
                    
                    **Ejemplo:** Si el coeficiente de "tama√±o_casa" es 50, significa que por cada unidad adicional de tama√±o, el precio aumenta en 50 unidades.
                    
                    **Intercepto:** Es el valor predicho cuando todas las caracter√≠sticas son 0.
                    """)
                else:
                    st.markdown("""
                    **Coeficientes en Regresi√≥n Log√≠stica:**
                    
                    - **Valor del coeficiente:** Indica el cambio en el log-odds por cada unidad de cambio en la caracter√≠stica
                    - **Interpretaci√≥n del signo:**
                      - **Positivo (+):** Aumenta la probabilidad de la clase positiva
                      - **Negativo (-):** Disminuye la probabilidad de la clase positiva
                    - **Magnitud:** Indica la fuerza de la influencia en la probabilidad
                    
                    **Nota:** Los coeficientes se pueden convertir a "odds ratios" usando exp(coeficiente) para una interpretaci√≥n m√°s intuitiva.
                    """)

            if model is not None and hasattr(model, 'coef_'):
                # Preparar datos de coeficientes
                if len(model.coef_.shape) > 1:
                    coefficients = model.coef_.flatten()
                else:
                    coefficients = model.coef_

                coef_df = pd.DataFrame({
                    'Caracter√≠stica': feature_names,
                    'Coeficiente': coefficients,
                    'Valor_Absoluto': np.abs(coefficients)
                })
                coef_df = coef_df.sort_values(
                    'Valor_Absoluto', ascending=False)

                # A√±adir interpretaci√≥n
                coef_df['Efecto'] = coef_df['Coeficiente'].apply(
                    lambda x: 'üìà Positivo' if x > 0 else 'üìâ Negativo'
                )
                coef_df['Importancia'] = coef_df['Valor_Absoluto'].apply(
                    lambda x: 'üî• Alta' if x > coef_df['Valor_Absoluto'].quantile(0.75)
                    else ('üî∂ Media' if x > coef_df['Valor_Absoluto'].quantile(0.25) else 'üîπ Baja')
                )

                # Mostrar tabla de coeficientes
                st.markdown("### üìä Tabla de Coeficientes")

                # Formatear la tabla para mejor visualizaci√≥n
                display_df = coef_df[[
                    'Caracter√≠stica', 'Coeficiente', 'Efecto', 'Importancia']].copy()
                display_df['Coeficiente'] = display_df['Coeficiente'].apply(
                    lambda x: f"{x:.4f}")

                st.dataframe(display_df, use_container_width=True,
                             hide_index=True)

                # Mostrar intercepto si existe
                if hasattr(model, 'intercept_'):
                    st.markdown("### üéØ Intercepto del Modelo")
                    intercept = model.intercept_[0] if hasattr(
                        model.intercept_, '__len__') else model.intercept_
                    st.metric("Intercepto", f"{intercept:.4f}")

                    if model_type == "Linear":
                        st.info(
                            f"**Interpretaci√≥n:** Cuando todas las caracter√≠sticas son 0, el modelo predice un valor de {intercept:.4f}")
                    else:
                        st.info(
                            f"**Interpretaci√≥n:** El log-odds base (cuando todas las caracter√≠sticas son 0) es {intercept:.4f}")

                # Gr√°fico de coeficientes
                st.markdown("### üìà Visualizaci√≥n de Coeficientes")

                fig, ax = plt.subplots(
                    figsize=(12, max(6, len(feature_names) * 0.4)))

                # Crear gr√°fico de barras horizontal
                colors = ['#ff6b6b' if x <
                          0 else '#4ecdc4' for x in coef_df['Coeficiente']]
                bars = ax.barh(range(
                    len(coef_df)), coef_df['Coeficiente'], color=colors, alpha=0.7, edgecolor='black')

                # Personalizaci√≥n
                ax.set_yticks(range(len(coef_df)))
                ax.set_yticklabels(coef_df['Caracter√≠stica'], fontsize=10)
                ax.set_xlabel('Valor del Coeficiente', fontsize=12)
                ax.set_title(
                    'Coeficientes del Modelo (ordenados por importancia)', fontsize=14, fontweight='bold')
                ax.axvline(x=0, color='black', linestyle='-',
                           alpha=0.8, linewidth=1)
                ax.grid(True, alpha=0.3, axis='x')

                # A√±adir valores en las barras
                for i, (bar, coef) in enumerate(zip(bars, coef_df['Coeficiente'])):
                    width = bar.get_width()
                    ax.text(width + (0.01 * (max(coef_df['Coeficiente']) - min(coef_df['Coeficiente']))) if width >= 0
                            else width - (0.01 * (max(coef_df['Coeficiente']) - min(coef_df['Coeficiente']))),
                            bar.get_y() + bar.get_height()/2,
                            f'{coef:.3f}', ha='left' if width >= 0 else 'right', va='center', fontsize=9)

                # Leyenda
                from matplotlib.patches import Patch
                legend_elements = [
                    Patch(facecolor='#4ecdc4', alpha=0.7,
                          label='Efecto Positivo'),
                    Patch(facecolor='#ff6b6b', alpha=0.7,
                          label='Efecto Negativo')
                ]
                ax.legend(handles=legend_elements, loc='upper right')

                plt.tight_layout()

                # Mostrar con 80% del ancho
                col1, col2, col3 = st.columns([0.1, 0.8, 0.1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # An√°lisis de importancia
                st.markdown("### üîç An√°lisis de Importancia")

                # Identificar las caracter√≠sticas m√°s importantes
                top_features = coef_df.head(3)

                importance_text = "**Caracter√≠sticas m√°s influyentes:**\n\n"
                for i, row in top_features.iterrows():
                    effect = "aumenta" if row['Coeficiente'] > 0 else "disminuye"
                    importance_text += f"‚Ä¢ **{row['Caracter√≠stica']}**: {effect} {'la predicci√≥n' if model_type == 'Linear' else 'la probabilidad'} (coeficiente: {row['Coeficiente']:.4f})\n"

                st.markdown(importance_text)

            else:
                st.error("El modelo no tiene coeficientes disponibles.")
        else:
            st.info("Entrena un modelo primero para ver los coeficientes.")

    # Pesta√±a de Predicciones
    elif st.session_state.active_tab_lr == 5:
        st.header("Hacer Predicciones")

        if st.session_state.get('model_trained_lr', False):
            model = st.session_state.get('model_lr')
            feature_names = st.session_state.get('feature_names_lr', [])
            dataset_name = st.session_state.get('selected_dataset_lr', '')
            X_train = st.session_state.get('X_train_lr')
            class_names = st.session_state.get('class_names_lr', [])
            model_type = st.session_state.get('model_type_lr', 'Linear')
            task_type = st.session_state.get('task_type_lr', 'Regresi√≥n')

            # Obtener metadata del dataset para adaptar los inputs
            from dataset_metadata import get_dataset_metadata
            metadata = get_dataset_metadata(dataset_name)
            feature_descriptions = metadata.get('feature_descriptions', {})
            value_mappings = metadata.get('value_mappings', {})
            original_to_display = metadata.get('original_to_display', {})
            categorical_features = metadata.get('categorical_features', [])

            st.markdown("### Ingresa los valores para hacer una predicci√≥n")

            # Analizar caracter√≠sticas si tenemos datos de entrenamiento
            feature_info = {}
            if X_train is not None:
                # Convertir a DataFrame si es necesario
                if hasattr(X_train, 'columns'):
                    column_names = X_train.columns
                else:
                    column_names = range(len(feature_names))

                for i, feature_display_name in enumerate(feature_names):
                    # Obtener el nombre original de la columna
                    if i < len(column_names):
                        original_col_name = column_names[i]
                    else:
                        original_col_name = feature_display_name

                    # Encontrar el nombre original usando reverse mapping
                    reverse_mapping = {v: k for k,
                                       v in original_to_display.items()}
                    if feature_display_name in reverse_mapping:
                        original_col_name = reverse_mapping[feature_display_name]

                    # Usar el √≠ndice para acceder a las columnas
                    if hasattr(X_train, 'iloc'):
                        feature_col = X_train.iloc[:, i]
                    else:
                        feature_col = X_train[:, i]

                    # Determinar tipo de caracter√≠stica
                    unique_values = len(set(feature_col)) if hasattr(
                        feature_col, '__iter__') else 10
                    unique_vals = sorted(list(set(feature_col))) if hasattr(
                        feature_col, '__iter__') else [0, 1]

                    # Verificar si es categ√≥rica seg√∫n metadata
                    is_categorical_by_metadata = original_col_name in categorical_features

                    if unique_values <= 2:
                        feature_type = 'binary'
                    elif unique_values <= 10 and (all(isinstance(x, (int, float)) and x == int(x) for x in unique_vals) or is_categorical_by_metadata):
                        feature_type = 'categorical'
                    else:
                        feature_type = 'continuous'

                    # Preparar informaci√≥n de la caracter√≠stica
                    if feature_type in ['binary', 'categorical'] and original_col_name in value_mappings:
                        display_values = []
                        value_to_original = {}
                        for orig_val in unique_vals:
                            if orig_val in value_mappings[original_col_name]:
                                display_val = value_mappings[original_col_name][orig_val]
                                display_values.append(display_val)
                                value_to_original[display_val] = orig_val
                            else:
                                display_values.append(str(orig_val))
                                value_to_original[str(orig_val)] = orig_val

                        feature_info[i] = {
                            'type': feature_type,
                            'values': unique_vals,
                            'display_values': display_values,
                            'value_to_original': value_to_original,
                            'original_column': original_col_name,
                            'display_name': feature_display_name
                        }
                    else:
                        feature_info[i] = {
                            'type': feature_type,
                            'values': unique_vals,
                            'min': float(min(unique_vals)) if feature_type == 'continuous' else min(unique_vals),
                            'max': float(max(unique_vals)) if feature_type == 'continuous' else max(unique_vals),
                            'mean': float(sum(feature_col) / len(feature_col)) if feature_type == 'continuous' and hasattr(feature_col, '__iter__') else None,
                            'original_column': original_col_name,
                            'display_name': feature_display_name
                        }
            else:
                # Valores por defecto si no hay datos de entrenamiento
                for i, feature in enumerate(feature_names):
                    feature_info[i] = {
                        'type': 'continuous',
                        'min': 0.0,
                        'max': 10.0,
                        'mean': 5.0,
                        'original_column': feature,
                        'display_name': feature
                    }

            # Crear controles adaptativos para cada caracter√≠stica
            input_values = []
            cols = st.columns(min(3, len(feature_names)))

            for i, feature in enumerate(feature_names):
                with cols[i % len(cols)]:
                    info = feature_info.get(
                        i, {'type': 'continuous', 'min': 0.0, 'max': 10.0, 'mean': 5.0})

                    # Crear etiqueta con descripci√≥n si est√° disponible
                    original_col = info.get('original_column', feature)
                    description = feature_descriptions.get(original_col, '')
                    if description:
                        label = f"**{feature}**\n\n*{description}*"
                    else:
                        label = feature

                    if info['type'] == 'binary':
                        # Control para caracter√≠sticas binarias
                        if 'display_values' in info and 'value_to_original' in info:
                            selected_display = st.selectbox(
                                label,
                                options=info['display_values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                            value = info['value_to_original'][selected_display]
                        elif len(info['values']) == 2 and 0 in info['values'] and 1 in info['values']:
                            value = st.checkbox(label, key=f"pred_input_{i}")
                            value = 1 if value else 0
                        else:
                            value = st.selectbox(
                                label,
                                options=info['values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                        input_values.append(value)

                    elif info['type'] == 'categorical':
                        # Control para caracter√≠sticas categ√≥ricas
                        if 'display_values' in info and 'value_to_original' in info:
                            selected_display = st.selectbox(
                                label,
                                options=info['display_values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                            value = info['value_to_original'][selected_display]
                        else:
                            value = st.selectbox(
                                label,
                                options=info['values'],
                                index=0,
                                key=f"pred_input_{i}"
                            )
                        input_values.append(value)

                    else:  # continuous
                        # Control para caracter√≠sticas continuas
                        if 'min' in info and 'max' in info:
                            step = (info['max'] - info['min']) / \
                                100 if info['max'] != info['min'] else 0.1
                            default_val = info.get(
                                'mean', (info['min'] + info['max']) / 2)
                            value = st.slider(
                                label,
                                min_value=info['min'],
                                max_value=info['max'],
                                value=default_val,
                                step=step,
                                key=f"pred_input_{i}"
                            )
                        else:
                            value = st.number_input(
                                label,
                                value=0.0,
                                key=f"pred_input_{i}"
                            )
                        input_values.append(value)

            if st.button("üîÆ Predecir", key="predict_lr_button"):
                try:
                    if model is not None:
                        prediction = model.predict([input_values])[0]

                        # For logistic regression, convert numeric prediction to class label
                        if task_type == 'Clasificaci√≥n' and class_names is not None:
                            prediction_label = class_names[int(prediction)]
                            st.success(f"Predicci√≥n: {prediction_label}")
                        else:
                            # For regression, show numeric prediction
                            st.success(f"Predicci√≥n: {prediction:.4f}")
                    else:
                        st.error("Modelo no disponible")
                except Exception as e:
                    st.error(f"Error en la predicci√≥n: {str(e)}")
        else:
            st.info("Entrena un modelo primero para hacer predicciones.")

    # Pesta√±a de Exportar
    elif st.session_state.active_tab_lr == 6:
        st.header("Exportar Modelo")

        if st.session_state.get('model_trained_lr', False):
            model = st.session_state.get('model_lr')

            col1, col2 = st.columns(2)

            with col2:
                if st.button("üì• Descargar Modelo (Pickle)", key="download_pickle_lr"):
                    pickle_data = export_model_pickle(model)
                    st.download_button(
                        label="Descargar modelo.pkl",
                        data=pickle_data,
                        file_name="linear_regression_model.pkl",
                        mime="application/octet-stream"
                    )

            with col1:
                if st.button("üìÑ Generar C√≥digo", key="generate_code_lr"):
                    # Generate complete code for linear models
                    model_type = st.session_state.get(
                        'model_type_lr', 'Linear')
                    feature_names = st.session_state.get(
                        'feature_names_lr', [])
                    class_names = st.session_state.get('class_names_lr', [])

                    if model_type == "Logistic":
                        code = generate_logistic_regression_code(
                            feature_names, class_names)
                    else:
                        code = generate_linear_regression_code(feature_names)

                    st.code(code, language="python")

                    # Download button for the code
                    st.download_button(
                        label="üì• Descargar c√≥digo",
                        data=code,
                        file_name=f"{'logistic' if model_type == 'Logistic' else 'linear'}_regression_code.py",
                        mime="text/plain"
                    )
        else:
            st.info("Entrena un modelo primero para exportarlo.")


def run_csv_loader_app():
    """Ejecuta la aplicaci√≥n espec√≠fica para cargar archivos CSV personalizados."""
    st.header("üìÅ Cargar CSV Personalizado")
    st.markdown(
        "Carga tu propio dataset en formato CSV para an√°lisis personalizado")

    # Informaci√≥n sobre cargar CSV
    with st.expander("‚ÑπÔ∏è ¬øC√≥mo usar esta herramienta?", expanded=True):
        st.markdown("""
        **Esta herramienta te permite cargar tus propios datasets CSV para an√°lisis con Machine Learning.**

        ### üìã Requisitos del archivo CSV:
        - Formato CSV con encabezados (primera fila con nombres de columnas)
        - Al menos 2 columnas (caracter√≠sticas + variable objetivo)
        - Datos limpios y estructurados
        - Codificaci√≥n UTF-8 preferible

        ### üîß Funcionalidades:
        - **Vista previa autom√°tica** del dataset cargado
        - **Detecci√≥n autom√°tica** del tipo de tarea (Clasificaci√≥n/Regresi√≥n)
        - **Selecci√≥n de columna objetivo** personalizable
        - **Estad√≠sticas descriptivas** del dataset
        - **Integraci√≥n completa** con todos los algoritmos disponibles

        ### üí° Consejos:
        - Aseg√∫rate de que los datos num√©ricos est√©n en formato correcto
        - Para clasificaci√≥n, la columna objetivo debe contener categor√≠as
        - Para regresi√≥n, la columna objetivo debe contener valores num√©ricos continuos
        """)

    # Usar la funci√≥n existente de dataset_manager
    st.markdown("---")

    # Llamar a la funci√≥n de carga de CSV sin mostrar datasets predefinidos
    result = create_dataset_selector(show_predefined=False)

    if result is not None:
        if isinstance(result, tuple):
            # CSV cargado exitosamente
            file_path, target_col, task_type = result

            st.markdown("---")
            st.success("‚úÖ ¬°Dataset CSV cargado exitosamente!")

            # Mostrar opciones de an√°lisis
            st.markdown("### üöÄ Pr√≥ximos pasos:")

            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button("üå≤ Analizar con √Årboles de Decisi√≥n",
                             key="analyze_trees",
                             use_container_width=True,
                             type="primary"):
                    st.session_state.navigation = "üå≤ √Årboles de Decisi√≥n"
                    st.rerun()

            with col2:
                if st.button("üìä Analizar con Regresi√≥n",
                             key="analyze_linear",
                             use_container_width=True,
                             type="primary"):
                    st.session_state.navigation = "üìä Regresi√≥n"
                    st.rerun()

            with col3:
                if st.button("üîÑ Cargar otro archivo",
                             key="load_another",
                             use_container_width=True):
                    # Limpiar el estado del CSV cargado
                    if 'csv_datasets' in st.session_state:
                        st.session_state.csv_datasets.clear()
                    if 'selected_dataset' in st.session_state:
                        del st.session_state.selected_dataset
                    st.rerun()

            # Informaci√≥n adicional sobre el dataset cargado
            st.markdown("### üìä Informaci√≥n del Dataset Cargado:")

            try:
                # Leer el archivo para mostrar estad√≠sticas
                df = pd.read_csv(file_path)

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìè Filas", df.shape[0])
                with col2:
                    st.metric("üìä Columnas", df.shape[1])
                with col3:
                    st.metric("üéØ Variable Objetivo", target_col)
                with col4:
                    task_icon = "üè∑Ô∏è" if task_type == "Clasificaci√≥n" else "üìà"
                    st.metric(f"{task_icon} Tipo de Tarea", task_type)

                # Mostrar estad√≠sticas descriptivas
                with st.expander("üìà Estad√≠sticas Descriptivas", expanded=False):
                    st.dataframe(df.describe(), use_container_width=True)

                # Mostrar distribuci√≥n de la variable objetivo
                with st.expander("üéØ Distribuci√≥n de la Variable Objetivo", expanded=False):
                    if task_type == "Clasificaci√≥n":
                        value_counts = df[target_col].value_counts()

                        col1, col2 = st.columns(2)
                        with col1:
                            st.dataframe(value_counts.to_frame(
                                "Cantidad"), use_container_width=True)

                        with col2:
                            fig, ax = plt.subplots(figsize=(8, 6))
                            value_counts.plot(kind='bar', ax=ax)
                            ax.set_title(f'Distribuci√≥n de {target_col}')
                            ax.set_ylabel('Cantidad')
                            plt.xticks(rotation=45)
                            plt.tight_layout()
                            st.pyplot(fig)
                    else:
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write("**Estad√≠sticas:**")
                            st.write(f"‚Ä¢ M√≠nimo: {df[target_col].min():.4f}")
                            st.write(f"‚Ä¢ M√°ximo: {df[target_col].max():.4f}")
                            st.write(f"‚Ä¢ Media: {df[target_col].mean():.4f}")
                            st.write(
                                f"‚Ä¢ Mediana: {df[target_col].median():.4f}")
                            st.write(
                                f"‚Ä¢ Desv. Est√°ndar: {df[target_col].std():.4f}")

                        with col2:
                            fig, ax = plt.subplots(figsize=(8, 6))
                            df[target_col].hist(bins=30, ax=ax, alpha=0.7)
                            ax.set_title(f'Distribuci√≥n de {target_col}')
                            ax.set_xlabel(target_col)
                            ax.set_ylabel('Frecuencia')
                            plt.tight_layout()
                            st.pyplot(fig)

            except Exception as e:
                st.warning(
                    f"No se pudieron cargar las estad√≠sticas adicionales: {str(e)}")

    else:
        # Mostrar consejos mientras no hay archivo cargado
        st.markdown("### üí° Ejemplos de Datasets que puedes cargar:")

        examples = [
            {
                "name": "Dataset de Ventas",
                "description": "Datos de ventas con caracter√≠sticas como precio, descuento, temporada ‚Üí Predictor de ventas",
                "task": "Regresi√≥n",
                "icon": "üí∞"
            },
            {
                "name": "Dataset de Clientes",
                "description": "Datos de clientes con edad, ingresos, historial ‚Üí Clasificaci√≥n de segmentos",
                "task": "Clasificaci√≥n",
                "icon": "üë•"
            },
            {
                "name": "Dataset de Productos",
                "description": "Caracter√≠sticas de productos con ratings ‚Üí Predicci√≥n de popularidad",
                "task": "Regresi√≥n",
                "icon": "üì¶"
            },
            {
                "name": "Dataset M√©dico",
                "description": "S√≠ntomas y caracter√≠sticas del paciente ‚Üí Diagn√≥stico binario",
                "task": "Clasificaci√≥n",
                "icon": "üè•"
            }
        ]

        for example in examples:
            with st.container():
                col1, col2 = st.columns([1, 10])
                with col1:
                    st.markdown(f"## {example['icon']}")
                with col2:
                    st.markdown(f"**{example['name']}** ({example['task']})")
                    st.markdown(f"_{example['description']}_")
                st.markdown("---")


def generate_linear_regression_code(feature_names):
    """Generate complete Python code for linear regression."""
    feature_names_str = str(feature_names)

    code = f"""# C√≥digo completo para Regresi√≥n Lineal
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt

# 1. CARGAR Y PREPARAR LOS DATOS
# Reemplaza esta secci√≥n con tu m√©todo de carga de datos
# df = pd.read_csv('tu_archivo.csv')  # Cargar desde CSV
# O usa datos de ejemplo:

# Datos de ejemplo (reemplaza con tus datos reales)
# X = df[{feature_names_str}]  # Caracter√≠sticas
# y = df['variable_objetivo']  # Variable objetivo

# 2. DIVIDIR LOS DATOS
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 3. CREAR Y ENTRENAR EL MODELO
model = LinearRegression()
model.fit(X_train, y_train)

# 4. HACER PREDICCIONES
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# 5. EVALUAR EL MODELO
r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)
mae_test = mean_absolute_error(y_test, y_pred_test)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))

print("=== RESULTADOS DEL MODELO ===")
print(f"R¬≤ Score (Entrenamiento): {{r2_train:.4f}}")
print(f"R¬≤ Score (Prueba): {{r2_test:.4f}}")
print(f"MAE (Error Absoluto Medio): {{mae_test:.4f}}")
print(f"RMSE (Ra√≠z Error Cuadr√°tico Medio): {{rmse_test:.4f}}")

# 6. MOSTRAR COEFICIENTES
print("\\n=== COEFICIENTES DEL MODELO ===")
feature_names = {feature_names_str}
for i, coef in enumerate(model.coef_):
    print(f"{{feature_names[i]}}: {{coef:.4f}}")
print(f"Intercepto: {{model.intercept_:.4f}}")

# 7. VISUALIZAR RESULTADOS
plt.figure(figsize=(12, 5))

# Gr√°fico 1: Predicciones vs Valores Reales
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_test, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Valores Reales')
plt.ylabel('Predicciones')
plt.title('Predicciones vs Valores Reales')
plt.grid(True, alpha=0.3)

# Gr√°fico 2: Residuos
plt.subplot(1, 2, 2)
residuals = y_test - y_pred_test
plt.scatter(y_pred_test, residuals, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicciones')
plt.ylabel('Residuos')
plt.title('An√°lisis de Residuos')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 8. FUNCI√ìN PARA NUEVAS PREDICCIONES
def predecir_nuevo_valor(nuevo_ejemplo):
    \"\"\"
    Funci√≥n para hacer predicciones con nuevos datos.
    
    Par√°metros:
    nuevo_ejemplo: lista con valores para cada caracter√≠stica
                  en el orden: {feature_names_str}
    \"\"\"
    nuevo_ejemplo = np.array(nuevo_ejemplo).reshape(1, -1)
    prediccion = model.predict(nuevo_ejemplo)[0]
    return prediccion

# Ejemplo de uso para nuevas predicciones:
# nuevo_ejemplo = [valor1, valor2, valor3, ...]  # Reemplaza con tus valores
# resultado = predecir_nuevo_valor(nuevo_ejemplo)
# print(f"Predicci√≥n para nuevo ejemplo: {{resultado:.4f}}")

# 9. GUARDAR EL MODELO (OPCIONAL)
import pickle

# Guardar modelo
with open('modelo_regresion_lineal.pkl', 'wb') as f:
    pickle.dump(model, f)

# Cargar modelo guardado
# with open('modelo_regresion_lineal.pkl', 'rb') as f:
#     modelo_cargado = pickle.load(f)
"""
    return code


def generate_logistic_regression_code(feature_names, class_names):
    """Generate complete Python code for logistic regression."""
    feature_names_str = str(feature_names)
    class_names_str = str(class_names)

    code = f"""# C√≥digo completo para Regresi√≥n Log√≠stica
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1. CARGAR Y PREPARAR LOS DATOS
# Reemplaza esta secci√≥n con tu m√©todo de carga de datos
# df = pd.read_csv('tu_archivo.csv')  # Cargar desde CSV
# O usa datos de ejemplo:

# Datos de ejemplo (reemplaza con tus datos reales)
# X = df[{feature_names_str}]  # Caracter√≠sticas
# y = df['variable_objetivo']  # Variable objetivo (0, 1, 2, ...)

# 2. DIVIDIR LOS DATOS
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 3. CREAR Y ENTRENAR EL MODELO
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)

# 4. HACER PREDICCIONES
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# 5. EVALUAR EL MODELO
accuracy_train = accuracy_score(y_train, y_pred_train)
accuracy_test = accuracy_score(y_test, y_pred_test)

print("=== RESULTADOS DEL MODELO ===")
print(f"Accuracy (Entrenamiento): {{accuracy_train:.4f}}")
print(f"Accuracy (Prueba): {{accuracy_test:.4f}}")

# Reporte detallado de clasificaci√≥n
class_names = {class_names_str}
print("\\n=== REPORTE DE CLASIFICACI√ìN ===")
print(classification_report(y_test, y_pred_test, target_names=class_names))

# 6. MATRIZ DE CONFUSI√ìN
plt.figure(figsize=(12, 5))

# Gr√°fico 1: Matriz de Confusi√≥n
plt.subplot(1, 2, 1)
cm = confusion_matrix(y_test, y_pred_test)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=class_names, yticklabels=class_names)
plt.title('Matriz de Confusi√≥n')
plt.xlabel('Predicciones')
plt.ylabel('Valores Reales')

# Gr√°fico 2: Importancia de caracter√≠sticas (coeficientes)
plt.subplot(1, 2, 2)
feature_names = {feature_names_str}
coef = model.coef_.flatten() if len(model.coef_.shape) > 1 else model.coef_
colors = ['red' if x < 0 else 'blue' for x in coef]
plt.barh(range(len(coef)), coef, color=colors, alpha=0.7)
plt.yticks(range(len(coef)), feature_names)
plt.xlabel('Coeficientes')
plt.title('Importancia de Caracter√≠sticas')
plt.axvline(x=0, color='black', linestyle='-', alpha=0.8)
plt.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.show()

# 7. MOSTRAR COEFICIENTES DETALLADOS
print("\\n=== COEFICIENTES DEL MODELO ===")
for i, coef in enumerate(coef):
    effect = "aumenta" if coef > 0 else "disminuye"
    print(f"{{feature_names[i]}}: {{coef:.4f}} ({{effect}} la probabilidad)")
print(f"Intercepto: {{model.intercept_[0]:.4f}}")

# 8. FUNCI√ìN PARA NUEVAS PREDICCIONES
def predecir_nueva_muestra(nuevo_ejemplo):
    \"\"\"
    Funci√≥n para hacer predicciones con nuevos datos.
    
    Par√°metros:
    nuevo_ejemplo: lista con valores para cada caracter√≠stica
                  en el orden: {feature_names_str}
    
    Retorna:
    prediccion: clase predicha
    probabilidades: probabilidades para cada clase
    \"\"\"
    nuevo_ejemplo = np.array(nuevo_ejemplo).reshape(1, -1)
    prediccion = model.predict(nuevo_ejemplo)[0]
    probabilidades = model.predict_proba(nuevo_ejemplo)[0]
    
    clase_predicha = class_names[prediccion]
    return clase_predicha, probabilidades

# Ejemplo de uso para nuevas predicciones:
# nuevo_ejemplo = [valor1, valor2, valor3, ...]  # Reemplaza con tus valores
# clase, probas = predecir_nueva_muestra(nuevo_ejemplo)
# print(f"Clase predicha: {{clase}}")
# print("Probabilidades por clase:")
# for i, prob in enumerate(probas):
#     print(f"  {{class_names[i]}}: {{prob:.4f}} ({{prob*100:.1f}}%)")

# 9. GUARDAR EL MODELO (OPCIONAL)
import pickle

# Guardar modelo
with open('modelo_regresion_logistica.pkl', 'wb') as f:
    pickle.dump(model, f)

# Cargar modelo guardado
# with open('modelo_regresion_logistica.pkl', 'rb') as f:
#     modelo_cargado = pickle.load(f)

# 10. FUNCI√ìN PARA INTERPRETAR PROBABILIDADES
def interpretar_prediccion(nuevo_ejemplo, umbral_confianza=0.8):
    \"\"\"
    Interpreta una predicci√≥n mostrando la confianza del modelo.
    \"\"\"
    clase, probabilidades = predecir_nueva_muestra(nuevo_ejemplo)
    max_prob = max(probabilidades)
    
    print(f"Predicci√≥n: {{clase}}")
    print(f"Confianza: {{max_prob:.4f}} ({{max_prob*100:.1f}}%)")
    
    if max_prob >= umbral_confianza:
        print("‚úÖ Alta confianza en la predicci√≥n")
    elif max_prob >= 0.6:
        print("‚ö†Ô∏è Confianza moderada en la predicci√≥n")
    else:
        print("‚ùå Baja confianza en la predicci√≥n")
    
    return clase, max_prob

# Ejemplo de interpretaci√≥n:
# interpretar_prediccion([valor1, valor2, valor3, ...])
"""
    return code


if __name__ == "__main__":
    main()
