#!/usr/bin/env python3
"""
MLTutor: Plataforma educativa para el aprendizaje de Machine Learning.

Esta es la versi√≥n refactorizada de la aplicaci√≥n MLTutor, que separa la p√°gina de inicio
de los algoritmos espec√≠ficos para una mejor experiencia de usuario.
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import base64
import io

# Importar m√≥dulos refactorizados
from dataset_manager import load_data, preprocess_data, create_dataset_selector, load_dataset_from_file
from model_training import train_decision_tree, predict_sample
from model_evaluation import evaluate_classification_model, evaluate_regression_model, show_detailed_evaluation
from decision_boundary import plot_decision_boundary
from sklearn.model_selection import train_test_split
from ui import (
    setup_page, init_session_state, show_welcome_page,
    display_feature_importance, display_model_export_options, create_prediction_interface
)
from tree_visualizer import (
    render_tree_visualization,
    create_tree_visualization, get_tree_text
)
from utils import (
    get_image_download_link, generate_model_code, export_model_pickle, export_model_onnx,
    create_info_box, format_number, show_code_with_download
)


def main():
    """Funci√≥n principal que ejecuta la aplicaci√≥n MLTutor."""
    # Configuraci√≥n de la p√°gina
    setup_page()

    # Inicializar estado de la sesi√≥n
    init_session_state()

    # Configurar navegaci√≥n principal con botones en lugar de radio
    st.sidebar.markdown("### Navegaci√≥n:")

    # Estilo para los botones de navegaci√≥n
    button_style = """
    <style>
    div.stButton > button {
        width: 100%;
        text-align: left;
        padding: 10px;
        margin-bottom: 5px;
        border-radius: 5px;
        font-weight: normal;
    }
    div.stButton > button:hover {
        background-color: #E3F2FD;
        border-color: #90CAF9;
    }
    </style>
    """
    st.sidebar.markdown(button_style, unsafe_allow_html=True)

    # Crear los botones de navegaci√≥n
    if st.sidebar.button("üè† Inicio",
                         key="nav_home",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üè† Inicio" else "primary"):
        st.session_state.navigation = "üè† Inicio"
        st.rerun()

    if st.sidebar.button("üå≤ √Årboles de Decisi√≥n",
                         key="nav_trees",
                         use_container_width=True,
                         type="secondary" if st.session_state.navigation != "üå≤ √Årboles de Decisi√≥n" else "primary"):
        st.session_state.navigation = "üå≤ √Årboles de Decisi√≥n"
        st.rerun()

    if st.sidebar.button("üìä Regresi√≥n Log√≠stica (pr√≥ximamente)",
                         key="nav_logistic",
                         use_container_width=True,
                         disabled=True):
        st.session_state.navigation = "üìä Regresi√≥n Log√≠stica (pr√≥ximamente)"
        st.rerun()

    if st.sidebar.button("üîç K-Nearest Neighbors (pr√≥ximamente)",
                         key="nav_knn",
                         use_container_width=True,
                         disabled=True):
        st.session_state.navigation = "üîç K-Nearest Neighbors (pr√≥ximamente)"
        st.rerun()

    if st.sidebar.button("üß† Redes Neuronales (pr√≥ximamente)",
                         key="nav_nn",
                         use_container_width=True,
                         disabled=True):
        st.session_state.navigation = "üß† Redes Neuronales (pr√≥ximamente)"
        st.rerun()

    # Separador
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üîß Herramientas:")

    if st.sidebar.button("üìÅ Cargar CSV Personalizado",
                         key="nav_csv",
                         use_container_width=True):
        st.session_state.navigation = "üìÅ Cargar CSV Personalizado"
        st.rerun()

    # P√°gina de inicio
    if st.session_state.navigation == "üè† Inicio":
        show_welcome_page()
        return

    # P√°ginas de algoritmos
    if st.session_state.navigation == "üå≤ √Årboles de Decisi√≥n":
        run_decision_trees_app()
    elif st.session_state.navigation == "üìÅ Cargar CSV Personalizado":
        run_csv_loader_app()
    elif st.session_state.navigation in ["üìä Regresi√≥n Log√≠stica (pr√≥ximamente)",
                                         "üîç K-Nearest Neighbors (pr√≥ximamente)",
                                         "üß† Redes Neuronales (pr√≥ximamente)"]:
        algorithm_name = st.session_state.navigation.split(" ")[1]
        st.header(f"{algorithm_name} (pr√≥ximamente)")
        st.info(
            f"La funcionalidad de {algorithm_name} estar√° disponible pr√≥ximamente. Por ahora, puedes explorar los √Årboles de Decisi√≥n.")

        # Mostrar una imagen ilustrativa seg√∫n el algoritmo
        if "Regresi√≥n Log√≠stica" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_logistic_001.png",
                     caption="Ilustraci√≥n de Regresi√≥n Log√≠stica")
        elif "K-Nearest Neighbors" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_classification_001.png",
                     caption="Ilustraci√≥n de K-Nearest Neighbors")
        elif "Redes Neuronales" in st.session_state.navigation:
            st.image("https://scikit-learn.org/stable/_images/sphx_glr_plot_mlp_001.png",
                     caption="Ilustraci√≥n de Redes Neuronales")


def run_decision_trees_app():
    """Ejecuta la aplicaci√≥n espec√≠fica de √°rboles de decisi√≥n."""
    st.header("üå≤ √Årboles de Decisi√≥n")
    st.markdown("Aprende sobre los √°rboles de decisi√≥n de forma interactiva")

    # Informaci√≥n sobre √°rboles de decisi√≥n
    with st.expander("‚ÑπÔ∏è ¬øQu√© son los √Årboles de Decisi√≥n?", expanded=False):
        st.markdown("""
        Los √°rboles de decisi√≥n son algoritmos de aprendizaje supervisado que se pueden usar tanto para tareas de clasificaci√≥n como de regresi√≥n.
        
        **Caracter√≠sticas principales:**
        - Funcionan dividiendo el conjunto de datos en subconjuntos m√°s peque√±os bas√°ndose en condiciones sobre las caracter√≠sticas
        - Son f√°ciles de interpretar y visualizar
        - Pueden manejar tanto datos num√©ricos como categ√≥ricos
        - No requieren escalado de datos
        
        **Limitaciones:**
        - Pueden sobreajustarse f√°cilmente (esto se puede controlar con par√°metros como max_depth)
        - Pueden ser inestables (peque√±os cambios en los datos pueden generar √°rboles muy diferentes)
        - No son tan precisos como algoritmos m√°s complejos para algunas tareas
        
        Experimenta con diferentes configuraciones para ver c√≥mo afectan al rendimiento del modelo.
        """)

    # Variables para almacenar datos
    dataset_loaded = False
    X, y, feature_names, class_names, dataset_info, task_type = None, None, None, None, None, None

    # Inicializar el estado de la pesta√±a activa si no existe
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = 0

    # Crear pesta√±as para organizar la informaci√≥n
    tab_options = [
        "üìä Datos",
        "üèãÔ∏è Entrenamiento",
        "üìà Evaluaci√≥n",
        "üå≤ Visualizaci√≥n",
        "üîç Caracter√≠sticas",
        "üîÆ Predicciones",
        "üíæ Exportar Modelo"
    ]

    # Crear contenedor para los botones de las pesta√±as
    tab_cols = st.columns(len(tab_options))

    # Estilo CSS para los botones de pesta√±as
    st.markdown("""
    <style>
    div.tab-button > button {
        border-radius: 4px 4px 0 0;
        padding: 10px;
        width: 100%;
        white-space: nowrap;
        background-color: #F0F2F6;
        border-bottom: 2px solid #E0E0E0;
    }
    div.tab-button-active > button {
        background-color: #E3F2FD;
        border-bottom: 2px solid #1E88E5;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

    # Crear botones para las pesta√±as
    for i, (tab_name, col) in enumerate(zip(tab_options, tab_cols)):
        button_key = f"tab_{i}"
        button_style = "tab-button-active" if st.session_state.active_tab == i else "tab-button"

        with col:
            st.markdown(f"<div class='{button_style}'>",
                        unsafe_allow_html=True)
            if st.button(tab_name, key=button_key, use_container_width=True):
                st.session_state.active_tab = i
                st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    # Separador visual
    st.markdown("---")
    
    # SELECTOR UNIFICADO DE DATASET (solo mostrar en pesta√±as que lo necesiten)
    if st.session_state.active_tab in [0, 1]:  # Exploraci√≥n y Entrenamiento
        st.markdown("### üìä Selecci√≥n de Dataset")
        
        # Inicializar dataset seleccionado si no existe
        if 'selected_dataset' not in st.session_state:
            st.session_state.selected_dataset = "üå∏ Iris - Clasificaci√≥n de flores"
        
        # Selector unificado
        dataset_option = st.selectbox(
            "Dataset de ejemplo:",
            ("üå∏ Iris - Clasificaci√≥n de flores",
             "üç∑ Vino - Clasificaci√≥n de vinos",
             "üî¨ C√°ncer - Diagn√≥stico binario",
             "üö¢ Titanic - Supervivencia",
             "üí∞ Propinas - Predicci√≥n de propinas",
             "üè† Viviendas California - Precios",
             "üêß Ping√ºinos - Clasificaci√≥n de especies"),
            index=("üå∏ Iris - Clasificaci√≥n de flores",
                   "üç∑ Vino - Clasificaci√≥n de vinos",
                   "üî¨ C√°ncer - Diagn√≥stico binario",
                   "üö¢ Titanic - Supervivencia",
                   "üí∞ Propinas - Predicci√≥n de propinas",
                   "üè† Viviendas California - Precios",
                   "üêß Ping√ºinos - Clasificaci√≥n de especies").index(st.session_state.selected_dataset),
            key="unified_dataset_selector",
            help="El dataset seleccionado se mantendr√° entre las pesta√±as de Exploraci√≥n y Entrenamiento"
        )
        
        # Actualizar la variable de sesi√≥n
        st.session_state.selected_dataset = dataset_option
        
        # Separador despu√©s del selector
        st.markdown("---")
    else:
        # Para otras pesta√±as, mostrar qu√© dataset est√° seleccionado actualmente
        if hasattr(st.session_state, 'selected_dataset'):
            st.info(f"üìä **Dataset actual:** {st.session_state.selected_dataset}")
            st.markdown("---")

    # Pesta√±a de Datos
    if st.session_state.active_tab == 0:
        st.header("Exploraci√≥n de Datos")

        try:
            # Cargar datos para exploraci√≥n
            X, y, feature_names, class_names, dataset_info, task_type = load_data(
                st.session_state.selected_dataset)

            # Convertir a DataFrames para facilitar el manejo
            # FIXED: No sobrescribir las columnas si X ya es DataFrame para evitar NaN
            if isinstance(X, pd.DataFrame):
                X_df = X.copy()  # Usar las columnas originales
                # Crear mapeo de nombres para mostrar
                column_mapping = {}
                if len(feature_names) == len(X_df.columns):
                    column_mapping = dict(zip(X_df.columns, feature_names))
            else:
                X_df = pd.DataFrame(X, columns=feature_names)
                column_mapping = {}

            y_df = pd.Series(y, name="target")

            # Mapear nombres de clases si est√°n disponibles
            if task_type == "Clasificaci√≥n" and class_names is not None:
                y_df = y_df.map(
                    {i: name for i, name in enumerate(class_names)})

            df = pd.concat([X_df, y_df], axis=1)

            # Renombrar columnas para mostrar nombres amigables si existe el mapeo
            if column_mapping:
                df_display = df.rename(columns=column_mapping)
            else:
                df_display = df

            # Mostrar informaci√≥n del dataset
            st.markdown("### Informaci√≥n del Dataset")
            st.markdown(create_info_box(dataset_info), unsafe_allow_html=True)

            # Mostrar las primeras filas de los datos
            st.markdown("### Vista previa de datos")
            st.dataframe(df_display.head(10))

            # Estad√≠sticas descriptivas
            st.markdown("### Estad√≠sticas Descriptivas")
            st.dataframe(df_display.describe())

            # Distribuci√≥n de clases o valores objetivo
            st.markdown("### Distribuci√≥n del Objetivo")

            fig, ax = plt.subplots(figsize=(10, 6))

            if task_type == "Clasificaci√≥n":
                # Gr√°fico de barras para clasificaci√≥n
                value_counts = y_df.value_counts().sort_index()
                sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
                ax.set_title("Distribuci√≥n de Clases")
                ax.set_xlabel("Clase")
                ax.set_ylabel("Cantidad")

                # Rotar etiquetas si son muchas
                if len(value_counts) > 3:
                    plt.xticks(rotation=45, ha='right')
            else:
                # Histograma para regresi√≥n
                # Convertir a num√©rico en caso de que sean strings
                y_numeric = pd.to_numeric(y_df, errors='coerce')
                # Usar matplotlib directamente para evitar problemas de tipo
                ax.hist(y_numeric.dropna(), bins=30,
                        alpha=0.7, edgecolor='black')
                ax.set_title("Distribuci√≥n de Valores Objetivo")
                ax.set_xlabel("Valor")
                ax.set_ylabel("Frecuencia")

            # Mostrar la figura con tama√±o reducido pero expandible
            col1, col2, col3 = st.columns([1, 3, 1])
            with col2:
                st.pyplot(fig, use_container_width=True)

            # An√°lisis de correlaci√≥n
            st.markdown("### Matriz de Correlaci√≥n")

            # Matriz de correlaci√≥n
            corr = X_df.corr()

            # Generar m√°scara para el tri√°ngulo superior
            mask = np.triu(np.ones_like(corr, dtype=bool))

            # Generar mapa de calor
            fig_corr, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
                        square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
            ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

            # Mostrar la figura con tama√±o reducido pero expandible
            col1, col2, col3 = st.columns([1, 3, 1])
            with col2:
                st.pyplot(fig_corr, use_container_width=True)

            # Matriz de dispersi√≥n (Scatterplot Matrix)
            st.markdown("### Matriz de Dispersi√≥n (Pairplot)")

            # Opciones de visualizaci√≥n
            st.markdown("#### Opciones de visualizaci√≥n")
            col1, col2 = st.columns(2)

            with col1:
                # Seleccionar tipo de gr√°fico para la diagonal
                diag_kind = st.radio(
                    "Tipo de gr√°fico en la diagonal:",
                    ["Histograma", "KDE (Estimaci√≥n de Densidad)"],
                    index=1,
                    horizontal=True
                )
                diag_kind = "hist" if diag_kind == "Histograma" else "kde"

            with col2:
                # Seleccionar n√∫mero m√°ximo de caracter√≠sticas
                max_features_selected = st.slider(
                    "N√∫mero m√°ximo de caracter√≠sticas:",
                    min_value=2,
                    max_value=min(6, len(X_df.columns)),
                    value=min(4, len(X_df.columns)),
                    help="Un n√∫mero mayor de caracter√≠sticas puede hacer que el gr√°fico sea m√°s dif√≠cil de interpretar."
                )

            # Permitir al usuario seleccionar las caracter√≠sticas espec√≠ficas
            st.markdown("#### Selecciona las caracter√≠sticas para visualizar")

            # Limitar a max_features_selected
            # Usar nombres amigables si est√°n disponibles, sino usar originales
            if column_mapping:
                available_features = list(
                    column_mapping.values())  # Nombres amigables
                display_to_original = {
                    v: k for k, v in column_mapping.items()}  # Mapeo inverso
            else:
                available_features = X_df.columns.tolist()
                display_to_original = {}

            # Usar multiselect para seleccionar caracter√≠sticas
            selected_features = st.multiselect(
                "Caracter√≠sticas a incluir en la matriz de dispersi√≥n:",
                available_features,
                default=available_features[:max_features_selected],
                max_selections=max_features_selected,
                help=f"Selecciona hasta {max_features_selected} caracter√≠sticas para incluir en la visualizaci√≥n."
            )

            # Si no se seleccion√≥ ninguna caracter√≠stica, usar las primeras por defecto
            if not selected_features:
                selected_features = available_features[:max_features_selected]
                st.info(
                    f"No se seleccionaron caracter√≠sticas. Usando las primeras {max_features_selected} por defecto.")

            # Convertir nombres amigables a nombres originales si es necesario
            if column_mapping:
                original_features = [display_to_original[feat]
                                     for feat in selected_features]
            else:
                original_features = selected_features

            # Crear el dataframe para la visualizaci√≥n
            plot_df = X_df[original_features].copy()
            # Renombrar a nombres amigables para visualizaci√≥n
            if column_mapping:
                plot_df = plot_df.rename(columns=column_mapping)
            # A√±adir la variable objetivo para colorear
            plot_df['target'] = y_df

            # Generar el pairplot
            with st.spinner("Generando matriz de dispersi√≥n..."):
                pair_plot = sns.pairplot(
                    plot_df,
                    hue='target',
                    diag_kind=diag_kind,
                    plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
                    diag_kws={'alpha': 0.5},
                    height=2.0  # Reducir altura para que sea m√°s compacto
                )
                pair_plot.fig.suptitle(
                    "Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=14)

                # Mostrar la figura con tama√±o reducido pero expandible
                col1, col2, col3 = st.columns([1, 3, 1])
                with col2:
                    st.pyplot(pair_plot.fig, use_container_width=True)

                # Enlace para descargar
                st.markdown(
                    get_image_download_link(
                        pair_plot.fig, "matriz_dispersion", "üì• Descargar matriz de dispersi√≥n"),
                    unsafe_allow_html=True
                )

            # Generar c√≥digo para este an√°lisis
            code = """
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar tus datos (reemplaza esto con tu m√©todo de carga)
# df = pd.read_csv('tu_archivo.csv')

# Separar caracter√≠sticas y objetivo
X = df.iloc[:, :-1]  # Todas las columnas excepto la √∫ltima
y = df.iloc[:, -1]   # √öltima columna como objetivo

# Estad√≠sticas descriptivas
print(df.describe())

# Distribuci√≥n del objetivo
fig, ax = plt.subplots(figsize=(10, 6))

# Para clasificaci√≥n:
if len(np.unique(y)) <= 10:  # Si hay pocas clases √∫nicas
    value_counts = y.value_counts().sort_index()
    sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
    ax.set_title("Distribuci√≥n de Clases")
    ax.set_xlabel("Clase")
    ax.set_ylabel("Cantidad")
else:  # Para regresi√≥n
    sns.histplot(y, kde=True, ax=ax)
    ax.set_title("Distribuci√≥n de Valores Objetivo")
    ax.set_xlabel("Valor")
    ax.set_ylabel("Frecuencia")

plt.tight_layout()
plt.show()

# Matriz de correlaci√≥n
corr = X.corr()
mask = np.triu(np.ones_like(corr, dtype=bool))  # M√°scara para tri√°ngulo superior

fig, ax = plt.subplots(figsize=(12, 10))
sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", cmap="coolwarm",
           square=True, linewidths=.5, cbar_kws={"shrink": .8}, ax=ax)
ax.set_title("Matriz de Correlaci√≥n de Caracter√≠sticas")

plt.tight_layout()
plt.show()

# Matriz de dispersi√≥n (Scatterplot Matrix)
# Seleccionar caracter√≠sticas espec√≠ficas para visualizar
selected_features = ['feature1', 'feature2', 'feature3']  # Reemplaza con tus caracter√≠sticas de inter√©s
max_features = min(6, len(selected_features))

# Crear el dataframe para la visualizaci√≥n
plot_df = X[selected_features].copy()
plot_df['target'] = y  # A√±adir la variable objetivo para colorear

# Generar el pairplot
pair_plot = sns.pairplot(
    plot_df, 
    hue='target', 
    diag_kind='kde',  # Opciones: 'hist' para histograma o 'kde' para densidad
    plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'},
    diag_kws={'alpha': 0.5},
    height=2.5
)
pair_plot.fig.suptitle("Matriz de Dispersi√≥n de Caracter√≠sticas", y=1.02, fontsize=16)
plt.tight_layout()
plt.show()
"""

            show_code_with_download(
                code, "C√≥digo para an√°lisis exploratorio", "analisis_exploratorio.py")

        except Exception as e:
            st.error(f"Error al cargar el dataset: {str(e)}")
            st.info(
                "Por favor, selecciona un dataset v√°lido para continuar con la exploraci√≥n.")

    # Pesta√±a de Entrenamiento
    elif st.session_state.active_tab == 1:
        st.header("Configuraci√≥n del Modelo")

        # Inicializar session state variables
        if 'dataset_option' not in st.session_state:
            st.session_state.dataset_option = st.session_state.selected_dataset
        if 'tree_type' not in st.session_state:
            st.session_state.tree_type = "Clasificaci√≥n"
        if 'is_trained' not in st.session_state:
            st.session_state.is_trained = False

        # Cargar datos para la vista previa si cambia el dataset o si no se ha cargado
        if st.session_state.selected_dataset != st.session_state.dataset_option or not dataset_loaded:
            try:
                X, y, feature_names, class_names, dataset_info, task_type = load_data(
                    st.session_state.selected_dataset)

                st.session_state.dataset_option = st.session_state.selected_dataset
                dataset_loaded = True

                # Mostrar informaci√≥n del dataset
                st.markdown("### Informaci√≥n del Dataset")
                st.markdown(create_info_box(dataset_info),
                            unsafe_allow_html=True)

                # Usar el tipo de tarea detectado por la funci√≥n load_data
                st.markdown("### Tipo de √Årbol de Decisi√≥n")

                # Usar botones en lugar de radio para seleccionar el tipo de √°rbol
                tipo_col1, tipo_col2 = st.columns(2)

                with tipo_col1:
                    is_classification = True
                    if "tree_type" in st.session_state:
                        is_classification = st.session_state.tree_type == "Clasificaci√≥n"

                    if st.button("üè∑Ô∏è Clasificaci√≥n",
                                 key="btn_classification",
                                 type="primary" if is_classification else "secondary",
                                 use_container_width=True,
                                 help="Para predecir categor√≠as o clases"):
                        tree_type = "Clasificaci√≥n"
                        st.session_state.tree_type = tree_type
                        st.rerun()

                with tipo_col2:
                    is_regression = False
                    if "tree_type" in st.session_state:
                        is_regression = st.session_state.tree_type == "Regresi√≥n"

                    if st.button("üìà Regresi√≥n",
                                 key="btn_regression",
                                 type="primary" if is_regression else "secondary",
                                 use_container_width=True,
                                 help="Para predecir valores num√©ricos continuos"):
                        tree_type = "Regresi√≥n"
                        st.session_state.tree_type = tree_type
                        st.rerun()

                # Obtener el valor actual del tipo de √°rbol
                tree_type = st.session_state.get('tree_type', task_type)

                # Si no hay tree_type definido, usar el detectado
                if 'tree_type' not in st.session_state:
                    st.session_state.tree_type = task_type

                # Mostrar advertencia si la selecci√≥n no coincide con el tipo de tarea detectado
                if tree_type != task_type:
                    st.warning(
                        f"Este dataset parece ser m√°s adecuado para {task_type}. La selecci√≥n actual podr√≠a no ofrecer resultados √≥ptimos.")

            except Exception as e:
                st.error(f"Error al cargar el dataset: {str(e)}")
                dataset_loaded = False

        # Par√°metros del modelo
        st.markdown("### Par√°metros del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            criterion = st.selectbox(
                "Criterio de Divisi√≥n:",
                ["gini", "entropy"] if st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" else [
                    "squared_error", "friedman_mse", "absolute_error"],
                index=0,
                help="Medida de la calidad de una divisi√≥n. Gini o Entropy para clasificaci√≥n, MSE para regresi√≥n."
            )

            max_depth = st.slider(
                "Profundidad M√°xima:",
                min_value=1,
                max_value=10,
                value=3,
                help="La profundidad m√°xima del √°rbol. A mayor profundidad, m√°s complejo el modelo."
            )

        with col2:
            min_samples_split = st.slider(
                "Muestras M√≠nimas para Divisi√≥n:",
                min_value=2,
                max_value=10,
                value=2,
                help="N√∫mero m√≠nimo de muestras para dividir un nodo."
            )

            test_size = st.slider(
                "Tama√±o del Conjunto de Prueba:",
                min_value=0.1,
                max_value=0.5,
                value=0.3,
                step=0.05,
                help="Proporci√≥n de datos que se usar√° para evaluar el modelo."
            )

        # Guardar par√°metros en el estado de la sesi√≥n
        st.session_state.criterion = criterion
        st.session_state.max_depth = max_depth
        st.session_state.min_samples_split = min_samples_split
        st.session_state.test_size = test_size

        # Bot√≥n para entrenar el modelo
        train_button = st.button("Entrenar Modelo", type="primary")

        if train_button:
            with st.spinner("Entrenando modelo..."):
                try:
                    # Cargar y preprocesar datos
                    X, y, feature_names, class_names, dataset_info, task_type = load_data(
                        st.session_state.selected_dataset)
                    X_train, X_test, y_train, y_test = preprocess_data(
                        X, y, test_size=test_size)

                    # Entrenar el modelo
                    model_results = train_decision_tree(
                        X_train, y_train,
                        criterion=criterion,
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        tree_type=tree_type
                    )

                    # Extraer el modelo del diccionario de resultados
                    tree_model = model_results["model"]

                    # Guardar en el estado de la sesi√≥n
                    st.session_state.tree_model = tree_model
                    st.session_state.X_train = X_train
                    st.session_state.X_test = X_test
                    st.session_state.y_train = y_train
                    st.session_state.y_test = y_test
                    st.session_state.feature_names = feature_names
                    st.session_state.class_names = class_names
                    st.session_state.dataset_info = dataset_info
                    st.session_state.is_trained = True

                    # Evaluar el modelo
                    if tree_type == "Clasificaci√≥n":
                        # Obtener predicciones del modelo
                        y_pred = tree_model.predict(X_test)
                        st.session_state.test_results = evaluate_classification_model(
                            y_test, y_pred, class_names
                        )
                    else:
                        # Obtener predicciones del modelo
                        y_pred = tree_model.predict(X_test)
                        st.session_state.test_results = evaluate_regression_model(
                            y_test, y_pred
                        )

                    st.success(
                        "¬°Modelo entrenado con √©xito! Ahora puedes explorar las otras pesta√±as.")

                    # Sugerir ir a la pesta√±a de visualizaci√≥n
                    st.info(
                        "üëâ Ve a la pesta√±a 'üå≤ Visualizaci√≥n' para ver el √°rbol generado.")

                except Exception as e:
                    st.error(f"Error al entrenar el modelo: {str(e)}")

    # Pesta√±a de Evaluaci√≥n
    elif st.session_state.active_tab == 2:
        st.header("Evaluaci√≥n del Modelo")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Obtener predicciones del modelo
            y_pred = st.session_state.tree_model.predict(
                st.session_state.X_test)

            # Mostrar evaluaci√≥n detallada del modelo
            show_detailed_evaluation(
                st.session_state.y_test,
                y_pred,
                st.session_state.class_names if st.session_state.get(
                    'tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" else None,
                st.session_state.get('tree_type', 'Clasificaci√≥n')
            )

            # Decisi√≥n boundary si es clasificaci√≥n y tiene 2 caracter√≠sticas
            if st.session_state.get('tree_type', 'Clasificaci√≥n') == "Clasificaci√≥n" and st.session_state.X_train.shape[1] <= 2:
                st.markdown("### Frontera de Decisi√≥n")

                if st.session_state.X_train.shape[1] == 1:
                    # Caso especial: solo una caracter√≠stica - agregar una segunda artificial
                    X_plot = np.column_stack(
                        [st.session_state.X_train, np.zeros_like(st.session_state.X_train)])
                    feature_idx = [0]
                    feature_names_plot = [
                        st.session_state.feature_names[0], "Caracter√≠stica artificial"]
                else:
                    # Dos caracter√≠sticas - dejar seleccionar cu√°les usar
                    st.markdown(
                        "Selecciona las caracter√≠sticas para visualizar la frontera de decisi√≥n:")
                    col1, col2 = st.columns(2)

                    with col1:
                        feature1 = st.selectbox(
                            "Primera caracter√≠stica:",
                            st.session_state.feature_names,
                            index=0
                        )

                    with col2:
                        feature2 = st.selectbox(
                            "Segunda caracter√≠stica:",
                            st.session_state.feature_names,
                            index=min(
                                1, len(st.session_state.feature_names) - 1)
                        )

                    feature_idx = [st.session_state.feature_names.index(feature1),
                                   st.session_state.feature_names.index(feature2)]
                    X_plot = st.session_state.X_train[:, feature_idx]
                    feature_names_plot = [feature1, feature2]

                # Generar y mostrar el plot en tama√±o reducido
                ax = plot_decision_boundary(
                    st.session_state.tree_model,
                    X_plot,
                    st.session_state.y_train,
                    feature_names=feature_names_plot,
                    class_names=st.session_state.class_names
                )

                # Obtener la figura desde los ejes
                fig = ax.figure

                # Mostrar en columnas para reducir el tama√±o al 75%
                col1, col2, col3 = st.columns([1, 3, 1])
                with col2:
                    st.pyplot(fig)                # Enlace para descargar
                st.markdown(
                    get_image_download_link(
                        fig, "frontera_decision", "üì• Descargar visualizaci√≥n de la frontera"),
                    unsafe_allow_html=True
                )

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_boundary = """
import numpy as np
import matplotlib.pyplot as plt
from sklearn.inspection import DecisionBoundaryDisplay

def plot_decision_boundary(model, X, y, feature_names=None, class_names=None):
    \"\"\"
    Visualiza la frontera de decisi√≥n para un modelo con 2 caracter√≠sticas.
    
    Parameters:
    -----------
    model : Modelo de scikit-learn
        Modelo entrenado con m√©todo predict
    X : array-like
        Datos de caracter√≠sticas (solo se usan las primeras 2 columnas)
    y : array-like
        Etiquetas de clase
    feature_names : list, opcional
        Nombres de las caracter√≠sticas
    class_names : list, opcional
        Nombres de las clases
    
    Returns:
    --------
    fig : Figura de matplotlib
    \"\"\"
    # Asegurar que solo usamos 2 caracter√≠sticas
    X_plot = X[:, :2] if X.shape[1] > 2 else X
    
    # Crear figura
    fig, ax = plt.subplots(figsize=(8, 6))
    
    # Crear objeto de visualizaci√≥n de frontera
    disp = DecisionBoundaryDisplay.from_estimator(
        model,
        X_plot,
        alpha=0.5,
        ax=ax,
        response_method="predict"
    )
    
    # Colorear los puntos seg√∫n su clase
    scatter = ax.scatter(
        X_plot[:, 0],
        X_plot[:, 1],
        c=y,
        edgecolor="k",
        s=50
    )
    
    # Configurar etiquetas
    if feature_names and len(feature_names) >= 2:
        ax.set_xlabel(feature_names[0])
        ax.set_ylabel(feature_names[1])
    else:
        ax.set_xlabel("Caracter√≠stica 1")
        ax.set_ylabel("Caracter√≠stica 2")
    
    # Configurar leyenda
    if class_names:
        legend_labels = class_names
    else:
        legend_labels = [f"Clase {i}" for i in range(len(np.unique(y)))]
    
    legend = ax.legend(
        handles=scatter.legend_elements()[0],
        labels=legend_labels,
        title="Clases"
    )
    
    ax.add_artist(legend)
    ax.set_title("Frontera de Decisi√≥n")
    
    return fig

# Para usar:
# fig = plot_decision_boundary(model, X, y, feature_names, class_names)
# plt.show()
"""

                show_code_with_download(
                    code_boundary, "C√≥digo para generar la frontera de decisi√≥n",
                    "frontera_decision.py"
                )

    # Pesta√±a de Visualizaci√≥n
    elif st.session_state.active_tab == 3:
        st.header("Visualizaci√≥n del √Årbol")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Configuraci√≥n de la visualizaci√≥n
            st.markdown("### Tipo de visualizaci√≥n")

            # Usar botones para seleccionar el tipo de visualizaci√≥n
            if "viz_type" not in st.session_state:
                st.session_state.viz_type = "Est√°ndar"

            viz_col1, viz_col2 = st.columns(2)

            with viz_col1:
                if st.button("üìä Est√°ndar",
                             key="viz_standard",
                             type="primary" if st.session_state.viz_type == "Est√°ndar" else "secondary",
                             use_container_width=True):
                    st.session_state.viz_type = "Est√°ndar"
                    st.rerun()

            with viz_col2:
                if st.button("üìù Texto",
                             key="viz_text",
                             type="primary" if st.session_state.viz_type == "Texto" else "secondary",
                             use_container_width=True):
                    st.session_state.viz_type = "Texto"
                    st.rerun()

            viz_type = st.session_state.viz_type

            # Opciones de tama√±o para la visualizaci√≥n
            col1, col2 = st.columns(2)

            with col1:
                fig_width = st.slider("Ancho de figura:", 8, 20, 14)

            with col2:
                fig_height = st.slider("Alto de figura:", 6, 15, 10)

            # Mostrar la visualizaci√≥n seg√∫n el tipo seleccionado
            if viz_type == "Est√°ndar":
                # Visualizaci√≥n est√°ndar de scikit-learn
                fig, ax = plt.subplots(figsize=(fig_width, fig_height))
                from sklearn.tree import plot_tree

                plot_tree(
                    st.session_state.tree_model,
                    feature_names=st.session_state.feature_names,
                    class_names=st.session_state.class_names if st.session_state.tree_type == "Clasificaci√≥n" else None,
                    filled=True,
                    rounded=True,
                    ax=ax,
                    proportion=True,
                    impurity=True
                )

                # Mostrar con tama√±o reducido pero expandible
                col1, col2, col3 = st.columns([1, 4, 1])
                with col2:
                    st.pyplot(fig, use_container_width=True)

                # Enlace para descargar
                st.markdown(
                    get_image_download_link(
                        fig, "arbol_decision", "üì• Descargar visualizaci√≥n del √°rbol"),
                    unsafe_allow_html=True
                )

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_tree = """
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# Suponiendo que ya tienes un modelo entrenado (tree_model)
# y los nombres de las caracter√≠sticas (feature_names) y clases (class_names)

fig, ax = plt.subplots(figsize=(14, 10))

plot_tree(
    tree_model,
    feature_names=feature_names,
    class_names=class_names,  # Solo para clasificaci√≥n
    filled=True,
    rounded=True,
    ax=ax,
    proportion=True,
    impurity=True
)

plt.tight_layout()
plt.show()

# Para guardar a un archivo:
# plt.savefig('arbol_decision.png', dpi=300, bbox_inches='tight')
"""

                show_code_with_download(
                    code_tree, "C√≥digo para visualizar el √°rbol", "visualizar_arbol.py")

            else:  # Visualizaci√≥n de texto
                # Obtener representaci√≥n de texto
                tree_text = get_tree_text(
                    st.session_state.tree_model,
                    st.session_state.feature_names,
                )

                # Mostrar en un √°rea de texto
                st.text(tree_text)

                # Bot√≥n para descargar
                text_bytes = tree_text.encode()
                b64 = base64.b64encode(text_bytes).decode()
                href = f'<a href="data:text/plain;base64,{b64}" download="arbol_texto.txt">üì• Descargar texto del √°rbol</a>'
                st.markdown(href, unsafe_allow_html=True)

                # Mostrar c√≥digo para generar esta visualizaci√≥n
                code_text = """
from sklearn.tree import export_text

def get_tree_text(model, feature_names, show_class_name=True):
    \"\"\"
    Obtiene una representaci√≥n de texto de un √°rbol de decisi√≥n.
    
    Parameters:
    -----------
    model : DecisionTreeClassifier o DecisionTreeRegressor
        Modelo de √°rbol entrenado
    feature_names : list
        Nombres de las caracter√≠sticas
    show_class_name : bool
        Si es True, muestra los nombres de las clases (para clasificaci√≥n)
        
    Returns:
    --------
    str
        Representaci√≥n de texto del √°rbol
    \"\"\"
    return export_text(
        model,
        feature_names=feature_names,
        show_weights=True
    )

# Para usar:
# tree_text = get_tree_text(tree_model, feature_names)
# print(tree_text)

# Para guardar a un archivo:
# with open('arbol_texto.txt', 'w') as f:
#     f.write(tree_text)
"""

                show_code_with_download(
                    code_text, "C√≥digo para visualizaci√≥n de texto", "visualizacion_texto.py")

    # Pesta√±a de Caracter√≠sticas
    elif st.session_state.active_tab == 4:
        st.header("Importancia de Caracter√≠sticas")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Mostrar importancia de caracter√≠sticas
            display_feature_importance(
                st.session_state.tree_model,
                st.session_state.feature_names
            )

    # Pesta√±a de Predicciones
    elif st.session_state.active_tab == 5:
        st.header("Predicciones con Nuevos Datos")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Interfaz para hacer predicciones
            create_prediction_interface(
                st.session_state.tree_model,
                st.session_state.feature_names,
                st.session_state.class_names,
                st.session_state.get('tree_type', 'Clasificaci√≥n'),
                st.session_state.get('X_train', None)  # Pasar datos de entrenamiento para rangos din√°micos
            )

    # Pesta√±a de Exportar Modelo
    elif st.session_state.active_tab == 6:
        st.header("Exportar Modelo")

        if not st.session_state.get('is_trained', False):
            st.warning(
                "Primero debes entrenar un modelo en la pesta√±a 'üèãÔ∏è Entrenamiento'.")
        else:
            # Opciones para exportar el modelo
            display_model_export_options(
                st.session_state.tree_model,
                st.session_state.feature_names,
                st.session_state.class_names,
                st.session_state.get('tree_type', 'Clasificaci√≥n'),
                st.session_state.get('max_depth', 3),
                st.session_state.get('min_samples_split', 2),
                st.session_state.get('criterion', 'gini')
            )


def run_csv_loader_app():
    """Aplicaci√≥n para cargar y analizar datasets CSV personalizados."""
    st.header("üìÅ Cargar Dataset CSV Personalizado")
    st.markdown("""
    Esta herramienta te permite cargar y analizar tus propios datasets en formato CSV.
    Puedes explorar los datos, entrenar modelos de Machine Learning y comparar diferentes algoritmos.
    """)

    # Usar el selector de dataset mejorado
    dataset_result = create_dataset_selector()

    if dataset_result is None:
        st.info("üëÜ Por favor, carga un archivo CSV para continuar con el an√°lisis.")
        return

    # Verificar si se carg√≥ un CSV o se seleccion√≥ un dataset predefinido
    if isinstance(dataset_result, tuple):
        # Se carg√≥ un CSV personalizado
        file_path, target_col, task_type = dataset_result

        try:
            # Cargar el dataset personalizado
            X, y, feature_names, class_names, dataset_info, detected_task_type = load_dataset_from_file(
                file_path, target_col, task_type
            )

            st.success(f"‚úÖ Dataset cargado exitosamente: {dataset_info}")

            # Mostrar tabs para an√°lisis
            tab1, tab2, tab3, tab4 = st.tabs([
                "üìä Exploraci√≥n de Datos",
                "üèãÔ∏è Entrenamiento de Modelo",
                "üìà Evaluaci√≥n",
                "üîç Predicciones"
            ])

            with tab1:
                st.subheader("üìä An√°lisis Exploratorio de Datos")

                # Informaci√≥n general del dataset
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Muestras", len(X))
                with col2:
                    st.metric("Caracter√≠sticas", len(feature_names))
                with col3:
                    st.metric("Tipo de Tarea", detected_task_type)
                with col4:
                    if detected_task_type == "Clasificaci√≥n":
                        st.metric("Clases", len(class_names)
                                  if class_names else "N/A")
                    else:
                        st.metric("Variable Objetivo", target_col)

                # Vista previa de los datos
                st.subheader("Vista Previa de los Datos")
                df_combined = pd.DataFrame(X, columns=feature_names)
                df_combined[target_col] = y
                st.dataframe(df_combined.head(10), use_container_width=True)

                # Estad√≠sticas descriptivas
                st.subheader("Estad√≠sticas Descriptivas")
                col1, col2 = st.columns(2)

                with col1:
                    st.write("**Caracter√≠sticas num√©ricas:**")
                    numeric_features = X.select_dtypes(
                        include=[np.number]).columns
                    if len(numeric_features) > 0:
                        st.dataframe(X[numeric_features].describe(),
                                     use_container_width=True)
                    else:
                        st.info("No hay caracter√≠sticas num√©ricas")

                with col2:
                    st.write("**Variable objetivo:**")
                    if detected_task_type == "Clasificaci√≥n":
                        value_counts = pd.Series(y).value_counts()
                        st.dataframe(value_counts.to_frame(
                            "Frecuencia"), use_container_width=True)
                    else:
                        target_stats = pd.Series(y).describe()
                        st.dataframe(target_stats.to_frame(
                            "Estad√≠stica"), use_container_width=True)

                # Visualizaciones
                if len(numeric_features) > 0:
                    st.subheader("Visualizaciones")

                    # Histogramas de caracter√≠sticas num√©ricas
                    if len(numeric_features) <= 10:  # Evitar sobrecarga con muchas caracter√≠sticas
                        fig, axes = plt.subplots(
                            nrows=(len(numeric_features) + 2) // 3,
                            ncols=3,
                            figsize=(
                                12, 4 * ((len(numeric_features) + 2) // 3))
                        )
                        if len(numeric_features) == 1:
                            axes = [axes]
                        elif (len(numeric_features) + 2) // 3 == 1:
                            axes = [axes]
                        else:
                            axes = axes.flatten()

                        for i, col in enumerate(numeric_features):
                            axes[i].hist(X[col], bins=20,
                                         alpha=0.7, edgecolor='black')
                            axes[i].set_title(f'Distribuci√≥n de {col}')
                            axes[i].set_xlabel(col)
                            axes[i].set_ylabel('Frecuencia')

                        # Ocultar subplots vac√≠os
                        for i in range(len(numeric_features), len(axes)):
                            axes[i].set_visible(False)

                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close()

            with tab2:
                st.subheader("üèãÔ∏è Entrenamiento de Modelo")

                # Divisi√≥n de datos
                test_size = st.slider(
                    "Porcentaje para prueba (%)", 10, 50, 30) / 100

                # Preprocesamiento b√°sico para datos categ√≥ricos
                X_processed = X.copy()

                # Codificar variables categ√≥ricas si existen
                categorical_features = X.select_dtypes(
                    include=['object']).columns
                if len(categorical_features) > 0:
                    st.info(
                        f"Se encontraron {len(categorical_features)} caracter√≠sticas categ√≥ricas que ser√°n codificadas autom√°ticamente.")

                    from sklearn.preprocessing import LabelEncoder
                    for col in categorical_features:
                        le = LabelEncoder()
                        X_processed[col] = le.fit_transform(X[col].astype(str))

                # Dividir los datos
                X_train, X_test, y_train, y_test = train_test_split(
                    X_processed, y, test_size=test_size, random_state=42
                )

                st.success(
                    f"Datos divididos: {len(X_train)} muestras para entrenamiento, {len(X_test)} para prueba")

                # Selecci√≥n de algoritmo
                st.subheader("Selecci√≥n de Algoritmo")

                if detected_task_type == "Clasificaci√≥n":
                    algorithm = st.selectbox(
                        "Algoritmo:",
                        ["√Årbol de Decisi√≥n", "Random Forest", "Regresi√≥n Log√≠stica"]
                    )
                else:
                    algorithm = st.selectbox(
                        "Algoritmo:",
                        ["√Årbol de Decisi√≥n", "Random Forest", "Regresi√≥n Lineal"]
                    )

                # Entrenar modelo
                if st.button("üöÄ Entrenar Modelo", type="primary"):
                    with st.spinner("Entrenando modelo..."):
                        if algorithm == "√Årbol de Decisi√≥n":
                            from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor

                            if detected_task_type == "Clasificaci√≥n":
                                model = DecisionTreeClassifier(
                                    random_state=42, max_depth=5)
                            else:
                                model = DecisionTreeRegressor(
                                    random_state=42, max_depth=5)

                            model.fit(X_train, y_train)
                            y_pred = model.predict(X_test)

                        elif algorithm == "Random Forest":
                            from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor

                            if detected_task_type == "Clasificaci√≥n":
                                model = RandomForestClassifier(
                                    random_state=42, n_estimators=100)
                            else:
                                model = RandomForestRegressor(
                                    random_state=42, n_estimators=100)

                            model.fit(X_train, y_train)
                            y_pred = model.predict(X_test)

                        else:  # Regresi√≥n Log√≠stica o Lineal
                            if detected_task_type == "Clasificaci√≥n":
                                from sklearn.linear_model import LogisticRegression
                                model = LogisticRegression(
                                    random_state=42, max_iter=1000)
                            else:
                                from sklearn.linear_model import LinearRegression
                                model = LinearRegression()

                            model.fit(X_train, y_train)
                            y_pred = model.predict(X_test)

                        # Guardar en session state
                        st.session_state.csv_model = model
                        st.session_state.csv_X_test = X_test
                        st.session_state.csv_y_test = y_test
                        st.session_state.csv_y_pred = y_pred
                        st.session_state.csv_feature_names = feature_names
                        st.session_state.csv_task_type = detected_task_type
                        st.session_state.csv_algorithm = algorithm

                        st.success(
                            f"‚úÖ Modelo {algorithm} entrenado exitosamente!")

            with tab3:
                st.subheader("üìà Evaluaci√≥n del Modelo")

                if 'csv_model' not in st.session_state:
                    st.warning(
                        "Primero entrena un modelo en la pesta√±a 'Entrenamiento'.")
                else:
                    model = st.session_state.csv_model
                    X_test = st.session_state.csv_X_test
                    y_test = st.session_state.csv_y_test
                    y_pred = st.session_state.csv_y_pred
                    task_type = st.session_state.csv_task_type
                    algorithm = st.session_state.csv_algorithm

                    st.info(f"Evaluando modelo: {algorithm} para {task_type}")

                    if task_type == "Clasificaci√≥n":
                        from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

                        # M√©tricas principales
                        accuracy = accuracy_score(y_test, y_pred)
                        st.metric("Precisi√≥n", f"{accuracy:.3f}")

                        # Matriz de confusi√≥n
                        fig, ax = plt.subplots(figsize=(8, 6))
                        cm = confusion_matrix(y_test, y_pred)
                        sns.heatmap(cm, annot=True, fmt='d',
                                    cmap='Blues', ax=ax)
                        ax.set_title('Matriz de Confusi√≥n')
                        ax.set_xlabel('Predicci√≥n')
                        ax.set_ylabel('Valor Real')
                        st.pyplot(fig)
                        plt.close()

                        # Reporte de clasificaci√≥n
                        st.subheader("Reporte Detallado")
                        report = classification_report(
                            y_test, y_pred, output_dict=True)
                        report_df = pd.DataFrame(report).transpose()
                        st.dataframe(report_df, use_container_width=True)

                    else:  # Regresi√≥n
                        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

                        # M√©tricas principales
                        mse = mean_squared_error(y_test, y_pred)
                        rmse = np.sqrt(mse)
                        mae = mean_absolute_error(y_test, y_pred)
                        r2 = r2_score(y_test, y_pred)

                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("R¬≤", f"{r2:.3f}")
                        with col2:
                            st.metric("RMSE", f"{rmse:.3f}")
                        with col3:
                            st.metric("MAE", f"{mae:.3f}")
                        with col4:
                            st.metric("MSE", f"{mse:.3f}")

                        # Gr√°fico de predicciones vs valores reales
                        fig, ax = plt.subplots(figsize=(8, 6))
                        ax.scatter(y_test, y_pred, alpha=0.6)
                        ax.plot([y_test.min(), y_test.max()], [
                                y_test.min(), y_test.max()], 'r--', lw=2)
                        ax.set_xlabel('Valores Reales')
                        ax.set_ylabel('Predicciones')
                        ax.set_title('Predicciones vs Valores Reales')
                        st.pyplot(fig)
                        plt.close()

            with tab4:
                st.subheader("üîç Hacer Predicciones")

                if 'csv_model' not in st.session_state:
                    st.warning(
                        "Primero entrena un modelo en la pesta√±a 'Entrenamiento'.")
                else:
                    st.info("Introduce los valores para hacer una predicci√≥n:")

                    # Crear formulario para predicci√≥n
                    prediction_values = {}

                    # Obtener solo caracter√≠sticas num√©ricas para simplificar
                    numeric_features = X.select_dtypes(
                        include=[np.number]).columns

                    # Limitar a 10 caracter√≠sticas
                    for feature in numeric_features[:10]:
                        min_val = float(X[feature].min())
                        max_val = float(X[feature].max())
                        mean_val = float(X[feature].mean())

                        prediction_values[feature] = st.number_input(
                            f"{feature}:",
                            min_value=min_val,
                            max_value=max_val,
                            value=mean_val,
                            step=(max_val - min_val) / 100
                        )

                    if st.button("üéØ Realizar Predicci√≥n"):
                        # Preparar datos para predicci√≥n
                        pred_data = []
                        for feature in feature_names:
                            if feature in prediction_values:
                                pred_data.append(prediction_values[feature])
                            else:
                                # Para caracter√≠sticas categ√≥ricas, usar valor m√°s com√∫n
                                if feature in X.columns:
                                    pred_data.append(X[feature].mode()[0] if len(
                                        X[feature].mode()) > 0 else 0)
                                else:
                                    pred_data.append(0)

                        # Hacer predicci√≥n
                        model = st.session_state.csv_model
                        pred_array = np.array([pred_data])
                        prediction = model.predict(pred_array)[0]

                        # Mostrar resultado
                        task_type = st.session_state.csv_task_type
                        if task_type == "Clasificaci√≥n":
                            if class_names and prediction < len(class_names):
                                result = class_names[int(prediction)]
                            else:
                                result = f"Clase {int(prediction)}"
                            st.success(f"üéØ Predicci√≥n: **{result}**")
                        else:
                            st.success(f"üéØ Predicci√≥n: **{prediction:.3f}**")

                        # Mostrar confianza si es posible
                        if hasattr(model, 'predict_proba') and task_type == "Clasificaci√≥n":
                            probabilities = model.predict_proba(pred_array)[0]
                            st.subheader("Confianza por clase:")
                            for i, prob in enumerate(probabilities):
                                class_name = class_names[i] if class_names and i < len(
                                    class_names) else f"Clase {i}"
                                st.write(
                                    f"‚Ä¢ {class_name}: {prob:.3f} ({prob*100:.1f}%)")

        except Exception as e:
            st.error(f"‚ùå Error al procesar el dataset: {str(e)}")

    else:
        # Se seleccion√≥ un dataset predefinido
        st.info(f"Dataset seleccionado: {dataset_result}")
        st.markdown("### üéØ An√°lisis con Dataset Predefinido")
        st.markdown("""
        Para analizar datasets predefinidos como Iris, Titanic, etc., 
        ve a la secci√≥n **üå≤ √Årboles de Decisi√≥n** donde encontrar√°s todas las herramientas de an√°lisis.
        """)

        if st.button("üöÄ Ir a √Årboles de Decisi√≥n"):
            st.session_state.navigation = "üå≤ √Årboles de Decisi√≥n"
            st.rerun()


if __name__ == "__main__":
    main()
