import base64
import pickle
import io
import streamlit as st

from sklearn.tree import export_text

from utils import show_code_with_download, export_model_pickle
from algorithms.code_examples import (
    generate_tree_model_export_code,
    generate_regression_code,
    generate_neural_network_code,
    LOAD_NN,
)
from viz.nn import calculate_network_parameters
from ui import create_button_panel
import traceback
import tempfile
import zipfile
import os


def _zip_dir(src_dir: str) -> bytes:
    """Empaqueta recursivamente un directorio en un ZIP y devuelve los bytes."""
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, 'w', zipfile.ZIP_DEFLATED) as zf:
        for root, _, files in os.walk(src_dir):
            for f in files:
                fp = os.path.join(root, f)
                arc = os.path.relpath(fp, src_dir)
                zf.write(fp, arc)
    buf.seek(0)
    return buf.getvalue()


def export_saved_model_as_zip(model, safe_mode: bool):
    """
    Exporta un modelo Keras como SavedModel comprimido en ZIP.
    safe_mode=True intenta desactivar traces (save_traces=False) para evitar problemas
    con capas Lambda o funciones no serializables.
    """
    # Asegurar que el modelo est√© construido
    try:
        if not getattr(model, 'built', False) and getattr(model, 'input_shape', None):
            import numpy as np
            dummy_shape = [
                1] + [d if d is not None else 1 for d in model.input_shape[1:]]
            _ = model.predict(np.zeros(dummy_shape), verbose=0)
    except Exception:
        pass

    with tempfile.TemporaryDirectory() as tmp:
        model_dir = os.path.join(tmp, 'saved_model')
        import inspect
        # Determinar si el m√©todo save admite save_traces
        try:
            save_func = model.save
            sig = inspect.signature(save_func)
            has_save_traces = 'save_traces' in sig.parameters
        except Exception:
            has_save_traces = False
        try:
            if has_save_traces:
                model.save(model_dir, include_optimizer=True,
                           save_traces=not safe_mode)
            else:
                model.save(model_dir, include_optimizer=True)
        except (TypeError, ValueError):
            # Reintentar usando API moderna si model.save requiere extensi√≥n (Keras 3)
            try:
                import tensorflow as tf
                if hasattr(model, 'export'):
                    model.export(model_dir)
                else:
                    tf.saved_model.save(model, model_dir)
            except Exception as e2:
                raise RuntimeError(
                    f"Fallo exportando SavedModel (alternativas). Error: {e2!r}") from e2
        return _zip_dir(model_dir)


def export_tree_as_python_code(model, feature_names):
    """Exporta el √°rbol de decisi√≥n como una funci√≥n Python con if-else."""
    def recurse(node, depth=0):
        indent = "    " * depth
        # Nodo hoja
        if model.tree_.children_left[node] == model.tree_.children_right[node]:
            value = model.tree_.value[node][0]
            if hasattr(model, 'classes_'):
                class_idx = int(value.argmax())
                class_name = model.classes_[class_idx] if hasattr(
                    model, 'classes_') else f"Clase_{class_idx}"
                probability = value[class_idx] / value.sum()
                return f'{indent}return "{class_name}"  # Probabilidad: {probability:.3f}'
            else:
                return f'{indent}return {value[0]:.6f}'
        # Nodo interno
        feature_idx = model.tree_.feature[node]
        threshold = model.tree_.threshold[node]
        feature_name = feature_names[
            feature_idx] if feature_names else f"feature_{feature_idx}"
        left_child = model.tree_.children_left[node]
        right_child = model.tree_.children_right[node]
        code = f'{indent}if {feature_name} <= {threshold:.6f}:\n'
        code += recurse(left_child, depth + 1) + '\n'
        code += f'{indent}else:\n'
        code += recurse(right_child, depth + 1)
        return code

    task_type = "clasificaci√≥n" if hasattr(model, 'classes_') else "regresi√≥n"
    function_name = "predecir_clase" if hasattr(
        model, 'classes_') else "predecir_valor"
    params_doc = "\n".join(
        [f"\t{name}: float - {name}" for name in feature_names])
    code = f'''def {function_name}({", ".join(feature_names)}):
    """
    Funci√≥n generada autom√°ticamente que implementa el √°rbol de decisi√≥n entrenado.

    Parameters:
    {params_doc}

    Returns:
    {'    str - La clase predicha' if hasattr(model, 'classes_') else '    float - El valor predicho'}

    √Årbol entrenado para {task_type} con {len(feature_names)} caracter√≠sticas.
    Profundidad m√°xima: {model.tree_.max_depth}
    N√∫mero de nodos: {model.tree_.node_count}
    """
{recurse(0)}

# Ejemplo de uso:
# resultado = {function_name}({", ".join([f"{name}=valor_{i+1}" for i, name in enumerate(feature_names)])})
# print(f"Predicci√≥n: {{resultado}}")
'''
    return code

    # Nodo interno
    feature_idx = model.tree_.feature[node]
    threshold = model.tree_.threshold[node]
    feature_name = feature_names[
        feature_idx] if feature_names else f"feature_{feature_idx}"

    left_child = model.tree_.children_left[node]
    right_child = model.tree_.children_right[node]

    code = f'{indent}if {feature_name} <= {threshold:.6f}:\n'
    code += recurse(left_child, depth + 1) + '\n'
    code += f'{indent}else:\n'
    code += recurse(right_child, depth + 1)

    return code

    # Generar el c√≥digo completo
    task_type = "clasificaci√≥n" if hasattr(model, 'classes_') else "regresi√≥n"
    function_name = "predecir_clase" if hasattr(
        model, 'classes_') else "predecir_valor"
    params_doc = "\n".join(
        [f"\t{name}: float - {name}" for name in feature_names])

    code = f'''def {function_name}({", ".join(feature_names)}):
    """
    Funci√≥n generada autom√°ticamente que implementa el √°rbol de decisi√≥n entrenado.

    Parameters:
    {params_doc}

    Returns:
    {'    str - La clase predicha' if hasattr(
        model, 'classes_') else '    float - El valor predicho'}

    √Årbol entrenado para {task_type} con {len(feature_names)} caracter√≠sticas.
    Profundidad m√°xima: {model.tree_.max_depth}
    N√∫mero de nodos: {model.tree_.node_count}
    """
{recurse(0)}

# Ejemplo de uso:
# resultado = {function_name}({", ".join([f"{name}=valor_{i+1}" for i, name in enumerate(feature_names)])})
# print(f"Predicci√≥n: {{resultado}}")
'''

    return code


def display_tree_export_options(model, feature_names, class_names, task_type, max_depth, min_samples_split, criterion):
    """
    Muestra opciones para exportar el modelo usando solo librer√≠as de terceros.
    """

    # Informaci√≥n del modelo antes de las opciones
    model_info = {
        'task_type': task_type,
        'max_depth': max_depth,
        'min_samples_split': min_samples_split,
        'criterion': criterion,
        'n_features': len(feature_names),
        'n_nodes': model.tree_.node_count,
        'n_leaves': model.tree_.n_leaves
    }

    # Opciones de exportaci√≥n
    st.markdown("#### Formatos de Exportaci√≥n")

    col1, col2, col3 = st.columns(3)

    with col1:
        # Exportar como pickle
        if st.button("üì¶ Exportar como Pickle", use_container_width=True):
            # Crear objeto para serializar
            model_data = {
                'model': model,
                'feature_names': feature_names,
                'class_names': class_names,
                'task_type': task_type,
                'model_info': model_info
            }

            # Serializar
            buffer = io.BytesIO()
            pickle.dump(model_data, buffer)
            buffer.seek(0)

            st.download_button(
                label="Descargar Modelo (.pkl)",
                data=buffer.getvalue(),
                file_name=f"decision_tree_model.pkl",
                mime="application/octet-stream"
            )

    with col2:
        # Exportar reglas como texto
        if st.button("üìù Exportar Reglas como Texto", use_container_width=True):
            tree_rules = export_text(
                model,
                feature_names=feature_names
            )

            st.download_button(
                label="Descargar Reglas (.txt)",
                data=tree_rules,
                file_name="decision_tree_rules.txt",
                mime="text/plain"
            )

    python_tree_code = export_tree_as_python_code(model, feature_names)

    with col3:
        # Nueva opci√≥n: Exportar como c√≥digo Python con if-else
        if st.button("üêç Exportar como C√≥digo Python", use_container_width=True):
            st.download_button(
                label="Descargar C√≥digo Python (.py)",
                data=python_tree_code,
                file_name="arbol_decision.py",
                mime="text/plain"
            )

    # Vista previa del c√≥digo Python
    st.markdown("#### üëÄ Vista Previa del C√≥digo Python")
    with st.expander("Ver c√≥digo Python del √°rbol", expanded=False):
        st.code(python_tree_code, language='python')

        # Informaci√≥n adicional sobre el c√≥digo generado
        st.info(f"""
        **Informaci√≥n del c√≥digo generado:**
        - üå≥ **Nodos totales:** {model.tree_.node_count}
        - üçÉ **Nodos hoja:** {model.tree_.n_leaves}
        - üìè **Profundidad m√°xima:** {model.tree_.max_depth}
        - üìä **Caracter√≠sticas:** {len(feature_names)} ({', '.join(feature_names[:3])}{'...' if len(feature_names) > 3 else ''})
        - üéØ **Tipo de tarea:** {task_type}

        Este c√≥digo es completamente **autocontenido** y no requiere scikit-learn para ejecutarse.
        """)

    # C√≥digo Python para usar el modelo
    python_code = generate_tree_model_export_code(feature_names)

    show_code_with_download(
        python_code, "C√≥digo para Usar el Modelo", "usar_modelo.py")


def display_model_export_options(model):
    col1, col2 = st.columns(2)
    with col2:
        if st.button("üì• Descargar Modelo (Pickle)", key="download_pickle_lr"):
            pickle_data = export_model_pickle(model)
            st.download_button(
                label="Descargar modelo.pkl",
                data=pickle_data,
                file_name="linear_regression_model.pkl",
                mime="application/octet-stream"
            )

    with col1:
        if st.button("üìÑ Generar C√≥digo", key="generate_code_lr"):

            code = generate_regression_code()

            st.code(code, language="python")

            # Download button for the code
            st.download_button(
                label="üì• Descargar c√≥digo",
                data=code,
                file_name=f"regression_code.py",
                mime="text/plain"
            )


def show_neural_network_export():
    """Permite exportar el modelo entrenado."""
    if 'nn_model' not in st.session_state or st.session_state.nn_model is None:
        st.warning(
            "‚ö†Ô∏è Primero debes entrenar un modelo en la pesta√±a 'Entrenamiento'")
        return

    try:
        import pickle
        import json
        from datetime import datetime

        model = st.session_state.nn_model
        scaler = st.session_state.nn_scaler
        label_encoder = st.session_state.nn_label_encoder
        config = st.session_state.nn_config

        # Informaci√≥n del modelo
        st.subheader("‚ÑπÔ∏è Informaci√≥n del Modelo")

        col1, col2 = st.columns(2)

        with col1:
            st.info(f"""
            **Arquitectura:**
            - Tipo: {config['task_type']}
            - Capas: {len(config['architecture'])}
            - Neuronas: {config['architecture']}
            - Activaci√≥n: {config['activation']}
            - Optimizador: {config['optimizer']}
            """)

        with col2:
            total_params = calculate_network_parameters(config['architecture'])
            st.info(f"""
            **Par√°metros:**
            - Total: {total_params:,}
            - Dropout: {config['dropout_rate']}
            - Batch size: {config['batch_size']}
            - Fecha entrenamiento: {datetime.now().strftime('%Y-%m-%d %H:%M')}
            """)

        # Opciones de exportaci√≥n
        st.subheader("üìÅ Opciones de Exportaci√≥n")

        # Usar botones para seleccionar el tipo de visualizaci√≥n
        viz_options = [
            ("ü§ñ Modelo TensorFlow", "Tensorflow", "viz_tf"),
            ("üìä Modelo Completo", "Completo", "viz_complete"),
            ("üìù C√≥digo Python", "Python", "viz_python"),
            ("üìã Metadatos", "Metadatos", "viz_metadata")
        ]

        viz_type = create_button_panel(viz_options)

        if viz_type == "Tensorflow":
            st.markdown("**Exportar solo el modelo de TensorFlow:**")

            format_option = st.radio(
                "Formato:",
                ["SavedModel (.pb)", "HDF5 (.h5)",
                 "TensorFlow Lite (.tflite)"],
                key="nn_export_format"
            )
            safe_mode = st.checkbox(
                "Modo seguro (desactivar traces)",
                value=True,
                help="√ötil si hay capas Lambda / funciones personalizadas que impiden la serializaci√≥n"
            )

            if st.button("üíæ Exportar Modelo TensorFlow", type="primary"):
                try:
                    if format_option == "SavedModel (.pb)":
                        zip_bytes = export_saved_model_as_zip(model, safe_mode)
                        st.download_button(
                            label="üì• Descargar SavedModel (ZIP)",
                            data=zip_bytes,
                            file_name="neural_network_savedmodel.zip",
                            mime="application/zip"
                        )
                        st.success("‚úÖ SavedModel generado")
                    elif format_option == "HDF5 (.h5)":
                        with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as tmp_file:
                            import inspect
                            try:
                                sig = inspect.signature(model.save)
                                has_save_traces = 'save_traces' in sig.parameters
                            except Exception:
                                has_save_traces = False
                            try:
                                if has_save_traces:
                                    model.save(
                                        tmp_file.name, include_optimizer=True, save_traces=not safe_mode)
                                else:
                                    model.save(tmp_file.name,
                                               include_optimizer=True)
                            except (TypeError, ValueError):
                                model.save(tmp_file.name,
                                           include_optimizer=True)
                            except Exception:
                                if not safe_mode and has_save_traces:
                                    try:
                                        model.save(
                                            tmp_file.name, include_optimizer=True, save_traces=False)
                                    except Exception:
                                        raise
                                else:
                                    raise
                            with open(tmp_file.name, 'rb') as f:
                                model_data = f.read()
                        st.download_button(
                            label="üì• Descargar Modelo HDF5",
                            data=model_data,
                            file_name="neural_network_model.h5",
                            mime="application/octet-stream"
                        )
                        st.success("‚úÖ HDF5 generado")
                    elif format_option == "TensorFlow Lite (.tflite)":
                        import tensorflow as tf
                        converter = tf.lite.TFLiteConverter.from_keras_model(
                            model)
                        tflite_model = converter.convert()
                        st.download_button(
                            label="üì• Descargar Modelo TFLite",
                            data=tflite_model,
                            file_name="neural_network_model.tflite",
                            mime="application/octet-stream"
                        )
                        st.success("‚úÖ TFLite generado")
                        st.info(
                            "üí° TensorFlow Lite es ideal para dispositivos m√≥viles y embebidos")
                except Exception as e:
                    st.error(f"Error exportando modelo: {e}")
                    with st.expander("Detalles del error"):
                        st.code("".join(traceback.format_exc()),
                                language="text")
                        layer_info = [f"{idx}: {layer.__class__.__name__} (name={layer.name})" for idx, layer in enumerate(
                            getattr(model, 'layers', []))]
                        st.code("\n".join(layer_info), language="text")

        elif viz_type == "Completo":
            st.markdown("**Exportar modelo completo con preprocesadores:**")
            st.info("Incluye el modelo, scaler, label encoder y configuraci√≥n")

            if st.button("üíæ Exportar Modelo Completo", type="primary"):
                try:
                    # Crear diccionario con todos los componentes
                    complete_model = {
                        'model': model,
                        'scaler': scaler,
                        'label_encoder': label_encoder,
                        'config': config,
                        'feature_names': st.session_state.get('nn_feature_names', []),
                        'export_date': datetime.now().isoformat(),
                        'version': '1.0'
                    }

                    # Serializar con pickle
                    model_data = pickle.dumps(complete_model)

                    st.download_button(
                        label="üì• Descargar Modelo Completo",
                        data=model_data,
                        file_name="neural_network_complete.pkl",
                        mime="application/octet-stream"
                    )

                    st.success("‚úÖ Modelo completo exportado")
                    st.info(
                        "üí° Este archivo contiene todo lo necesario para hacer predicciones")

                except Exception as e:
                    st.error(f"Error exportando modelo completo: {str(e)}")

            # Mostrar c√≥digo de ejemplo para cargar
            st.markdown("**C√≥digo para cargar el modelo:**")

            load_code = LOAD_NN

            st.code(load_code, language='python')

        elif viz_type == "Python":
            st.markdown("**Generar c√≥digo Python independiente:**")

            if st.button("üìù Generar C√≥digo", type="primary"):
                try:
                    # Obtener pesos del modelo
                    weights_data = []
                    for layer in model.layers:
                        if hasattr(layer, 'get_weights') and layer.get_weights():
                            weights_data.append(layer.get_weights())

                    # Generar c√≥digo
                    code = generate_neural_network_code(config, label_encoder)

                    st.code(code, language='python')

                    # Bot√≥n para descargar el c√≥digo
                    st.download_button(
                        label="üì• Descargar C√≥digo",
                        data=code,
                        file_name="neural_network_predictor.py",
                        mime="text/plain"
                    )

                    st.warning(
                        "‚ö†Ô∏è El c√≥digo generado es una plantilla. Debes implementar los pesos espec√≠ficos del modelo entrenado.")

                except Exception as e:
                    st.error(f"Error generando c√≥digo: {str(e)}")

        elif viz_type == "Metadatos":
            st.markdown("**Exportar metadatos del modelo:**")

            # Preparar metadatos
            if 'nn_history' in st.session_state:
                history = st.session_state.nn_history
                final_metrics = {
                    'final_loss': float(history.history['loss'][-1]),
                    'final_val_loss': float(history.history.get('val_loss', [0])[-1]) if 'val_loss' in history.history else None,
                    'epochs_trained': len(history.history['loss'])
                }

                if config['task_type'] == 'Clasificaci√≥n' and 'accuracy' in history.history:
                    final_metrics['final_accuracy'] = float(
                        history.history['accuracy'][-1])
                    if 'val_accuracy' in history.history:
                        final_metrics['final_val_accuracy'] = float(
                            history.history['val_accuracy'][-1])
            else:
                final_metrics = {}

            metadata = {
                'model_info': {
                    'type': 'Neural Network',
                    'task_type': config['task_type'],
                    'architecture': config['architecture'],
                    'total_parameters': calculate_network_parameters(config['architecture']),
                    'activation_function': config['activation'],
                    'output_activation': config['output_activation'],
                    'optimizer': config['optimizer'],
                    'dropout_rate': config['dropout_rate'],
                    'batch_size': config['batch_size']
                },
                'training_info': final_metrics,
                'data_info': {
                    'feature_names': st.session_state.get('nn_feature_names', []),
                    'target_column': st.session_state.get('nn_target_col', ''),
                    'num_features': config['input_size'],
                    'num_classes': config['output_size'] if config['task_type'] == 'Clasificaci√≥n' else 1
                },
                'export_info': {
                    'export_date': datetime.now().isoformat(),
                    'version': '1.0',
                    'framework': 'TensorFlow/Keras'
                }
            }

            # Mostrar metadatos
            st.json(metadata)

            # Bot√≥n para descargar metadatos
            metadata_json = json.dumps(metadata, indent=2)

            st.download_button(
                label="üì• Descargar Metadatos",
                data=metadata_json,
                file_name="neural_network_metadata.json",
                mime="application/json"
            )

        # Informaci√≥n adicional
        st.subheader("üí° Informaci√≥n Adicional")

        st.info("""
        **Recomendaciones para el uso del modelo:**

        1. **Modelo TensorFlow**: Ideal para integrar en aplicaciones que ya usan TensorFlow
        2. **Modelo Completo**: Incluye preprocesadores, perfecto para producci√≥n
        3. **C√≥digo Python**: Para entender la implementaci√≥n o crear versiones optimizadas
        4. **Metadatos**: Para documentaci√≥n y seguimiento del modelo

        **Consideraciones de versi√≥n:**
        - TensorFlow versi√≥n utilizada en entrenamiento
        - Compatibilidad con versiones futuras
        - Dependencias del entorno de producci√≥n
        """)

    except Exception as e:
        st.error(f"Error en la exportaci√≥n: {str(e)}")
        st.info("Aseg√∫rate de que el modelo est√© entrenado correctamente.")
